{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "republican-belief",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from typing import *\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "pd.set_option('max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "waiting-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field, asdict\n",
    "import yaml\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    # General\n",
    "    outdir: str = \"results\"\n",
    "    device: str = \"cuda\"\n",
    "\n",
    "    # Data config\n",
    "    imgdir_name: str = \"../../data/ChestXRay14\"\n",
    "    seed: int = 111\n",
    "    n_splits: int = 5\n",
    "    label_smoothing: float = 0.0\n",
    "    # Model config\n",
    "    model_name: str = \"resnet18\"\n",
    "    model_mode: str = \"normal\"  # normal, cnn_fixed supported\n",
    "    # Training config\n",
    "    epoch: int = 20\n",
    "    lr: float = 1e-3\n",
    "    batchsize: int = 8\n",
    "    valid_batchsize: int = 16\n",
    "    num_workers: int = 4\n",
    "    snapshot_freq: int = 5\n",
    "    ema_decay: float = 0.999  # negative value is to inactivate ema.\n",
    "    scheduler_type: str = \"\"\n",
    "    scheduler_kwargs: Dict[str, Any] = field(default_factory=lambda: {})\n",
    "    scheduler_trigger: List[Union[int, str]] = field(default_factory=lambda: [1, \"iteration\"])\n",
    "    aug_kwargs: Dict[str, Dict[str, Any]] = field(default_factory=lambda: {})\n",
    "    mixup_prob: float = 0.\n",
    "\n",
    "    def update(self, param_dict: Dict) -> \"Config\":\n",
    "        # Overwrite by `param_dict`\n",
    "        for key, value in param_dict.items():\n",
    "            if not hasattr(self, key):\n",
    "                raise ValueError(f\"[ERROR] Unexpected key for flag = {key}\")\n",
    "            setattr(self, key, value)\n",
    "        return self\n",
    "    \n",
    "    def to_yaml(self, filepath: str, width: int = 120):\n",
    "        with open(filepath, 'w') as f:\n",
    "            yaml.dump(asdict(self), f, width=width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "noble-picking",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1+cu101 True\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "import torch\n",
    "assert torch.__version__.startswith(\"1.7\")\n",
    "from detectron2.structures import BoxMode\n",
    "\n",
    "\n",
    "def get_vinbigdata_dicts(\n",
    "    imgdir: Path,\n",
    "    train_df: pd.DataFrame,\n",
    "    train_data_type: str = \"original\",\n",
    "    use_cache: bool = True,\n",
    "    debug: bool = True,\n",
    "    target_indices: Optional[np.ndarray] = None,\n",
    "):\n",
    "    debug_str = f\"_debug{int(debug)}\"\n",
    "    train_data_type_str = f\"_{train_data_type}\"\n",
    "    cache_path = Path(\".\") / f\"dataset_dicts_cache{train_data_type_str}{debug_str}.pkl\"\n",
    "    if not use_cache or not cache_path.exists():\n",
    "        print(\"Creating data...\")\n",
    "        train_meta = pd.read_csv(imgdir / \"train_meta.csv\")\n",
    "        if debug:\n",
    "            train_meta = train_meta.iloc[:500]  # For debug....\n",
    "\n",
    "        # Load 1 image to get image size.\n",
    "        image_id = train_meta.loc[0, \"image_id\"]\n",
    "        image_path = str(imgdir / \"train\" / f\"{image_id}.png\")\n",
    "        image = cv2.imread(image_path)\n",
    "        resized_height, resized_width, ch = image.shape\n",
    "        print(f\"image shape: {image.shape}\")\n",
    "\n",
    "        dataset_dicts = []\n",
    "        for index, train_meta_row in tqdm(train_meta.iterrows(), total=len(train_meta)):\n",
    "            record = {}\n",
    "\n",
    "            image_id, height, width = train_meta_row.values\n",
    "            filename = str(imgdir / \"train\" / f\"{image_id}.png\")\n",
    "            record[\"file_name\"] = filename\n",
    "            record[\"image_id\"] = image_id\n",
    "            record[\"height\"] = resized_height\n",
    "            record[\"width\"] = resized_width\n",
    "            objs = []\n",
    "            for index2, row in train_df.query(\"image_id == @image_id\").iterrows():\n",
    "                # print(row)\n",
    "                # print(row[\"class_name\"])\n",
    "                # class_name = row[\"class_name\"]\n",
    "                class_id = row[\"class_id\"]\n",
    "                if class_id == 14:\n",
    "                    # It is \"No finding\"\n",
    "                    # This annotator does not find anything, skip.\n",
    "                    pass\n",
    "                else:\n",
    "                    # bbox_original = [int(row[\"x_min\"]), int(row[\"y_min\"]), int(row[\"x_max\"]), int(row[\"y_max\"])]\n",
    "                    h_ratio = resized_height / height\n",
    "                    w_ratio = resized_width / width\n",
    "                    bbox_resized = [\n",
    "                        int(row[\"x_min\"]) * w_ratio,\n",
    "                        int(row[\"y_min\"]) * h_ratio,\n",
    "                        int(row[\"x_max\"]) * w_ratio,\n",
    "                        int(row[\"y_max\"]) * h_ratio,\n",
    "                    ]\n",
    "                    obj = {\n",
    "                        \"bbox\": bbox_resized,\n",
    "                        \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                        \"category_id\": class_id,\n",
    "                    }\n",
    "                    objs.append(obj)\n",
    "            record[\"annotations\"] = objs\n",
    "            dataset_dicts.append(record)\n",
    "        with open(cache_path, mode=\"wb\") as f:\n",
    "            pickle.dump(dataset_dicts, f)\n",
    "\n",
    "    print(f\"Load from cache {cache_path}\")\n",
    "    with open(cache_path, mode=\"rb\") as f:\n",
    "        dataset_dicts = pickle.load(f)\n",
    "    if target_indices is not None:\n",
    "        dataset_dicts = [dataset_dicts[i] for i in target_indices]\n",
    "    return dataset_dicts\n",
    "\n",
    "\n",
    "def get_vinbigdata_dicts_test(\n",
    "    imgdir: Path, test_meta: pd.DataFrame, use_cache: bool = True, debug: bool = True,\n",
    "):\n",
    "    debug_str = f\"_debug{int(debug)}\"\n",
    "    cache_path = Path(\".\") / f\"dataset_dicts_cache_test{debug_str}.pkl\"\n",
    "    if not use_cache or not cache_path.exists():\n",
    "        print(\"Creating data...\")\n",
    "        # test_meta = pd.read_csv(imgdir / \"test_meta.csv\")\n",
    "        if debug:\n",
    "            test_meta = test_meta.iloc[:500]  # For debug....\n",
    "\n",
    "        # Load 1 image to get image size.\n",
    "        image_id = test_meta.loc[0, \"image_id\"]\n",
    "        image_path = str(imgdir / \"test\" / f\"{image_id}.png\")\n",
    "        image = cv2.imread(image_path)\n",
    "        resized_height, resized_width, ch = image.shape\n",
    "        print(f\"image shape: {image.shape}\")\n",
    "\n",
    "        dataset_dicts = []\n",
    "        for index, test_meta_row in tqdm(test_meta.iterrows(), total=len(test_meta)):\n",
    "            record = {}\n",
    "\n",
    "            image_id, height, width = test_meta_row.values\n",
    "            filename = str(imgdir / \"test\" / f\"{image_id}.png\")\n",
    "            record[\"file_name\"] = filename\n",
    "            # record[\"image_id\"] = index\n",
    "            record[\"image_id\"] = image_id\n",
    "            record[\"height\"] = resized_height\n",
    "            record[\"width\"] = resized_width\n",
    "            # objs = []\n",
    "            # record[\"annotations\"] = objs\n",
    "            dataset_dicts.append(record)\n",
    "        with open(cache_path, mode=\"wb\") as f:\n",
    "            pickle.dump(dataset_dicts, f)\n",
    "\n",
    "    print(f\"Load from cache {cache_path}\")\n",
    "    with open(cache_path, mode=\"rb\") as f:\n",
    "        dataset_dicts = pickle.load(f)\n",
    "    return dataset_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "metropolitan-watts",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "\n",
    "class Transform:\n",
    "    def __init__(self, aug_kwargs: Dict):\n",
    "        self.transform = A.Compose([getattr(A, name)(**kwargs) for name, kwargs in aug_kwargs.items()])\n",
    "\n",
    "    def __call__(self, image):\n",
    "        image = self.transform(image=image)[\"image\"]\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "raising-metro",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fail to import apex_C: apex was not installed or installed without --cpp_ext.\n",
      "fail to import amp_C: apex was not installed or installed without --cpp_ext.\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "\n",
    "\n",
    "class CNNFixedPredictor(nn.Module):\n",
    "    def __init__(self, cnn: nn.Module, num_classes: int = 2):\n",
    "        super(CNNFixedPredictor, self).__init__()\n",
    "        self.cnn = cnn\n",
    "        self.lin = Linear(cnn.num_features, num_classes)\n",
    "        print(\"cnn.num_features\", cnn.num_features)\n",
    "\n",
    "        # We do not learn CNN parameters.\n",
    "        # https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
    "        for param in self.cnn.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.cnn(x)\n",
    "        return self.lin(feat)\n",
    "\n",
    "\n",
    "def build_predictor(model_name: str, model_mode: str = \"normal\"):\n",
    "    if model_mode == \"normal\":\n",
    "        # normal configuration. train all parameters.\n",
    "        return timm.create_model(model_name, pretrained=True, num_classes=2, in_chans=3)\n",
    "    elif model_mode == \"cnn_fixed\":\n",
    "        # normal configuration. train all parameters.\n",
    "        # https://rwightman.github.io/pytorch-image-models/feature_extraction/\n",
    "        timm_model = timm.create_model(model_name, pretrained=True, num_classes=0, in_chans=3)\n",
    "        return CNNFixedPredictor(timm_model, num_classes=2)\n",
    "    else:\n",
    "        raise ValueError(f\"[ERROR] Unexpected value model_mode={model_mode}\")\n",
    "\n",
    "        \n",
    "def accuracy(y: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Computes multi-class classification accuracy\"\"\"\n",
    "    assert y.shape[:-1] == t.shape, f\"y {y.shape}, t {t.shape} is inconsistent.\"\n",
    "    pred_label = torch.max(y.detach(), dim=-1)[1]\n",
    "    count = t.nelement()\n",
    "    correct = (pred_label == t).sum().float()\n",
    "    acc = correct / count\n",
    "    return acc\n",
    "\n",
    "\n",
    "def accuracy_with_logits(y: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Computes multi-class classification accuracy\"\"\"\n",
    "    assert y.shape == t.shape\n",
    "    gt_label = torch.max(t.detach(), dim=-1)[1]\n",
    "    return accuracy(y, gt_label)\n",
    "\n",
    "\n",
    "def cross_entropy_with_logits(input, target, dim=-1):\n",
    "    loss = torch.sum(- target * F.log_softmax(input, dim), dim)\n",
    "    return loss.mean()\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import pytorch_pfn_extras as ppe\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    \"\"\"two class classfication\"\"\"\n",
    "\n",
    "    def __init__(self, predictor, lossfun=cross_entropy_with_logits):\n",
    "        super().__init__()\n",
    "        self.predictor = predictor\n",
    "        self.lossfun = lossfun\n",
    "        self.prefix = \"\"\n",
    "\n",
    "    def forward(self, image, targets):\n",
    "        outputs = self.predictor(image)\n",
    "        loss = self.lossfun(outputs, targets)\n",
    "        metrics = {\n",
    "            f\"{self.prefix}loss\": loss.item(),\n",
    "            f\"{self.prefix}acc\": accuracy_with_logits(outputs, targets).item()\n",
    "        }\n",
    "        ppe.reporting.report(metrics, self)\n",
    "        return loss, metrics\n",
    "\n",
    "    def predict(self, data_loader):\n",
    "        pred = self.predict_proba(data_loader)\n",
    "        label = torch.argmax(pred, dim=1)\n",
    "        return label\n",
    "\n",
    "    def predict_proba(self, data_loader):\n",
    "        device: torch.device = next(self.parameters()).device\n",
    "        y_list = []\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in data_loader:\n",
    "                if isinstance(batch, (tuple, list)):\n",
    "                    # Assumes first argument is \"image\"\n",
    "                    batch = batch[0].to(device)\n",
    "                else:\n",
    "                    batch = batch.to(device)\n",
    "                y = self.predictor(batch)\n",
    "                y = torch.softmax(y, dim=-1)\n",
    "                y_list.append(y)\n",
    "        pred = torch.cat(y_list)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "verbal-ridge",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "From https://github.com/pfnet-research/kaggle-lyft-motion-prediction-4th-place-solution\n",
    "\"\"\"\n",
    "from logging import getLogger\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class EMA(object):\n",
    "    \"\"\"Exponential moving average of model parameters.\n",
    "\n",
    "    Ref\n",
    "     - https://github.com/tensorflow/addons/blob/v0.10.0/tensorflow_addons/optimizers/moving_average.py#L26-L103\n",
    "     - https://anmoljoshi.com/Pytorch-Dicussions/\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Model with parameters whose EMA will be kept.\n",
    "        decay (float): Decay rate for exponential moving average.\n",
    "        strict (bool): Apply strict check for `assign` & `resume`.\n",
    "        use_dynamic_decay (bool): Dynamically change decay rate. If `True`, small decay rate is\n",
    "            used at the beginning of training to move moving average faster.\n",
    "    \"\"\"  # NOQA\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        decay: float,\n",
    "        strict: bool = True,\n",
    "        use_dynamic_decay: bool = True,\n",
    "    ):\n",
    "        self.decay = decay\n",
    "        self.model = model\n",
    "        self.strict = strict\n",
    "        self.use_dynamic_decay = use_dynamic_decay\n",
    "        self.logger = getLogger(__name__)\n",
    "        self.n_step = 0\n",
    "\n",
    "        self.shadow = {}\n",
    "        self.original = {}\n",
    "\n",
    "        # Flag to manage which parameter is assigned.\n",
    "        # When `False`, original model's parameter is used.\n",
    "        # When `True` (`assign` method is called), `shadow` parameter (ema param) is used.\n",
    "        self._assigned = False\n",
    "\n",
    "        # Register model parameters\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data.clone()\n",
    "\n",
    "    def step(self):\n",
    "        self.n_step += 1\n",
    "        if self.use_dynamic_decay:\n",
    "            _n_step = float(self.n_step)\n",
    "            decay = min(self.decay, (1.0 + _n_step) / (10.0 + _n_step))\n",
    "        else:\n",
    "            decay = self.decay\n",
    "\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                assert name in self.shadow\n",
    "                new_average = (1.0 - decay) * param.data + decay * self.shadow[name]\n",
    "                self.shadow[name] = new_average.clone()\n",
    "\n",
    "    # alias\n",
    "    __call__ = step\n",
    "\n",
    "    def assign(self):\n",
    "        \"\"\"Assign exponential moving average of parameter values to the respective parameters.\"\"\"\n",
    "        if self._assigned:\n",
    "            if self.strict:\n",
    "                raise ValueError(\"[ERROR] `assign` is called again before `resume`.\")\n",
    "            else:\n",
    "                self.logger.warning(\n",
    "                    \"`assign` is called again before `resume`.\"\n",
    "                    \"shadow parameter is already assigned, skip.\"\n",
    "                )\n",
    "                return\n",
    "\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                assert name in self.shadow\n",
    "                self.original[name] = param.data.clone()\n",
    "                param.data = self.shadow[name]\n",
    "        self._assigned = True\n",
    "\n",
    "    def resume(self):\n",
    "        \"\"\"Restore original parameters to a model.\n",
    "\n",
    "        That is, put back the values that were in each parameter at the last call to `assign`.\n",
    "        \"\"\"\n",
    "        if not self._assigned:\n",
    "            if self.strict:\n",
    "                raise ValueError(\"[ERROR] `resume` is called before `assign`.\")\n",
    "            else:\n",
    "                self.logger.warning(\"`resume` is called before `assign`, skip.\")\n",
    "                return\n",
    "\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                assert name in self.shadow\n",
    "                param.data = self.original[name]\n",
    "        self._assigned = False\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "From https://github.com/pfnet-research/kaggle-lyft-motion-prediction-4th-place-solution\n",
    "\"\"\"\n",
    "from typing import Mapping, Any\n",
    "from torch import optim\n",
    "from pytorch_pfn_extras.training.extension import Extension, PRIORITY_READER\n",
    "from pytorch_pfn_extras.training.manager import ExtensionsManager\n",
    "\n",
    "\n",
    "class LRScheduler(Extension):\n",
    "    \"\"\"A thin wrapper to resume the lr_scheduler\"\"\"\n",
    "\n",
    "    trigger = 1, 'iteration'\n",
    "    priority = PRIORITY_READER\n",
    "    name = None\n",
    "\n",
    "    def __init__(self, optimizer: optim.Optimizer, scheduler_type: str, scheduler_kwargs: Mapping[str, Any]) -> None:\n",
    "        super().__init__()\n",
    "        self.scheduler = getattr(optim.lr_scheduler, scheduler_type)(optimizer, **scheduler_kwargs)\n",
    "\n",
    "    def __call__(self, manager: ExtensionsManager) -> None:\n",
    "        self.scheduler.step()\n",
    "\n",
    "    def state_dict(self) -> None:\n",
    "        return self.scheduler.state_dict()\n",
    "\n",
    "    def load_state_dict(self, to_load) -> None:\n",
    "        self.scheduler.load_state_dict(to_load)\n",
    "\n",
    "\n",
    "from ignite.engine import Engine\n",
    "\n",
    "\n",
    "def create_trainer(model, optimizer, device) -> Engine:\n",
    "    model.to(device)\n",
    "\n",
    "    def update_fn(engine, batch):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        loss, metrics = model(*[elem.to(device) for elem in batch])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        return metrics\n",
    "    trainer = Engine(update_fn)\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "early-surge",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ChestRayDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, filepaths: List[str], labels: List[int], label_smoothing: float = 0., mixup_prob: float = 0., image_transform: Transform = None):\n",
    "        self.filepaths = filepaths\n",
    "        self.labels = labels\n",
    "        self.label_smoothing = label_smoothing\n",
    "        self.mixup_prob = mixup_prob\n",
    "        self.image_transform = image_transform\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.filepaths)\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        img, label = self.__get_single_example(idx=idx)\n",
    "        img, label = self.__mixup(img=img, label=label)\n",
    "        \n",
    "        label_logit = torch.tensor([1 - label, label], dtype=torch.float32)\n",
    "        \n",
    "        return img, label_logit\n",
    "    \n",
    "    def __get_single_example(self, idx: int) -> Tuple[torch.Tensor, float]:\n",
    "        img = cv2.imread(self.filepaths[idx])\n",
    "        if self.image_transform:\n",
    "            img = self.image_transform(img)\n",
    "        img = torch.tensor(np.transpose(img, (2, 0, 1)).astype(np.float32))\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        if label == 0:\n",
    "            return img, float(label) + self.label_smoothing\n",
    "        else:\n",
    "            return img, float(label) - self.label_smoothing\n",
    "    \n",
    "    def __mixup(self, img: torch.Tensor, label: float):\n",
    "        if np.random.uniform() < self.mixup_prob:\n",
    "            pair_idx = np.random.randint(0, len(filepaths))\n",
    "            prob = np.random.uniform()\n",
    "            pair_img, pair_label = self.__get_single_example(idx=pair_idx)\n",
    "            img = img * p + pair_img * (1 - p)\n",
    "            label = label * p + pair_label * (1 - p)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "endless-collapse",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import cv2\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "\n",
    "class StratifiedKFoldWrapper:\n",
    "    def __init__(self, datadir: Path, n_splits: int, shuffle: bool, seed: int, \n",
    "                 label_smoothing: float = 0., mixup_prob: float = 0., aug_kwargs: Dict = {}):\n",
    "        self.datadir = datadir\n",
    "        fl = self.__load_filelist()\n",
    "        fp = self.__load_filepath()\n",
    "        \n",
    "        df = pd.merge(fl, fp, how='left', on='Image Index')[['Image Index', 'Normal', 'Unique Image Index', 'File Path']]  \n",
    "        df = df.groupby('Unique Image Index').first().reset_index()\n",
    "        self.datalist = df\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=shuffle, random_state=seed)\n",
    "        self.split_idxs = list(skf.split(self.datalist['File Path'].values, self.datalist['Normal'].values))\n",
    "        self.__i = -1\n",
    "        \n",
    "        self.label_smoothing = label_smoothing\n",
    "        self.mixup_prob = mixup_prob\n",
    "        self.image_transform = Transform(aug_kwargs=aug_kwargs)\n",
    "        \n",
    "    def __load_filelist(self):\n",
    "        df = pd.read_csv(self.datadir / 'Data_Entry_2017.csv')\n",
    "        df['Unique Image Index'] = df['Image Index'].map(lambda x: x.split('_')[0])\n",
    "        df['Normal'] = (df['Finding Labels'] == 'No Finding').astype('int8')\n",
    "        return df\n",
    "        \n",
    "    def __load_filepath(self):\n",
    "        records = {'Image Index': [], 'File Path': []}\n",
    "        \n",
    "        for dn in [tmp for tmp in sorted(os.listdir(self.datadir)) if 'image' in tmp]:\n",
    "            for fn in sorted(os.listdir(self.datadir / dn / 'images')):\n",
    "                records['Image Index'] += [fn]\n",
    "                records['File Path'] += [str(self.datadir / dn / 'images' / fn)]\n",
    "                \n",
    "        return pd.DataFrame(records)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        self.__i = -1\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        self.__i += 1\n",
    "        if self.__i < 0 or len(self.split_idxs) <= self.__i:\n",
    "            raise StopIteration()\n",
    "        return self.generate_datasets()\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.split_idxs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if idx < 0 or len(self.split_idxs) <= idx:\n",
    "            raise ValueError()\n",
    "        self.__i = idx\n",
    "        return self.generate_datasets()\n",
    "        \n",
    "    def generate_datasets(self) -> ChestRayDataset:\n",
    "        train_idx, valid_idx = self.split_idxs[self.__i]\n",
    "        \n",
    "        train_ds = ChestRayDataset(\n",
    "            filepaths=self.datalist['File Path'].values[train_idx].tolist(),\n",
    "            labels=self.datalist['Normal'].values[train_idx].tolist(),\n",
    "            label_smoothing=self.label_smoothing,\n",
    "            mixup_prob=self.mixup_prob,\n",
    "            image_transform=self.image_transform\n",
    "        )\n",
    "        valid_ds = ChestRayDataset(\n",
    "            filepaths=self.datalist['File Path'].values[valid_idx].tolist(),\n",
    "            labels=self.datalist['Normal'].values[valid_idx].tolist(),\n",
    "        )\n",
    "        \n",
    "        return train_ds, valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "labeled-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = {\n",
    "    # Model\n",
    "    \"model_name\": \"resnet18\",\n",
    "    # Training\n",
    "    \"num_workers\": 4,\n",
    "    \"epoch\": 15,\n",
    "    \"batchsize\": 32,\n",
    "    \"lr\": 1e-4,\n",
    "    \"scheduler_type\": \"CosineAnnealingWarmRestarts\",\n",
    "    \"scheduler_kwargs\": {\"T_0\": 28125},  # 15000 * 15 epoch // (batchsize=8)\n",
    "    \"scheduler_trigger\": [1, \"iteration\"],\n",
    "    \"aug_kwargs\": {\n",
    "        \"HorizontalFlip\": {\"p\": 0.5},\n",
    "        \"ShiftScaleRotate\": {\"scale_limit\": 0.15, \"rotate_limit\": 10, \"p\": 0.5},\n",
    "        \"RandomBrightnessContrast\": {\"p\": 0.5},\n",
    "        \"CoarseDropout\": {\"max_holes\": 8, \"max_height\": 25, \"max_width\": 25, \"p\": 0.5},\n",
    "        \"Blur\": {\"blur_limit\": [3, 7], \"p\": 0.5},\n",
    "        \"Downscale\": {\"scale_min\": 0.25, \"scale_max\": 0.9, \"p\": 0.3},\n",
    "        \"RandomGamma\": {\"gamma_limit\": [80, 120], \"p\": 0.6},\n",
    "    }\n",
    "}\n",
    "\n",
    "config = Config().update(config_dict)\n",
    "\n",
    "base_dir = Path().resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "presidential-territory",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFoldWrapper(\n",
    "    datadir=base_dir / config.imgdir_name,\n",
    "    n_splits=config.n_splits,\n",
    "    shuffle=True,\n",
    "    seed=config.seed,\n",
    "    label_smoothing=config.label_smoothing,\n",
    "    mixup_prob=config.mixup_prob,\n",
    "    aug_kwargs=config.aug_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dramatic-remedy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config(outdir='results', device='cuda', imgdir_name='../data', seed=111, n_splits=5, label_smoothing=0.0, model_name='resnet18', model_mode='normal', epoch=15, lr=0.0001, batchsize=32, valid_batchsize=16, num_workers=4, snapshot_freq=5, ema_decay=0.999, scheduler_type='CosineAnnealingWarmRestarts', scheduler_kwargs={'T_0': 28125}, scheduler_trigger=[1, 'iteration'], aug_kwargs={'HorizontalFlip': {'p': 0.5}, 'ShiftScaleRotate': {'scale_limit': 0.15, 'rotate_limit': 10, 'p': 0.5}, 'RandomBrightnessContrast': {'p': 0.5}, 'CoarseDropout': {'max_holes': 8, 'max_height': 25, 'max_width': 25, 'p': 0.5}, 'Blur': {'blur_limit': [3, 7], 'p': 0.5}, 'Downscale': {'scale_min': 0.25, 'scale_max': 0.9, 'p': 0.3}, 'RandomGamma': {'gamma_limit': [80, 120], 'p': 0.6}}, mixup_prob=0.0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "strange-individual",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import pytorch_pfn_extras.training.extensions as E\n",
    "import torch\n",
    "from ignite.engine import Events\n",
    "from pytorch_pfn_extras.training import IgniteExtensionsManager\n",
    "from torch import nn, optim\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.nn import DataParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "rural-payday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using CosineAnnealingWarmRestarts scheduler with kwargs {'T_0': 28125}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "109cf6ab9bad405497e3150b31395d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(FloatProgress(value=0.0, bar_style='info', description='total', max=1.0), HTML(vâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1958e37ec5a44c96a47909fff1d315e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Only 0-th fold\n",
    "\n",
    "fold = 0\n",
    "train_dataset, valid_dataset = skf[fold]\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.batchsize,\n",
    "    num_workers=config.num_workers,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=config.valid_batchsize,\n",
    "    num_workers=config.num_workers,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "device = torch.device(config.device)\n",
    "\n",
    "predictor = build_predictor(model_name=config.model_name, model_mode=config.model_mode)\n",
    "classifier = Classifier(predictor)\n",
    "model = classifier\n",
    "# model = DataParallel(model)\n",
    "optimizer = optim.Adam([param for param in model.parameters() if param.requires_grad], lr=config.lr)\n",
    "\n",
    "# Train setup\n",
    "trainer = create_trainer(model, optimizer, device)\n",
    "\n",
    "ema = EMA(predictor, decay=config.ema_decay)\n",
    "\n",
    "def eval_func(*batch):\n",
    "    loss, metrics = model(*[elem.to(device) for elem in batch])\n",
    "    # HACKING: report ema value with prefix.\n",
    "    if config.ema_decay > 0:\n",
    "        classifier.prefix = \"ema_\"\n",
    "        ema.assign()\n",
    "        loss, metrics = model(*[elem.to(device) for elem in batch])\n",
    "        ema.resume()\n",
    "        classifier.prefix = \"\"\n",
    "\n",
    "valid_evaluator = E.Evaluator(\n",
    "    valid_loader, model, progress_bar=False, eval_func=eval_func, device=device\n",
    ")\n",
    "\n",
    "# log_trigger = (10 if debug else 1000, \"iteration\")\n",
    "log_trigger = (1, \"epoch\")\n",
    "log_report = E.LogReport(trigger=log_trigger)\n",
    "extensions = [\n",
    "    log_report,\n",
    "    E.ProgressBarNotebook(update_interval=100),  # Show progress bar during training\n",
    "    E.PrintReportNotebook(),  # Show \"log\" on jupyter notebook  \n",
    "    E.FailOnNonNumber(),  # Stop training when nan is detected.\n",
    "]\n",
    "\n",
    "models = {\"main\": model}\n",
    "optimizers = {\"main\": optimizer}\n",
    "manager = IgniteExtensionsManager(\n",
    "    trainer, models, optimizers, config.epoch, extensions=extensions, out_dir=str(base_dir / config.outdir),\n",
    ")\n",
    "# Run evaluation for valid dataset in each epoch.\n",
    "manager.extend(valid_evaluator)\n",
    "\n",
    "# Save predictor.pt every epoch\n",
    "manager.extend(\n",
    "    E.snapshot_object(predictor, \"predictor.pt\"), trigger=(config.snapshot_freq, \"epoch\")\n",
    ")\n",
    "# Check & Save best validation predictor.pt every epoch\n",
    "# manager.extend(E.snapshot_object(predictor, \"best_predictor.pt\"),\n",
    "#                trigger=MinValueTrigger(\"validation/module/nll\",\n",
    "#                trigger=(flags.snapshot_freq, \"iteration\")))\n",
    "\n",
    "# --- lr scheduler ---\n",
    "if config.scheduler_type != \"\":\n",
    "    print(f\"using {config.scheduler_type} scheduler with kwargs {config.scheduler_kwargs}\")\n",
    "    manager.extend(\n",
    "        LRScheduler(optimizer, config.scheduler_type, config.scheduler_kwargs),\n",
    "        trigger=config.scheduler_trigger,\n",
    "    )\n",
    "\n",
    "manager.extend(E.observe_lr(optimizer=optimizer), trigger=log_trigger)\n",
    "\n",
    "if config.ema_decay > 0:\n",
    "    # Exponential moving average\n",
    "    manager.extend(lambda manager: ema(), trigger=(1, \"iteration\"))\n",
    "\n",
    "    def save_ema_model(manager):\n",
    "        ema.assign()\n",
    "        torch.save(predictor.state_dict(), str(base_dir / config.outdir / \"predictor_ema.pt\"))\n",
    "        ema.resume()\n",
    "\n",
    "    manager.extend(save_ema_model, trigger=(config.snapshot_freq, \"epoch\"))\n",
    "\n",
    "_ = trainer.run(train_loader, max_epochs=config.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "limiting-reserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(predictor.state_dict(), base_dir / config.outdir / \"predictor_last.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "chinese-founder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main/loss</th>\n",
       "      <th>main/acc</th>\n",
       "      <th>validation/main/loss</th>\n",
       "      <th>validation/main/acc</th>\n",
       "      <th>validation/main/ema_loss</th>\n",
       "      <th>validation/main/ema_acc</th>\n",
       "      <th>lr</th>\n",
       "      <th>epoch</th>\n",
       "      <th>iteration</th>\n",
       "      <th>elapsed_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.589766</td>\n",
       "      <td>0.700713</td>\n",
       "      <td>0.690214</td>\n",
       "      <td>0.607351</td>\n",
       "      <td>0.578531</td>\n",
       "      <td>0.712111</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1</td>\n",
       "      <td>771</td>\n",
       "      <td>548.255181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.568590</td>\n",
       "      <td>0.718264</td>\n",
       "      <td>0.558133</td>\n",
       "      <td>0.728141</td>\n",
       "      <td>0.570298</td>\n",
       "      <td>0.720693</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>2</td>\n",
       "      <td>1542</td>\n",
       "      <td>1094.601476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.561684</td>\n",
       "      <td>0.727140</td>\n",
       "      <td>0.561749</td>\n",
       "      <td>0.731865</td>\n",
       "      <td>0.554602</td>\n",
       "      <td>0.727494</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>3</td>\n",
       "      <td>2313</td>\n",
       "      <td>1639.962020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.556094</td>\n",
       "      <td>0.731031</td>\n",
       "      <td>0.545229</td>\n",
       "      <td>0.735913</td>\n",
       "      <td>0.565839</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>4</td>\n",
       "      <td>3084</td>\n",
       "      <td>2184.658513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.550227</td>\n",
       "      <td>0.732652</td>\n",
       "      <td>0.544888</td>\n",
       "      <td>0.737856</td>\n",
       "      <td>0.591999</td>\n",
       "      <td>0.716807</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>5</td>\n",
       "      <td>3855</td>\n",
       "      <td>2730.329143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.547596</td>\n",
       "      <td>0.732450</td>\n",
       "      <td>0.543825</td>\n",
       "      <td>0.732351</td>\n",
       "      <td>0.544850</td>\n",
       "      <td>0.739961</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>6</td>\n",
       "      <td>4626</td>\n",
       "      <td>3276.960602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.537949</td>\n",
       "      <td>0.741934</td>\n",
       "      <td>0.550021</td>\n",
       "      <td>0.734618</td>\n",
       "      <td>0.555870</td>\n",
       "      <td>0.730732</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>7</td>\n",
       "      <td>5397</td>\n",
       "      <td>3823.659438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.533350</td>\n",
       "      <td>0.744812</td>\n",
       "      <td>0.556445</td>\n",
       "      <td>0.733808</td>\n",
       "      <td>0.555478</td>\n",
       "      <td>0.737694</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>8</td>\n",
       "      <td>6168</td>\n",
       "      <td>4369.801706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.527270</td>\n",
       "      <td>0.749311</td>\n",
       "      <td>0.558938</td>\n",
       "      <td>0.734780</td>\n",
       "      <td>0.538588</td>\n",
       "      <td>0.743199</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>9</td>\n",
       "      <td>6939</td>\n",
       "      <td>4915.015606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.520428</td>\n",
       "      <td>0.750567</td>\n",
       "      <td>0.574018</td>\n",
       "      <td>0.732189</td>\n",
       "      <td>0.580721</td>\n",
       "      <td>0.728141</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>10</td>\n",
       "      <td>7710</td>\n",
       "      <td>5461.014018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.512719</td>\n",
       "      <td>0.756809</td>\n",
       "      <td>0.543321</td>\n",
       "      <td>0.736885</td>\n",
       "      <td>0.559208</td>\n",
       "      <td>0.729760</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>11</td>\n",
       "      <td>8481</td>\n",
       "      <td>6006.432570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.500541</td>\n",
       "      <td>0.763294</td>\n",
       "      <td>0.559244</td>\n",
       "      <td>0.730408</td>\n",
       "      <td>0.539108</td>\n",
       "      <td>0.740447</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>12</td>\n",
       "      <td>9252</td>\n",
       "      <td>6552.583302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.491939</td>\n",
       "      <td>0.766983</td>\n",
       "      <td>0.567111</td>\n",
       "      <td>0.740123</td>\n",
       "      <td>0.623875</td>\n",
       "      <td>0.723284</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>13</td>\n",
       "      <td>10023</td>\n",
       "      <td>7100.265622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.477689</td>\n",
       "      <td>0.777764</td>\n",
       "      <td>0.563900</td>\n",
       "      <td>0.734456</td>\n",
       "      <td>0.565450</td>\n",
       "      <td>0.729113</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>14</td>\n",
       "      <td>10794</td>\n",
       "      <td>7646.313171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.459655</td>\n",
       "      <td>0.788181</td>\n",
       "      <td>0.585833</td>\n",
       "      <td>0.736399</td>\n",
       "      <td>0.718500</td>\n",
       "      <td>0.730408</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>15</td>\n",
       "      <td>11565</td>\n",
       "      <td>8192.024782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    main/loss  main/acc  validation/main/loss  validation/main/acc  \\\n",
       "0    0.589766  0.700713              0.690214             0.607351   \n",
       "1    0.568590  0.718264              0.558133             0.728141   \n",
       "2    0.561684  0.727140              0.561749             0.731865   \n",
       "3    0.556094  0.731031              0.545229             0.735913   \n",
       "4    0.550227  0.732652              0.544888             0.737856   \n",
       "5    0.547596  0.732450              0.543825             0.732351   \n",
       "6    0.537949  0.741934              0.550021             0.734618   \n",
       "7    0.533350  0.744812              0.556445             0.733808   \n",
       "8    0.527270  0.749311              0.558938             0.734780   \n",
       "9    0.520428  0.750567              0.574018             0.732189   \n",
       "10   0.512719  0.756809              0.543321             0.736885   \n",
       "11   0.500541  0.763294              0.559244             0.730408   \n",
       "12   0.491939  0.766983              0.567111             0.740123   \n",
       "13   0.477689  0.777764              0.563900             0.734456   \n",
       "14   0.459655  0.788181              0.585833             0.736399   \n",
       "\n",
       "    validation/main/ema_loss  validation/main/ema_acc        lr  epoch  \\\n",
       "0                   0.578531                 0.712111  0.000100      1   \n",
       "1                   0.570298                 0.720693  0.000099      2   \n",
       "2                   0.554602                 0.727494  0.000098      3   \n",
       "3                   0.565839                 0.718750  0.000097      4   \n",
       "4                   0.591999                 0.716807  0.000095      5   \n",
       "5                   0.544850                 0.739961  0.000093      6   \n",
       "6                   0.555870                 0.730732  0.000091      7   \n",
       "7                   0.555478                 0.737694  0.000089      8   \n",
       "8                   0.538588                 0.743199  0.000086      9   \n",
       "9                   0.580721                 0.728141  0.000083     10   \n",
       "10                  0.559208                 0.729760  0.000079     11   \n",
       "11                  0.539108                 0.740447  0.000076     12   \n",
       "12                  0.623875                 0.723284  0.000072     13   \n",
       "13                  0.565450                 0.729113  0.000068     14   \n",
       "14                  0.718500                 0.730408  0.000064     15   \n",
       "\n",
       "    iteration  elapsed_time  \n",
       "0         771    548.255181  \n",
       "1        1542   1094.601476  \n",
       "2        2313   1639.962020  \n",
       "3        3084   2184.658513  \n",
       "4        3855   2730.329143  \n",
       "5        4626   3276.960602  \n",
       "6        5397   3823.659438  \n",
       "7        6168   4369.801706  \n",
       "8        6939   4915.015606  \n",
       "9        7710   5461.014018  \n",
       "10       8481   6006.432570  \n",
       "11       9252   6552.583302  \n",
       "12      10023   7100.265622  \n",
       "13      10794   7646.313171  \n",
       "14      11565   8192.024782  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = log_report.to_dataframe()\n",
    "df.to_csv(base_dir / config.outdir / \"log.csv\", index=False)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
