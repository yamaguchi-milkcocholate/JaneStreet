{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dedicated-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import pickle\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from typing import *\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "pd.set_option('max_columns', 50)\n",
    "pd.set_option('max_rows', 200)\n",
    "warnings.simplefilter('ignore')\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "permanent-settlement",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fail to import apex_C: apex was not installed or installed without --cpp_ext.\n",
      "fail to import amp_C: apex was not installed or installed without --cpp_ext.\n",
      "** fvcore version of PathManager will be deprecated soon. **\n",
      "** Please migrate to the version in iopath repo. **\n",
      "https://github.com/facebookresearch/iopath \n",
      "\n",
      "** fvcore version of PathManager will be deprecated soon. **\n",
      "** Please migrate to the version in iopath repo. **\n",
      "https://github.com/facebookresearch/iopath \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HACKING: overriding COCOeval.summarize = vin_summarize...\n"
     ]
    }
   ],
   "source": [
    "base_dir = Path().resolve()\n",
    "sys.path.append(str(base_dir / '../'))\n",
    "\n",
    "from utils.preprocess import *\n",
    "from utils.model import *\n",
    "from utils.train import *\n",
    "from utils.eval import *\n",
    "from utils.detectron2helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "front-rider",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int, device: str):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    with torch.cuda.device(device):\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fewer-clothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field, asdict\n",
    "import yaml\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    # General\n",
    "    debug: bool = False\n",
    "    outdir: str = \"detectron2_results/results01\"\n",
    "    device: str = \"cuda:1\"\n",
    "    device_id: int = 1\n",
    "    num_workers: int = 8\n",
    "\n",
    "    # Data config\n",
    "    imgconf_file: str = '../../data/VinBigData/train.csv'\n",
    "    meta_file: str = '../../data/VinBigData/train_meta.csv'\n",
    "    test_meta_file: str = '../../data/VinBigData/test_meta.csv'\n",
    "    imgdir_name: str = \"../../data/VinBigData/png1024\"\n",
    "    img_size: int = 1024\n",
    "    seed: int = 111\n",
    "    n_splits: int = 5\n",
    "    iou_thr: float = 0.5\n",
    "    skip_box_thr: float = 0.0001\n",
    "    rm: bool = False\n",
    "    \n",
    "    model_config: str = 'Misc/cascade_mask_rcnn_R_50_FPN_3x.yaml'\n",
    "    \n",
    "    # Training config\n",
    "    batch_size: int = 2\n",
    "    iter: int = 10000\n",
    "    lr_scheduler_name: str = \"WarmupCosineLR\"  # WarmupMultiStepLR (default) or WarmupCosineLR\n",
    "    base_lr: float = 0.00025\n",
    "    roi_batch_size_per_image: int = 512\n",
    "    eval_period: int = 10000\n",
    "    checkpoint_period: int = 10000\n",
    "        \n",
    "    aug_kwargs: Dict = field(default_factory=lambda: {})\n",
    "        \n",
    "\n",
    "    def update(self, param_dict: Dict) -> \"Config\":\n",
    "        # Overwrite by `param_dict`\n",
    "        for key, value in param_dict.items():\n",
    "            if not hasattr(self, key):\n",
    "                raise ValueError(f\"[ERROR] Unexpected key for flag = {key}\")\n",
    "            setattr(self, key, value)\n",
    "        return self\n",
    "    \n",
    "    def to_yaml(self, filepath: str, width: int = 120):\n",
    "        with open(filepath, 'w') as f:\n",
    "            yaml.dump(asdict(self), f, width=width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "loving-python",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = {\n",
    "    'debug': False,\n",
    "    'batch_size': 8,\n",
    "    'base_lr': 1e-4,\n",
    "    'iou_thr': 0.5,\n",
    "    'rm': True,\n",
    "    'iter': 10000,\n",
    "    'eval_period': 1000,\n",
    "    'checkpoint_period': 1000,\n",
    "    \"aug_kwargs\": {\n",
    "        \"HorizontalFlip\": {\"p\": 0.5},\n",
    "        \"ShiftScaleRotate\": {\"scale_limit\": 0.15, \"rotate_limit\": 10, \"p\": 0.5},\n",
    "        \"RandomBrightnessContrast\": {\"p\": 0.5},\n",
    "        \"Blur\": {\"blur_limit\": (3, 10), \"p\": 0.4},\n",
    "        \"IAAAffine\": {\"p\": 0.5}\n",
    "    },\n",
    "}\n",
    "config = Config().update(config_dict)\n",
    "config.to_yaml(base_dir / config.outdir / 'config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "naughty-viewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_nms = [\n",
    "    \"Aortic enlargement\",\n",
    "    \"Atelectasis\",\n",
    "    \"Calcification\",\n",
    "    \"Cardiomegaly\",\n",
    "    \"Consolidation\",\n",
    "    \"ILD\",\n",
    "    \"Infiltration\",\n",
    "    \"Lung Opacity\",\n",
    "    \"Nodule/Mass\",\n",
    "    \"Other lesion\",\n",
    "    \"Pleural effusion\",\n",
    "    \"Pleural thickening\",\n",
    "    \"Pneumothorax\",\n",
    "    \"Pulmonary fibrosis\",\n",
    "#     \"No Finding\"\n",
    "]\n",
    "classes_dict = {index: class_name  for index, class_name in enumerate(classes_nms)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unique-italian",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger detectron2 (DEBUG)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "import dataclasses\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from distutils.util import strtobool\n",
    "import cv2\n",
    "import detectron2\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer, launch\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data.samplers.distributed_sampler import RepeatFactorTrainingSampler\n",
    "\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "federal-aside",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from scipy.stats.mstats import gmean\n",
    "\n",
    "\n",
    "def get_repeat_factor(class_weights: List[float], dataset_dicts_fold: List[Dict[str, Any]]) -> torch.Tensor:\n",
    "    repeat_factor = list()\n",
    "    for dd in dataset_dicts_fold:\n",
    "        weights = list()\n",
    "        for annot in dd['annotations']:\n",
    "            weights += [weight_by_folds[0][annot['category_id']]]\n",
    "#         repeat_factor += [stats.hmean(weights)]\n",
    "        repeat_factor += [stats.gmean(weights)]\n",
    "#         repeat_factor += [np.mean(weights)]\n",
    "    \n",
    "    return torch.tensor(repeat_factor, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acquired-glucose",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = '_rm' if config.rm else ''\n",
    "train = pickle.load(open(str(base_dir / f'nms{config.iou_thr}_train_{config.img_size}{rm}.pkl'), 'rb'))\n",
    "dataset_dicts = pickle.load(open(str(base_dir / f'nms{config.iou_thr}_dataset_dicts_{config.img_size}{rm}.pkl'), 'rb'))\n",
    "mkf = pickle.load(open(str(base_dir / f'nms{config.iou_thr}_mkf_{config.img_size}{rm}.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "computational-discussion",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_by_folds = list()\n",
    "for n_data_by_class in mkf.stats.values[:, 1:]:\n",
    "    weight_by_folds += [(1 / n_data_by_class) / (1 / n_data_by_class).sum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "thick-scanning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add segmentation\n",
    "for dd in dataset_dicts:\n",
    "    for annot in dd['annotations']:\n",
    "        x_min, y_min, x_max, y_max = annot['bbox']\n",
    "        annot['segmentation'] = [[x_min, y_min, x_min, y_max, x_max, y_max, x_max, y_min]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "median-trance",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cfg.OUTPUT_DIR ./output -> /home/yamaguchi-milkcocholate/VinBigData/src/VinBigData-ObjectDetection/detectron2_results/results01/fold-1\n",
      "\u001b[32m[03/26 10:33:15 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): CascadeROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): ModuleList(\n",
      "      (0): FastRCNNConvFCHead(\n",
      "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "        (fc_relu1): ReLU()\n",
      "        (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (fc_relu2): ReLU()\n",
      "      )\n",
      "      (1): FastRCNNConvFCHead(\n",
      "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "        (fc_relu1): ReLU()\n",
      "        (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (fc_relu2): ReLU()\n",
      "      )\n",
      "      (2): FastRCNNConvFCHead(\n",
      "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "        (fc_relu1): ReLU()\n",
      "        (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (fc_relu2): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (box_predictor): ModuleList(\n",
      "      (0): FastRCNNOutputLayers(\n",
      "        (cls_score): Linear(in_features=1024, out_features=15, bias=True)\n",
      "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      )\n",
      "      (1): FastRCNNOutputLayers(\n",
      "        (cls_score): Linear(in_features=1024, out_features=15, bias=True)\n",
      "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      )\n",
      "      (2): FastRCNNOutputLayers(\n",
      "        (cls_score): Linear(in_features=1024, out_features=15, bias=True)\n",
      "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 14, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[AlbumentationsMapper] Augmentations used in training: Compose([\n",
      "  HorizontalFlip(always_apply=False, p=0.5),\n",
      "  ShiftScaleRotate(always_apply=False, p=0.5, shift_limit_x=(-0.0625, 0.0625), shift_limit_y=(-0.0625, 0.0625), scale_limit=(-0.15000000000000002, 0.1499999999999999), rotate_limit=(-10, 10), interpolation=1, border_mode=4, value=None, mask_value=None),\n",
      "  RandomBrightnessContrast(always_apply=False, p=0.5, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), brightness_by_max=True),\n",
      "  Blur(always_apply=False, p=0.4, blur_limit=(3, 10)),\n",
      "  IAAAffine(always_apply=False, p=0.5, scale=(1.0, 1.0), translate_percent=None, translate_px=None, rotate=(-0.0, 0.0), shear=(-0.0, 0.0), order=1, cval=0, mode='reflect'),\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/26 10:33:15 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 3478 images left.\n",
      "\u001b[32m[03/26 10:33:15 d2.data.build]: \u001b[0mDistribution of instances among all 14 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "| Aortic enla.. | 2699         |  Atelectasis  | 188          | Calcification | 609          |\n",
      "| Cardiomegaly  | 1912         | Consolidation | 338          |      ILD      | 583          |\n",
      "| Infiltration  | 738          | Lung Opacity  | 1608         |  Nodule/Mass  | 1472         |\n",
      "| Other lesion  | 1471         | Pleural eff.. | 1382         | Pleural thi.. | 3213         |\n",
      "| Pneumothorax  | 101          | Pulmonary f.. | 2690         |               |              |\n",
      "|     total     | 19004        |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/26 10:33:15 d2.data.common]: \u001b[0mSerializing 3478 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/26 10:33:16 d2.data.common]: \u001b[0mSerialized dataset takes 3.61 MiB\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/26 10:33:16 d2.data.build]: \u001b[0mDistribution of instances among all 14 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "| Aortic enla.. | 676          |  Atelectasis  | 44           | Calcification | 134          |\n",
      "| Cardiomegaly  | 471          | Consolidation | 85           |      ILD      | 138          |\n",
      "| Infiltration  | 205          | Lung Opacity  | 371          |  Nodule/Mass  | 380          |\n",
      "| Other lesion  | 336          | Pleural eff.. | 366          | Pleural thi.. | 812          |\n",
      "| Pneumothorax  | 28           | Pulmonary f.. | 664          |               |              |\n",
      "|     total     | 4710         |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/26 10:33:16 d2.data.common]: \u001b[0mSerializing 900 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/26 10:33:16 d2.data.common]: \u001b[0mSerialized dataset takes 0.91 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'proposal_generator.anchor_generator.cell_anchors.0' to the model due to incompatible shapes: (3, 4) in the checkpoint but (5, 4) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.anchor_generator.cell_anchors.1' to the model due to incompatible shapes: (3, 4) in the checkpoint but (5, 4) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.anchor_generator.cell_anchors.2' to the model due to incompatible shapes: (3, 4) in the checkpoint but (5, 4) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.anchor_generator.cell_anchors.3' to the model due to incompatible shapes: (3, 4) in the checkpoint but (5, 4) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.anchor_generator.cell_anchors.4' to the model due to incompatible shapes: (3, 4) in the checkpoint but (5, 4) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.objectness_logits.weight' to the model due to incompatible shapes: (3, 256, 1, 1) in the checkpoint but (5, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.objectness_logits.bias' to the model due to incompatible shapes: (3,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.anchor_deltas.weight' to the model due to incompatible shapes: (12, 256, 1, 1) in the checkpoint but (20, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.anchor_deltas.bias' to the model due to incompatible shapes: (12,) in the checkpoint but (20,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.0.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (15, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.0.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (15,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.1.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (15, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.1.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (15,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.2.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (15, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.2.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (15,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (14, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (14,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/26 10:33:16 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/26 10:33:43 d2.utils.events]: \u001b[0m eta: 3:42:20  iter: 19  total_loss: 10.06  loss_cls_stage0: 2.787  loss_box_reg_stage0: 0.02155  loss_cls_stage1: 2.967  loss_box_reg_stage1: 0.04886  loss_cls_stage2: 2.656  loss_box_reg_stage2: 0.02835  loss_mask: 0.6932  loss_rpn_cls: 0.8013  loss_rpn_loc: 0.04552  time: 1.3378  data_time: 0.0454  lr: 1.9981e-06  max_mem: 10320M\n",
      "\u001b[32m[03/26 10:34:10 d2.utils.events]: \u001b[0m eta: 3:42:10  iter: 39  total_loss: 9.448  loss_cls_stage0: 2.59  loss_box_reg_stage0: 0.02407  loss_cls_stage1: 2.779  loss_box_reg_stage1: 0.04888  loss_cls_stage2: 2.468  loss_box_reg_stage2: 0.03075  loss_mask: 0.6932  loss_rpn_cls: 0.791  loss_rpn_loc: 0.05326  time: 1.3425  data_time: 0.0217  lr: 3.996e-06  max_mem: 10320M\n",
      "\u001b[32m[03/26 10:34:37 d2.utils.events]: \u001b[0m eta: 3:41:58  iter: 59  total_loss: 8.198  loss_cls_stage0: 2.209  loss_box_reg_stage0: 0.0193  loss_cls_stage1: 2.306  loss_box_reg_stage1: 0.04611  loss_cls_stage2: 2.057  loss_box_reg_stage2: 0.03487  loss_mask: 0.693  loss_rpn_cls: 0.7672  loss_rpn_loc: 0.05079  time: 1.3428  data_time: 0.0232  lr: 5.9936e-06  max_mem: 10320M\n",
      "\u001b[32m[03/26 10:35:03 d2.utils.events]: \u001b[0m eta: 3:41:34  iter: 79  total_loss: 6.428  loss_cls_stage0: 1.65  loss_box_reg_stage0: 0.02181  loss_cls_stage1: 1.711  loss_box_reg_stage1: 0.05146  loss_cls_stage2: 1.487  loss_box_reg_stage2: 0.03732  loss_mask: 0.693  loss_rpn_cls: 0.7378  loss_rpn_loc: 0.04981  time: 1.3427  data_time: 0.0225  lr: 7.9909e-06  max_mem: 10320M\n",
      "\u001b[32m[03/26 10:35:30 d2.utils.events]: \u001b[0m eta: 3:41:20  iter: 99  total_loss: 4.649  loss_cls_stage0: 1.068  loss_box_reg_stage0: 0.02271  loss_cls_stage1: 1.093  loss_box_reg_stage1: 0.05003  loss_cls_stage2: 0.9085  loss_box_reg_stage2: 0.03639  loss_mask: 0.6926  loss_rpn_cls: 0.6989  loss_rpn_loc: 0.05617  time: 1.3449  data_time: 0.0230  lr: 9.9877e-06  max_mem: 10320M\n",
      "\u001b[32m[03/26 10:35:58 d2.utils.events]: \u001b[0m eta: 3:41:26  iter: 119  total_loss: 3.18  loss_cls_stage0: 0.582  loss_box_reg_stage0: 0.02525  loss_cls_stage1: 0.5684  loss_box_reg_stage1: 0.05511  loss_cls_stage2: 0.4624  loss_box_reg_stage2: 0.03509  loss_mask: 0.6919  loss_rpn_cls: 0.6487  loss_rpn_loc: 0.05466  time: 1.3466  data_time: 0.0224  lr: 1.1984e-05  max_mem: 10320M\n",
      "\u001b[32m[03/26 10:36:25 d2.utils.events]: \u001b[0m eta: 3:41:13  iter: 139  total_loss: 2.493  loss_cls_stage0: 0.3686  loss_box_reg_stage0: 0.02698  loss_cls_stage1: 0.3765  loss_box_reg_stage1: 0.05051  loss_cls_stage2: 0.3054  loss_box_reg_stage2: 0.03234  loss_mask: 0.692  loss_rpn_cls: 0.5947  loss_rpn_loc: 0.0553  time: 1.3503  data_time: 0.0229  lr: 1.3979e-05  max_mem: 10320M\n",
      "\u001b[32m[03/26 10:36:53 d2.utils.events]: \u001b[0m eta: 3:41:06  iter: 159  total_loss: 2.388  loss_cls_stage0: 0.3201  loss_box_reg_stage0: 0.03216  loss_cls_stage1: 0.3688  loss_box_reg_stage1: 0.05442  loss_cls_stage2: 0.3095  loss_box_reg_stage2: 0.03406  loss_mask: 0.6908  loss_rpn_cls: 0.5228  loss_rpn_loc: 0.04911  time: 1.3583  data_time: 0.0228  lr: 1.5974e-05  max_mem: 10320M\n",
      "\u001b[32m[03/26 10:37:22 d2.utils.events]: \u001b[0m eta: 3:41:00  iter: 179  total_loss: 2.431  loss_cls_stage0: 0.3325  loss_box_reg_stage0: 0.05534  loss_cls_stage1: 0.3941  loss_box_reg_stage1: 0.06707  loss_cls_stage2: 0.3501  loss_box_reg_stage2: 0.04247  loss_mask: 0.6903  loss_rpn_cls: 0.4573  loss_rpn_loc: 0.05307  time: 1.3674  data_time: 0.0233  lr: 1.7968e-05  max_mem: 10320M\n",
      "\u001b[32m[03/26 10:37:51 d2.utils.events]: \u001b[0m eta: 3:41:15  iter: 199  total_loss: 2.384  loss_cls_stage0: 0.3334  loss_box_reg_stage0: 0.08717  loss_cls_stage1: 0.3606  loss_box_reg_stage1: 0.08587  loss_cls_stage2: 0.3375  loss_box_reg_stage2: 0.04384  loss_mask: 0.6888  loss_rpn_cls: 0.3881  loss_rpn_loc: 0.05283  time: 1.3773  data_time: 0.0236  lr: 1.9961e-05  max_mem: 10320M\n",
      "\u001b[32m[03/26 10:38:21 d2.utils.events]: \u001b[0m eta: 3:41:38  iter: 219  total_loss: 2.367  loss_cls_stage0: 0.3304  loss_box_reg_stage0: 0.112  loss_cls_stage1: 0.3259  loss_box_reg_stage1: 0.1014  loss_cls_stage2: 0.2929  loss_box_reg_stage2: 0.05138  loss_mask: 0.6869  loss_rpn_cls: 0.3454  loss_rpn_loc: 0.05363  time: 1.3874  data_time: 0.0245  lr: 2.1952e-05  max_mem: 10320M\n",
      "\u001b[32m[03/26 10:38:51 d2.utils.events]: \u001b[0m eta: 3:42:17  iter: 239  total_loss: 2.054  loss_cls_stage0: 0.2832  loss_box_reg_stage0: 0.1176  loss_cls_stage1: 0.2477  loss_box_reg_stage1: 0.1017  loss_cls_stage2: 0.2245  loss_box_reg_stage2: 0.05356  loss_mask: 0.6849  loss_rpn_cls: 0.2875  loss_rpn_loc: 0.05264  time: 1.3957  data_time: 0.0234  lr: 2.3942e-05  max_mem: 10320M\n",
      "\u001b[32m[03/26 10:39:21 d2.utils.events]: \u001b[0m eta: 3:43:16  iter: 259  total_loss: 1.886  loss_cls_stage0: 0.2651  loss_box_reg_stage0: 0.1255  loss_cls_stage1: 0.1948  loss_box_reg_stage1: 0.1027  loss_cls_stage2: 0.1663  loss_box_reg_stage2: 0.04627  loss_mask: 0.6815  loss_rpn_cls: 0.2543  loss_rpn_loc: 0.05852  time: 1.4028  data_time: 0.0227  lr: 2.5931e-05  max_mem: 10320M\n",
      "\u001b[32m[03/26 10:39:51 d2.utils.events]: \u001b[0m eta: 3:45:33  iter: 279  total_loss: 1.845  loss_cls_stage0: 0.2531  loss_box_reg_stage0: 0.1198  loss_cls_stage1: 0.1953  loss_box_reg_stage1: 0.1089  loss_cls_stage2: 0.1564  loss_box_reg_stage2: 0.05632  loss_mask: 0.6786  loss_rpn_cls: 0.2285  loss_rpn_loc: 0.05063  time: 1.4093  data_time: 0.0223  lr: 2.7918e-05  max_mem: 10320M\n",
      "\u001b[32m[03/26 10:40:20 d2.utils.events]: \u001b[0m eta: 3:48:40  iter: 299  total_loss: 1.826  loss_cls_stage0: 0.2605  loss_box_reg_stage0: 0.1062  loss_cls_stage1: 0.1931  loss_box_reg_stage1: 0.1021  loss_cls_stage2: 0.1466  loss_box_reg_stage2: 0.0628  loss_mask: 0.6827  loss_rpn_cls: 0.2132  loss_rpn_loc: 0.05277  time: 1.4146  data_time: 0.0221  lr: 2.9904e-05  max_mem: 10320M\n",
      "\u001b[32m[03/26 10:40:50 d2.utils.events]: \u001b[0m eta: 3:50:30  iter: 319  total_loss: 1.774  loss_cls_stage0: 0.2525  loss_box_reg_stage0: 0.106  loss_cls_stage1: 0.1814  loss_box_reg_stage1: 0.1008  loss_cls_stage2: 0.1301  loss_box_reg_stage2: 0.05986  loss_mask: 0.6802  loss_rpn_cls: 0.2117  loss_rpn_loc: 0.05049  time: 1.4191  data_time: 0.0217  lr: 3.1888e-05  max_mem: 10320M\n",
      "\u001b[32m[03/26 10:41:20 d2.utils.events]: \u001b[0m eta: 3:53:02  iter: 339  total_loss: 1.802  loss_cls_stage0: 0.2637  loss_box_reg_stage0: 0.1202  loss_cls_stage1: 0.1935  loss_box_reg_stage1: 0.1087  loss_cls_stage2: 0.1338  loss_box_reg_stage2: 0.06591  loss_mask: 0.6706  loss_rpn_cls: 0.1968  loss_rpn_loc: 0.04958  time: 1.4238  data_time: 0.0211  lr: 3.387e-05  max_mem: 10320M\n",
      "\u001b[32m[03/26 10:41:50 d2.utils.events]: \u001b[0m eta: 3:54:05  iter: 359  total_loss: 1.573  loss_cls_stage0: 0.2029  loss_box_reg_stage0: 0.08791  loss_cls_stage1: 0.1549  loss_box_reg_stage1: 0.07191  loss_cls_stage2: 0.1206  loss_box_reg_stage2: 0.05473  loss_mask: 0.6774  loss_rpn_cls: 0.1812  loss_rpn_loc: 0.04492  time: 1.4271  data_time: 0.0231  lr: 3.585e-05  max_mem: 10320M\n",
      "\u001b[32m[03/26 10:42:20 d2.utils.events]: \u001b[0m eta: 3:54:29  iter: 379  total_loss: 1.783  loss_cls_stage0: 0.255  loss_box_reg_stage0: 0.1097  loss_cls_stage1: 0.1909  loss_box_reg_stage1: 0.1117  loss_cls_stage2: 0.1335  loss_box_reg_stage2: 0.06021  loss_mask: 0.6874  loss_rpn_cls: 0.1881  loss_rpn_loc: 0.0504  time: 1.4306  data_time: 0.0225  lr: 3.7828e-05  max_mem: 10320M\n",
      "\u001b[32m[03/26 10:42:50 d2.utils.events]: \u001b[0m eta: 3:54:38  iter: 399  total_loss: 1.773  loss_cls_stage0: 0.2605  loss_box_reg_stage0: 0.1131  loss_cls_stage1: 0.1826  loss_box_reg_stage1: 0.09094  loss_cls_stage2: 0.1246  loss_box_reg_stage2: 0.06696  loss_mask: 0.6739  loss_rpn_cls: 0.1639  loss_rpn_loc: 0.04424  time: 1.4340  data_time: 0.0228  lr: 3.9803e-05  max_mem: 10320M\n",
      "\u001b[32m[03/26 10:43:20 d2.utils.events]: \u001b[0m eta: 3:54:38  iter: 419  total_loss: 1.738  loss_cls_stage0: 0.2537  loss_box_reg_stage0: 0.1111  loss_cls_stage1: 0.1813  loss_box_reg_stage1: 0.08935  loss_cls_stage2: 0.1382  loss_box_reg_stage2: 0.06325  loss_mask: 0.6742  loss_rpn_cls: 0.1706  loss_rpn_loc: 0.04679  time: 1.4369  data_time: 0.0238  lr: 4.1777e-05  max_mem: 10320M\n",
      "\u001b[32m[03/26 10:43:50 d2.utils.events]: \u001b[0m eta: 3:54:24  iter: 439  total_loss: 1.828  loss_cls_stage0: 0.2777  loss_box_reg_stage0: 0.1319  loss_cls_stage1: 0.2012  loss_box_reg_stage1: 0.109  loss_cls_stage2: 0.1503  loss_box_reg_stage2: 0.07207  loss_mask: 0.6676  loss_rpn_cls: 0.1851  loss_rpn_loc: 0.05091  time: 1.4398  data_time: 0.0217  lr: 4.3747e-05  max_mem: 10320M\n",
      "\u001b[32m[03/26 10:44:20 d2.utils.events]: \u001b[0m eta: 3:54:24  iter: 459  total_loss: 1.773  loss_cls_stage0: 0.2754  loss_box_reg_stage0: 0.1317  loss_cls_stage1: 0.1813  loss_box_reg_stage1: 0.1055  loss_cls_stage2: 0.1319  loss_box_reg_stage2: 0.06333  loss_mask: 0.6735  loss_rpn_cls: 0.1557  loss_rpn_loc: 0.04398  time: 1.4429  data_time: 0.0241  lr: 4.5716e-05  max_mem: 10320M\n",
      "\u001b[32m[03/26 10:44:50 d2.utils.events]: \u001b[0m eta: 3:54:03  iter: 479  total_loss: 1.748  loss_cls_stage0: 0.2717  loss_box_reg_stage0: 0.1271  loss_cls_stage1: 0.1892  loss_box_reg_stage1: 0.1044  loss_cls_stage2: 0.1258  loss_box_reg_stage2: 0.06709  loss_mask: 0.6719  loss_rpn_cls: 0.1479  loss_rpn_loc: 0.04403  time: 1.4453  data_time: 0.0236  lr: 4.7681e-05  max_mem: 10320M\n",
      "\u001b[32m[03/26 10:45:20 d2.utils.events]: \u001b[0m eta: 3:53:44  iter: 499  total_loss: 1.913  loss_cls_stage0: 0.3077  loss_box_reg_stage0: 0.1501  loss_cls_stage1: 0.2123  loss_box_reg_stage1: 0.1327  loss_cls_stage2: 0.1406  loss_box_reg_stage2: 0.07429  loss_mask: 0.6924  loss_rpn_cls: 0.1523  loss_rpn_loc: 0.04071  time: 1.4482  data_time: 0.0226  lr: 4.9644e-05  max_mem: 10320M\n",
      "\u001b[32m[03/26 10:45:50 d2.utils.events]: \u001b[0m eta: 3:53:32  iter: 519  total_loss: 1.728  loss_cls_stage0: 0.271  loss_box_reg_stage0: 0.1233  loss_cls_stage1: 0.1914  loss_box_reg_stage1: 0.1052  loss_cls_stage2: 0.1341  loss_box_reg_stage2: 0.06768  loss_mask: 0.6688  loss_rpn_cls: 0.1452  loss_rpn_loc: 0.04291  time: 1.4503  data_time: 0.0244  lr: 5.1604e-05  max_mem: 10320M\n",
      "\u001b[32m[03/26 10:46:20 d2.utils.events]: \u001b[0m eta: 3:53:18  iter: 539  total_loss: 1.849  loss_cls_stage0: 0.2948  loss_box_reg_stage0: 0.1371  loss_cls_stage1: 0.201  loss_box_reg_stage1: 0.1185  loss_cls_stage2: 0.1322  loss_box_reg_stage2: 0.06541  loss_mask: 0.6631  loss_rpn_cls: 0.15  loss_rpn_loc: 0.04668  time: 1.4523  data_time: 0.0243  lr: 5.356e-05  max_mem: 10320M\n",
      "\u001b[32m[03/26 10:46:51 d2.utils.events]: \u001b[0m eta: 3:53:07  iter: 559  total_loss: 1.938  loss_cls_stage0: 0.3312  loss_box_reg_stage0: 0.1704  loss_cls_stage1: 0.2217  loss_box_reg_stage1: 0.1351  loss_cls_stage2: 0.1379  loss_box_reg_stage2: 0.08617  loss_mask: 0.6716  loss_rpn_cls: 0.1438  loss_rpn_loc: 0.04298  time: 1.4545  data_time: 0.0236  lr: 5.5514e-05  max_mem: 10320M\n",
      "\u001b[32m[03/26 10:47:21 d2.utils.events]: \u001b[0m eta: 3:52:50  iter: 579  total_loss: 1.836  loss_cls_stage0: 0.2989  loss_box_reg_stage0: 0.1518  loss_cls_stage1: 0.1951  loss_box_reg_stage1: 0.1232  loss_cls_stage2: 0.1362  loss_box_reg_stage2: 0.07258  loss_mask: 0.6763  loss_rpn_cls: 0.137  loss_rpn_loc: 0.0407  time: 1.4562  data_time: 0.0233  lr: 5.7464e-05  max_mem: 10320M\n",
      "\u001b[32m[03/26 10:47:51 d2.utils.events]: \u001b[0m eta: 3:52:32  iter: 599  total_loss: 1.93  loss_cls_stage0: 0.3349  loss_box_reg_stage0: 0.1729  loss_cls_stage1: 0.2195  loss_box_reg_stage1: 0.1364  loss_cls_stage2: 0.1426  loss_box_reg_stage2: 0.07502  loss_mask: 0.639  loss_rpn_cls: 0.1467  loss_rpn_loc: 0.04251  time: 1.4581  data_time: 0.0231  lr: 5.9411e-05  max_mem: 10320M\n",
      "\u001b[32m[03/26 10:48:21 d2.utils.events]: \u001b[0m eta: 3:52:07  iter: 619  total_loss: 1.98  loss_cls_stage0: 0.3328  loss_box_reg_stage0: 0.1593  loss_cls_stage1: 0.2185  loss_box_reg_stage1: 0.1351  loss_cls_stage2: 0.1409  loss_box_reg_stage2: 0.07803  loss_mask: 0.6965  loss_rpn_cls: 0.1545  loss_rpn_loc: 0.04366  time: 1.4596  data_time: 0.0228  lr: 6.1354e-05  max_mem: 10320M\n",
      "\u001b[32m[03/26 10:48:51 d2.utils.events]: \u001b[0m eta: 3:51:46  iter: 639  total_loss: 1.932  loss_cls_stage0: 0.3228  loss_box_reg_stage0: 0.1545  loss_cls_stage1: 0.2227  loss_box_reg_stage1: 0.1306  loss_cls_stage2: 0.1454  loss_box_reg_stage2: 0.0748  loss_mask: 0.654  loss_rpn_cls: 0.1542  loss_rpn_loc: 0.04082  time: 1.4609  data_time: 0.0241  lr: 6.3294e-05  max_mem: 10320M\n",
      "\u001b[32m[03/26 10:49:21 d2.utils.events]: \u001b[0m eta: 3:51:23  iter: 659  total_loss: 1.968  loss_cls_stage0: 0.3365  loss_box_reg_stage0: 0.1676  loss_cls_stage1: 0.2327  loss_box_reg_stage1: 0.1376  loss_cls_stage2: 0.1528  loss_box_reg_stage2: 0.08737  loss_mask: 0.6657  loss_rpn_cls: 0.1579  loss_rpn_loc: 0.04854  time: 1.4624  data_time: 0.0303  lr: 6.523e-05  max_mem: 10335M\n",
      "\u001b[32m[03/26 10:49:51 d2.utils.events]: \u001b[0m eta: 3:50:54  iter: 679  total_loss: 1.743  loss_cls_stage0: 0.2805  loss_box_reg_stage0: 0.1332  loss_cls_stage1: 0.1897  loss_box_reg_stage1: 0.1115  loss_cls_stage2: 0.1244  loss_box_reg_stage2: 0.06821  loss_mask: 0.6468  loss_rpn_cls: 0.132  loss_rpn_loc: 0.03731  time: 1.4633  data_time: 0.0248  lr: 6.7162e-05  max_mem: 10335M\n",
      "\u001b[32m[03/26 10:50:21 d2.utils.events]: \u001b[0m eta: 3:50:28  iter: 699  total_loss: 1.905  loss_cls_stage0: 0.3269  loss_box_reg_stage0: 0.1556  loss_cls_stage1: 0.2219  loss_box_reg_stage1: 0.1352  loss_cls_stage2: 0.1499  loss_box_reg_stage2: 0.07718  loss_mask: 0.6704  loss_rpn_cls: 0.1584  loss_rpn_loc: 0.04989  time: 1.4645  data_time: 0.0227  lr: 6.909e-05  max_mem: 10335M\n",
      "\u001b[32m[03/26 10:50:51 d2.utils.events]: \u001b[0m eta: 3:49:58  iter: 719  total_loss: 1.765  loss_cls_stage0: 0.2881  loss_box_reg_stage0: 0.1237  loss_cls_stage1: 0.2033  loss_box_reg_stage1: 0.1111  loss_cls_stage2: 0.1308  loss_box_reg_stage2: 0.0748  loss_mask: 0.6345  loss_rpn_cls: 0.1447  loss_rpn_loc: 0.04104  time: 1.4652  data_time: 0.0227  lr: 7.1015e-05  max_mem: 10335M\n",
      "\u001b[32m[03/26 10:51:21 d2.utils.events]: \u001b[0m eta: 3:49:31  iter: 739  total_loss: 1.845  loss_cls_stage0: 0.3161  loss_box_reg_stage0: 0.1495  loss_cls_stage1: 0.2122  loss_box_reg_stage1: 0.1165  loss_cls_stage2: 0.1427  loss_box_reg_stage2: 0.07305  loss_mask: 0.6552  loss_rpn_cls: 0.1476  loss_rpn_loc: 0.04647  time: 1.4661  data_time: 0.0234  lr: 7.2934e-05  max_mem: 10335M\n",
      "\u001b[32m[03/26 10:51:51 d2.utils.events]: \u001b[0m eta: 3:49:01  iter: 759  total_loss: 1.774  loss_cls_stage0: 0.2978  loss_box_reg_stage0: 0.1525  loss_cls_stage1: 0.192  loss_box_reg_stage1: 0.1197  loss_cls_stage2: 0.124  loss_box_reg_stage2: 0.07021  loss_mask: 0.6546  loss_rpn_cls: 0.1398  loss_rpn_loc: 0.04539  time: 1.4670  data_time: 0.0234  lr: 7.485e-05  max_mem: 10335M\n",
      "\u001b[32m[03/26 10:52:21 d2.utils.events]: \u001b[0m eta: 3:48:34  iter: 779  total_loss: 2.013  loss_cls_stage0: 0.3359  loss_box_reg_stage0: 0.1744  loss_cls_stage1: 0.2323  loss_box_reg_stage1: 0.1569  loss_cls_stage2: 0.1439  loss_box_reg_stage2: 0.08633  loss_mask: 0.6738  loss_rpn_cls: 0.1623  loss_rpn_loc: 0.04768  time: 1.4678  data_time: 0.0248  lr: 7.6761e-05  max_mem: 10335M\n",
      "\u001b[32m[03/26 10:52:51 d2.utils.events]: \u001b[0m eta: 3:48:05  iter: 799  total_loss: 1.78  loss_cls_stage0: 0.2959  loss_box_reg_stage0: 0.1455  loss_cls_stage1: 0.1976  loss_box_reg_stage1: 0.1216  loss_cls_stage2: 0.1275  loss_box_reg_stage2: 0.07554  loss_mask: 0.6684  loss_rpn_cls: 0.1371  loss_rpn_loc: 0.0413  time: 1.4686  data_time: 0.0243  lr: 7.8668e-05  max_mem: 10335M\n",
      "\u001b[32m[03/26 10:53:21 d2.utils.events]: \u001b[0m eta: 3:47:33  iter: 819  total_loss: 1.773  loss_cls_stage0: 0.2725  loss_box_reg_stage0: 0.1353  loss_cls_stage1: 0.1902  loss_box_reg_stage1: 0.111  loss_cls_stage2: 0.1293  loss_box_reg_stage2: 0.06961  loss_mask: 0.6684  loss_rpn_cls: 0.1416  loss_rpn_loc: 0.04275  time: 1.4690  data_time: 0.0236  lr: 8.057e-05  max_mem: 10335M\n",
      "\u001b[32m[03/26 10:53:51 d2.utils.events]: \u001b[0m eta: 3:47:06  iter: 839  total_loss: 2.013  loss_cls_stage0: 0.3513  loss_box_reg_stage0: 0.1796  loss_cls_stage1: 0.237  loss_box_reg_stage1: 0.1559  loss_cls_stage2: 0.1544  loss_box_reg_stage2: 0.09649  loss_mask: 0.6332  loss_rpn_cls: 0.1323  loss_rpn_loc: 0.04371  time: 1.4698  data_time: 0.0250  lr: 8.2467e-05  max_mem: 10335M\n",
      "\u001b[32m[03/26 10:54:21 d2.utils.events]: \u001b[0m eta: 3:46:37  iter: 859  total_loss: 1.793  loss_cls_stage0: 0.3006  loss_box_reg_stage0: 0.1512  loss_cls_stage1: 0.1936  loss_box_reg_stage1: 0.1235  loss_cls_stage2: 0.135  loss_box_reg_stage2: 0.07588  loss_mask: 0.6218  loss_rpn_cls: 0.145  loss_rpn_loc: 0.04448  time: 1.4704  data_time: 0.0232  lr: 8.4359e-05  max_mem: 10335M\n",
      "\u001b[32m[03/26 10:54:51 d2.utils.events]: \u001b[0m eta: 3:46:13  iter: 879  total_loss: 2.03  loss_cls_stage0: 0.3419  loss_box_reg_stage0: 0.1735  loss_cls_stage1: 0.2381  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.156  loss_box_reg_stage2: 0.08887  loss_mask: 0.6358  loss_rpn_cls: 0.1384  loss_rpn_loc: 0.04367  time: 1.4710  data_time: 0.0251  lr: 8.6247e-05  max_mem: 10335M\n",
      "\u001b[32m[03/26 10:55:21 d2.utils.events]: \u001b[0m eta: 3:45:47  iter: 899  total_loss: 1.881  loss_cls_stage0: 0.3231  loss_box_reg_stage0: 0.1694  loss_cls_stage1: 0.2107  loss_box_reg_stage1: 0.1361  loss_cls_stage2: 0.1425  loss_box_reg_stage2: 0.08632  loss_mask: 0.6615  loss_rpn_cls: 0.1343  loss_rpn_loc: 0.0415  time: 1.4718  data_time: 0.0240  lr: 8.8129e-05  max_mem: 10371M\n",
      "\u001b[32m[03/26 10:55:51 d2.utils.events]: \u001b[0m eta: 3:45:18  iter: 919  total_loss: 1.918  loss_cls_stage0: 0.3027  loss_box_reg_stage0: 0.156  loss_cls_stage1: 0.2149  loss_box_reg_stage1: 0.1371  loss_cls_stage2: 0.1392  loss_box_reg_stage2: 0.08608  loss_mask: 0.6862  loss_rpn_cls: 0.1273  loss_rpn_loc: 0.03641  time: 1.4723  data_time: 0.0237  lr: 9.0006e-05  max_mem: 10586M\n",
      "\u001b[32m[03/26 10:56:21 d2.utils.events]: \u001b[0m eta: 3:44:47  iter: 939  total_loss: 1.871  loss_cls_stage0: 0.3167  loss_box_reg_stage0: 0.1464  loss_cls_stage1: 0.2119  loss_box_reg_stage1: 0.1343  loss_cls_stage2: 0.1466  loss_box_reg_stage2: 0.08616  loss_mask: 0.6742  loss_rpn_cls: 0.139  loss_rpn_loc: 0.0436  time: 1.4727  data_time: 0.0232  lr: 9.1878e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 10:56:51 d2.utils.events]: \u001b[0m eta: 3:44:19  iter: 959  total_loss: 1.959  loss_cls_stage0: 0.3273  loss_box_reg_stage0: 0.1542  loss_cls_stage1: 0.2366  loss_box_reg_stage1: 0.1503  loss_cls_stage2: 0.1526  loss_box_reg_stage2: 0.09357  loss_mask: 0.659  loss_rpn_cls: 0.1293  loss_rpn_loc: 0.04166  time: 1.4732  data_time: 0.0241  lr: 9.3744e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 10:57:20 d2.utils.events]: \u001b[0m eta: 3:43:48  iter: 979  total_loss: 1.825  loss_cls_stage0: 0.2994  loss_box_reg_stage0: 0.1504  loss_cls_stage1: 0.2145  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.1498  loss_box_reg_stage2: 0.08357  loss_mask: 0.6434  loss_rpn_cls: 0.133  loss_rpn_loc: 0.04319  time: 1.4736  data_time: 0.0235  lr: 9.5605e-05  max_mem: 10619M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/26 10:57:52 d2.data.common]: \u001b[0mSerializing 900 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/26 10:57:52 d2.data.common]: \u001b[0mSerialized dataset takes 0.91 MiB\n",
      "\u001b[32m[03/26 10:57:52 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'vinbigdata_valid_fold1' to COCO format ...)\n",
      "\u001b[32m[03/26 10:57:52 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
      "\u001b[32m[03/26 10:57:53 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 900, #annotations: 4710\n",
      "\u001b[32m[03/26 10:57:53 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at '/home/yamaguchi-milkcocholate/VinBigData/src/VinBigData-ObjectDetection/detectron2_results/results01/fold-1/inference/vinbigdata_valid_fold1_coco_format.json' ...\n",
      "\u001b[32m[03/26 10:57:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 900 images\n",
      "\u001b[32m[03/26 10:57:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/900. 0.0764 s / img. ETA=0:01:09\n",
      "\u001b[32m[03/26 10:58:00 d2.evaluation.evaluator]: \u001b[0mInference done 75/900. 0.0763 s / img. ETA=0:01:05\n",
      "\u001b[32m[03/26 10:58:05 d2.evaluation.evaluator]: \u001b[0mInference done 138/900. 0.0765 s / img. ETA=0:01:00\n",
      "\u001b[32m[03/26 10:58:10 d2.evaluation.evaluator]: \u001b[0mInference done 202/900. 0.0764 s / img. ETA=0:00:55\n",
      "\u001b[32m[03/26 10:58:15 d2.evaluation.evaluator]: \u001b[0mInference done 266/900. 0.0764 s / img. ETA=0:00:50\n",
      "\u001b[32m[03/26 10:58:20 d2.evaluation.evaluator]: \u001b[0mInference done 330/900. 0.0764 s / img. ETA=0:00:45\n",
      "\u001b[32m[03/26 10:58:25 d2.evaluation.evaluator]: \u001b[0mInference done 394/900. 0.0763 s / img. ETA=0:00:39\n",
      "\u001b[32m[03/26 10:58:30 d2.evaluation.evaluator]: \u001b[0mInference done 458/900. 0.0763 s / img. ETA=0:00:34\n",
      "\u001b[32m[03/26 10:58:35 d2.evaluation.evaluator]: \u001b[0mInference done 521/900. 0.0764 s / img. ETA=0:00:29\n",
      "\u001b[32m[03/26 10:58:40 d2.evaluation.evaluator]: \u001b[0mInference done 585/900. 0.0764 s / img. ETA=0:00:24\n",
      "\u001b[32m[03/26 10:58:45 d2.evaluation.evaluator]: \u001b[0mInference done 648/900. 0.0764 s / img. ETA=0:00:19\n",
      "\u001b[32m[03/26 10:58:50 d2.evaluation.evaluator]: \u001b[0mInference done 712/900. 0.0764 s / img. ETA=0:00:14\n",
      "\u001b[32m[03/26 10:58:55 d2.evaluation.evaluator]: \u001b[0mInference done 775/900. 0.0764 s / img. ETA=0:00:09\n",
      "\u001b[32m[03/26 10:59:00 d2.evaluation.evaluator]: \u001b[0mInference done 839/900. 0.0764 s / img. ETA=0:00:04\n",
      "\u001b[32m[03/26 10:59:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:10.931353 (0.079253 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/26 10:59:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:08 (0.076413 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.34 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "\u001b[32m[03/26 10:59:05 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold1 in csv format:\n",
      "\u001b[32m[03/26 10:59:05 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/26 10:59:05 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/26 10:59:05 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n",
      "validation do loss eval 1.9027806595189354\n",
      "\u001b[32m[03/26 11:00:35 d2.utils.events]: \u001b[0m eta: 3:43:18  iter: 999  total_loss: 1.755  loss_cls_stage0: 0.2776  loss_box_reg_stage0: 0.1399  loss_cls_stage1: 0.1939  loss_box_reg_stage1: 0.1217  loss_cls_stage2: 0.1355  loss_box_reg_stage2: 0.08313  loss_mask: 0.6475  loss_rpn_cls: 0.1077  loss_rpn_loc: 0.03288  validation_loss: 1.903  time: 1.4740  data_time: 0.0247  lr: 9.746e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:01:05 d2.utils.events]: \u001b[0m eta: 3:42:58  iter: 1019  total_loss: 2.017  loss_cls_stage0: 0.3506  loss_box_reg_stage0: 0.1805  loss_cls_stage1: 0.2394  loss_box_reg_stage1: 0.1632  loss_cls_stage2: 0.1641  loss_box_reg_stage2: 0.1058  loss_mask: 0.6198  loss_rpn_cls: 0.1394  loss_rpn_loc: 0.04656  validation_loss: 1.903  time: 1.4741  data_time: 0.0258  lr: 9.746e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:01:35 d2.utils.events]: \u001b[0m eta: 3:42:35  iter: 1039  total_loss: 1.939  loss_cls_stage0: 0.326  loss_box_reg_stage0: 0.1581  loss_cls_stage1: 0.2453  loss_box_reg_stage1: 0.1643  loss_cls_stage2: 0.1623  loss_box_reg_stage2: 0.09712  loss_mask: 0.6351  loss_rpn_cls: 0.1226  loss_rpn_loc: 0.04282  validation_loss: 1.903  time: 1.4746  data_time: 0.0235  lr: 9.736e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:02:05 d2.utils.events]: \u001b[0m eta: 3:42:10  iter: 1059  total_loss: 1.922  loss_cls_stage0: 0.3015  loss_box_reg_stage0: 0.1452  loss_cls_stage1: 0.2254  loss_box_reg_stage1: 0.1506  loss_cls_stage2: 0.1489  loss_box_reg_stage2: 0.09456  loss_mask: 0.6719  loss_rpn_cls: 0.1295  loss_rpn_loc: 0.04117  validation_loss: 1.903  time: 1.4749  data_time: 0.0303  lr: 9.7258e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:02:35 d2.utils.events]: \u001b[0m eta: 3:41:47  iter: 1079  total_loss: 1.906  loss_cls_stage0: 0.3156  loss_box_reg_stage0: 0.1618  loss_cls_stage1: 0.2242  loss_box_reg_stage1: 0.1511  loss_cls_stage2: 0.1449  loss_box_reg_stage2: 0.08477  loss_mask: 0.6346  loss_rpn_cls: 0.1242  loss_rpn_loc: 0.04067  validation_loss: 1.903  time: 1.4752  data_time: 0.0224  lr: 9.7155e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:03:05 d2.utils.events]: \u001b[0m eta: 3:41:20  iter: 1099  total_loss: 1.955  loss_cls_stage0: 0.3247  loss_box_reg_stage0: 0.1669  loss_cls_stage1: 0.235  loss_box_reg_stage1: 0.1675  loss_cls_stage2: 0.1536  loss_box_reg_stage2: 0.09639  loss_mask: 0.6353  loss_rpn_cls: 0.1212  loss_rpn_loc: 0.0381  validation_loss: 1.903  time: 1.4757  data_time: 0.0241  lr: 9.7049e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:03:35 d2.utils.events]: \u001b[0m eta: 3:40:58  iter: 1119  total_loss: 1.865  loss_cls_stage0: 0.3104  loss_box_reg_stage0: 0.1464  loss_cls_stage1: 0.2325  loss_box_reg_stage1: 0.1517  loss_cls_stage2: 0.1618  loss_box_reg_stage2: 0.1026  loss_mask: 0.6351  loss_rpn_cls: 0.1233  loss_rpn_loc: 0.03863  validation_loss: 1.903  time: 1.4765  data_time: 0.0231  lr: 9.6942e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:04:05 d2.utils.events]: \u001b[0m eta: 3:40:32  iter: 1139  total_loss: 2.04  loss_cls_stage0: 0.3471  loss_box_reg_stage0: 0.1785  loss_cls_stage1: 0.2521  loss_box_reg_stage1: 0.1819  loss_cls_stage2: 0.1743  loss_box_reg_stage2: 0.1094  loss_mask: 0.6162  loss_rpn_cls: 0.1253  loss_rpn_loc: 0.03921  validation_loss: 1.903  time: 1.4770  data_time: 0.0226  lr: 9.6833e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:04:49 d2.utils.events]: \u001b[0m eta: 3:40:13  iter: 1159  total_loss: 1.922  loss_cls_stage0: 0.3304  loss_box_reg_stage0: 0.1673  loss_cls_stage1: 0.2358  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.1525  loss_box_reg_stage2: 0.09624  loss_mask: 0.6349  loss_rpn_cls: 0.1328  loss_rpn_loc: 0.03941  validation_loss: 1.903  time: 1.4896  data_time: 0.0246  lr: 9.6722e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:05:47 d2.utils.events]: \u001b[0m eta: 3:39:48  iter: 1179  total_loss: 1.978  loss_cls_stage0: 0.3179  loss_box_reg_stage0: 0.1623  loss_cls_stage1: 0.2398  loss_box_reg_stage1: 0.1733  loss_cls_stage2: 0.1552  loss_box_reg_stage2: 0.09655  loss_mask: 0.6251  loss_rpn_cls: 0.1294  loss_rpn_loc: 0.04398  validation_loss: 1.903  time: 1.5131  data_time: 0.0233  lr: 9.6609e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:06:45 d2.utils.events]: \u001b[0m eta: 3:39:26  iter: 1199  total_loss: 2.066  loss_cls_stage0: 0.34  loss_box_reg_stage0: 0.1756  loss_cls_stage1: 0.2516  loss_box_reg_stage1: 0.1744  loss_cls_stage2: 0.1633  loss_box_reg_stage2: 0.1055  loss_mask: 0.65  loss_rpn_cls: 0.1194  loss_rpn_loc: 0.04337  validation_loss: 1.903  time: 1.5361  data_time: 0.0227  lr: 9.6495e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:07:41 d2.utils.events]: \u001b[0m eta: 3:39:02  iter: 1219  total_loss: 1.983  loss_cls_stage0: 0.3201  loss_box_reg_stage0: 0.1557  loss_cls_stage1: 0.2348  loss_box_reg_stage1: 0.1705  loss_cls_stage2: 0.16  loss_box_reg_stage2: 0.09685  loss_mask: 0.623  loss_rpn_cls: 0.126  loss_rpn_loc: 0.04129  validation_loss: 1.903  time: 1.5571  data_time: 0.0232  lr: 9.6378e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:08:39 d2.utils.events]: \u001b[0m eta: 3:38:39  iter: 1239  total_loss: 1.865  loss_cls_stage0: 0.3004  loss_box_reg_stage0: 0.151  loss_cls_stage1: 0.2279  loss_box_reg_stage1: 0.1541  loss_cls_stage2: 0.1442  loss_box_reg_stage2: 0.08769  loss_mask: 0.6199  loss_rpn_cls: 0.122  loss_rpn_loc: 0.03964  validation_loss: 1.903  time: 1.5786  data_time: 0.0216  lr: 9.626e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:09:37 d2.utils.events]: \u001b[0m eta: 3:38:17  iter: 1259  total_loss: 1.954  loss_cls_stage0: 0.3304  loss_box_reg_stage0: 0.1701  loss_cls_stage1: 0.2432  loss_box_reg_stage1: 0.1839  loss_cls_stage2: 0.1575  loss_box_reg_stage2: 0.1101  loss_mask: 0.6445  loss_rpn_cls: 0.1176  loss_rpn_loc: 0.03641  validation_loss: 1.903  time: 1.5998  data_time: 0.0240  lr: 9.614e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:10:33 d2.utils.events]: \u001b[0m eta: 3:37:53  iter: 1279  total_loss: 1.913  loss_cls_stage0: 0.2899  loss_box_reg_stage0: 0.1502  loss_cls_stage1: 0.2327  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.1587  loss_box_reg_stage2: 0.1053  loss_mask: 0.6412  loss_rpn_cls: 0.1134  loss_rpn_loc: 0.03476  validation_loss: 1.903  time: 1.6186  data_time: 0.0232  lr: 9.6018e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:11:31 d2.utils.events]: \u001b[0m eta: 3:37:34  iter: 1299  total_loss: 2.107  loss_cls_stage0: 0.3555  loss_box_reg_stage0: 0.1847  loss_cls_stage1: 0.2737  loss_box_reg_stage1: 0.2015  loss_cls_stage2: 0.1748  loss_box_reg_stage2: 0.1097  loss_mask: 0.6203  loss_rpn_cls: 0.116  loss_rpn_loc: 0.04332  validation_loss: 1.903  time: 1.6385  data_time: 0.0239  lr: 9.5894e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:12:29 d2.utils.events]: \u001b[0m eta: 3:37:13  iter: 1319  total_loss: 1.934  loss_cls_stage0: 0.3206  loss_box_reg_stage0: 0.165  loss_cls_stage1: 0.2475  loss_box_reg_stage1: 0.1765  loss_cls_stage2: 0.1546  loss_box_reg_stage2: 0.1099  loss_mask: 0.6265  loss_rpn_cls: 0.1229  loss_rpn_loc: 0.04339  validation_loss: 1.903  time: 1.6574  data_time: 0.0250  lr: 9.5768e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:13:25 d2.utils.events]: \u001b[0m eta: 3:36:51  iter: 1339  total_loss: 1.988  loss_cls_stage0: 0.3449  loss_box_reg_stage0: 0.1895  loss_cls_stage1: 0.2481  loss_box_reg_stage1: 0.1829  loss_cls_stage2: 0.1668  loss_box_reg_stage2: 0.113  loss_mask: 0.6346  loss_rpn_cls: 0.1307  loss_rpn_loc: 0.041  validation_loss: 1.903  time: 1.6744  data_time: 0.0247  lr: 9.5641e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:14:23 d2.utils.events]: \u001b[0m eta: 3:36:35  iter: 1359  total_loss: 1.912  loss_cls_stage0: 0.3028  loss_box_reg_stage0: 0.1512  loss_cls_stage1: 0.2322  loss_box_reg_stage1: 0.1636  loss_cls_stage2: 0.1543  loss_box_reg_stage2: 0.1019  loss_mask: 0.6458  loss_rpn_cls: 0.11  loss_rpn_loc: 0.03692  validation_loss: 1.903  time: 1.6922  data_time: 0.0227  lr: 9.5512e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:15:20 d2.utils.events]: \u001b[0m eta: 3:36:13  iter: 1379  total_loss: 1.968  loss_cls_stage0: 0.3198  loss_box_reg_stage0: 0.158  loss_cls_stage1: 0.2365  loss_box_reg_stage1: 0.1643  loss_cls_stage2: 0.1708  loss_box_reg_stage2: 0.1091  loss_mask: 0.6187  loss_rpn_cls: 0.1202  loss_rpn_loc: 0.04364  validation_loss: 1.903  time: 1.7096  data_time: 0.0236  lr: 9.5381e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:16:16 d2.utils.events]: \u001b[0m eta: 3:35:55  iter: 1399  total_loss: 1.888  loss_cls_stage0: 0.2986  loss_box_reg_stage0: 0.159  loss_cls_stage1: 0.2175  loss_box_reg_stage1: 0.1472  loss_cls_stage2: 0.1549  loss_box_reg_stage2: 0.1006  loss_mask: 0.6225  loss_rpn_cls: 0.1162  loss_rpn_loc: 0.03938  validation_loss: 1.903  time: 1.7249  data_time: 0.0248  lr: 9.5248e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:17:14 d2.utils.events]: \u001b[0m eta: 3:35:37  iter: 1419  total_loss: 1.817  loss_cls_stage0: 0.2821  loss_box_reg_stage0: 0.142  loss_cls_stage1: 0.2269  loss_box_reg_stage1: 0.1522  loss_cls_stage2: 0.1511  loss_box_reg_stage2: 0.09745  loss_mask: 0.598  loss_rpn_cls: 0.1137  loss_rpn_loc: 0.03836  validation_loss: 1.903  time: 1.7411  data_time: 0.0235  lr: 9.5113e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:18:09 d2.utils.events]: \u001b[0m eta: 3:35:21  iter: 1439  total_loss: 1.991  loss_cls_stage0: 0.3448  loss_box_reg_stage0: 0.1775  loss_cls_stage1: 0.2527  loss_box_reg_stage1: 0.1937  loss_cls_stage2: 0.1623  loss_box_reg_stage2: 0.102  loss_mask: 0.6028  loss_rpn_cls: 0.12  loss_rpn_loc: 0.03744  validation_loss: 1.903  time: 1.7552  data_time: 0.0230  lr: 9.4977e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:18:39 d2.utils.events]: \u001b[0m eta: 3:34:52  iter: 1459  total_loss: 1.893  loss_cls_stage0: 0.311  loss_box_reg_stage0: 0.1625  loss_cls_stage1: 0.2282  loss_box_reg_stage1: 0.1708  loss_cls_stage2: 0.1584  loss_box_reg_stage2: 0.1054  loss_mask: 0.6019  loss_rpn_cls: 0.1253  loss_rpn_loc: 0.04428  validation_loss: 1.903  time: 1.7518  data_time: 0.0239  lr: 9.4839e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:19:09 d2.utils.events]: \u001b[0m eta: 3:34:21  iter: 1479  total_loss: 1.871  loss_cls_stage0: 0.31  loss_box_reg_stage0: 0.1536  loss_cls_stage1: 0.2452  loss_box_reg_stage1: 0.1615  loss_cls_stage2: 0.1682  loss_box_reg_stage2: 0.1165  loss_mask: 0.5851  loss_rpn_cls: 0.1156  loss_rpn_loc: 0.03858  validation_loss: 1.903  time: 1.7484  data_time: 0.0233  lr: 9.4699e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:19:39 d2.utils.events]: \u001b[0m eta: 3:33:49  iter: 1499  total_loss: 1.953  loss_cls_stage0: 0.298  loss_box_reg_stage0: 0.158  loss_cls_stage1: 0.2289  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.1599  loss_box_reg_stage2: 0.1078  loss_mask: 0.6473  loss_rpn_cls: 0.1139  loss_rpn_loc: 0.03695  validation_loss: 1.903  time: 1.7451  data_time: 0.0228  lr: 9.4557e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:20:09 d2.utils.events]: \u001b[0m eta: 3:33:18  iter: 1519  total_loss: 1.951  loss_cls_stage0: 0.3104  loss_box_reg_stage0: 0.1575  loss_cls_stage1: 0.2442  loss_box_reg_stage1: 0.1756  loss_cls_stage2: 0.1678  loss_box_reg_stage2: 0.1123  loss_mask: 0.6325  loss_rpn_cls: 0.1106  loss_rpn_loc: 0.03765  validation_loss: 1.903  time: 1.7419  data_time: 0.0233  lr: 9.4414e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:20:39 d2.utils.events]: \u001b[0m eta: 3:32:43  iter: 1539  total_loss: 1.833  loss_cls_stage0: 0.2855  loss_box_reg_stage0: 0.1492  loss_cls_stage1: 0.214  loss_box_reg_stage1: 0.1524  loss_cls_stage2: 0.1372  loss_box_reg_stage2: 0.09362  loss_mask: 0.6365  loss_rpn_cls: 0.1074  loss_rpn_loc: 0.04102  validation_loss: 1.903  time: 1.7387  data_time: 0.0228  lr: 9.4269e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:21:09 d2.utils.events]: \u001b[0m eta: 3:32:07  iter: 1559  total_loss: 1.895  loss_cls_stage0: 0.3106  loss_box_reg_stage0: 0.155  loss_cls_stage1: 0.2351  loss_box_reg_stage1: 0.1675  loss_cls_stage2: 0.1572  loss_box_reg_stage2: 0.1025  loss_mask: 0.6182  loss_rpn_cls: 0.1134  loss_rpn_loc: 0.04055  validation_loss: 1.903  time: 1.7356  data_time: 0.0238  lr: 9.4122e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:21:39 d2.utils.events]: \u001b[0m eta: 3:31:35  iter: 1579  total_loss: 1.919  loss_cls_stage0: 0.3058  loss_box_reg_stage0: 0.1537  loss_cls_stage1: 0.2303  loss_box_reg_stage1: 0.1754  loss_cls_stage2: 0.1578  loss_box_reg_stage2: 0.1081  loss_mask: 0.6541  loss_rpn_cls: 0.1083  loss_rpn_loc: 0.03526  validation_loss: 1.903  time: 1.7327  data_time: 0.0233  lr: 9.3973e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:22:09 d2.utils.events]: \u001b[0m eta: 3:31:03  iter: 1599  total_loss: 1.901  loss_cls_stage0: 0.319  loss_box_reg_stage0: 0.1736  loss_cls_stage1: 0.2361  loss_box_reg_stage1: 0.1821  loss_cls_stage2: 0.1594  loss_box_reg_stage2: 0.1177  loss_mask: 0.5957  loss_rpn_cls: 0.1094  loss_rpn_loc: 0.0384  validation_loss: 1.903  time: 1.7298  data_time: 0.0240  lr: 9.3823e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:22:39 d2.utils.events]: \u001b[0m eta: 3:30:34  iter: 1619  total_loss: 2.148  loss_cls_stage0: 0.3462  loss_box_reg_stage0: 0.1867  loss_cls_stage1: 0.261  loss_box_reg_stage1: 0.2022  loss_cls_stage2: 0.1783  loss_box_reg_stage2: 0.1185  loss_mask: 0.6073  loss_rpn_cls: 0.1311  loss_rpn_loc: 0.04395  validation_loss: 1.903  time: 1.7271  data_time: 0.0238  lr: 9.3671e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:23:09 d2.utils.events]: \u001b[0m eta: 3:30:03  iter: 1639  total_loss: 1.819  loss_cls_stage0: 0.2783  loss_box_reg_stage0: 0.1446  loss_cls_stage1: 0.2177  loss_box_reg_stage1: 0.1656  loss_cls_stage2: 0.156  loss_box_reg_stage2: 0.1203  loss_mask: 0.593  loss_rpn_cls: 0.1031  loss_rpn_loc: 0.03409  validation_loss: 1.903  time: 1.7243  data_time: 0.0240  lr: 9.3517e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:23:39 d2.utils.events]: \u001b[0m eta: 3:29:33  iter: 1659  total_loss: 1.908  loss_cls_stage0: 0.2957  loss_box_reg_stage0: 0.1613  loss_cls_stage1: 0.22  loss_box_reg_stage1: 0.1584  loss_cls_stage2: 0.1629  loss_box_reg_stage2: 0.1092  loss_mask: 0.6215  loss_rpn_cls: 0.1188  loss_rpn_loc: 0.0411  validation_loss: 1.903  time: 1.7217  data_time: 0.0231  lr: 9.3361e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:24:09 d2.utils.events]: \u001b[0m eta: 3:29:03  iter: 1679  total_loss: 1.834  loss_cls_stage0: 0.2781  loss_box_reg_stage0: 0.1443  loss_cls_stage1: 0.2196  loss_box_reg_stage1: 0.1583  loss_cls_stage2: 0.1494  loss_box_reg_stage2: 0.1049  loss_mask: 0.5892  loss_rpn_cls: 0.1121  loss_rpn_loc: 0.03975  validation_loss: 1.903  time: 1.7191  data_time: 0.0228  lr: 9.3204e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:24:40 d2.utils.events]: \u001b[0m eta: 3:28:33  iter: 1699  total_loss: 2.029  loss_cls_stage0: 0.32  loss_box_reg_stage0: 0.1677  loss_cls_stage1: 0.2506  loss_box_reg_stage1: 0.1851  loss_cls_stage2: 0.1797  loss_box_reg_stage2: 0.1285  loss_mask: 0.6417  loss_rpn_cls: 0.1073  loss_rpn_loc: 0.03822  validation_loss: 1.903  time: 1.7165  data_time: 0.0228  lr: 9.3045e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:25:10 d2.utils.events]: \u001b[0m eta: 3:28:06  iter: 1719  total_loss: 1.932  loss_cls_stage0: 0.3166  loss_box_reg_stage0: 0.1681  loss_cls_stage1: 0.2595  loss_box_reg_stage1: 0.1974  loss_cls_stage2: 0.1763  loss_box_reg_stage2: 0.1399  loss_mask: 0.568  loss_rpn_cls: 0.1069  loss_rpn_loc: 0.03741  validation_loss: 1.903  time: 1.7141  data_time: 0.0235  lr: 9.2884e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:25:40 d2.utils.events]: \u001b[0m eta: 3:27:37  iter: 1739  total_loss: 1.979  loss_cls_stage0: 0.3074  loss_box_reg_stage0: 0.1662  loss_cls_stage1: 0.2451  loss_box_reg_stage1: 0.1954  loss_cls_stage2: 0.1663  loss_box_reg_stage2: 0.1192  loss_mask: 0.5924  loss_rpn_cls: 0.1206  loss_rpn_loc: 0.04021  validation_loss: 1.903  time: 1.7118  data_time: 0.0232  lr: 9.2722e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:26:10 d2.utils.events]: \u001b[0m eta: 3:27:07  iter: 1759  total_loss: 1.788  loss_cls_stage0: 0.2998  loss_box_reg_stage0: 0.1683  loss_cls_stage1: 0.2237  loss_box_reg_stage1: 0.1705  loss_cls_stage2: 0.1585  loss_box_reg_stage2: 0.1063  loss_mask: 0.5573  loss_rpn_cls: 0.1086  loss_rpn_loc: 0.03766  validation_loss: 1.903  time: 1.7094  data_time: 0.0228  lr: 9.2558e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:26:40 d2.utils.events]: \u001b[0m eta: 3:26:40  iter: 1779  total_loss: 1.878  loss_cls_stage0: 0.3249  loss_box_reg_stage0: 0.1732  loss_cls_stage1: 0.2339  loss_box_reg_stage1: 0.1685  loss_cls_stage2: 0.1651  loss_box_reg_stage2: 0.1227  loss_mask: 0.5487  loss_rpn_cls: 0.1115  loss_rpn_loc: 0.03835  validation_loss: 1.903  time: 1.7072  data_time: 0.0230  lr: 9.2392e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:27:10 d2.utils.events]: \u001b[0m eta: 3:26:10  iter: 1799  total_loss: 1.796  loss_cls_stage0: 0.2679  loss_box_reg_stage0: 0.1392  loss_cls_stage1: 0.2129  loss_box_reg_stage1: 0.1638  loss_cls_stage2: 0.1518  loss_box_reg_stage2: 0.1197  loss_mask: 0.5762  loss_rpn_cls: 0.1103  loss_rpn_loc: 0.03531  validation_loss: 1.903  time: 1.7048  data_time: 0.0235  lr: 9.2225e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:27:43 d2.utils.events]: \u001b[0m eta: 3:25:44  iter: 1819  total_loss: 1.89  loss_cls_stage0: 0.2761  loss_box_reg_stage0: 0.1463  loss_cls_stage1: 0.2247  loss_box_reg_stage1: 0.1702  loss_cls_stage2: 0.1595  loss_box_reg_stage2: 0.1134  loss_mask: 0.5945  loss_rpn_cls: 0.1108  loss_rpn_loc: 0.03784  validation_loss: 1.903  time: 1.7041  data_time: 0.0246  lr: 9.2056e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:28:37 d2.utils.events]: \u001b[0m eta: 3:25:26  iter: 1839  total_loss: 1.89  loss_cls_stage0: 0.3003  loss_box_reg_stage0: 0.1632  loss_cls_stage1: 0.24  loss_box_reg_stage1: 0.1817  loss_cls_stage2: 0.1598  loss_box_reg_stage2: 0.1182  loss_mask: 0.5783  loss_rpn_cls: 0.112  loss_rpn_loc: 0.03724  validation_loss: 1.903  time: 1.7151  data_time: 0.0224  lr: 9.1885e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:29:32 d2.utils.events]: \u001b[0m eta: 3:25:06  iter: 1859  total_loss: 1.971  loss_cls_stage0: 0.2926  loss_box_reg_stage0: 0.1602  loss_cls_stage1: 0.238  loss_box_reg_stage1: 0.1921  loss_cls_stage2: 0.1564  loss_box_reg_stage2: 0.123  loss_mask: 0.6147  loss_rpn_cls: 0.1085  loss_rpn_loc: 0.03916  validation_loss: 1.903  time: 1.7260  data_time: 0.0231  lr: 9.1713e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:30:25 d2.utils.events]: \u001b[0m eta: 3:24:53  iter: 1879  total_loss: 1.872  loss_cls_stage0: 0.2717  loss_box_reg_stage0: 0.1364  loss_cls_stage1: 0.2285  loss_box_reg_stage1: 0.1697  loss_cls_stage2: 0.1643  loss_box_reg_stage2: 0.1236  loss_mask: 0.6205  loss_rpn_cls: 0.09891  loss_rpn_loc: 0.03784  validation_loss: 1.903  time: 1.7360  data_time: 0.0227  lr: 9.1539e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:31:20 d2.utils.events]: \u001b[0m eta: 3:24:41  iter: 1899  total_loss: 2.054  loss_cls_stage0: 0.31  loss_box_reg_stage0: 0.1682  loss_cls_stage1: 0.2534  loss_box_reg_stage1: 0.2012  loss_cls_stage2: 0.1851  loss_box_reg_stage2: 0.1369  loss_mask: 0.5832  loss_rpn_cls: 0.1126  loss_rpn_loc: 0.04591  validation_loss: 1.903  time: 1.7466  data_time: 0.0228  lr: 9.1363e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:32:15 d2.utils.events]: \u001b[0m eta: 3:24:31  iter: 1919  total_loss: 1.902  loss_cls_stage0: 0.2952  loss_box_reg_stage0: 0.1569  loss_cls_stage1: 0.2258  loss_box_reg_stage1: 0.1843  loss_cls_stage2: 0.1668  loss_box_reg_stage2: 0.1399  loss_mask: 0.5817  loss_rpn_cls: 0.1096  loss_rpn_loc: 0.03601  validation_loss: 1.903  time: 1.7568  data_time: 0.0236  lr: 9.1186e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:33:08 d2.utils.events]: \u001b[0m eta: 3:24:26  iter: 1939  total_loss: 1.864  loss_cls_stage0: 0.2778  loss_box_reg_stage0: 0.1487  loss_cls_stage1: 0.2189  loss_box_reg_stage1: 0.1636  loss_cls_stage2: 0.1628  loss_box_reg_stage2: 0.1285  loss_mask: 0.5942  loss_rpn_cls: 0.1089  loss_rpn_loc: 0.03747  validation_loss: 1.903  time: 1.7662  data_time: 0.0240  lr: 9.1007e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:34:03 d2.utils.events]: \u001b[0m eta: 3:24:32  iter: 1959  total_loss: 1.958  loss_cls_stage0: 0.3197  loss_box_reg_stage0: 0.1759  loss_cls_stage1: 0.2427  loss_box_reg_stage1: 0.1877  loss_cls_stage2: 0.1692  loss_box_reg_stage2: 0.1298  loss_mask: 0.6002  loss_rpn_cls: 0.1158  loss_rpn_loc: 0.04314  validation_loss: 1.903  time: 1.7761  data_time: 0.0237  lr: 9.0826e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:34:56 d2.utils.events]: \u001b[0m eta: 3:24:51  iter: 1979  total_loss: 1.885  loss_cls_stage0: 0.3031  loss_box_reg_stage0: 0.164  loss_cls_stage1: 0.2318  loss_box_reg_stage1: 0.1851  loss_cls_stage2: 0.1615  loss_box_reg_stage2: 0.122  loss_mask: 0.5717  loss_rpn_cls: 0.09622  loss_rpn_loc: 0.0379  validation_loss: 1.903  time: 1.7852  data_time: 0.0236  lr: 9.0644e-05  max_mem: 10619M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/26 11:35:53 d2.data.common]: \u001b[0mSerializing 900 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/26 11:35:53 d2.data.common]: \u001b[0mSerialized dataset takes 0.91 MiB\n",
      "\u001b[32m[03/26 11:35:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 900 images\n",
      "\u001b[32m[03/26 11:35:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/900. 0.1829 s / img. ETA=0:02:48\n",
      "\u001b[32m[03/26 11:36:01 d2.evaluation.evaluator]: \u001b[0mInference done 36/900. 0.1917 s / img. ETA=0:02:52\n",
      "\u001b[32m[03/26 11:36:06 d2.evaluation.evaluator]: \u001b[0mInference done 62/900. 0.1908 s / img. ETA=0:02:46\n",
      "\u001b[32m[03/26 11:36:11 d2.evaluation.evaluator]: \u001b[0mInference done 87/900. 0.1934 s / img. ETA=0:02:43\n",
      "\u001b[32m[03/26 11:36:16 d2.evaluation.evaluator]: \u001b[0mInference done 112/900. 0.1932 s / img. ETA=0:02:38\n",
      "\u001b[32m[03/26 11:36:22 d2.evaluation.evaluator]: \u001b[0mInference done 138/900. 0.1930 s / img. ETA=0:02:33\n",
      "\u001b[32m[03/26 11:36:27 d2.evaluation.evaluator]: \u001b[0mInference done 163/900. 0.1933 s / img. ETA=0:02:28\n",
      "\u001b[32m[03/26 11:36:32 d2.evaluation.evaluator]: \u001b[0mInference done 188/900. 0.1935 s / img. ETA=0:02:23\n",
      "\u001b[32m[03/26 11:36:37 d2.evaluation.evaluator]: \u001b[0mInference done 221/900. 0.1866 s / img. ETA=0:02:12\n",
      "\u001b[32m[03/26 11:36:42 d2.evaluation.evaluator]: \u001b[0mInference done 246/900. 0.1874 s / img. ETA=0:02:07\n",
      "\u001b[32m[03/26 11:36:47 d2.evaluation.evaluator]: \u001b[0mInference done 270/900. 0.1889 s / img. ETA=0:02:04\n",
      "\u001b[32m[03/26 11:36:52 d2.evaluation.evaluator]: \u001b[0mInference done 294/900. 0.1901 s / img. ETA=0:02:00\n",
      "\u001b[32m[03/26 11:36:57 d2.evaluation.evaluator]: \u001b[0mInference done 321/900. 0.1898 s / img. ETA=0:01:54\n",
      "\u001b[32m[03/26 11:37:03 d2.evaluation.evaluator]: \u001b[0mInference done 345/900. 0.1908 s / img. ETA=0:01:50\n",
      "\u001b[32m[03/26 11:37:08 d2.evaluation.evaluator]: \u001b[0mInference done 370/900. 0.1910 s / img. ETA=0:01:45\n",
      "\u001b[32m[03/26 11:37:13 d2.evaluation.evaluator]: \u001b[0mInference done 394/900. 0.1915 s / img. ETA=0:01:40\n",
      "\u001b[32m[03/26 11:37:18 d2.evaluation.evaluator]: \u001b[0mInference done 419/900. 0.1917 s / img. ETA=0:01:36\n",
      "\u001b[32m[03/26 11:37:23 d2.evaluation.evaluator]: \u001b[0mInference done 444/900. 0.1921 s / img. ETA=0:01:31\n",
      "\u001b[32m[03/26 11:37:28 d2.evaluation.evaluator]: \u001b[0mInference done 469/900. 0.1922 s / img. ETA=0:01:26\n",
      "\u001b[32m[03/26 11:37:33 d2.evaluation.evaluator]: \u001b[0mInference done 494/900. 0.1923 s / img. ETA=0:01:21\n",
      "\u001b[32m[03/26 11:37:38 d2.evaluation.evaluator]: \u001b[0mInference done 519/900. 0.1927 s / img. ETA=0:01:16\n",
      "\u001b[32m[03/26 11:37:43 d2.evaluation.evaluator]: \u001b[0mInference done 543/900. 0.1932 s / img. ETA=0:01:11\n",
      "\u001b[32m[03/26 11:37:48 d2.evaluation.evaluator]: \u001b[0mInference done 569/900. 0.1929 s / img. ETA=0:01:06\n",
      "\u001b[32m[03/26 11:37:53 d2.evaluation.evaluator]: \u001b[0mInference done 595/900. 0.1929 s / img. ETA=0:01:01\n",
      "\u001b[32m[03/26 11:37:59 d2.evaluation.evaluator]: \u001b[0mInference done 621/900. 0.1927 s / img. ETA=0:00:56\n",
      "\u001b[32m[03/26 11:38:04 d2.evaluation.evaluator]: \u001b[0mInference done 649/900. 0.1921 s / img. ETA=0:00:50\n",
      "\u001b[32m[03/26 11:38:09 d2.evaluation.evaluator]: \u001b[0mInference done 676/900. 0.1916 s / img. ETA=0:00:44\n",
      "\u001b[32m[03/26 11:38:14 d2.evaluation.evaluator]: \u001b[0mInference done 734/900. 0.1825 s / img. ETA=0:00:31\n",
      "\u001b[32m[03/26 11:38:19 d2.evaluation.evaluator]: \u001b[0mInference done 792/900. 0.1749 s / img. ETA=0:00:19\n",
      "\u001b[32m[03/26 11:38:24 d2.evaluation.evaluator]: \u001b[0mInference done 851/900. 0.1681 s / img. ETA=0:00:08\n",
      "\u001b[32m[03/26 11:38:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:33.384468 (0.171379 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/26 11:38:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:26 (0.163191 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.21 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.028\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.055\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.059\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.018\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.029\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.047\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.047\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.029\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.048\n",
      "\u001b[32m[03/26 11:38:29 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold1 in csv format:\n",
      "\u001b[32m[03/26 11:38:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/26 11:38:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/26 11:38:29 d2.evaluation.testing]: \u001b[0mcopypaste: 2.8499,5.4828,5.8739,0.0943,1.7685,2.9382\n",
      "validation do loss eval 1.919908093655249\n",
      "\u001b[32m[03/26 11:39:59 d2.utils.events]: \u001b[0m eta: 3:25:32  iter: 1999  total_loss: 1.901  loss_cls_stage0: 0.2887  loss_box_reg_stage0: 0.1571  loss_cls_stage1: 0.2362  loss_box_reg_stage1: 0.1857  loss_cls_stage2: 0.1689  loss_box_reg_stage2: 0.1301  loss_mask: 0.5978  loss_rpn_cls: 0.1051  loss_rpn_loc: 0.03719  validation_loss: 1.911  time: 1.7947  data_time: 0.0236  lr: 9.046e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:40:29 d2.utils.events]: \u001b[0m eta: 3:25:15  iter: 2019  total_loss: 2.117  loss_cls_stage0: 0.3289  loss_box_reg_stage0: 0.1787  loss_cls_stage1: 0.2592  loss_box_reg_stage1: 0.2159  loss_cls_stage2: 0.1866  loss_box_reg_stage2: 0.1552  loss_mask: 0.5913  loss_rpn_cls: 0.1147  loss_rpn_loc: 0.04369  validation_loss: 1.911  time: 1.7917  data_time: 0.0231  lr: 9.0275e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:40:59 d2.utils.events]: \u001b[0m eta: 3:24:44  iter: 2039  total_loss: 1.95  loss_cls_stage0: 0.3075  loss_box_reg_stage0: 0.169  loss_cls_stage1: 0.2398  loss_box_reg_stage1: 0.1946  loss_cls_stage2: 0.1616  loss_box_reg_stage2: 0.1291  loss_mask: 0.5554  loss_rpn_cls: 0.09214  loss_rpn_loc: 0.03821  validation_loss: 1.911  time: 1.7889  data_time: 0.0233  lr: 9.0088e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:41:29 d2.utils.events]: \u001b[0m eta: 3:24:18  iter: 2059  total_loss: 1.851  loss_cls_stage0: 0.284  loss_box_reg_stage0: 0.1605  loss_cls_stage1: 0.2274  loss_box_reg_stage1: 0.1778  loss_cls_stage2: 0.1625  loss_box_reg_stage2: 0.1221  loss_mask: 0.5591  loss_rpn_cls: 0.1053  loss_rpn_loc: 0.03712  validation_loss: 1.911  time: 1.7862  data_time: 0.0235  lr: 8.9899e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:41:59 d2.utils.events]: \u001b[0m eta: 3:23:47  iter: 2079  total_loss: 1.934  loss_cls_stage0: 0.2817  loss_box_reg_stage0: 0.1556  loss_cls_stage1: 0.226  loss_box_reg_stage1: 0.1874  loss_cls_stage2: 0.1695  loss_box_reg_stage2: 0.134  loss_mask: 0.6047  loss_rpn_cls: 0.1046  loss_rpn_loc: 0.04184  validation_loss: 1.911  time: 1.7835  data_time: 0.0239  lr: 8.9709e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:42:29 d2.utils.events]: \u001b[0m eta: 3:23:11  iter: 2099  total_loss: 1.96  loss_cls_stage0: 0.2991  loss_box_reg_stage0: 0.1648  loss_cls_stage1: 0.2378  loss_box_reg_stage1: 0.1897  loss_cls_stage2: 0.1652  loss_box_reg_stage2: 0.1246  loss_mask: 0.5838  loss_rpn_cls: 0.1086  loss_rpn_loc: 0.04316  validation_loss: 1.911  time: 1.7808  data_time: 0.0245  lr: 8.9517e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:43:00 d2.utils.events]: \u001b[0m eta: 3:22:41  iter: 2119  total_loss: 1.892  loss_cls_stage0: 0.2987  loss_box_reg_stage0: 0.1587  loss_cls_stage1: 0.2428  loss_box_reg_stage1: 0.1926  loss_cls_stage2: 0.1778  loss_box_reg_stage2: 0.1375  loss_mask: 0.5862  loss_rpn_cls: 0.1198  loss_rpn_loc: 0.04109  validation_loss: 1.911  time: 1.7784  data_time: 0.0253  lr: 8.9324e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:43:30 d2.utils.events]: \u001b[0m eta: 3:22:08  iter: 2139  total_loss: 1.891  loss_cls_stage0: 0.2971  loss_box_reg_stage0: 0.1613  loss_cls_stage1: 0.23  loss_box_reg_stage1: 0.1819  loss_cls_stage2: 0.1651  loss_box_reg_stage2: 0.1353  loss_mask: 0.5675  loss_rpn_cls: 0.1012  loss_rpn_loc: 0.03729  validation_loss: 1.911  time: 1.7758  data_time: 0.0247  lr: 8.9129e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:44:00 d2.utils.events]: \u001b[0m eta: 3:20:53  iter: 2159  total_loss: 1.861  loss_cls_stage0: 0.2765  loss_box_reg_stage0: 0.1509  loss_cls_stage1: 0.2366  loss_box_reg_stage1: 0.1951  loss_cls_stage2: 0.1661  loss_box_reg_stage2: 0.1333  loss_mask: 0.5626  loss_rpn_cls: 0.1041  loss_rpn_loc: 0.03435  validation_loss: 1.911  time: 1.7733  data_time: 0.0244  lr: 8.8933e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:44:30 d2.utils.events]: \u001b[0m eta: 3:19:39  iter: 2179  total_loss: 1.953  loss_cls_stage0: 0.2908  loss_box_reg_stage0: 0.1671  loss_cls_stage1: 0.227  loss_box_reg_stage1: 0.1924  loss_cls_stage2: 0.1649  loss_box_reg_stage2: 0.1299  loss_mask: 0.588  loss_rpn_cls: 0.1025  loss_rpn_loc: 0.0379  validation_loss: 1.911  time: 1.7709  data_time: 0.0234  lr: 8.8735e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:45:01 d2.utils.events]: \u001b[0m eta: 3:18:34  iter: 2199  total_loss: 1.888  loss_cls_stage0: 0.2865  loss_box_reg_stage0: 0.1625  loss_cls_stage1: 0.2353  loss_box_reg_stage1: 0.1968  loss_cls_stage2: 0.1682  loss_box_reg_stage2: 0.1255  loss_mask: 0.5481  loss_rpn_cls: 0.09728  loss_rpn_loc: 0.03265  validation_loss: 1.911  time: 1.7685  data_time: 0.0244  lr: 8.8536e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:45:31 d2.utils.events]: \u001b[0m eta: 3:17:36  iter: 2219  total_loss: 1.874  loss_cls_stage0: 0.2829  loss_box_reg_stage0: 0.1585  loss_cls_stage1: 0.2218  loss_box_reg_stage1: 0.1897  loss_cls_stage2: 0.1683  loss_box_reg_stage2: 0.1306  loss_mask: 0.5687  loss_rpn_cls: 0.09033  loss_rpn_loc: 0.03335  validation_loss: 1.911  time: 1.7662  data_time: 0.0231  lr: 8.8335e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:46:01 d2.utils.events]: \u001b[0m eta: 3:16:38  iter: 2239  total_loss: 1.972  loss_cls_stage0: 0.2916  loss_box_reg_stage0: 0.1628  loss_cls_stage1: 0.2422  loss_box_reg_stage1: 0.2089  loss_cls_stage2: 0.183  loss_box_reg_stage2: 0.1459  loss_mask: 0.5912  loss_rpn_cls: 0.09412  loss_rpn_loc: 0.0343  validation_loss: 1.911  time: 1.7639  data_time: 0.0245  lr: 8.8132e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:46:31 d2.utils.events]: \u001b[0m eta: 3:15:54  iter: 2259  total_loss: 1.99  loss_cls_stage0: 0.3053  loss_box_reg_stage0: 0.166  loss_cls_stage1: 0.228  loss_box_reg_stage1: 0.1999  loss_cls_stage2: 0.1621  loss_box_reg_stage2: 0.1431  loss_mask: 0.5896  loss_rpn_cls: 0.103  loss_rpn_loc: 0.04027  validation_loss: 1.911  time: 1.7617  data_time: 0.0237  lr: 8.7928e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:47:02 d2.utils.events]: \u001b[0m eta: 3:15:14  iter: 2279  total_loss: 2.034  loss_cls_stage0: 0.3126  loss_box_reg_stage0: 0.1764  loss_cls_stage1: 0.2467  loss_box_reg_stage1: 0.2033  loss_cls_stage2: 0.175  loss_box_reg_stage2: 0.1391  loss_mask: 0.6118  loss_rpn_cls: 0.1074  loss_rpn_loc: 0.03987  validation_loss: 1.911  time: 1.7595  data_time: 0.0225  lr: 8.7723e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:47:32 d2.utils.events]: \u001b[0m eta: 3:14:34  iter: 2299  total_loss: 1.94  loss_cls_stage0: 0.308  loss_box_reg_stage0: 0.17  loss_cls_stage1: 0.2384  loss_box_reg_stage1: 0.1863  loss_cls_stage2: 0.169  loss_box_reg_stage2: 0.1308  loss_mask: 0.5931  loss_rpn_cls: 0.1027  loss_rpn_loc: 0.04208  validation_loss: 1.911  time: 1.7574  data_time: 0.0235  lr: 8.7516e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:48:02 d2.utils.events]: \u001b[0m eta: 3:13:53  iter: 2319  total_loss: 1.804  loss_cls_stage0: 0.2813  loss_box_reg_stage0: 0.1588  loss_cls_stage1: 0.216  loss_box_reg_stage1: 0.1912  loss_cls_stage2: 0.156  loss_box_reg_stage2: 0.1332  loss_mask: 0.5849  loss_rpn_cls: 0.0944  loss_rpn_loc: 0.03539  validation_loss: 1.911  time: 1.7552  data_time: 0.0232  lr: 8.7308e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:48:32 d2.utils.events]: \u001b[0m eta: 3:13:12  iter: 2339  total_loss: 1.74  loss_cls_stage0: 0.2624  loss_box_reg_stage0: 0.1396  loss_cls_stage1: 0.2  loss_box_reg_stage1: 0.1644  loss_cls_stage2: 0.1554  loss_box_reg_stage2: 0.1273  loss_mask: 0.5764  loss_rpn_cls: 0.1001  loss_rpn_loc: 0.03797  validation_loss: 1.911  time: 1.7531  data_time: 0.0237  lr: 8.7098e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:49:03 d2.utils.events]: \u001b[0m eta: 3:12:35  iter: 2359  total_loss: 1.943  loss_cls_stage0: 0.297  loss_box_reg_stage0: 0.1568  loss_cls_stage1: 0.2262  loss_box_reg_stage1: 0.1878  loss_cls_stage2: 0.1625  loss_box_reg_stage2: 0.1371  loss_mask: 0.572  loss_rpn_cls: 0.098  loss_rpn_loc: 0.03613  validation_loss: 1.911  time: 1.7511  data_time: 0.0233  lr: 8.6886e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:49:33 d2.utils.events]: \u001b[0m eta: 3:11:58  iter: 2379  total_loss: 1.988  loss_cls_stage0: 0.2923  loss_box_reg_stage0: 0.1699  loss_cls_stage1: 0.2473  loss_box_reg_stage1: 0.2102  loss_cls_stage2: 0.1786  loss_box_reg_stage2: 0.1535  loss_mask: 0.5854  loss_rpn_cls: 0.104  loss_rpn_loc: 0.03849  validation_loss: 1.911  time: 1.7491  data_time: 0.0240  lr: 8.6673e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:50:03 d2.utils.events]: \u001b[0m eta: 3:11:25  iter: 2399  total_loss: 2.094  loss_cls_stage0: 0.3212  loss_box_reg_stage0: 0.1777  loss_cls_stage1: 0.2577  loss_box_reg_stage1: 0.2104  loss_cls_stage2: 0.1887  loss_box_reg_stage2: 0.1535  loss_mask: 0.5541  loss_rpn_cls: 0.1057  loss_rpn_loc: 0.04441  validation_loss: 1.911  time: 1.7473  data_time: 0.0242  lr: 8.6459e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:50:34 d2.utils.events]: \u001b[0m eta: 3:10:50  iter: 2419  total_loss: 1.916  loss_cls_stage0: 0.2812  loss_box_reg_stage0: 0.1552  loss_cls_stage1: 0.2296  loss_box_reg_stage1: 0.1967  loss_cls_stage2: 0.1624  loss_box_reg_stage2: 0.1359  loss_mask: 0.582  loss_rpn_cls: 0.08693  loss_rpn_loc: 0.03434  validation_loss: 1.911  time: 1.7453  data_time: 0.0239  lr: 8.6243e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:51:04 d2.utils.events]: \u001b[0m eta: 3:10:14  iter: 2439  total_loss: 1.959  loss_cls_stage0: 0.28  loss_box_reg_stage0: 0.1609  loss_cls_stage1: 0.2408  loss_box_reg_stage1: 0.2046  loss_cls_stage2: 0.166  loss_box_reg_stage2: 0.1433  loss_mask: 0.5579  loss_rpn_cls: 0.09839  loss_rpn_loc: 0.03913  validation_loss: 1.911  time: 1.7434  data_time: 0.0232  lr: 8.6026e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:51:34 d2.utils.events]: \u001b[0m eta: 3:09:48  iter: 2459  total_loss: 1.971  loss_cls_stage0: 0.3249  loss_box_reg_stage0: 0.1816  loss_cls_stage1: 0.25  loss_box_reg_stage1: 0.218  loss_cls_stage2: 0.1791  loss_box_reg_stage2: 0.1535  loss_mask: 0.5482  loss_rpn_cls: 0.1004  loss_rpn_loc: 0.04158  validation_loss: 1.911  time: 1.7416  data_time: 0.0227  lr: 8.5808e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:52:05 d2.utils.events]: \u001b[0m eta: 3:09:21  iter: 2479  total_loss: 2.07  loss_cls_stage0: 0.3169  loss_box_reg_stage0: 0.179  loss_cls_stage1: 0.2453  loss_box_reg_stage1: 0.2161  loss_cls_stage2: 0.1697  loss_box_reg_stage2: 0.1371  loss_mask: 0.6331  loss_rpn_cls: 0.1031  loss_rpn_loc: 0.04041  validation_loss: 1.911  time: 1.7398  data_time: 0.0238  lr: 8.5588e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:52:35 d2.utils.events]: \u001b[0m eta: 3:08:54  iter: 2499  total_loss: 2.085  loss_cls_stage0: 0.3167  loss_box_reg_stage0: 0.184  loss_cls_stage1: 0.2629  loss_box_reg_stage1: 0.2329  loss_cls_stage2: 0.1832  loss_box_reg_stage2: 0.1527  loss_mask: 0.5888  loss_rpn_cls: 0.1017  loss_rpn_loc: 0.04624  validation_loss: 1.911  time: 1.7381  data_time: 0.0232  lr: 8.5366e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:53:06 d2.utils.events]: \u001b[0m eta: 3:08:25  iter: 2519  total_loss: 1.898  loss_cls_stage0: 0.2781  loss_box_reg_stage0: 0.1684  loss_cls_stage1: 0.2248  loss_box_reg_stage1: 0.2031  loss_cls_stage2: 0.1682  loss_box_reg_stage2: 0.1592  loss_mask: 0.5776  loss_rpn_cls: 0.0974  loss_rpn_loc: 0.03915  validation_loss: 1.911  time: 1.7363  data_time: 0.0238  lr: 8.5144e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:53:52 d2.utils.events]: \u001b[0m eta: 3:08:06  iter: 2539  total_loss: 1.907  loss_cls_stage0: 0.2988  loss_box_reg_stage0: 0.1658  loss_cls_stage1: 0.2312  loss_box_reg_stage1: 0.1994  loss_cls_stage2: 0.1633  loss_box_reg_stage2: 0.1461  loss_mask: 0.5781  loss_rpn_cls: 0.09845  loss_rpn_loc: 0.03467  validation_loss: 1.911  time: 1.7411  data_time: 0.0230  lr: 8.492e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:54:40 d2.utils.events]: \u001b[0m eta: 3:07:44  iter: 2559  total_loss: 1.853  loss_cls_stage0: 0.245  loss_box_reg_stage0: 0.1388  loss_cls_stage1: 0.2069  loss_box_reg_stage1: 0.1897  loss_cls_stage2: 0.1605  loss_box_reg_stage2: 0.1506  loss_mask: 0.5571  loss_rpn_cls: 0.0941  loss_rpn_loc: 0.03763  validation_loss: 1.911  time: 1.7461  data_time: 0.0233  lr: 8.4694e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:55:29 d2.utils.events]: \u001b[0m eta: 3:07:23  iter: 2579  total_loss: 2.057  loss_cls_stage0: 0.3082  loss_box_reg_stage0: 0.1915  loss_cls_stage1: 0.2444  loss_box_reg_stage1: 0.2242  loss_cls_stage2: 0.1675  loss_box_reg_stage2: 0.1636  loss_mask: 0.6204  loss_rpn_cls: 0.1051  loss_rpn_loc: 0.04433  validation_loss: 1.911  time: 1.7516  data_time: 0.0227  lr: 8.4467e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:56:18 d2.utils.events]: \u001b[0m eta: 3:07:00  iter: 2599  total_loss: 1.922  loss_cls_stage0: 0.2796  loss_box_reg_stage0: 0.1603  loss_cls_stage1: 0.2339  loss_box_reg_stage1: 0.2155  loss_cls_stage2: 0.1687  loss_box_reg_stage2: 0.1428  loss_mask: 0.5611  loss_rpn_cls: 0.08743  loss_rpn_loc: 0.0359  validation_loss: 1.911  time: 1.7569  data_time: 0.0228  lr: 8.4239e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:57:06 d2.utils.events]: \u001b[0m eta: 3:06:40  iter: 2619  total_loss: 1.885  loss_cls_stage0: 0.2866  loss_box_reg_stage0: 0.1768  loss_cls_stage1: 0.2194  loss_box_reg_stage1: 0.2069  loss_cls_stage2: 0.1548  loss_box_reg_stage2: 0.145  loss_mask: 0.5631  loss_rpn_cls: 0.08313  loss_rpn_loc: 0.03451  validation_loss: 1.911  time: 1.7619  data_time: 0.0242  lr: 8.4009e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:57:55 d2.utils.events]: \u001b[0m eta: 3:06:22  iter: 2639  total_loss: 1.831  loss_cls_stage0: 0.2826  loss_box_reg_stage0: 0.1685  loss_cls_stage1: 0.2218  loss_box_reg_stage1: 0.1998  loss_cls_stage2: 0.1587  loss_box_reg_stage2: 0.1468  loss_mask: 0.5855  loss_rpn_cls: 0.08676  loss_rpn_loc: 0.03599  validation_loss: 1.911  time: 1.7668  data_time: 0.0243  lr: 8.3778e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:58:43 d2.utils.events]: \u001b[0m eta: 3:06:05  iter: 2659  total_loss: 1.777  loss_cls_stage0: 0.2585  loss_box_reg_stage0: 0.1495  loss_cls_stage1: 0.21  loss_box_reg_stage1: 0.1884  loss_cls_stage2: 0.1572  loss_box_reg_stage2: 0.1482  loss_mask: 0.5848  loss_rpn_cls: 0.08439  loss_rpn_loc: 0.0348  validation_loss: 1.911  time: 1.7719  data_time: 0.0238  lr: 8.3546e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:59:17 d2.utils.events]: \u001b[0m eta: 3:05:41  iter: 2679  total_loss: 2.168  loss_cls_stage0: 0.3313  loss_box_reg_stage0: 0.1939  loss_cls_stage1: 0.2521  loss_box_reg_stage1: 0.2138  loss_cls_stage2: 0.1882  loss_box_reg_stage2: 0.1584  loss_mask: 0.6228  loss_rpn_cls: 0.09886  loss_rpn_loc: 0.03964  validation_loss: 1.911  time: 1.7713  data_time: 0.0250  lr: 8.3312e-05  max_mem: 10619M\n",
      "\u001b[32m[03/26 11:59:54 d2.utils.events]: \u001b[0m eta: 3:05:16  iter: 2699  total_loss: 2.025  loss_cls_stage0: 0.3023  loss_box_reg_stage0: 0.1692  loss_cls_stage1: 0.2476  loss_box_reg_stage1: 0.2129  loss_cls_stage2: 0.1778  loss_box_reg_stage2: 0.1511  loss_mask: 0.5771  loss_rpn_cls: 0.09863  loss_rpn_loc: 0.04111  validation_loss: 1.911  time: 1.7717  data_time: 0.0242  lr: 8.3077e-05  max_mem: 10700M\n",
      "\u001b[32m[03/26 12:00:44 d2.utils.events]: \u001b[0m eta: 3:05:01  iter: 2719  total_loss: 1.945  loss_cls_stage0: 0.2782  loss_box_reg_stage0: 0.1679  loss_cls_stage1: 0.2274  loss_box_reg_stage1: 0.2052  loss_cls_stage2: 0.1631  loss_box_reg_stage2: 0.1485  loss_mask: 0.5593  loss_rpn_cls: 0.0974  loss_rpn_loc: 0.03659  validation_loss: 1.911  time: 1.7773  data_time: 0.0232  lr: 8.2841e-05  max_mem: 10700M\n",
      "\u001b[32m[03/26 12:01:34 d2.utils.events]: \u001b[0m eta: 3:04:48  iter: 2739  total_loss: 2.015  loss_cls_stage0: 0.3056  loss_box_reg_stage0: 0.1822  loss_cls_stage1: 0.2564  loss_box_reg_stage1: 0.2257  loss_cls_stage2: 0.1851  loss_box_reg_stage2: 0.1732  loss_mask: 0.5616  loss_rpn_cls: 0.09391  loss_rpn_loc: 0.0401  validation_loss: 1.911  time: 1.7825  data_time: 0.0221  lr: 8.2604e-05  max_mem: 10700M\n",
      "\u001b[32m[03/26 12:02:24 d2.utils.events]: \u001b[0m eta: 3:04:39  iter: 2759  total_loss: 1.945  loss_cls_stage0: 0.2894  loss_box_reg_stage0: 0.1761  loss_cls_stage1: 0.2383  loss_box_reg_stage1: 0.2251  loss_cls_stage2: 0.1639  loss_box_reg_stage2: 0.1561  loss_mask: 0.5505  loss_rpn_cls: 0.08182  loss_rpn_loc: 0.03344  validation_loss: 1.911  time: 1.7876  data_time: 0.0234  lr: 8.2365e-05  max_mem: 10700M\n",
      "\u001b[32m[03/26 12:03:15 d2.utils.events]: \u001b[0m eta: 3:04:32  iter: 2779  total_loss: 2.002  loss_cls_stage0: 0.3151  loss_box_reg_stage0: 0.1869  loss_cls_stage1: 0.2423  loss_box_reg_stage1: 0.227  loss_cls_stage2: 0.173  loss_box_reg_stage2: 0.1627  loss_mask: 0.596  loss_rpn_cls: 0.09843  loss_rpn_loc: 0.03992  validation_loss: 1.911  time: 1.7932  data_time: 0.0240  lr: 8.2125e-05  max_mem: 10700M\n",
      "\u001b[32m[03/26 12:04:05 d2.utils.events]: \u001b[0m eta: 3:04:30  iter: 2799  total_loss: 1.961  loss_cls_stage0: 0.2941  loss_box_reg_stage0: 0.1897  loss_cls_stage1: 0.2349  loss_box_reg_stage1: 0.2241  loss_cls_stage2: 0.171  loss_box_reg_stage2: 0.1727  loss_mask: 0.5567  loss_rpn_cls: 0.08502  loss_rpn_loc: 0.03218  validation_loss: 1.911  time: 1.7981  data_time: 0.0235  lr: 8.1883e-05  max_mem: 10700M\n",
      "\u001b[32m[03/26 12:04:55 d2.utils.events]: \u001b[0m eta: 3:04:42  iter: 2819  total_loss: 2.041  loss_cls_stage0: 0.3146  loss_box_reg_stage0: 0.1923  loss_cls_stage1: 0.2445  loss_box_reg_stage1: 0.2315  loss_cls_stage2: 0.1737  loss_box_reg_stage2: 0.1502  loss_mask: 0.5823  loss_rpn_cls: 0.08394  loss_rpn_loc: 0.03992  validation_loss: 1.911  time: 1.8031  data_time: 0.0230  lr: 8.1641e-05  max_mem: 10700M\n",
      "\u001b[32m[03/26 12:05:46 d2.utils.events]: \u001b[0m eta: 3:04:11  iter: 2839  total_loss: 2.058  loss_cls_stage0: 0.3075  loss_box_reg_stage0: 0.1858  loss_cls_stage1: 0.2419  loss_box_reg_stage1: 0.2255  loss_cls_stage2: 0.1771  loss_box_reg_stage2: 0.169  loss_mask: 0.5615  loss_rpn_cls: 0.08258  loss_rpn_loc: 0.03446  validation_loss: 1.911  time: 1.8084  data_time: 0.0241  lr: 8.1397e-05  max_mem: 10700M\n",
      "\u001b[32m[03/26 12:06:26 d2.utils.events]: \u001b[0m eta: 3:03:21  iter: 2859  total_loss: 1.956  loss_cls_stage0: 0.2874  loss_box_reg_stage0: 0.167  loss_cls_stage1: 0.2166  loss_box_reg_stage1: 0.2077  loss_cls_stage2: 0.1709  loss_box_reg_stage2: 0.1737  loss_mask: 0.5953  loss_rpn_cls: 0.08961  loss_rpn_loc: 0.03425  validation_loss: 1.911  time: 1.8097  data_time: 0.0246  lr: 8.1152e-05  max_mem: 10700M\n",
      "\u001b[32m[03/26 12:06:56 d2.utils.events]: \u001b[0m eta: 3:02:12  iter: 2879  total_loss: 2.114  loss_cls_stage0: 0.3109  loss_box_reg_stage0: 0.1877  loss_cls_stage1: 0.2399  loss_box_reg_stage1: 0.2165  loss_cls_stage2: 0.1715  loss_box_reg_stage2: 0.1674  loss_mask: 0.5925  loss_rpn_cls: 0.0941  loss_rpn_loc: 0.03882  validation_loss: 1.911  time: 1.8078  data_time: 0.0260  lr: 8.0905e-05  max_mem: 10700M\n",
      "\u001b[32m[03/26 12:07:27 d2.utils.events]: \u001b[0m eta: 3:01:20  iter: 2899  total_loss: 1.953  loss_cls_stage0: 0.2901  loss_box_reg_stage0: 0.186  loss_cls_stage1: 0.2318  loss_box_reg_stage1: 0.2288  loss_cls_stage2: 0.1606  loss_box_reg_stage2: 0.1629  loss_mask: 0.5881  loss_rpn_cls: 0.09124  loss_rpn_loc: 0.03749  validation_loss: 1.911  time: 1.8058  data_time: 0.0232  lr: 8.0658e-05  max_mem: 10700M\n",
      "\u001b[32m[03/26 12:07:57 d2.utils.events]: \u001b[0m eta: 3:00:34  iter: 2919  total_loss: 1.887  loss_cls_stage0: 0.2586  loss_box_reg_stage0: 0.1619  loss_cls_stage1: 0.2136  loss_box_reg_stage1: 0.2244  loss_cls_stage2: 0.1592  loss_box_reg_stage2: 0.1738  loss_mask: 0.5682  loss_rpn_cls: 0.08679  loss_rpn_loc: 0.03719  validation_loss: 1.911  time: 1.8038  data_time: 0.0248  lr: 8.0409e-05  max_mem: 10700M\n",
      "\u001b[32m[03/26 12:08:28 d2.utils.events]: \u001b[0m eta: 2:59:56  iter: 2939  total_loss: 1.981  loss_cls_stage0: 0.302  loss_box_reg_stage0: 0.1902  loss_cls_stage1: 0.2372  loss_box_reg_stage1: 0.2363  loss_cls_stage2: 0.1599  loss_box_reg_stage2: 0.158  loss_mask: 0.5699  loss_rpn_cls: 0.08155  loss_rpn_loc: 0.03764  validation_loss: 1.911  time: 1.8020  data_time: 0.0235  lr: 8.0159e-05  max_mem: 10700M\n",
      "\u001b[32m[03/26 12:08:59 d2.utils.events]: \u001b[0m eta: 2:59:12  iter: 2959  total_loss: 2.158  loss_cls_stage0: 0.3414  loss_box_reg_stage0: 0.2155  loss_cls_stage1: 0.2575  loss_box_reg_stage1: 0.2505  loss_cls_stage2: 0.1847  loss_box_reg_stage2: 0.1729  loss_mask: 0.5827  loss_rpn_cls: 0.09907  loss_rpn_loc: 0.04112  validation_loss: 1.911  time: 1.8002  data_time: 0.0235  lr: 7.9908e-05  max_mem: 10700M\n",
      "\u001b[32m[03/26 12:09:29 d2.utils.events]: \u001b[0m eta: 2:58:29  iter: 2979  total_loss: 1.879  loss_cls_stage0: 0.2991  loss_box_reg_stage0: 0.1919  loss_cls_stage1: 0.2234  loss_box_reg_stage1: 0.2118  loss_cls_stage2: 0.1556  loss_box_reg_stage2: 0.1603  loss_mask: 0.5328  loss_rpn_cls: 0.08192  loss_rpn_loc: 0.03803  validation_loss: 1.911  time: 1.7983  data_time: 0.0224  lr: 7.9655e-05  max_mem: 10700M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/26 12:10:02 d2.data.common]: \u001b[0mSerializing 900 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/26 12:10:02 d2.data.common]: \u001b[0mSerialized dataset takes 0.91 MiB\n",
      "\u001b[32m[03/26 12:10:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 900 images\n",
      "\u001b[32m[03/26 12:10:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/900. 0.0793 s / img. ETA=0:01:30\n",
      "\u001b[32m[03/26 12:10:08 d2.evaluation.evaluator]: \u001b[0mInference done 60/900. 0.0791 s / img. ETA=0:01:25\n",
      "\u001b[32m[03/26 12:10:13 d2.evaluation.evaluator]: \u001b[0mInference done 109/900. 0.0792 s / img. ETA=0:01:20\n",
      "\u001b[32m[03/26 12:10:18 d2.evaluation.evaluator]: \u001b[0mInference done 159/900. 0.0791 s / img. ETA=0:01:15\n",
      "\u001b[32m[03/26 12:10:23 d2.evaluation.evaluator]: \u001b[0mInference done 207/900. 0.0792 s / img. ETA=0:01:11\n",
      "\u001b[32m[03/26 12:10:29 d2.evaluation.evaluator]: \u001b[0mInference done 254/900. 0.0794 s / img. ETA=0:01:06\n",
      "\u001b[32m[03/26 12:10:34 d2.evaluation.evaluator]: \u001b[0mInference done 304/900. 0.0794 s / img. ETA=0:01:01\n",
      "\u001b[32m[03/26 12:10:39 d2.evaluation.evaluator]: \u001b[0mInference done 353/900. 0.0794 s / img. ETA=0:00:56\n",
      "\u001b[32m[03/26 12:10:44 d2.evaluation.evaluator]: \u001b[0mInference done 402/900. 0.0794 s / img. ETA=0:00:51\n",
      "\u001b[32m[03/26 12:10:49 d2.evaluation.evaluator]: \u001b[0mInference done 453/900. 0.0794 s / img. ETA=0:00:45\n",
      "\u001b[32m[03/26 12:10:54 d2.evaluation.evaluator]: \u001b[0mInference done 500/900. 0.0794 s / img. ETA=0:00:41\n",
      "\u001b[32m[03/26 12:10:59 d2.evaluation.evaluator]: \u001b[0mInference done 549/900. 0.0794 s / img. ETA=0:00:36\n",
      "\u001b[32m[03/26 12:11:04 d2.evaluation.evaluator]: \u001b[0mInference done 598/900. 0.0794 s / img. ETA=0:00:31\n",
      "\u001b[32m[03/26 12:11:09 d2.evaluation.evaluator]: \u001b[0mInference done 648/900. 0.0794 s / img. ETA=0:00:25\n",
      "\u001b[32m[03/26 12:11:14 d2.evaluation.evaluator]: \u001b[0mInference done 697/900. 0.0794 s / img. ETA=0:00:20\n",
      "\u001b[32m[03/26 12:11:19 d2.evaluation.evaluator]: \u001b[0mInference done 746/900. 0.0794 s / img. ETA=0:00:15\n",
      "\u001b[32m[03/26 12:11:24 d2.evaluation.evaluator]: \u001b[0mInference done 795/900. 0.0794 s / img. ETA=0:00:10\n",
      "\u001b[32m[03/26 12:11:29 d2.evaluation.evaluator]: \u001b[0mInference done 845/900. 0.0794 s / img. ETA=0:00:05\n",
      "\u001b[32m[03/26 12:11:34 d2.evaluation.evaluator]: \u001b[0mInference done 894/900. 0.0794 s / img. ETA=0:00:00\n",
      "\u001b[32m[03/26 12:11:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:32.375594 (0.103213 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/26 12:11:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:11 (0.079390 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.38 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.053\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.093\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.097\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.027\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.053\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.079\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.088\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.088\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.036\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.088\n",
      "\u001b[32m[03/26 12:11:36 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold1 in csv format:\n",
      "\u001b[32m[03/26 12:11:36 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/26 12:11:36 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/26 12:11:36 d2.evaluation.testing]: \u001b[0mcopypaste: 5.2580,9.2647,9.6660,0.5203,2.6857,5.2800\n",
      "validation do loss eval 1.9957287929892644\n",
      "\u001b[32m[03/26 12:14:06 d2.utils.events]: \u001b[0m eta: 2:57:51  iter: 2999  total_loss: 1.909  loss_cls_stage0: 0.2839  loss_box_reg_stage0: 0.1902  loss_cls_stage1: 0.2335  loss_box_reg_stage1: 0.233  loss_cls_stage2: 0.1657  loss_box_reg_stage2: 0.163  loss_mask: 0.5929  loss_rpn_cls: 0.0888  loss_rpn_loc: 0.03776  validation_loss: 1.92  time: 1.7965  data_time: 0.0234  lr: 7.9402e-05  max_mem: 10700M\n",
      "\u001b[32m[03/26 12:14:53 d2.utils.events]: \u001b[0m eta: 2:57:29  iter: 3019  total_loss: 2.138  loss_cls_stage0: 0.3024  loss_box_reg_stage0: 0.1968  loss_cls_stage1: 0.2486  loss_box_reg_stage1: 0.2483  loss_cls_stage2: 0.1712  loss_box_reg_stage2: 0.1725  loss_mask: 0.5981  loss_rpn_cls: 0.08587  loss_rpn_loc: 0.04061  validation_loss: 1.92  time: 1.8003  data_time: 0.0223  lr: 7.9147e-05  max_mem: 10700M\n",
      "\u001b[32m[03/26 12:15:42 d2.utils.events]: \u001b[0m eta: 2:57:14  iter: 3039  total_loss: 1.909  loss_cls_stage0: 0.2817  loss_box_reg_stage0: 0.1844  loss_cls_stage1: 0.2254  loss_box_reg_stage1: 0.217  loss_cls_stage2: 0.1692  loss_box_reg_stage2: 0.1626  loss_mask: 0.5782  loss_rpn_cls: 0.08121  loss_rpn_loc: 0.03503  validation_loss: 1.92  time: 1.8045  data_time: 0.0235  lr: 7.8891e-05  max_mem: 10700M\n",
      "\u001b[32m[03/26 12:16:30 d2.utils.events]: \u001b[0m eta: 2:56:58  iter: 3059  total_loss: 2.115  loss_cls_stage0: 0.3281  loss_box_reg_stage0: 0.2092  loss_cls_stage1: 0.2592  loss_box_reg_stage1: 0.2441  loss_cls_stage2: 0.1871  loss_box_reg_stage2: 0.1808  loss_mask: 0.5849  loss_rpn_cls: 0.08976  loss_rpn_loc: 0.04001  validation_loss: 1.92  time: 1.8084  data_time: 0.0239  lr: 7.8634e-05  max_mem: 10810M\n",
      "\u001b[32m[03/26 12:17:14 d2.utils.events]: \u001b[0m eta: 2:56:44  iter: 3079  total_loss: 2.014  loss_cls_stage0: 0.3068  loss_box_reg_stage0: 0.209  loss_cls_stage1: 0.2472  loss_box_reg_stage1: 0.2559  loss_cls_stage2: 0.1745  loss_box_reg_stage2: 0.1828  loss_mask: 0.5531  loss_rpn_cls: 0.09121  loss_rpn_loc: 0.03671  validation_loss: 1.92  time: 1.8108  data_time: 0.0232  lr: 7.8376e-05  max_mem: 10810M\n",
      "\u001b[32m[03/26 12:17:44 d2.utils.events]: \u001b[0m eta: 2:56:18  iter: 3099  total_loss: 2.091  loss_cls_stage0: 0.3221  loss_box_reg_stage0: 0.2031  loss_cls_stage1: 0.2356  loss_box_reg_stage1: 0.228  loss_cls_stage2: 0.1654  loss_box_reg_stage2: 0.1818  loss_mask: 0.5961  loss_rpn_cls: 0.08885  loss_rpn_loc: 0.04115  validation_loss: 1.92  time: 1.8090  data_time: 0.0235  lr: 7.8117e-05  max_mem: 10810M\n",
      "\u001b[32m[03/26 12:18:15 d2.utils.events]: \u001b[0m eta: 2:55:47  iter: 3119  total_loss: 2.009  loss_cls_stage0: 0.2957  loss_box_reg_stage0: 0.1875  loss_cls_stage1: 0.2473  loss_box_reg_stage1: 0.2508  loss_cls_stage2: 0.1727  loss_box_reg_stage2: 0.1876  loss_mask: 0.5569  loss_rpn_cls: 0.08033  loss_rpn_loc: 0.03438  validation_loss: 1.92  time: 1.8071  data_time: 0.0235  lr: 7.7857e-05  max_mem: 10810M\n",
      "\u001b[32m[03/26 12:18:45 d2.utils.events]: \u001b[0m eta: 2:55:21  iter: 3139  total_loss: 2.046  loss_cls_stage0: 0.2845  loss_box_reg_stage0: 0.1706  loss_cls_stage1: 0.2378  loss_box_reg_stage1: 0.2255  loss_cls_stage2: 0.1753  loss_box_reg_stage2: 0.187  loss_mask: 0.6097  loss_rpn_cls: 0.09469  loss_rpn_loc: 0.044  validation_loss: 1.92  time: 1.8053  data_time: 0.0307  lr: 7.7595e-05  max_mem: 10810M\n",
      "\u001b[32m[03/26 12:19:16 d2.utils.events]: \u001b[0m eta: 2:54:51  iter: 3159  total_loss: 1.99  loss_cls_stage0: 0.2779  loss_box_reg_stage0: 0.1892  loss_cls_stage1: 0.2293  loss_box_reg_stage1: 0.2363  loss_cls_stage2: 0.1679  loss_box_reg_stage2: 0.1832  loss_mask: 0.6045  loss_rpn_cls: 0.08537  loss_rpn_loc: 0.03532  validation_loss: 1.92  time: 1.8035  data_time: 0.0245  lr: 7.7333e-05  max_mem: 10810M\n",
      "\u001b[32m[03/26 12:19:46 d2.utils.events]: \u001b[0m eta: 2:54:21  iter: 3179  total_loss: 1.983  loss_cls_stage0: 0.3116  loss_box_reg_stage0: 0.1907  loss_cls_stage1: 0.2512  loss_box_reg_stage1: 0.2406  loss_cls_stage2: 0.1801  loss_box_reg_stage2: 0.1971  loss_mask: 0.5182  loss_rpn_cls: 0.07922  loss_rpn_loc: 0.03599  validation_loss: 1.92  time: 1.8018  data_time: 0.0228  lr: 7.7069e-05  max_mem: 10810M\n",
      "\u001b[32m[03/26 12:20:17 d2.utils.events]: \u001b[0m eta: 2:53:53  iter: 3199  total_loss: 1.982  loss_cls_stage0: 0.3081  loss_box_reg_stage0: 0.2038  loss_cls_stage1: 0.2284  loss_box_reg_stage1: 0.2278  loss_cls_stage2: 0.1592  loss_box_reg_stage2: 0.1691  loss_mask: 0.5375  loss_rpn_cls: 0.0831  loss_rpn_loc: 0.03667  validation_loss: 1.92  time: 1.8000  data_time: 0.0238  lr: 7.6805e-05  max_mem: 10810M\n",
      "\u001b[32m[03/26 12:20:47 d2.utils.events]: \u001b[0m eta: 2:53:29  iter: 3219  total_loss: 2.043  loss_cls_stage0: 0.2816  loss_box_reg_stage0: 0.1875  loss_cls_stage1: 0.2249  loss_box_reg_stage1: 0.2292  loss_cls_stage2: 0.1688  loss_box_reg_stage2: 0.1707  loss_mask: 0.5892  loss_rpn_cls: 0.08166  loss_rpn_loc: 0.03426  validation_loss: 1.92  time: 1.7983  data_time: 0.0234  lr: 7.6539e-05  max_mem: 10810M\n",
      "\u001b[32m[03/26 12:21:18 d2.utils.events]: \u001b[0m eta: 2:53:07  iter: 3239  total_loss: 2.137  loss_cls_stage0: 0.3091  loss_box_reg_stage0: 0.1982  loss_cls_stage1: 0.2515  loss_box_reg_stage1: 0.2559  loss_cls_stage2: 0.178  loss_box_reg_stage2: 0.1881  loss_mask: 0.576  loss_rpn_cls: 0.08014  loss_rpn_loc: 0.03793  validation_loss: 1.92  time: 1.7966  data_time: 0.0311  lr: 7.6272e-05  max_mem: 10810M\n",
      "\u001b[32m[03/26 12:21:48 d2.utils.events]: \u001b[0m eta: 2:52:39  iter: 3259  total_loss: 1.964  loss_cls_stage0: 0.2898  loss_box_reg_stage0: 0.1923  loss_cls_stage1: 0.2378  loss_box_reg_stage1: 0.2355  loss_cls_stage2: 0.1613  loss_box_reg_stage2: 0.1681  loss_mask: 0.5469  loss_rpn_cls: 0.07886  loss_rpn_loc: 0.03291  validation_loss: 1.92  time: 1.7949  data_time: 0.0240  lr: 7.6004e-05  max_mem: 10810M\n",
      "\u001b[32m[03/26 12:22:19 d2.utils.events]: \u001b[0m eta: 2:52:21  iter: 3279  total_loss: 2.086  loss_cls_stage0: 0.3254  loss_box_reg_stage0: 0.2007  loss_cls_stage1: 0.2601  loss_box_reg_stage1: 0.2539  loss_cls_stage2: 0.1845  loss_box_reg_stage2: 0.1872  loss_mask: 0.5641  loss_rpn_cls: 0.08415  loss_rpn_loc: 0.03452  validation_loss: 1.92  time: 1.7933  data_time: 0.0231  lr: 7.5735e-05  max_mem: 10810M\n",
      "\u001b[32m[03/26 12:22:49 d2.utils.events]: \u001b[0m eta: 2:51:58  iter: 3299  total_loss: 2.119  loss_cls_stage0: 0.3232  loss_box_reg_stage0: 0.2092  loss_cls_stage1: 0.2457  loss_box_reg_stage1: 0.2556  loss_cls_stage2: 0.1753  loss_box_reg_stage2: 0.1889  loss_mask: 0.5567  loss_rpn_cls: 0.08781  loss_rpn_loc: 0.03952  validation_loss: 1.92  time: 1.7917  data_time: 0.0246  lr: 7.5466e-05  max_mem: 10810M\n",
      "\u001b[32m[03/26 12:23:20 d2.utils.events]: \u001b[0m eta: 2:51:35  iter: 3319  total_loss: 2.032  loss_cls_stage0: 0.2922  loss_box_reg_stage0: 0.1883  loss_cls_stage1: 0.2421  loss_box_reg_stage1: 0.2439  loss_cls_stage2: 0.1787  loss_box_reg_stage2: 0.1826  loss_mask: 0.6048  loss_rpn_cls: 0.08307  loss_rpn_loc: 0.03402  validation_loss: 1.92  time: 1.7901  data_time: 0.0249  lr: 7.5195e-05  max_mem: 10810M\n",
      "\u001b[32m[03/26 12:23:51 d2.utils.events]: \u001b[0m eta: 2:51:12  iter: 3339  total_loss: 2.04  loss_cls_stage0: 0.3082  loss_box_reg_stage0: 0.2002  loss_cls_stage1: 0.2477  loss_box_reg_stage1: 0.2448  loss_cls_stage2: 0.1673  loss_box_reg_stage2: 0.1826  loss_mask: 0.6085  loss_rpn_cls: 0.08197  loss_rpn_loc: 0.03803  validation_loss: 1.92  time: 1.7886  data_time: 0.0235  lr: 7.4923e-05  max_mem: 10810M\n",
      "\u001b[32m[03/26 12:24:21 d2.utils.events]: \u001b[0m eta: 2:50:42  iter: 3359  total_loss: 2.055  loss_cls_stage0: 0.2906  loss_box_reg_stage0: 0.1971  loss_cls_stage1: 0.2394  loss_box_reg_stage1: 0.2436  loss_cls_stage2: 0.1719  loss_box_reg_stage2: 0.1898  loss_mask: 0.5611  loss_rpn_cls: 0.08708  loss_rpn_loc: 0.03724  validation_loss: 1.92  time: 1.7870  data_time: 0.0226  lr: 7.465e-05  max_mem: 10810M\n",
      "\u001b[32m[03/26 12:24:52 d2.utils.events]: \u001b[0m eta: 2:50:14  iter: 3379  total_loss: 1.961  loss_cls_stage0: 0.3075  loss_box_reg_stage0: 0.207  loss_cls_stage1: 0.2479  loss_box_reg_stage1: 0.264  loss_cls_stage2: 0.1677  loss_box_reg_stage2: 0.1867  loss_mask: 0.5683  loss_rpn_cls: 0.06683  loss_rpn_loc: 0.03091  validation_loss: 1.92  time: 1.7855  data_time: 0.0241  lr: 7.4376e-05  max_mem: 10810M\n",
      "\u001b[32m[03/26 12:25:22 d2.utils.events]: \u001b[0m eta: 2:49:43  iter: 3399  total_loss: 2.008  loss_cls_stage0: 0.2914  loss_box_reg_stage0: 0.1998  loss_cls_stage1: 0.2245  loss_box_reg_stage1: 0.2407  loss_cls_stage2: 0.1598  loss_box_reg_stage2: 0.1805  loss_mask: 0.5729  loss_rpn_cls: 0.07895  loss_rpn_loc: 0.03435  validation_loss: 1.92  time: 1.7840  data_time: 0.0212  lr: 7.4101e-05  max_mem: 10810M\n",
      "\u001b[32m[03/26 12:25:53 d2.utils.events]: \u001b[0m eta: 2:49:13  iter: 3419  total_loss: 2.026  loss_cls_stage0: 0.2924  loss_box_reg_stage0: 0.1894  loss_cls_stage1: 0.2401  loss_box_reg_stage1: 0.2497  loss_cls_stage2: 0.1704  loss_box_reg_stage2: 0.2012  loss_mask: 0.5549  loss_rpn_cls: 0.08147  loss_rpn_loc: 0.03449  validation_loss: 1.92  time: 1.7825  data_time: 0.0290  lr: 7.3826e-05  max_mem: 10810M\n",
      "\u001b[32m[03/26 12:26:23 d2.utils.events]: \u001b[0m eta: 2:48:49  iter: 3439  total_loss: 1.954  loss_cls_stage0: 0.2904  loss_box_reg_stage0: 0.1865  loss_cls_stage1: 0.2259  loss_box_reg_stage1: 0.2313  loss_cls_stage2: 0.1604  loss_box_reg_stage2: 0.1907  loss_mask: 0.5651  loss_rpn_cls: 0.08323  loss_rpn_loc: 0.03366  validation_loss: 1.92  time: 1.7810  data_time: 0.0235  lr: 7.3549e-05  max_mem: 10810M\n",
      "\u001b[32m[03/26 12:26:54 d2.utils.events]: \u001b[0m eta: 2:48:18  iter: 3459  total_loss: 2.127  loss_cls_stage0: 0.2872  loss_box_reg_stage0: 0.1769  loss_cls_stage1: 0.2341  loss_box_reg_stage1: 0.2473  loss_cls_stage2: 0.1759  loss_box_reg_stage2: 0.1858  loss_mask: 0.594  loss_rpn_cls: 0.083  loss_rpn_loc: 0.04066  validation_loss: 1.92  time: 1.7795  data_time: 0.0240  lr: 7.3271e-05  max_mem: 10810M\n",
      "\u001b[32m[03/26 12:27:24 d2.utils.events]: \u001b[0m eta: 2:47:45  iter: 3479  total_loss: 2.019  loss_cls_stage0: 0.2754  loss_box_reg_stage0: 0.1936  loss_cls_stage1: 0.2179  loss_box_reg_stage1: 0.2466  loss_cls_stage2: 0.161  loss_box_reg_stage2: 0.1841  loss_mask: 0.5673  loss_rpn_cls: 0.08538  loss_rpn_loc: 0.03651  validation_loss: 1.92  time: 1.7780  data_time: 0.0226  lr: 7.2993e-05  max_mem: 10810M\n",
      "\u001b[32m[03/26 12:27:55 d2.utils.events]: \u001b[0m eta: 2:47:18  iter: 3499  total_loss: 2.141  loss_cls_stage0: 0.3379  loss_box_reg_stage0: 0.2143  loss_cls_stage1: 0.2622  loss_box_reg_stage1: 0.2786  loss_cls_stage2: 0.1872  loss_box_reg_stage2: 0.2098  loss_mask: 0.5515  loss_rpn_cls: 0.07937  loss_rpn_loc: 0.03567  validation_loss: 1.92  time: 1.7766  data_time: 0.0242  lr: 7.2714e-05  max_mem: 10810M\n",
      "\u001b[32m[03/26 12:28:26 d2.utils.events]: \u001b[0m eta: 2:46:51  iter: 3519  total_loss: 2.115  loss_cls_stage0: 0.321  loss_box_reg_stage0: 0.2117  loss_cls_stage1: 0.2589  loss_box_reg_stage1: 0.2684  loss_cls_stage2: 0.183  loss_box_reg_stage2: 0.218  loss_mask: 0.5933  loss_rpn_cls: 0.08834  loss_rpn_loc: 0.04245  validation_loss: 1.92  time: 1.7753  data_time: 0.0235  lr: 7.2433e-05  max_mem: 10810M\n",
      "\u001b[32m[03/26 12:28:56 d2.utils.events]: \u001b[0m eta: 2:46:06  iter: 3539  total_loss: 2.105  loss_cls_stage0: 0.3308  loss_box_reg_stage0: 0.2148  loss_cls_stage1: 0.2526  loss_box_reg_stage1: 0.2678  loss_cls_stage2: 0.1742  loss_box_reg_stage2: 0.2115  loss_mask: 0.5647  loss_rpn_cls: 0.08737  loss_rpn_loc: 0.04015  validation_loss: 1.92  time: 1.7739  data_time: 0.0250  lr: 7.2152e-05  max_mem: 10879M\n",
      "\u001b[32m[03/26 12:29:27 d2.utils.events]: \u001b[0m eta: 2:45:22  iter: 3559  total_loss: 1.815  loss_cls_stage0: 0.2752  loss_box_reg_stage0: 0.1908  loss_cls_stage1: 0.2185  loss_box_reg_stage1: 0.2253  loss_cls_stage2: 0.1573  loss_box_reg_stage2: 0.1773  loss_mask: 0.5685  loss_rpn_cls: 0.07604  loss_rpn_loc: 0.03546  validation_loss: 1.92  time: 1.7725  data_time: 0.0238  lr: 7.187e-05  max_mem: 10879M\n",
      "\u001b[32m[03/26 12:29:58 d2.utils.events]: \u001b[0m eta: 2:44:42  iter: 3579  total_loss: 2.052  loss_cls_stage0: 0.2798  loss_box_reg_stage0: 0.1903  loss_cls_stage1: 0.2288  loss_box_reg_stage1: 0.2472  loss_cls_stage2: 0.1628  loss_box_reg_stage2: 0.1893  loss_mask: 0.5756  loss_rpn_cls: 0.0891  loss_rpn_loc: 0.03936  validation_loss: 1.92  time: 1.7712  data_time: 0.0293  lr: 7.1587e-05  max_mem: 10879M\n",
      "\u001b[32m[03/26 12:30:28 d2.utils.events]: \u001b[0m eta: 2:43:57  iter: 3599  total_loss: 2.247  loss_cls_stage0: 0.3227  loss_box_reg_stage0: 0.2175  loss_cls_stage1: 0.2581  loss_box_reg_stage1: 0.2867  loss_cls_stage2: 0.1862  loss_box_reg_stage2: 0.2133  loss_mask: 0.5611  loss_rpn_cls: 0.08823  loss_rpn_loc: 0.0401  validation_loss: 1.92  time: 1.7699  data_time: 0.0233  lr: 7.1303e-05  max_mem: 10879M\n",
      "\u001b[32m[03/26 12:30:59 d2.utils.events]: \u001b[0m eta: 2:43:09  iter: 3619  total_loss: 2.055  loss_cls_stage0: 0.3003  loss_box_reg_stage0: 0.1962  loss_cls_stage1: 0.2428  loss_box_reg_stage1: 0.2513  loss_cls_stage2: 0.1815  loss_box_reg_stage2: 0.1976  loss_mask: 0.5724  loss_rpn_cls: 0.0718  loss_rpn_loc: 0.03446  validation_loss: 1.92  time: 1.7686  data_time: 0.0242  lr: 7.1019e-05  max_mem: 10879M\n",
      "\u001b[32m[03/26 12:31:30 d2.utils.events]: \u001b[0m eta: 2:42:35  iter: 3639  total_loss: 2.109  loss_cls_stage0: 0.3202  loss_box_reg_stage0: 0.2118  loss_cls_stage1: 0.2611  loss_box_reg_stage1: 0.2962  loss_cls_stage2: 0.1871  loss_box_reg_stage2: 0.2234  loss_mask: 0.5126  loss_rpn_cls: 0.07653  loss_rpn_loc: 0.04251  validation_loss: 1.92  time: 1.7673  data_time: 0.0242  lr: 7.0733e-05  max_mem: 10879M\n",
      "\u001b[32m[03/26 12:32:01 d2.utils.events]: \u001b[0m eta: 2:42:02  iter: 3659  total_loss: 2.322  loss_cls_stage0: 0.3552  loss_box_reg_stage0: 0.2311  loss_cls_stage1: 0.2997  loss_box_reg_stage1: 0.2998  loss_cls_stage2: 0.2006  loss_box_reg_stage2: 0.2112  loss_mask: 0.5573  loss_rpn_cls: 0.08701  loss_rpn_loc: 0.04141  validation_loss: 1.92  time: 1.7660  data_time: 0.0240  lr: 7.0447e-05  max_mem: 10879M\n",
      "\u001b[32m[03/26 12:32:31 d2.utils.events]: \u001b[0m eta: 2:41:32  iter: 3679  total_loss: 2.058  loss_cls_stage0: 0.2864  loss_box_reg_stage0: 0.1962  loss_cls_stage1: 0.2404  loss_box_reg_stage1: 0.2496  loss_cls_stage2: 0.1702  loss_box_reg_stage2: 0.198  loss_mask: 0.5764  loss_rpn_cls: 0.08068  loss_rpn_loc: 0.03678  validation_loss: 1.92  time: 1.7648  data_time: 0.0237  lr: 7.016e-05  max_mem: 10879M\n",
      "\u001b[32m[03/26 12:33:02 d2.utils.events]: \u001b[0m eta: 2:41:01  iter: 3699  total_loss: 2.135  loss_cls_stage0: 0.3424  loss_box_reg_stage0: 0.2243  loss_cls_stage1: 0.2699  loss_box_reg_stage1: 0.278  loss_cls_stage2: 0.1764  loss_box_reg_stage2: 0.2009  loss_mask: 0.5283  loss_rpn_cls: 0.08272  loss_rpn_loc: 0.03749  validation_loss: 1.92  time: 1.7636  data_time: 0.0232  lr: 6.9872e-05  max_mem: 10928M\n",
      "\u001b[32m[03/26 12:33:33 d2.utils.events]: \u001b[0m eta: 2:40:24  iter: 3719  total_loss: 2.101  loss_cls_stage0: 0.2963  loss_box_reg_stage0: 0.1986  loss_cls_stage1: 0.2215  loss_box_reg_stage1: 0.2727  loss_cls_stage2: 0.1576  loss_box_reg_stage2: 0.2112  loss_mask: 0.4959  loss_rpn_cls: 0.07268  loss_rpn_loc: 0.03412  validation_loss: 1.92  time: 1.7624  data_time: 0.0245  lr: 6.9583e-05  max_mem: 10928M\n",
      "\u001b[32m[03/26 12:34:04 d2.utils.events]: \u001b[0m eta: 2:39:47  iter: 3739  total_loss: 2.224  loss_cls_stage0: 0.3333  loss_box_reg_stage0: 0.2329  loss_cls_stage1: 0.2665  loss_box_reg_stage1: 0.2904  loss_cls_stage2: 0.1938  loss_box_reg_stage2: 0.2248  loss_mask: 0.5541  loss_rpn_cls: 0.08689  loss_rpn_loc: 0.04197  validation_loss: 1.92  time: 1.7612  data_time: 0.0235  lr: 6.9294e-05  max_mem: 10928M\n",
      "\u001b[32m[03/26 12:34:35 d2.utils.events]: \u001b[0m eta: 2:39:13  iter: 3759  total_loss: 2.204  loss_cls_stage0: 0.3179  loss_box_reg_stage0: 0.2204  loss_cls_stage1: 0.2559  loss_box_reg_stage1: 0.2816  loss_cls_stage2: 0.1805  loss_box_reg_stage2: 0.2353  loss_mask: 0.5539  loss_rpn_cls: 0.0717  loss_rpn_loc: 0.0333  validation_loss: 1.92  time: 1.7600  data_time: 0.0237  lr: 6.9003e-05  max_mem: 10928M\n",
      "\u001b[32m[03/26 12:35:06 d2.utils.events]: \u001b[0m eta: 2:38:40  iter: 3779  total_loss: 2.012  loss_cls_stage0: 0.3168  loss_box_reg_stage0: 0.2197  loss_cls_stage1: 0.248  loss_box_reg_stage1: 0.2926  loss_cls_stage2: 0.1666  loss_box_reg_stage2: 0.2333  loss_mask: 0.5269  loss_rpn_cls: 0.08316  loss_rpn_loc: 0.0367  validation_loss: 1.92  time: 1.7589  data_time: 0.0235  lr: 6.8713e-05  max_mem: 11066M\n",
      "\u001b[32m[03/26 12:35:36 d2.utils.events]: \u001b[0m eta: 2:38:04  iter: 3799  total_loss: 2.086  loss_cls_stage0: 0.3153  loss_box_reg_stage0: 0.2054  loss_cls_stage1: 0.2536  loss_box_reg_stage1: 0.2763  loss_cls_stage2: 0.1662  loss_box_reg_stage2: 0.2119  loss_mask: 0.5578  loss_rpn_cls: 0.07745  loss_rpn_loc: 0.03437  validation_loss: 1.92  time: 1.7577  data_time: 0.0240  lr: 6.8421e-05  max_mem: 11066M\n",
      "\u001b[32m[03/26 12:36:08 d2.utils.events]: \u001b[0m eta: 2:37:32  iter: 3819  total_loss: 2.087  loss_cls_stage0: 0.3034  loss_box_reg_stage0: 0.2075  loss_cls_stage1: 0.2422  loss_box_reg_stage1: 0.2641  loss_cls_stage2: 0.177  loss_box_reg_stage2: 0.2221  loss_mask: 0.5761  loss_rpn_cls: 0.08005  loss_rpn_loc: 0.03684  validation_loss: 1.92  time: 1.7567  data_time: 0.0249  lr: 6.8128e-05  max_mem: 11066M\n",
      "\u001b[32m[03/26 12:36:38 d2.utils.events]: \u001b[0m eta: 2:36:59  iter: 3839  total_loss: 2.155  loss_cls_stage0: 0.3169  loss_box_reg_stage0: 0.2235  loss_cls_stage1: 0.2483  loss_box_reg_stage1: 0.3003  loss_cls_stage2: 0.1803  loss_box_reg_stage2: 0.2361  loss_mask: 0.5474  loss_rpn_cls: 0.0694  loss_rpn_loc: 0.03459  validation_loss: 1.92  time: 1.7555  data_time: 0.0229  lr: 6.7835e-05  max_mem: 11066M\n",
      "\u001b[32m[03/26 12:37:10 d2.utils.events]: \u001b[0m eta: 2:36:29  iter: 3859  total_loss: 2.033  loss_cls_stage0: 0.3041  loss_box_reg_stage0: 0.2085  loss_cls_stage1: 0.2363  loss_box_reg_stage1: 0.2631  loss_cls_stage2: 0.1715  loss_box_reg_stage2: 0.2325  loss_mask: 0.5328  loss_rpn_cls: 0.07192  loss_rpn_loc: 0.03393  validation_loss: 1.92  time: 1.7545  data_time: 0.0235  lr: 6.7541e-05  max_mem: 11066M\n",
      "\u001b[32m[03/26 12:37:43 d2.utils.events]: \u001b[0m eta: 2:35:59  iter: 3879  total_loss: 2.023  loss_cls_stage0: 0.2723  loss_box_reg_stage0: 0.1997  loss_cls_stage1: 0.2142  loss_box_reg_stage1: 0.2547  loss_cls_stage2: 0.1502  loss_box_reg_stage2: 0.1964  loss_mask: 0.5734  loss_rpn_cls: 0.0747  loss_rpn_loc: 0.03678  validation_loss: 1.92  time: 1.7542  data_time: 0.0233  lr: 6.7247e-05  max_mem: 11066M\n",
      "\u001b[32m[03/26 12:38:28 d2.utils.events]: \u001b[0m eta: 2:35:35  iter: 3899  total_loss: 2.122  loss_cls_stage0: 0.2983  loss_box_reg_stage0: 0.2092  loss_cls_stage1: 0.2456  loss_box_reg_stage1: 0.2795  loss_cls_stage2: 0.1797  loss_box_reg_stage2: 0.2131  loss_mask: 0.5647  loss_rpn_cls: 0.07805  loss_rpn_loc: 0.04351  validation_loss: 1.92  time: 1.7566  data_time: 0.0230  lr: 6.6952e-05  max_mem: 11066M\n",
      "\u001b[32m[03/26 12:39:12 d2.utils.events]: \u001b[0m eta: 2:35:09  iter: 3919  total_loss: 2.025  loss_cls_stage0: 0.2938  loss_box_reg_stage0: 0.201  loss_cls_stage1: 0.2473  loss_box_reg_stage1: 0.2655  loss_cls_stage2: 0.1735  loss_box_reg_stage2: 0.2111  loss_mask: 0.5269  loss_rpn_cls: 0.06984  loss_rpn_loc: 0.03525  validation_loss: 1.92  time: 1.7589  data_time: 0.0232  lr: 6.6656e-05  max_mem: 11066M\n",
      "\u001b[32m[03/26 12:39:57 d2.utils.events]: \u001b[0m eta: 2:34:47  iter: 3939  total_loss: 2.198  loss_cls_stage0: 0.3243  loss_box_reg_stage0: 0.2308  loss_cls_stage1: 0.2568  loss_box_reg_stage1: 0.2825  loss_cls_stage2: 0.1848  loss_box_reg_stage2: 0.2365  loss_mask: 0.5407  loss_rpn_cls: 0.07372  loss_rpn_loc: 0.03535  validation_loss: 1.92  time: 1.7613  data_time: 0.0242  lr: 6.6359e-05  max_mem: 11102M\n",
      "\u001b[32m[03/26 12:40:41 d2.utils.events]: \u001b[0m eta: 2:34:23  iter: 3959  total_loss: 2.097  loss_cls_stage0: 0.313  loss_box_reg_stage0: 0.2078  loss_cls_stage1: 0.247  loss_box_reg_stage1: 0.2605  loss_cls_stage2: 0.174  loss_box_reg_stage2: 0.2117  loss_mask: 0.5644  loss_rpn_cls: 0.07954  loss_rpn_loc: 0.03646  validation_loss: 1.92  time: 1.7635  data_time: 0.0232  lr: 6.6062e-05  max_mem: 11102M\n",
      "\u001b[32m[03/26 12:41:25 d2.utils.events]: \u001b[0m eta: 2:33:58  iter: 3979  total_loss: 2.021  loss_cls_stage0: 0.2873  loss_box_reg_stage0: 0.1971  loss_cls_stage1: 0.2333  loss_box_reg_stage1: 0.2758  loss_cls_stage2: 0.1587  loss_box_reg_stage2: 0.2196  loss_mask: 0.5613  loss_rpn_cls: 0.07533  loss_rpn_loc: 0.03282  validation_loss: 1.92  time: 1.7658  data_time: 0.0241  lr: 6.5764e-05  max_mem: 11102M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/26 12:42:11 d2.data.common]: \u001b[0mSerializing 900 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/26 12:42:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.91 MiB\n",
      "\u001b[32m[03/26 12:42:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 900 images\n",
      "\u001b[32m[03/26 12:42:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/900. 0.1140 s / img. ETA=0:02:20\n",
      "\u001b[32m[03/26 12:42:18 d2.evaluation.evaluator]: \u001b[0mInference done 45/900. 0.1121 s / img. ETA=0:02:08\n",
      "\u001b[32m[03/26 12:42:23 d2.evaluation.evaluator]: \u001b[0mInference done 77/900. 0.1152 s / img. ETA=0:02:06\n",
      "\u001b[32m[03/26 12:42:28 d2.evaluation.evaluator]: \u001b[0mInference done 110/900. 0.1153 s / img. ETA=0:02:00\n",
      "\u001b[32m[03/26 12:42:33 d2.evaluation.evaluator]: \u001b[0mInference done 143/900. 0.1164 s / img. ETA=0:01:55\n",
      "\u001b[32m[03/26 12:42:39 d2.evaluation.evaluator]: \u001b[0mInference done 177/900. 0.1160 s / img. ETA=0:01:50\n",
      "\u001b[32m[03/26 12:42:44 d2.evaluation.evaluator]: \u001b[0mInference done 211/900. 0.1156 s / img. ETA=0:01:44\n",
      "\u001b[32m[03/26 12:42:49 d2.evaluation.evaluator]: \u001b[0mInference done 244/900. 0.1156 s / img. ETA=0:01:39\n",
      "\u001b[32m[03/26 12:42:54 d2.evaluation.evaluator]: \u001b[0mInference done 278/900. 0.1151 s / img. ETA=0:01:34\n",
      "\u001b[32m[03/26 12:42:59 d2.evaluation.evaluator]: \u001b[0mInference done 313/900. 0.1152 s / img. ETA=0:01:28\n",
      "\u001b[32m[03/26 12:43:04 d2.evaluation.evaluator]: \u001b[0mInference done 347/900. 0.1153 s / img. ETA=0:01:23\n",
      "\u001b[32m[03/26 12:43:09 d2.evaluation.evaluator]: \u001b[0mInference done 384/900. 0.1150 s / img. ETA=0:01:17\n",
      "\u001b[32m[03/26 12:43:14 d2.evaluation.evaluator]: \u001b[0mInference done 418/900. 0.1158 s / img. ETA=0:01:12\n",
      "\u001b[32m[03/26 12:43:19 d2.evaluation.evaluator]: \u001b[0mInference done 452/900. 0.1164 s / img. ETA=0:01:07\n",
      "\u001b[32m[03/26 12:43:24 d2.evaluation.evaluator]: \u001b[0mInference done 486/900. 0.1167 s / img. ETA=0:01:01\n",
      "\u001b[32m[03/26 12:43:29 d2.evaluation.evaluator]: \u001b[0mInference done 520/900. 0.1171 s / img. ETA=0:00:56\n",
      "\u001b[32m[03/26 12:43:34 d2.evaluation.evaluator]: \u001b[0mInference done 554/900. 0.1177 s / img. ETA=0:00:51\n",
      "\u001b[32m[03/26 12:43:39 d2.evaluation.evaluator]: \u001b[0mInference done 588/900. 0.1178 s / img. ETA=0:00:46\n",
      "\u001b[32m[03/26 12:43:44 d2.evaluation.evaluator]: \u001b[0mInference done 622/900. 0.1183 s / img. ETA=0:00:41\n",
      "\u001b[32m[03/26 12:43:50 d2.evaluation.evaluator]: \u001b[0mInference done 656/900. 0.1185 s / img. ETA=0:00:36\n",
      "\u001b[32m[03/26 12:43:55 d2.evaluation.evaluator]: \u001b[0mInference done 690/900. 0.1188 s / img. ETA=0:00:31\n",
      "\u001b[32m[03/26 12:44:00 d2.evaluation.evaluator]: \u001b[0mInference done 724/900. 0.1190 s / img. ETA=0:00:26\n",
      "\u001b[32m[03/26 12:44:05 d2.evaluation.evaluator]: \u001b[0mInference done 758/900. 0.1192 s / img. ETA=0:00:21\n",
      "\u001b[32m[03/26 12:44:10 d2.evaluation.evaluator]: \u001b[0mInference done 792/900. 0.1194 s / img. ETA=0:00:16\n",
      "\u001b[32m[03/26 12:44:15 d2.evaluation.evaluator]: \u001b[0mInference done 839/900. 0.1174 s / img. ETA=0:00:08\n",
      "\u001b[32m[03/26 12:44:20 d2.evaluation.evaluator]: \u001b[0mInference done 887/900. 0.1154 s / img. ETA=0:00:01\n",
      "\u001b[32m[03/26 12:44:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:08.974115 (0.144105 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/26 12:44:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:42 (0.114853 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.44 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.066\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.112\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.118\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.030\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.097\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.115\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.115\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.039\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.120\n",
      "\u001b[32m[03/26 12:44:22 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold1 in csv format:\n",
      "\u001b[32m[03/26 12:44:22 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/26 12:44:22 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/26 12:44:22 d2.evaluation.testing]: \u001b[0mcopypaste: 6.6317,11.1980,11.8048,0.7367,3.0487,6.7996\n",
      "validation do loss eval 2.0953090447719376\n",
      "\u001b[32m[03/26 12:46:21 d2.utils.events]: \u001b[0m eta: 2:33:40  iter: 3999  total_loss: 2.041  loss_cls_stage0: 0.2747  loss_box_reg_stage0: 0.1908  loss_cls_stage1: 0.2239  loss_box_reg_stage1: 0.26  loss_cls_stage2: 0.1594  loss_box_reg_stage2: 0.208  loss_mask: 0.5885  loss_rpn_cls: 0.08177  loss_rpn_loc: 0.03545  validation_loss: 1.958  time: 1.7679  data_time: 0.0230  lr: 6.5466e-05  max_mem: 11102M\n",
      "\u001b[32m[03/26 12:47:05 d2.utils.events]: \u001b[0m eta: 2:33:09  iter: 4019  total_loss: 2.113  loss_cls_stage0: 0.291  loss_box_reg_stage0: 0.2146  loss_cls_stage1: 0.2408  loss_box_reg_stage1: 0.2823  loss_cls_stage2: 0.1754  loss_box_reg_stage2: 0.2162  loss_mask: 0.5489  loss_rpn_cls: 0.07323  loss_rpn_loc: 0.03672  validation_loss: 1.958  time: 1.7700  data_time: 0.0231  lr: 6.5167e-05  max_mem: 11126M\n",
      "\u001b[32m[03/26 12:47:49 d2.utils.events]: \u001b[0m eta: 2:32:38  iter: 4039  total_loss: 2.05  loss_cls_stage0: 0.2749  loss_box_reg_stage0: 0.1937  loss_cls_stage1: 0.2162  loss_box_reg_stage1: 0.2635  loss_cls_stage2: 0.1653  loss_box_reg_stage2: 0.2385  loss_mask: 0.5787  loss_rpn_cls: 0.06848  loss_rpn_loc: 0.03225  validation_loss: 1.958  time: 1.7722  data_time: 0.0228  lr: 6.4867e-05  max_mem: 11126M\n",
      "\u001b[32m[03/26 12:48:33 d2.utils.events]: \u001b[0m eta: 2:32:07  iter: 4059  total_loss: 2.119  loss_cls_stage0: 0.3023  loss_box_reg_stage0: 0.2141  loss_cls_stage1: 0.2526  loss_box_reg_stage1: 0.296  loss_cls_stage2: 0.1723  loss_box_reg_stage2: 0.218  loss_mask: 0.5694  loss_rpn_cls: 0.06674  loss_rpn_loc: 0.03108  validation_loss: 1.958  time: 1.7744  data_time: 0.0241  lr: 6.4567e-05  max_mem: 11126M\n",
      "\u001b[32m[03/26 12:49:17 d2.utils.events]: \u001b[0m eta: 2:31:38  iter: 4079  total_loss: 2.329  loss_cls_stage0: 0.338  loss_box_reg_stage0: 0.2373  loss_cls_stage1: 0.2675  loss_box_reg_stage1: 0.3021  loss_cls_stage2: 0.188  loss_box_reg_stage2: 0.2272  loss_mask: 0.5804  loss_rpn_cls: 0.08704  loss_rpn_loc: 0.03965  validation_loss: 1.958  time: 1.7765  data_time: 0.0241  lr: 6.4266e-05  max_mem: 11142M\n",
      "\u001b[32m[03/26 12:50:02 d2.utils.events]: \u001b[0m eta: 2:31:19  iter: 4099  total_loss: 2.087  loss_cls_stage0: 0.2949  loss_box_reg_stage0: 0.2039  loss_cls_stage1: 0.232  loss_box_reg_stage1: 0.2805  loss_cls_stage2: 0.1562  loss_box_reg_stage2: 0.2059  loss_mask: 0.5586  loss_rpn_cls: 0.0714  loss_rpn_loc: 0.03775  validation_loss: 1.958  time: 1.7788  data_time: 0.0230  lr: 6.3965e-05  max_mem: 11142M\n",
      "\u001b[32m[03/26 12:50:46 d2.utils.events]: \u001b[0m eta: 2:30:59  iter: 4119  total_loss: 2.142  loss_cls_stage0: 0.3009  loss_box_reg_stage0: 0.2238  loss_cls_stage1: 0.2521  loss_box_reg_stage1: 0.3171  loss_cls_stage2: 0.1802  loss_box_reg_stage2: 0.229  loss_mask: 0.4993  loss_rpn_cls: 0.06979  loss_rpn_loc: 0.03794  validation_loss: 1.958  time: 1.7808  data_time: 0.0247  lr: 6.3663e-05  max_mem: 11142M\n",
      "\u001b[32m[03/26 12:51:31 d2.utils.events]: \u001b[0m eta: 2:30:38  iter: 4139  total_loss: 2.028  loss_cls_stage0: 0.2935  loss_box_reg_stage0: 0.2015  loss_cls_stage1: 0.2285  loss_box_reg_stage1: 0.2712  loss_cls_stage2: 0.1722  loss_box_reg_stage2: 0.2328  loss_mask: 0.5775  loss_rpn_cls: 0.07367  loss_rpn_loc: 0.03713  validation_loss: 1.958  time: 1.7830  data_time: 0.0234  lr: 6.336e-05  max_mem: 11142M\n",
      "\u001b[32m[03/26 12:52:11 d2.utils.events]: \u001b[0m eta: 2:30:13  iter: 4159  total_loss: 2.139  loss_cls_stage0: 0.3114  loss_box_reg_stage0: 0.2282  loss_cls_stage1: 0.2552  loss_box_reg_stage1: 0.2905  loss_cls_stage2: 0.177  loss_box_reg_stage2: 0.2164  loss_mask: 0.5811  loss_rpn_cls: 0.07638  loss_rpn_loc: 0.03796  validation_loss: 1.958  time: 1.7840  data_time: 0.0240  lr: 6.3057e-05  max_mem: 11142M\n",
      "\u001b[32m[03/26 12:52:41 d2.utils.events]: \u001b[0m eta: 2:29:43  iter: 4179  total_loss: 2.109  loss_cls_stage0: 0.2948  loss_box_reg_stage0: 0.2145  loss_cls_stage1: 0.2422  loss_box_reg_stage1: 0.278  loss_cls_stage2: 0.1727  loss_box_reg_stage2: 0.2148  loss_mask: 0.5413  loss_rpn_cls: 0.07313  loss_rpn_loc: 0.03574  validation_loss: 1.958  time: 1.7829  data_time: 0.0237  lr: 6.2754e-05  max_mem: 11142M\n",
      "\u001b[32m[03/26 12:53:12 d2.utils.events]: \u001b[0m eta: 2:29:15  iter: 4199  total_loss: 2.256  loss_cls_stage0: 0.3205  loss_box_reg_stage0: 0.2324  loss_cls_stage1: 0.2644  loss_box_reg_stage1: 0.2998  loss_cls_stage2: 0.1911  loss_box_reg_stage2: 0.2439  loss_mask: 0.5494  loss_rpn_cls: 0.07851  loss_rpn_loc: 0.03937  validation_loss: 1.958  time: 1.7817  data_time: 0.0243  lr: 6.245e-05  max_mem: 11142M\n",
      "\u001b[32m[03/26 12:53:43 d2.utils.events]: \u001b[0m eta: 2:28:48  iter: 4219  total_loss: 2.216  loss_cls_stage0: 0.3203  loss_box_reg_stage0: 0.235  loss_cls_stage1: 0.2531  loss_box_reg_stage1: 0.3119  loss_cls_stage2: 0.1802  loss_box_reg_stage2: 0.2431  loss_mask: 0.5854  loss_rpn_cls: 0.08015  loss_rpn_loc: 0.03921  validation_loss: 1.958  time: 1.7806  data_time: 0.0234  lr: 6.2145e-05  max_mem: 11142M\n",
      "\u001b[32m[03/26 12:54:14 d2.utils.events]: \u001b[0m eta: 2:28:20  iter: 4239  total_loss: 2.196  loss_cls_stage0: 0.3126  loss_box_reg_stage0: 0.2052  loss_cls_stage1: 0.2634  loss_box_reg_stage1: 0.2866  loss_cls_stage2: 0.2003  loss_box_reg_stage2: 0.2451  loss_mask: 0.5506  loss_rpn_cls: 0.07169  loss_rpn_loc: 0.03469  validation_loss: 1.958  time: 1.7795  data_time: 0.0244  lr: 6.184e-05  max_mem: 11142M\n",
      "\u001b[32m[03/26 12:54:45 d2.utils.events]: \u001b[0m eta: 2:27:52  iter: 4259  total_loss: 2.167  loss_cls_stage0: 0.3088  loss_box_reg_stage0: 0.2229  loss_cls_stage1: 0.2364  loss_box_reg_stage1: 0.304  loss_cls_stage2: 0.1747  loss_box_reg_stage2: 0.2355  loss_mask: 0.5349  loss_rpn_cls: 0.06187  loss_rpn_loc: 0.03429  validation_loss: 1.958  time: 1.7784  data_time: 0.0232  lr: 6.1535e-05  max_mem: 11142M\n",
      "\u001b[32m[03/26 12:55:16 d2.utils.events]: \u001b[0m eta: 2:27:22  iter: 4279  total_loss: 2.051  loss_cls_stage0: 0.284  loss_box_reg_stage0: 0.1981  loss_cls_stage1: 0.2315  loss_box_reg_stage1: 0.2973  loss_cls_stage2: 0.1667  loss_box_reg_stage2: 0.2436  loss_mask: 0.5498  loss_rpn_cls: 0.07554  loss_rpn_loc: 0.0352  validation_loss: 1.958  time: 1.7773  data_time: 0.0244  lr: 6.1229e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 12:55:54 d2.utils.events]: \u001b[0m eta: 2:26:55  iter: 4299  total_loss: 2.17  loss_cls_stage0: 0.3257  loss_box_reg_stage0: 0.2332  loss_cls_stage1: 0.2655  loss_box_reg_stage1: 0.3253  loss_cls_stage2: 0.1779  loss_box_reg_stage2: 0.2462  loss_mask: 0.5577  loss_rpn_cls: 0.06555  loss_rpn_loc: 0.03851  validation_loss: 1.958  time: 1.7778  data_time: 0.0233  lr: 6.0922e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 12:56:43 d2.utils.events]: \u001b[0m eta: 2:26:30  iter: 4319  total_loss: 2.256  loss_cls_stage0: 0.3224  loss_box_reg_stage0: 0.2371  loss_cls_stage1: 0.2541  loss_box_reg_stage1: 0.3055  loss_cls_stage2: 0.1902  loss_box_reg_stage2: 0.2477  loss_mask: 0.5554  loss_rpn_cls: 0.06333  loss_rpn_loc: 0.03867  validation_loss: 1.958  time: 1.7809  data_time: 0.0304  lr: 6.0616e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 12:57:33 d2.utils.events]: \u001b[0m eta: 2:26:10  iter: 4339  total_loss: 2.245  loss_cls_stage0: 0.3201  loss_box_reg_stage0: 0.237  loss_cls_stage1: 0.263  loss_box_reg_stage1: 0.3205  loss_cls_stage2: 0.1781  loss_box_reg_stage2: 0.2219  loss_mask: 0.575  loss_rpn_cls: 0.0767  loss_rpn_loc: 0.0364  validation_loss: 1.958  time: 1.7842  data_time: 0.0244  lr: 6.0309e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 12:58:23 d2.utils.events]: \u001b[0m eta: 2:25:50  iter: 4359  total_loss: 2.225  loss_cls_stage0: 0.3364  loss_box_reg_stage0: 0.2431  loss_cls_stage1: 0.2563  loss_box_reg_stage1: 0.3172  loss_cls_stage2: 0.1794  loss_box_reg_stage2: 0.2368  loss_mask: 0.5523  loss_rpn_cls: 0.07711  loss_rpn_loc: 0.04116  validation_loss: 1.958  time: 1.7875  data_time: 0.0226  lr: 6.0001e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 12:59:12 d2.utils.events]: \u001b[0m eta: 2:25:34  iter: 4379  total_loss: 2.421  loss_cls_stage0: 0.3266  loss_box_reg_stage0: 0.2536  loss_cls_stage1: 0.276  loss_box_reg_stage1: 0.34  loss_cls_stage2: 0.1906  loss_box_reg_stage2: 0.262  loss_mask: 0.5214  loss_rpn_cls: 0.0692  loss_rpn_loc: 0.04215  validation_loss: 1.958  time: 1.7907  data_time: 0.0222  lr: 5.9693e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:00:02 d2.utils.events]: \u001b[0m eta: 2:25:36  iter: 4399  total_loss: 2.315  loss_cls_stage0: 0.339  loss_box_reg_stage0: 0.2509  loss_cls_stage1: 0.2673  loss_box_reg_stage1: 0.3282  loss_cls_stage2: 0.1924  loss_box_reg_stage2: 0.2559  loss_mask: 0.5759  loss_rpn_cls: 0.08412  loss_rpn_loc: 0.04196  validation_loss: 1.958  time: 1.7937  data_time: 0.0246  lr: 5.9384e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:00:41 d2.utils.events]: \u001b[0m eta: 2:25:20  iter: 4419  total_loss: 2.146  loss_cls_stage0: 0.309  loss_box_reg_stage0: 0.2142  loss_cls_stage1: 0.2436  loss_box_reg_stage1: 0.2962  loss_cls_stage2: 0.1793  loss_box_reg_stage2: 0.2393  loss_mask: 0.5608  loss_rpn_cls: 0.08286  loss_rpn_loc: 0.04152  validation_loss: 1.958  time: 1.7944  data_time: 0.0228  lr: 5.9076e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:01:12 d2.utils.events]: \u001b[0m eta: 2:24:54  iter: 4439  total_loss: 2.286  loss_cls_stage0: 0.3236  loss_box_reg_stage0: 0.2593  loss_cls_stage1: 0.2614  loss_box_reg_stage1: 0.3149  loss_cls_stage2: 0.1768  loss_box_reg_stage2: 0.231  loss_mask: 0.5532  loss_rpn_cls: 0.07279  loss_rpn_loc: 0.03715  validation_loss: 1.958  time: 1.7933  data_time: 0.0240  lr: 5.8767e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:01:42 d2.utils.events]: \u001b[0m eta: 2:24:30  iter: 4459  total_loss: 2.189  loss_cls_stage0: 0.2971  loss_box_reg_stage0: 0.2189  loss_cls_stage1: 0.2405  loss_box_reg_stage1: 0.306  loss_cls_stage2: 0.174  loss_box_reg_stage2: 0.2445  loss_mask: 0.5915  loss_rpn_cls: 0.07331  loss_rpn_loc: 0.03686  validation_loss: 1.958  time: 1.7922  data_time: 0.0250  lr: 5.8457e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:02:14 d2.utils.events]: \u001b[0m eta: 2:24:03  iter: 4479  total_loss: 2.175  loss_cls_stage0: 0.3017  loss_box_reg_stage0: 0.2214  loss_cls_stage1: 0.2524  loss_box_reg_stage1: 0.297  loss_cls_stage2: 0.1793  loss_box_reg_stage2: 0.2568  loss_mask: 0.5605  loss_rpn_cls: 0.07351  loss_rpn_loc: 0.03742  validation_loss: 1.958  time: 1.7911  data_time: 0.0232  lr: 5.8147e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:02:45 d2.utils.events]: \u001b[0m eta: 2:23:35  iter: 4499  total_loss: 2.318  loss_cls_stage0: 0.3273  loss_box_reg_stage0: 0.2373  loss_cls_stage1: 0.2774  loss_box_reg_stage1: 0.3352  loss_cls_stage2: 0.1976  loss_box_reg_stage2: 0.2547  loss_mask: 0.5578  loss_rpn_cls: 0.06971  loss_rpn_loc: 0.03578  validation_loss: 1.958  time: 1.7900  data_time: 0.0236  lr: 5.7837e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:03:16 d2.utils.events]: \u001b[0m eta: 2:23:05  iter: 4519  total_loss: 2.35  loss_cls_stage0: 0.3296  loss_box_reg_stage0: 0.2419  loss_cls_stage1: 0.275  loss_box_reg_stage1: 0.3151  loss_cls_stage2: 0.1855  loss_box_reg_stage2: 0.2508  loss_mask: 0.5757  loss_rpn_cls: 0.06464  loss_rpn_loc: 0.03677  validation_loss: 1.958  time: 1.7890  data_time: 0.0232  lr: 5.7527e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:03:47 d2.utils.events]: \u001b[0m eta: 2:22:42  iter: 4539  total_loss: 2.402  loss_cls_stage0: 0.3568  loss_box_reg_stage0: 0.2581  loss_cls_stage1: 0.2802  loss_box_reg_stage1: 0.3446  loss_cls_stage2: 0.1984  loss_box_reg_stage2: 0.275  loss_mask: 0.5542  loss_rpn_cls: 0.06791  loss_rpn_loc: 0.03533  validation_loss: 1.958  time: 1.7880  data_time: 0.0230  lr: 5.7216e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:04:18 d2.utils.events]: \u001b[0m eta: 2:22:24  iter: 4559  total_loss: 2.421  loss_cls_stage0: 0.3492  loss_box_reg_stage0: 0.2564  loss_cls_stage1: 0.3058  loss_box_reg_stage1: 0.3472  loss_cls_stage2: 0.2199  loss_box_reg_stage2: 0.2677  loss_mask: 0.5679  loss_rpn_cls: 0.06825  loss_rpn_loc: 0.03866  validation_loss: 1.958  time: 1.7870  data_time: 0.0234  lr: 5.6905e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:04:49 d2.utils.events]: \u001b[0m eta: 2:21:53  iter: 4579  total_loss: 2.1  loss_cls_stage0: 0.3089  loss_box_reg_stage0: 0.2204  loss_cls_stage1: 0.2498  loss_box_reg_stage1: 0.2993  loss_cls_stage2: 0.1812  loss_box_reg_stage2: 0.2256  loss_mask: 0.533  loss_rpn_cls: 0.06408  loss_rpn_loc: 0.03658  validation_loss: 1.958  time: 1.7860  data_time: 0.0233  lr: 5.6594e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:05:20 d2.utils.events]: \u001b[0m eta: 2:21:24  iter: 4599  total_loss: 2.232  loss_cls_stage0: 0.3166  loss_box_reg_stage0: 0.2349  loss_cls_stage1: 0.243  loss_box_reg_stage1: 0.3112  loss_cls_stage2: 0.1766  loss_box_reg_stage2: 0.2344  loss_mask: 0.5675  loss_rpn_cls: 0.07254  loss_rpn_loc: 0.03793  validation_loss: 1.958  time: 1.7849  data_time: 0.0238  lr: 5.6282e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:05:51 d2.utils.events]: \u001b[0m eta: 2:21:00  iter: 4619  total_loss: 2.181  loss_cls_stage0: 0.2916  loss_box_reg_stage0: 0.2161  loss_cls_stage1: 0.2461  loss_box_reg_stage1: 0.3064  loss_cls_stage2: 0.1749  loss_box_reg_stage2: 0.2543  loss_mask: 0.5409  loss_rpn_cls: 0.07038  loss_rpn_loc: 0.03332  validation_loss: 1.958  time: 1.7839  data_time: 0.0244  lr: 5.597e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:06:22 d2.utils.events]: \u001b[0m eta: 2:20:31  iter: 4639  total_loss: 2.233  loss_cls_stage0: 0.3223  loss_box_reg_stage0: 0.2529  loss_cls_stage1: 0.2589  loss_box_reg_stage1: 0.3229  loss_cls_stage2: 0.1896  loss_box_reg_stage2: 0.2489  loss_mask: 0.5204  loss_rpn_cls: 0.06704  loss_rpn_loc: 0.04191  validation_loss: 1.958  time: 1.7829  data_time: 0.0237  lr: 5.5658e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:06:54 d2.utils.events]: \u001b[0m eta: 2:20:07  iter: 4659  total_loss: 2.241  loss_cls_stage0: 0.3219  loss_box_reg_stage0: 0.2254  loss_cls_stage1: 0.2708  loss_box_reg_stage1: 0.3077  loss_cls_stage2: 0.1965  loss_box_reg_stage2: 0.2662  loss_mask: 0.5471  loss_rpn_cls: 0.0761  loss_rpn_loc: 0.03646  validation_loss: 1.958  time: 1.7820  data_time: 0.0229  lr: 5.5346e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:07:43 d2.utils.events]: \u001b[0m eta: 2:20:00  iter: 4679  total_loss: 2.065  loss_cls_stage0: 0.2931  loss_box_reg_stage0: 0.208  loss_cls_stage1: 0.2343  loss_box_reg_stage1: 0.267  loss_cls_stage2: 0.175  loss_box_reg_stage2: 0.2242  loss_mask: 0.5894  loss_rpn_cls: 0.07245  loss_rpn_loc: 0.03492  validation_loss: 1.958  time: 1.7850  data_time: 0.0247  lr: 5.5034e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:08:32 d2.utils.events]: \u001b[0m eta: 2:19:57  iter: 4699  total_loss: 2.341  loss_cls_stage0: 0.3484  loss_box_reg_stage0: 0.2496  loss_cls_stage1: 0.288  loss_box_reg_stage1: 0.3362  loss_cls_stage2: 0.1929  loss_box_reg_stage2: 0.2513  loss_mask: 0.583  loss_rpn_cls: 0.07056  loss_rpn_loc: 0.03654  validation_loss: 1.958  time: 1.7878  data_time: 0.0233  lr: 5.4721e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:09:21 d2.utils.events]: \u001b[0m eta: 2:19:58  iter: 4719  total_loss: 2.311  loss_cls_stage0: 0.3325  loss_box_reg_stage0: 0.2536  loss_cls_stage1: 0.2851  loss_box_reg_stage1: 0.3369  loss_cls_stage2: 0.1944  loss_box_reg_stage2: 0.2608  loss_mask: 0.532  loss_rpn_cls: 0.07126  loss_rpn_loc: 0.0355  validation_loss: 1.958  time: 1.7907  data_time: 0.0240  lr: 5.4408e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:10:11 d2.utils.events]: \u001b[0m eta: 2:21:36  iter: 4739  total_loss: 2.163  loss_cls_stage0: 0.3287  loss_box_reg_stage0: 0.2356  loss_cls_stage1: 0.2663  loss_box_reg_stage1: 0.3129  loss_cls_stage2: 0.1862  loss_box_reg_stage2: 0.2422  loss_mask: 0.5737  loss_rpn_cls: 0.07825  loss_rpn_loc: 0.04128  validation_loss: 1.958  time: 1.7935  data_time: 0.0234  lr: 5.4095e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:11:00 d2.utils.events]: \u001b[0m eta: 2:27:02  iter: 4759  total_loss: 2.105  loss_cls_stage0: 0.2935  loss_box_reg_stage0: 0.2178  loss_cls_stage1: 0.2516  loss_box_reg_stage1: 0.3032  loss_cls_stage2: 0.1906  loss_box_reg_stage2: 0.2472  loss_mask: 0.5047  loss_rpn_cls: 0.06591  loss_rpn_loc: 0.03373  validation_loss: 1.958  time: 1.7963  data_time: 0.0231  lr: 5.3782e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:11:48 d2.utils.events]: \u001b[0m eta: 2:38:58  iter: 4779  total_loss: 2.038  loss_cls_stage0: 0.2812  loss_box_reg_stage0: 0.2061  loss_cls_stage1: 0.2332  loss_box_reg_stage1: 0.2775  loss_cls_stage2: 0.1667  loss_box_reg_stage2: 0.2313  loss_mask: 0.5123  loss_rpn_cls: 0.06998  loss_rpn_loc: 0.03089  validation_loss: 1.958  time: 1.7989  data_time: 0.0234  lr: 5.3469e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:12:19 d2.utils.events]: \u001b[0m eta: 2:38:22  iter: 4799  total_loss: 2.101  loss_cls_stage0: 0.28  loss_box_reg_stage0: 0.2197  loss_cls_stage1: 0.248  loss_box_reg_stage1: 0.3087  loss_cls_stage2: 0.1719  loss_box_reg_stage2: 0.2597  loss_mask: 0.5373  loss_rpn_cls: 0.06736  loss_rpn_loc: 0.03443  validation_loss: 1.958  time: 1.7978  data_time: 0.0236  lr: 5.3155e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:12:50 d2.utils.events]: \u001b[0m eta: 2:37:45  iter: 4819  total_loss: 1.987  loss_cls_stage0: 0.2586  loss_box_reg_stage0: 0.183  loss_cls_stage1: 0.2297  loss_box_reg_stage1: 0.2994  loss_cls_stage2: 0.1803  loss_box_reg_stage2: 0.2741  loss_mask: 0.549  loss_rpn_cls: 0.05996  loss_rpn_loc: 0.03155  validation_loss: 1.958  time: 1.7968  data_time: 0.0237  lr: 5.2842e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:13:21 d2.utils.events]: \u001b[0m eta: 2:37:08  iter: 4839  total_loss: 2.415  loss_cls_stage0: 0.3378  loss_box_reg_stage0: 0.2569  loss_cls_stage1: 0.276  loss_box_reg_stage1: 0.3412  loss_cls_stage2: 0.1876  loss_box_reg_stage2: 0.2628  loss_mask: 0.557  loss_rpn_cls: 0.07327  loss_rpn_loc: 0.0431  validation_loss: 1.958  time: 1.7958  data_time: 0.0244  lr: 5.2528e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:13:57 d2.utils.events]: \u001b[0m eta: 2:42:36  iter: 4859  total_loss: 2.319  loss_cls_stage0: 0.3386  loss_box_reg_stage0: 0.2426  loss_cls_stage1: 0.269  loss_box_reg_stage1: 0.3257  loss_cls_stage2: 0.1926  loss_box_reg_stage2: 0.2659  loss_mask: 0.5585  loss_rpn_cls: 0.0697  loss_rpn_loc: 0.03679  validation_loss: 1.958  time: 1.7958  data_time: 0.0252  lr: 5.2214e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:14:45 d2.utils.events]: \u001b[0m eta: 3:02:43  iter: 4879  total_loss: 2.414  loss_cls_stage0: 0.326  loss_box_reg_stage0: 0.2443  loss_cls_stage1: 0.2766  loss_box_reg_stage1: 0.3456  loss_cls_stage2: 0.2084  loss_box_reg_stage2: 0.2841  loss_mask: 0.5741  loss_rpn_cls: 0.06829  loss_rpn_loc: 0.03567  validation_loss: 1.958  time: 1.7982  data_time: 0.0230  lr: 5.19e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:15:32 d2.utils.events]: \u001b[0m eta: 3:01:18  iter: 4899  total_loss: 2.4  loss_cls_stage0: 0.3389  loss_box_reg_stage0: 0.2517  loss_cls_stage1: 0.277  loss_box_reg_stage1: 0.3417  loss_cls_stage2: 0.206  loss_box_reg_stage2: 0.2881  loss_mask: 0.5476  loss_rpn_cls: 0.07404  loss_rpn_loc: 0.04116  validation_loss: 1.958  time: 1.8006  data_time: 0.0233  lr: 5.1586e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:16:20 d2.utils.events]: \u001b[0m eta: 3:00:15  iter: 4919  total_loss: 2.387  loss_cls_stage0: 0.3176  loss_box_reg_stage0: 0.2428  loss_cls_stage1: 0.2661  loss_box_reg_stage1: 0.3316  loss_cls_stage2: 0.2042  loss_box_reg_stage2: 0.2798  loss_mask: 0.5301  loss_rpn_cls: 0.06947  loss_rpn_loc: 0.03559  validation_loss: 1.958  time: 1.8029  data_time: 0.0223  lr: 5.1272e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:17:08 d2.utils.events]: \u001b[0m eta: 2:59:33  iter: 4939  total_loss: 2.108  loss_cls_stage0: 0.2885  loss_box_reg_stage0: 0.2044  loss_cls_stage1: 0.2256  loss_box_reg_stage1: 0.2983  loss_cls_stage2: 0.1744  loss_box_reg_stage2: 0.2706  loss_mask: 0.5686  loss_rpn_cls: 0.06115  loss_rpn_loc: 0.03067  validation_loss: 1.958  time: 1.8053  data_time: 0.0237  lr: 5.0958e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:17:56 d2.utils.events]: \u001b[0m eta: 2:59:09  iter: 4959  total_loss: 2.36  loss_cls_stage0: 0.3295  loss_box_reg_stage0: 0.2463  loss_cls_stage1: 0.2743  loss_box_reg_stage1: 0.3623  loss_cls_stage2: 0.1971  loss_box_reg_stage2: 0.2723  loss_mask: 0.5387  loss_rpn_cls: 0.06129  loss_rpn_loc: 0.03236  validation_loss: 1.958  time: 1.8077  data_time: 0.0228  lr: 5.0644e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:18:28 d2.utils.events]: \u001b[0m eta: 2:37:22  iter: 4979  total_loss: 2.523  loss_cls_stage0: 0.3654  loss_box_reg_stage0: 0.2642  loss_cls_stage1: 0.313  loss_box_reg_stage1: 0.344  loss_cls_stage2: 0.2213  loss_box_reg_stage2: 0.2917  loss_mask: 0.5591  loss_rpn_cls: 0.0827  loss_rpn_loc: 0.03965  validation_loss: 1.958  time: 1.8068  data_time: 0.0235  lr: 5.033e-05  max_mem: 11215M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/26 13:19:01 d2.data.common]: \u001b[0mSerializing 900 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/26 13:19:01 d2.data.common]: \u001b[0mSerialized dataset takes 0.91 MiB\n",
      "\u001b[32m[03/26 13:19:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 900 images\n",
      "\u001b[32m[03/26 13:19:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/900. 0.0803 s / img. ETA=0:01:37\n",
      "\u001b[32m[03/26 13:19:08 d2.evaluation.evaluator]: \u001b[0mInference done 60/900. 0.0800 s / img. ETA=0:01:27\n",
      "\u001b[32m[03/26 13:19:13 d2.evaluation.evaluator]: \u001b[0mInference done 108/900. 0.0800 s / img. ETA=0:01:23\n",
      "\u001b[32m[03/26 13:19:18 d2.evaluation.evaluator]: \u001b[0mInference done 158/900. 0.0799 s / img. ETA=0:01:17\n",
      "\u001b[32m[03/26 13:19:23 d2.evaluation.evaluator]: \u001b[0mInference done 207/900. 0.0799 s / img. ETA=0:01:11\n",
      "\u001b[32m[03/26 13:19:28 d2.evaluation.evaluator]: \u001b[0mInference done 255/900. 0.0799 s / img. ETA=0:01:07\n",
      "\u001b[32m[03/26 13:19:33 d2.evaluation.evaluator]: \u001b[0mInference done 304/900. 0.0799 s / img. ETA=0:01:02\n",
      "\u001b[32m[03/26 13:19:38 d2.evaluation.evaluator]: \u001b[0mInference done 352/900. 0.0799 s / img. ETA=0:00:57\n",
      "\u001b[32m[03/26 13:19:43 d2.evaluation.evaluator]: \u001b[0mInference done 400/900. 0.0799 s / img. ETA=0:00:52\n",
      "\u001b[32m[03/26 13:19:48 d2.evaluation.evaluator]: \u001b[0mInference done 448/900. 0.0799 s / img. ETA=0:00:47\n",
      "\u001b[32m[03/26 13:19:53 d2.evaluation.evaluator]: \u001b[0mInference done 494/900. 0.0800 s / img. ETA=0:00:42\n",
      "\u001b[32m[03/26 13:19:58 d2.evaluation.evaluator]: \u001b[0mInference done 544/900. 0.0799 s / img. ETA=0:00:37\n",
      "\u001b[32m[03/26 13:20:03 d2.evaluation.evaluator]: \u001b[0mInference done 589/900. 0.0803 s / img. ETA=0:00:32\n",
      "\u001b[32m[03/26 13:20:08 d2.evaluation.evaluator]: \u001b[0mInference done 637/900. 0.0802 s / img. ETA=0:00:27\n",
      "\u001b[32m[03/26 13:20:13 d2.evaluation.evaluator]: \u001b[0mInference done 684/900. 0.0803 s / img. ETA=0:00:22\n",
      "\u001b[32m[03/26 13:20:18 d2.evaluation.evaluator]: \u001b[0mInference done 731/900. 0.0803 s / img. ETA=0:00:17\n",
      "\u001b[32m[03/26 13:20:23 d2.evaluation.evaluator]: \u001b[0mInference done 779/900. 0.0802 s / img. ETA=0:00:12\n",
      "\u001b[32m[03/26 13:20:28 d2.evaluation.evaluator]: \u001b[0mInference done 828/900. 0.0802 s / img. ETA=0:00:07\n",
      "\u001b[32m[03/26 13:20:33 d2.evaluation.evaluator]: \u001b[0mInference done 877/900. 0.0802 s / img. ETA=0:00:02\n",
      "\u001b[32m[03/26 13:20:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:34.146658 (0.105192 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/26 13:20:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:11 (0.080193 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.29 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.076\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.125\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.136\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.033\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.079\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.112\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.139\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.139\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.044\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.149\n",
      "\u001b[32m[03/26 13:20:37 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold1 in csv format:\n",
      "\u001b[32m[03/26 13:20:37 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/26 13:20:37 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/26 13:20:37 d2.evaluation.testing]: \u001b[0mcopypaste: 7.5631,12.4647,13.6091,0.7277,3.2988,7.8942\n",
      "validation do loss eval 2.234849048752803\n",
      "\u001b[32m[03/26 13:22:24 d2.utils.events]: \u001b[0m eta: 2:21:05  iter: 4999  total_loss: 2.253  loss_cls_stage0: 0.307  loss_box_reg_stage0: 0.2444  loss_cls_stage1: 0.2631  loss_box_reg_stage1: 0.3201  loss_cls_stage2: 0.1881  loss_box_reg_stage2: 0.2352  loss_mask: 0.5148  loss_rpn_cls: 0.07118  loss_rpn_loc: 0.03764  validation_loss: 1.996  time: 1.8058  data_time: 0.0236  lr: 5.0016e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:23:11 d2.utils.events]: \u001b[0m eta: 2:20:32  iter: 5019  total_loss: 2.392  loss_cls_stage0: 0.3495  loss_box_reg_stage0: 0.263  loss_cls_stage1: 0.2752  loss_box_reg_stage1: 0.3325  loss_cls_stage2: 0.1873  loss_box_reg_stage2: 0.2785  loss_mask: 0.5474  loss_rpn_cls: 0.07171  loss_rpn_loc: 0.03797  validation_loss: 1.996  time: 1.8080  data_time: 0.0248  lr: 4.9702e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:23:59 d2.utils.events]: \u001b[0m eta: 2:19:58  iter: 5039  total_loss: 2.33  loss_cls_stage0: 0.3271  loss_box_reg_stage0: 0.2565  loss_cls_stage1: 0.2743  loss_box_reg_stage1: 0.327  loss_cls_stage2: 0.1999  loss_box_reg_stage2: 0.2451  loss_mask: 0.5912  loss_rpn_cls: 0.06772  loss_rpn_loc: 0.03772  validation_loss: 1.996  time: 1.8102  data_time: 0.0238  lr: 4.9387e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:24:46 d2.utils.events]: \u001b[0m eta: 2:19:24  iter: 5059  total_loss: 2.315  loss_cls_stage0: 0.3411  loss_box_reg_stage0: 0.2446  loss_cls_stage1: 0.284  loss_box_reg_stage1: 0.3507  loss_cls_stage2: 0.19  loss_box_reg_stage2: 0.263  loss_mask: 0.5508  loss_rpn_cls: 0.06236  loss_rpn_loc: 0.03926  validation_loss: 1.996  time: 1.8125  data_time: 0.0237  lr: 4.9073e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:25:34 d2.utils.events]: \u001b[0m eta: 2:18:50  iter: 5079  total_loss: 2.405  loss_cls_stage0: 0.3426  loss_box_reg_stage0: 0.2501  loss_cls_stage1: 0.2787  loss_box_reg_stage1: 0.3367  loss_cls_stage2: 0.2012  loss_box_reg_stage2: 0.2881  loss_mask: 0.5554  loss_rpn_cls: 0.07092  loss_rpn_loc: 0.03742  validation_loss: 1.996  time: 1.8148  data_time: 0.0232  lr: 4.8759e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:26:10 d2.utils.events]: \u001b[0m eta: 2:13:48  iter: 5099  total_loss: 2.164  loss_cls_stage0: 0.3051  loss_box_reg_stage0: 0.2228  loss_cls_stage1: 0.2563  loss_box_reg_stage1: 0.3175  loss_cls_stage2: 0.1862  loss_box_reg_stage2: 0.271  loss_mask: 0.5145  loss_rpn_cls: 0.06038  loss_rpn_loc: 0.03753  validation_loss: 1.996  time: 1.8147  data_time: 0.0235  lr: 4.8445e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:26:41 d2.utils.events]: \u001b[0m eta: 2:10:13  iter: 5119  total_loss: 2.222  loss_cls_stage0: 0.3061  loss_box_reg_stage0: 0.2333  loss_cls_stage1: 0.2609  loss_box_reg_stage1: 0.332  loss_cls_stage2: 0.1863  loss_box_reg_stage2: 0.253  loss_mask: 0.5646  loss_rpn_cls: 0.06972  loss_rpn_loc: 0.03558  validation_loss: 1.996  time: 1.8137  data_time: 0.0244  lr: 4.8131e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:27:12 d2.utils.events]: \u001b[0m eta: 2:08:44  iter: 5139  total_loss: 2.183  loss_cls_stage0: 0.3002  loss_box_reg_stage0: 0.227  loss_cls_stage1: 0.2532  loss_box_reg_stage1: 0.3085  loss_cls_stage2: 0.1787  loss_box_reg_stage2: 0.2632  loss_mask: 0.5735  loss_rpn_cls: 0.06147  loss_rpn_loc: 0.03394  validation_loss: 1.996  time: 1.8127  data_time: 0.0227  lr: 4.7817e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:27:43 d2.utils.events]: \u001b[0m eta: 2:07:55  iter: 5159  total_loss: 2.19  loss_cls_stage0: 0.3028  loss_box_reg_stage0: 0.2134  loss_cls_stage1: 0.2602  loss_box_reg_stage1: 0.2928  loss_cls_stage2: 0.1905  loss_box_reg_stage2: 0.2503  loss_mask: 0.5163  loss_rpn_cls: 0.07652  loss_rpn_loc: 0.03898  validation_loss: 1.996  time: 1.8116  data_time: 0.0225  lr: 4.7503e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:28:14 d2.utils.events]: \u001b[0m eta: 2:07:25  iter: 5179  total_loss: 2.36  loss_cls_stage0: 0.3336  loss_box_reg_stage0: 0.2517  loss_cls_stage1: 0.2812  loss_box_reg_stage1: 0.3452  loss_cls_stage2: 0.1932  loss_box_reg_stage2: 0.2792  loss_mask: 0.5625  loss_rpn_cls: 0.07891  loss_rpn_loc: 0.04055  validation_loss: 1.996  time: 1.8107  data_time: 0.0242  lr: 4.719e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:28:46 d2.utils.events]: \u001b[0m eta: 2:06:54  iter: 5199  total_loss: 2.183  loss_cls_stage0: 0.3044  loss_box_reg_stage0: 0.2395  loss_cls_stage1: 0.2481  loss_box_reg_stage1: 0.3113  loss_cls_stage2: 0.1817  loss_box_reg_stage2: 0.2846  loss_mask: 0.4917  loss_rpn_cls: 0.07217  loss_rpn_loc: 0.03632  validation_loss: 1.996  time: 1.8097  data_time: 0.0223  lr: 4.6876e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:29:17 d2.utils.events]: \u001b[0m eta: 2:06:26  iter: 5219  total_loss: 2.41  loss_cls_stage0: 0.3496  loss_box_reg_stage0: 0.2476  loss_cls_stage1: 0.2766  loss_box_reg_stage1: 0.3221  loss_cls_stage2: 0.1977  loss_box_reg_stage2: 0.2657  loss_mask: 0.5534  loss_rpn_cls: 0.07681  loss_rpn_loc: 0.03796  validation_loss: 1.996  time: 1.8087  data_time: 0.0233  lr: 4.6563e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:29:56 d2.utils.events]: \u001b[0m eta: 2:06:10  iter: 5239  total_loss: 2.467  loss_cls_stage0: 0.3494  loss_box_reg_stage0: 0.2808  loss_cls_stage1: 0.2842  loss_box_reg_stage1: 0.3753  loss_cls_stage2: 0.1974  loss_box_reg_stage2: 0.2986  loss_mask: 0.5694  loss_rpn_cls: 0.06551  loss_rpn_loc: 0.03858  validation_loss: 1.996  time: 1.8093  data_time: 0.0228  lr: 4.6249e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:30:43 d2.utils.events]: \u001b[0m eta: 2:06:37  iter: 5259  total_loss: 2.149  loss_cls_stage0: 0.2946  loss_box_reg_stage0: 0.2204  loss_cls_stage1: 0.2457  loss_box_reg_stage1: 0.3152  loss_cls_stage2: 0.1739  loss_box_reg_stage2: 0.2505  loss_mask: 0.524  loss_rpn_cls: 0.06833  loss_rpn_loc: 0.03512  validation_loss: 1.996  time: 1.8114  data_time: 0.0227  lr: 4.5936e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:31:31 d2.utils.events]: \u001b[0m eta: 2:07:42  iter: 5279  total_loss: 2.287  loss_cls_stage0: 0.3431  loss_box_reg_stage0: 0.2317  loss_cls_stage1: 0.2707  loss_box_reg_stage1: 0.3259  loss_cls_stage2: 0.1946  loss_box_reg_stage2: 0.2746  loss_mask: 0.5886  loss_rpn_cls: 0.06935  loss_rpn_loc: 0.0379  validation_loss: 1.996  time: 1.8135  data_time: 0.0234  lr: 4.5623e-05  max_mem: 11215M\n",
      "\u001b[32m[03/26 13:32:18 d2.utils.events]: \u001b[0m eta: 2:11:03  iter: 5299  total_loss: 2.293  loss_cls_stage0: 0.3183  loss_box_reg_stage0: 0.2382  loss_cls_stage1: 0.2629  loss_box_reg_stage1: 0.3285  loss_cls_stage2: 0.1892  loss_box_reg_stage2: 0.261  loss_mask: 0.5723  loss_rpn_cls: 0.06454  loss_rpn_loc: 0.03312  validation_loss: 1.996  time: 1.8156  data_time: 0.0225  lr: 4.531e-05  max_mem: 11374M\n",
      "\u001b[32m[03/26 13:33:05 d2.utils.events]: \u001b[0m eta: 2:10:41  iter: 5319  total_loss: 2.25  loss_cls_stage0: 0.3194  loss_box_reg_stage0: 0.2522  loss_cls_stage1: 0.2708  loss_box_reg_stage1: 0.3195  loss_cls_stage2: 0.196  loss_box_reg_stage2: 0.2558  loss_mask: 0.5085  loss_rpn_cls: 0.06619  loss_rpn_loc: 0.035  validation_loss: 1.996  time: 1.8177  data_time: 0.0228  lr: 4.4998e-05  max_mem: 11374M\n",
      "\u001b[32m[03/26 13:33:52 d2.utils.events]: \u001b[0m eta: 2:09:22  iter: 5339  total_loss: 2.285  loss_cls_stage0: 0.3336  loss_box_reg_stage0: 0.2428  loss_cls_stage1: 0.2568  loss_box_reg_stage1: 0.3318  loss_cls_stage2: 0.1782  loss_box_reg_stage2: 0.2585  loss_mask: 0.5243  loss_rpn_cls: 0.05758  loss_rpn_loc: 0.03382  validation_loss: 1.996  time: 1.8196  data_time: 0.0230  lr: 4.4685e-05  max_mem: 11374M\n",
      "\u001b[32m[03/26 13:34:23 d2.utils.events]: \u001b[0m eta: 2:04:26  iter: 5359  total_loss: 2.31  loss_cls_stage0: 0.3246  loss_box_reg_stage0: 0.245  loss_cls_stage1: 0.2776  loss_box_reg_stage1: 0.3381  loss_cls_stage2: 0.2002  loss_box_reg_stage2: 0.281  loss_mask: 0.5417  loss_rpn_cls: 0.0696  loss_rpn_loc: 0.03812  validation_loss: 1.996  time: 1.8186  data_time: 0.0235  lr: 4.4373e-05  max_mem: 11374M\n",
      "\u001b[32m[03/26 13:34:54 d2.utils.events]: \u001b[0m eta: 2:02:43  iter: 5379  total_loss: 2.369  loss_cls_stage0: 0.3408  loss_box_reg_stage0: 0.2636  loss_cls_stage1: 0.2831  loss_box_reg_stage1: 0.3472  loss_cls_stage2: 0.1989  loss_box_reg_stage2: 0.2979  loss_mask: 0.5714  loss_rpn_cls: 0.0674  loss_rpn_loc: 0.03732  validation_loss: 1.996  time: 1.8176  data_time: 0.0233  lr: 4.4061e-05  max_mem: 11374M\n",
      "\u001b[32m[03/26 13:35:25 d2.utils.events]: \u001b[0m eta: 2:01:49  iter: 5399  total_loss: 2.231  loss_cls_stage0: 0.3166  loss_box_reg_stage0: 0.233  loss_cls_stage1: 0.265  loss_box_reg_stage1: 0.3244  loss_cls_stage2: 0.1843  loss_box_reg_stage2: 0.2678  loss_mask: 0.535  loss_rpn_cls: 0.05991  loss_rpn_loc: 0.03643  validation_loss: 1.996  time: 1.8167  data_time: 0.0241  lr: 4.3749e-05  max_mem: 11374M\n",
      "\u001b[32m[03/26 13:35:57 d2.utils.events]: \u001b[0m eta: 2:01:08  iter: 5419  total_loss: 2.367  loss_cls_stage0: 0.3363  loss_box_reg_stage0: 0.2651  loss_cls_stage1: 0.2616  loss_box_reg_stage1: 0.3296  loss_cls_stage2: 0.177  loss_box_reg_stage2: 0.262  loss_mask: 0.5496  loss_rpn_cls: 0.06836  loss_rpn_loc: 0.03688  validation_loss: 1.996  time: 1.8158  data_time: 0.0232  lr: 4.3437e-05  max_mem: 11374M\n",
      "\u001b[32m[03/26 13:36:28 d2.utils.events]: \u001b[0m eta: 2:00:42  iter: 5439  total_loss: 2.204  loss_cls_stage0: 0.3047  loss_box_reg_stage0: 0.2322  loss_cls_stage1: 0.2456  loss_box_reg_stage1: 0.3246  loss_cls_stage2: 0.1845  loss_box_reg_stage2: 0.2604  loss_mask: 0.5256  loss_rpn_cls: 0.07732  loss_rpn_loc: 0.03584  validation_loss: 1.996  time: 1.8149  data_time: 0.0222  lr: 4.3126e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 13:36:59 d2.utils.events]: \u001b[0m eta: 2:00:10  iter: 5459  total_loss: 2.235  loss_cls_stage0: 0.3229  loss_box_reg_stage0: 0.2524  loss_cls_stage1: 0.2615  loss_box_reg_stage1: 0.3369  loss_cls_stage2: 0.1892  loss_box_reg_stage2: 0.2638  loss_mask: 0.5529  loss_rpn_cls: 0.0615  loss_rpn_loc: 0.03462  validation_loss: 1.996  time: 1.8139  data_time: 0.0240  lr: 4.2815e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 13:37:30 d2.utils.events]: \u001b[0m eta: 1:59:42  iter: 5479  total_loss: 2.427  loss_cls_stage0: 0.3888  loss_box_reg_stage0: 0.2906  loss_cls_stage1: 0.3092  loss_box_reg_stage1: 0.3915  loss_cls_stage2: 0.2076  loss_box_reg_stage2: 0.275  loss_mask: 0.4757  loss_rpn_cls: 0.07224  loss_rpn_loc: 0.04128  validation_loss: 1.996  time: 1.8130  data_time: 0.0243  lr: 4.2504e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 13:38:02 d2.utils.events]: \u001b[0m eta: 1:59:12  iter: 5499  total_loss: 2.237  loss_cls_stage0: 0.3278  loss_box_reg_stage0: 0.2575  loss_cls_stage1: 0.2607  loss_box_reg_stage1: 0.3427  loss_cls_stage2: 0.1719  loss_box_reg_stage2: 0.2773  loss_mask: 0.5303  loss_rpn_cls: 0.06266  loss_rpn_loc: 0.03419  validation_loss: 1.996  time: 1.8121  data_time: 0.0251  lr: 4.2194e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 13:38:47 d2.utils.events]: \u001b[0m eta: 1:59:04  iter: 5519  total_loss: 2.181  loss_cls_stage0: 0.2963  loss_box_reg_stage0: 0.2251  loss_cls_stage1: 0.2538  loss_box_reg_stage1: 0.3153  loss_cls_stage2: 0.1877  loss_box_reg_stage2: 0.2618  loss_mask: 0.539  loss_rpn_cls: 0.0796  loss_rpn_loc: 0.03301  validation_loss: 1.996  time: 1.8137  data_time: 0.0238  lr: 4.1884e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 13:39:36 d2.utils.events]: \u001b[0m eta: 1:59:22  iter: 5539  total_loss: 2.065  loss_cls_stage0: 0.2712  loss_box_reg_stage0: 0.2079  loss_cls_stage1: 0.227  loss_box_reg_stage1: 0.3011  loss_cls_stage2: 0.1693  loss_box_reg_stage2: 0.2713  loss_mask: 0.5157  loss_rpn_cls: 0.06513  loss_rpn_loc: 0.03251  validation_loss: 1.996  time: 1.8159  data_time: 0.0229  lr: 4.1574e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 13:40:25 d2.utils.events]: \u001b[0m eta: 2:00:37  iter: 5559  total_loss: 2.314  loss_cls_stage0: 0.3328  loss_box_reg_stage0: 0.2423  loss_cls_stage1: 0.2651  loss_box_reg_stage1: 0.3357  loss_cls_stage2: 0.1979  loss_box_reg_stage2: 0.2743  loss_mask: 0.5164  loss_rpn_cls: 0.05926  loss_rpn_loc: 0.03298  validation_loss: 1.996  time: 1.8184  data_time: 0.0234  lr: 4.1264e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 13:41:15 d2.utils.events]: \u001b[0m eta: 2:06:22  iter: 5579  total_loss: 2.356  loss_cls_stage0: 0.3572  loss_box_reg_stage0: 0.2606  loss_cls_stage1: 0.2727  loss_box_reg_stage1: 0.3449  loss_cls_stage2: 0.1951  loss_box_reg_stage2: 0.2837  loss_mask: 0.5161  loss_rpn_cls: 0.06698  loss_rpn_loc: 0.0337  validation_loss: 1.996  time: 1.8207  data_time: 0.0240  lr: 4.0955e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 13:42:04 d2.utils.events]: \u001b[0m eta: 2:20:19  iter: 5599  total_loss: 2.38  loss_cls_stage0: 0.3129  loss_box_reg_stage0: 0.253  loss_cls_stage1: 0.2692  loss_box_reg_stage1: 0.3567  loss_cls_stage2: 0.1922  loss_box_reg_stage2: 0.2958  loss_mask: 0.5623  loss_rpn_cls: 0.06491  loss_rpn_loc: 0.03752  validation_loss: 1.996  time: 1.8229  data_time: 0.0236  lr: 4.0646e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 13:42:53 d2.utils.events]: \u001b[0m eta: 2:39:34  iter: 5619  total_loss: 2.268  loss_cls_stage0: 0.2991  loss_box_reg_stage0: 0.2336  loss_cls_stage1: 0.2634  loss_box_reg_stage1: 0.3287  loss_cls_stage2: 0.1858  loss_box_reg_stage2: 0.2692  loss_mask: 0.5518  loss_rpn_cls: 0.06699  loss_rpn_loc: 0.03556  validation_loss: 1.996  time: 1.8252  data_time: 0.0240  lr: 4.0338e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 13:43:42 d2.utils.events]: \u001b[0m eta: 2:50:01  iter: 5639  total_loss: 2.34  loss_cls_stage0: 0.3004  loss_box_reg_stage0: 0.2332  loss_cls_stage1: 0.2577  loss_box_reg_stage1: 0.3519  loss_cls_stage2: 0.183  loss_box_reg_stage2: 0.2864  loss_mask: 0.5851  loss_rpn_cls: 0.06568  loss_rpn_loc: 0.03175  validation_loss: 1.996  time: 1.8275  data_time: 0.0240  lr: 4.003e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 13:44:21 d2.utils.events]: \u001b[0m eta: 2:49:39  iter: 5659  total_loss: 2.353  loss_cls_stage0: 0.332  loss_box_reg_stage0: 0.2512  loss_cls_stage1: 0.2748  loss_box_reg_stage1: 0.3435  loss_cls_stage2: 0.1918  loss_box_reg_stage2: 0.2897  loss_mask: 0.5618  loss_rpn_cls: 0.06746  loss_rpn_loc: 0.03675  validation_loss: 1.996  time: 1.8278  data_time: 0.0223  lr: 3.9722e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 13:44:52 d2.utils.events]: \u001b[0m eta: 2:46:15  iter: 5679  total_loss: 2.194  loss_cls_stage0: 0.3001  loss_box_reg_stage0: 0.2213  loss_cls_stage1: 0.2647  loss_box_reg_stage1: 0.3341  loss_cls_stage2: 0.183  loss_box_reg_stage2: 0.2777  loss_mask: 0.5592  loss_rpn_cls: 0.07001  loss_rpn_loc: 0.03655  validation_loss: 1.996  time: 1.8268  data_time: 0.0245  lr: 3.9415e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 13:45:23 d2.utils.events]: \u001b[0m eta: 2:25:51  iter: 5699  total_loss: 2.548  loss_cls_stage0: 0.3411  loss_box_reg_stage0: 0.2543  loss_cls_stage1: 0.2945  loss_box_reg_stage1: 0.3719  loss_cls_stage2: 0.2001  loss_box_reg_stage2: 0.2804  loss_mask: 0.5428  loss_rpn_cls: 0.07894  loss_rpn_loc: 0.04276  validation_loss: 1.996  time: 1.8259  data_time: 0.0236  lr: 3.9108e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 13:45:54 d2.utils.events]: \u001b[0m eta: 2:04:17  iter: 5719  total_loss: 2.174  loss_cls_stage0: 0.3016  loss_box_reg_stage0: 0.2267  loss_cls_stage1: 0.2513  loss_box_reg_stage1: 0.3102  loss_cls_stage2: 0.1783  loss_box_reg_stage2: 0.2348  loss_mask: 0.5325  loss_rpn_cls: 0.06114  loss_rpn_loc: 0.03193  validation_loss: 1.996  time: 1.8249  data_time: 0.0236  lr: 3.8802e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 13:46:25 d2.utils.events]: \u001b[0m eta: 1:57:06  iter: 5739  total_loss: 2.348  loss_cls_stage0: 0.3162  loss_box_reg_stage0: 0.2523  loss_cls_stage1: 0.2614  loss_box_reg_stage1: 0.3348  loss_cls_stage2: 0.1818  loss_box_reg_stage2: 0.2723  loss_mask: 0.5558  loss_rpn_cls: 0.06874  loss_rpn_loc: 0.03574  validation_loss: 1.996  time: 1.8240  data_time: 0.0247  lr: 3.8496e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 13:46:56 d2.utils.events]: \u001b[0m eta: 1:53:38  iter: 5759  total_loss: 2.352  loss_cls_stage0: 0.335  loss_box_reg_stage0: 0.2501  loss_cls_stage1: 0.2865  loss_box_reg_stage1: 0.3569  loss_cls_stage2: 0.2001  loss_box_reg_stage2: 0.2858  loss_mask: 0.5024  loss_rpn_cls: 0.05821  loss_rpn_loc: 0.03557  validation_loss: 1.996  time: 1.8231  data_time: 0.0240  lr: 3.819e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 13:47:28 d2.utils.events]: \u001b[0m eta: 1:52:21  iter: 5779  total_loss: 2.372  loss_cls_stage0: 0.3478  loss_box_reg_stage0: 0.27  loss_cls_stage1: 0.2841  loss_box_reg_stage1: 0.37  loss_cls_stage2: 0.2081  loss_box_reg_stage2: 0.3069  loss_mask: 0.5022  loss_rpn_cls: 0.06162  loss_rpn_loc: 0.03915  validation_loss: 1.996  time: 1.8222  data_time: 0.0246  lr: 3.7885e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 13:48:07 d2.utils.events]: \u001b[0m eta: 1:52:17  iter: 5799  total_loss: 2.295  loss_cls_stage0: 0.3198  loss_box_reg_stage0: 0.2322  loss_cls_stage1: 0.257  loss_box_reg_stage1: 0.309  loss_cls_stage2: 0.1946  loss_box_reg_stage2: 0.2836  loss_mask: 0.5463  loss_rpn_cls: 0.07373  loss_rpn_loc: 0.03906  validation_loss: 1.996  time: 1.8227  data_time: 0.0239  lr: 3.7581e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 13:48:55 d2.utils.events]: \u001b[0m eta: 1:54:02  iter: 5819  total_loss: 2.195  loss_cls_stage0: 0.3126  loss_box_reg_stage0: 0.2369  loss_cls_stage1: 0.2654  loss_box_reg_stage1: 0.323  loss_cls_stage2: 0.1918  loss_box_reg_stage2: 0.2777  loss_mask: 0.5497  loss_rpn_cls: 0.06746  loss_rpn_loc: 0.03618  validation_loss: 1.996  time: 1.8246  data_time: 0.0237  lr: 3.7277e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 13:49:43 d2.utils.events]: \u001b[0m eta: 1:59:51  iter: 5839  total_loss: 2.494  loss_cls_stage0: 0.3514  loss_box_reg_stage0: 0.2752  loss_cls_stage1: 0.2928  loss_box_reg_stage1: 0.3671  loss_cls_stage2: 0.2039  loss_box_reg_stage2: 0.2786  loss_mask: 0.5548  loss_rpn_cls: 0.07075  loss_rpn_loc: 0.04022  validation_loss: 1.996  time: 1.8266  data_time: 0.0238  lr: 3.6973e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 13:50:30 d2.utils.events]: \u001b[0m eta: 2:08:39  iter: 5859  total_loss: 2.253  loss_cls_stage0: 0.3295  loss_box_reg_stage0: 0.2614  loss_cls_stage1: 0.2609  loss_box_reg_stage1: 0.3673  loss_cls_stage2: 0.18  loss_box_reg_stage2: 0.2769  loss_mask: 0.5359  loss_rpn_cls: 0.05951  loss_rpn_loc: 0.03325  validation_loss: 1.996  time: 1.8285  data_time: 0.0236  lr: 3.667e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 13:51:18 d2.utils.events]: \u001b[0m eta: 2:08:01  iter: 5879  total_loss: 2.296  loss_cls_stage0: 0.3168  loss_box_reg_stage0: 0.2589  loss_cls_stage1: 0.2596  loss_box_reg_stage1: 0.3366  loss_cls_stage2: 0.1849  loss_box_reg_stage2: 0.2812  loss_mask: 0.5121  loss_rpn_cls: 0.06647  loss_rpn_loc: 0.03708  validation_loss: 1.996  time: 1.8303  data_time: 0.0232  lr: 3.6368e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 13:52:04 d2.utils.events]: \u001b[0m eta: 2:03:12  iter: 5899  total_loss: 2.327  loss_cls_stage0: 0.3467  loss_box_reg_stage0: 0.2662  loss_cls_stage1: 0.2769  loss_box_reg_stage1: 0.3417  loss_cls_stage2: 0.198  loss_box_reg_stage2: 0.2698  loss_mask: 0.5601  loss_rpn_cls: 0.07183  loss_rpn_loc: 0.03901  validation_loss: 1.996  time: 1.8319  data_time: 0.0254  lr: 3.6066e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 13:52:35 d2.utils.events]: \u001b[0m eta: 1:54:21  iter: 5919  total_loss: 2.333  loss_cls_stage0: 0.3354  loss_box_reg_stage0: 0.2806  loss_cls_stage1: 0.2901  loss_box_reg_stage1: 0.3629  loss_cls_stage2: 0.2059  loss_box_reg_stage2: 0.2689  loss_mask: 0.5178  loss_rpn_cls: 0.06402  loss_rpn_loc: 0.03531  validation_loss: 1.996  time: 1.8310  data_time: 0.0231  lr: 3.5764e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 13:53:07 d2.utils.events]: \u001b[0m eta: 1:49:39  iter: 5939  total_loss: 2.337  loss_cls_stage0: 0.3055  loss_box_reg_stage0: 0.2392  loss_cls_stage1: 0.2582  loss_box_reg_stage1: 0.3534  loss_cls_stage2: 0.1895  loss_box_reg_stage2: 0.2818  loss_mask: 0.5671  loss_rpn_cls: 0.06504  loss_rpn_loc: 0.0349  validation_loss: 1.996  time: 1.8301  data_time: 0.0233  lr: 3.5463e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 13:53:38 d2.utils.events]: \u001b[0m eta: 1:47:42  iter: 5959  total_loss: 2.238  loss_cls_stage0: 0.313  loss_box_reg_stage0: 0.239  loss_cls_stage1: 0.2537  loss_box_reg_stage1: 0.3365  loss_cls_stage2: 0.1842  loss_box_reg_stage2: 0.299  loss_mask: 0.5064  loss_rpn_cls: 0.06675  loss_rpn_loc: 0.03657  validation_loss: 1.996  time: 1.8292  data_time: 0.0235  lr: 3.5163e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 13:54:26 d2.utils.events]: \u001b[0m eta: 1:48:24  iter: 5979  total_loss: 2.268  loss_cls_stage0: 0.2878  loss_box_reg_stage0: 0.2377  loss_cls_stage1: 0.2446  loss_box_reg_stage1: 0.3426  loss_cls_stage2: 0.1859  loss_box_reg_stage2: 0.2723  loss_mask: 0.5587  loss_rpn_cls: 0.06485  loss_rpn_loc: 0.03561  validation_loss: 1.996  time: 1.8312  data_time: 0.0244  lr: 3.4863e-05  max_mem: 11386M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/26 13:55:18 d2.data.common]: \u001b[0mSerializing 900 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/26 13:55:18 d2.data.common]: \u001b[0mSerialized dataset takes 0.91 MiB\n",
      "\u001b[32m[03/26 13:55:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 900 images\n",
      "\u001b[32m[03/26 13:55:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/900. 0.1468 s / img. ETA=0:02:43\n",
      "\u001b[32m[03/26 13:55:25 d2.evaluation.evaluator]: \u001b[0mInference done 39/900. 0.1511 s / img. ETA=0:02:37\n",
      "\u001b[32m[03/26 13:55:30 d2.evaluation.evaluator]: \u001b[0mInference done 72/900. 0.1376 s / img. ETA=0:02:18\n",
      "\u001b[32m[03/26 13:55:35 d2.evaluation.evaluator]: \u001b[0mInference done 99/900. 0.1405 s / img. ETA=0:02:18\n",
      "\u001b[32m[03/26 13:55:40 d2.evaluation.evaluator]: \u001b[0mInference done 127/900. 0.1438 s / img. ETA=0:02:15\n",
      "\u001b[32m[03/26 13:55:46 d2.evaluation.evaluator]: \u001b[0mInference done 156/900. 0.1453 s / img. ETA=0:02:10\n",
      "\u001b[32m[03/26 13:55:51 d2.evaluation.evaluator]: \u001b[0mInference done 184/900. 0.1468 s / img. ETA=0:02:06\n",
      "\u001b[32m[03/26 13:55:56 d2.evaluation.evaluator]: \u001b[0mInference done 213/900. 0.1476 s / img. ETA=0:02:01\n",
      "\u001b[32m[03/26 13:56:01 d2.evaluation.evaluator]: \u001b[0mInference done 240/900. 0.1482 s / img. ETA=0:01:57\n",
      "\u001b[32m[03/26 13:56:06 d2.evaluation.evaluator]: \u001b[0mInference done 267/900. 0.1489 s / img. ETA=0:01:53\n",
      "\u001b[32m[03/26 13:56:11 d2.evaluation.evaluator]: \u001b[0mInference done 301/900. 0.1460 s / img. ETA=0:01:45\n",
      "\u001b[32m[03/26 13:56:16 d2.evaluation.evaluator]: \u001b[0mInference done 328/900. 0.1468 s / img. ETA=0:01:41\n",
      "\u001b[32m[03/26 13:56:21 d2.evaluation.evaluator]: \u001b[0mInference done 354/900. 0.1475 s / img. ETA=0:01:37\n",
      "\u001b[32m[03/26 13:56:26 d2.evaluation.evaluator]: \u001b[0mInference done 381/900. 0.1479 s / img. ETA=0:01:32\n",
      "\u001b[32m[03/26 13:56:31 d2.evaluation.evaluator]: \u001b[0mInference done 409/900. 0.1483 s / img. ETA=0:01:27\n",
      "\u001b[32m[03/26 13:56:36 d2.evaluation.evaluator]: \u001b[0mInference done 436/900. 0.1489 s / img. ETA=0:01:23\n",
      "\u001b[32m[03/26 13:56:41 d2.evaluation.evaluator]: \u001b[0mInference done 463/900. 0.1492 s / img. ETA=0:01:18\n",
      "\u001b[32m[03/26 13:56:46 d2.evaluation.evaluator]: \u001b[0mInference done 490/900. 0.1490 s / img. ETA=0:01:13\n",
      "\u001b[32m[03/26 13:56:52 d2.evaluation.evaluator]: \u001b[0mInference done 523/900. 0.1476 s / img. ETA=0:01:07\n",
      "\u001b[32m[03/26 13:56:57 d2.evaluation.evaluator]: \u001b[0mInference done 551/900. 0.1480 s / img. ETA=0:01:02\n",
      "\u001b[32m[03/26 13:57:02 d2.evaluation.evaluator]: \u001b[0mInference done 577/900. 0.1482 s / img. ETA=0:00:57\n",
      "\u001b[32m[03/26 13:57:07 d2.evaluation.evaluator]: \u001b[0mInference done 605/900. 0.1485 s / img. ETA=0:00:52\n",
      "\u001b[32m[03/26 13:57:12 d2.evaluation.evaluator]: \u001b[0mInference done 633/900. 0.1488 s / img. ETA=0:00:47\n",
      "\u001b[32m[03/26 13:57:17 d2.evaluation.evaluator]: \u001b[0mInference done 660/900. 0.1491 s / img. ETA=0:00:43\n",
      "\u001b[32m[03/26 13:57:22 d2.evaluation.evaluator]: \u001b[0mInference done 689/900. 0.1493 s / img. ETA=0:00:37\n",
      "\u001b[32m[03/26 13:57:27 d2.evaluation.evaluator]: \u001b[0mInference done 722/900. 0.1477 s / img. ETA=0:00:31\n",
      "\u001b[32m[03/26 13:57:32 d2.evaluation.evaluator]: \u001b[0mInference done 768/900. 0.1436 s / img. ETA=0:00:23\n",
      "\u001b[32m[03/26 13:57:37 d2.evaluation.evaluator]: \u001b[0mInference done 814/900. 0.1400 s / img. ETA=0:00:14\n",
      "\u001b[32m[03/26 13:57:43 d2.evaluation.evaluator]: \u001b[0mInference done 860/900. 0.1368 s / img. ETA=0:00:06\n",
      "\u001b[32m[03/26 13:57:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:28.061343 (0.165432 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/26 13:57:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:00 (0.134274 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.46 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.081\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.134\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.148\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.035\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.088\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.123\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.160\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.161\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.046\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.180\n",
      "\u001b[32m[03/26 13:57:48 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold1 in csv format:\n",
      "\u001b[32m[03/26 13:57:48 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/26 13:57:48 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/26 13:57:48 d2.evaluation.testing]: \u001b[0mcopypaste: 8.1255,13.4377,14.7842,0.6698,3.4606,8.7532\n",
      "validation do loss eval 2.2618369438173898\n",
      "\u001b[32m[03/26 13:59:20 d2.utils.events]: \u001b[0m eta: 1:52:02  iter: 5999  total_loss: 2.231  loss_cls_stage0: 0.2939  loss_box_reg_stage0: 0.2219  loss_cls_stage1: 0.244  loss_box_reg_stage1: 0.3301  loss_cls_stage2: 0.186  loss_box_reg_stage2: 0.2758  loss_mask: 0.5813  loss_rpn_cls: 0.05404  loss_rpn_loc: 0.03236  validation_loss: 2.046  time: 1.8333  data_time: 0.0226  lr: 3.4564e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 13:59:51 d2.utils.events]: \u001b[0m eta: 1:47:29  iter: 6019  total_loss: 2.365  loss_cls_stage0: 0.3267  loss_box_reg_stage0: 0.2426  loss_cls_stage1: 0.2622  loss_box_reg_stage1: 0.3537  loss_cls_stage2: 0.1877  loss_box_reg_stage2: 0.2558  loss_mask: 0.5704  loss_rpn_cls: 0.06193  loss_rpn_loc: 0.03328  validation_loss: 2.046  time: 1.8323  data_time: 0.0231  lr: 3.4266e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 14:00:22 d2.utils.events]: \u001b[0m eta: 1:45:34  iter: 6039  total_loss: 2.297  loss_cls_stage0: 0.3034  loss_box_reg_stage0: 0.2277  loss_cls_stage1: 0.2692  loss_box_reg_stage1: 0.334  loss_cls_stage2: 0.1963  loss_box_reg_stage2: 0.2787  loss_mask: 0.5898  loss_rpn_cls: 0.06345  loss_rpn_loc: 0.03621  validation_loss: 2.046  time: 1.8314  data_time: 0.0230  lr: 3.3968e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 14:00:54 d2.utils.events]: \u001b[0m eta: 1:44:37  iter: 6059  total_loss: 2.445  loss_cls_stage0: 0.3442  loss_box_reg_stage0: 0.2804  loss_cls_stage1: 0.2863  loss_box_reg_stage1: 0.3815  loss_cls_stage2: 0.2036  loss_box_reg_stage2: 0.3159  loss_mask: 0.563  loss_rpn_cls: 0.07072  loss_rpn_loc: 0.0392  validation_loss: 2.046  time: 1.8305  data_time: 0.0234  lr: 3.367e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 14:01:25 d2.utils.events]: \u001b[0m eta: 1:43:48  iter: 6079  total_loss: 2.485  loss_cls_stage0: 0.3895  loss_box_reg_stage0: 0.2846  loss_cls_stage1: 0.3085  loss_box_reg_stage1: 0.3745  loss_cls_stage2: 0.2075  loss_box_reg_stage2: 0.2764  loss_mask: 0.5217  loss_rpn_cls: 0.07992  loss_rpn_loc: 0.04809  validation_loss: 2.046  time: 1.8297  data_time: 0.0255  lr: 3.3374e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 14:01:56 d2.utils.events]: \u001b[0m eta: 1:43:12  iter: 6099  total_loss: 2.398  loss_cls_stage0: 0.3186  loss_box_reg_stage0: 0.2562  loss_cls_stage1: 0.2603  loss_box_reg_stage1: 0.3307  loss_cls_stage2: 0.1857  loss_box_reg_stage2: 0.2992  loss_mask: 0.5686  loss_rpn_cls: 0.06364  loss_rpn_loc: 0.03544  validation_loss: 2.046  time: 1.8288  data_time: 0.0240  lr: 3.3078e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 14:02:28 d2.utils.events]: \u001b[0m eta: 1:42:43  iter: 6119  total_loss: 2.442  loss_cls_stage0: 0.3544  loss_box_reg_stage0: 0.2814  loss_cls_stage1: 0.286  loss_box_reg_stage1: 0.3633  loss_cls_stage2: 0.1921  loss_box_reg_stage2: 0.2876  loss_mask: 0.5668  loss_rpn_cls: 0.07099  loss_rpn_loc: 0.03884  validation_loss: 2.046  time: 1.8280  data_time: 0.0225  lr: 3.2783e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 14:02:59 d2.utils.events]: \u001b[0m eta: 1:42:12  iter: 6139  total_loss: 2.386  loss_cls_stage0: 0.3457  loss_box_reg_stage0: 0.2725  loss_cls_stage1: 0.2743  loss_box_reg_stage1: 0.3661  loss_cls_stage2: 0.1953  loss_box_reg_stage2: 0.2902  loss_mask: 0.5468  loss_rpn_cls: 0.06335  loss_rpn_loc: 0.03823  validation_loss: 2.046  time: 1.8271  data_time: 0.0230  lr: 3.2488e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 14:03:31 d2.utils.events]: \u001b[0m eta: 1:41:42  iter: 6159  total_loss: 2.493  loss_cls_stage0: 0.3541  loss_box_reg_stage0: 0.2769  loss_cls_stage1: 0.2956  loss_box_reg_stage1: 0.3917  loss_cls_stage2: 0.2083  loss_box_reg_stage2: 0.3023  loss_mask: 0.5781  loss_rpn_cls: 0.07156  loss_rpn_loc: 0.03943  validation_loss: 2.046  time: 1.8263  data_time: 0.0239  lr: 3.2194e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 14:04:02 d2.utils.events]: \u001b[0m eta: 1:41:10  iter: 6179  total_loss: 2.338  loss_cls_stage0: 0.3402  loss_box_reg_stage0: 0.2534  loss_cls_stage1: 0.2687  loss_box_reg_stage1: 0.3454  loss_cls_stage2: 0.192  loss_box_reg_stage2: 0.2957  loss_mask: 0.5522  loss_rpn_cls: 0.0634  loss_rpn_loc: 0.03774  validation_loss: 2.046  time: 1.8254  data_time: 0.0236  lr: 3.1901e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 14:04:34 d2.utils.events]: \u001b[0m eta: 1:40:42  iter: 6199  total_loss: 2.484  loss_cls_stage0: 0.3395  loss_box_reg_stage0: 0.2685  loss_cls_stage1: 0.2904  loss_box_reg_stage1: 0.3796  loss_cls_stage2: 0.2082  loss_box_reg_stage2: 0.3228  loss_mask: 0.6073  loss_rpn_cls: 0.07153  loss_rpn_loc: 0.04243  validation_loss: 2.046  time: 1.8246  data_time: 0.0242  lr: 3.1608e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 14:05:05 d2.utils.events]: \u001b[0m eta: 1:40:13  iter: 6219  total_loss: 2.311  loss_cls_stage0: 0.3068  loss_box_reg_stage0: 0.2421  loss_cls_stage1: 0.2714  loss_box_reg_stage1: 0.3377  loss_cls_stage2: 0.1846  loss_box_reg_stage2: 0.2829  loss_mask: 0.5249  loss_rpn_cls: 0.06315  loss_rpn_loc: 0.03822  validation_loss: 2.046  time: 1.8238  data_time: 0.0240  lr: 3.1317e-05  max_mem: 11386M\n",
      "\u001b[32m[03/26 14:05:36 d2.utils.events]: \u001b[0m eta: 1:39:33  iter: 6239  total_loss: 2.509  loss_cls_stage0: 0.3784  loss_box_reg_stage0: 0.2877  loss_cls_stage1: 0.3018  loss_box_reg_stage1: 0.3656  loss_cls_stage2: 0.2271  loss_box_reg_stage2: 0.2993  loss_mask: 0.5233  loss_rpn_cls: 0.07185  loss_rpn_loc: 0.04565  validation_loss: 2.046  time: 1.8230  data_time: 0.0244  lr: 3.1026e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:06:08 d2.utils.events]: \u001b[0m eta: 1:38:51  iter: 6259  total_loss: 2.224  loss_cls_stage0: 0.3202  loss_box_reg_stage0: 0.2733  loss_cls_stage1: 0.244  loss_box_reg_stage1: 0.3303  loss_cls_stage2: 0.1787  loss_box_reg_stage2: 0.2843  loss_mask: 0.539  loss_rpn_cls: 0.05511  loss_rpn_loc: 0.03835  validation_loss: 2.046  time: 1.8222  data_time: 0.0219  lr: 3.0735e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:06:39 d2.utils.events]: \u001b[0m eta: 1:38:11  iter: 6279  total_loss: 2.099  loss_cls_stage0: 0.2825  loss_box_reg_stage0: 0.2274  loss_cls_stage1: 0.2423  loss_box_reg_stage1: 0.3131  loss_cls_stage2: 0.1797  loss_box_reg_stage2: 0.2868  loss_mask: 0.5171  loss_rpn_cls: 0.0769  loss_rpn_loc: 0.03521  validation_loss: 2.046  time: 1.8213  data_time: 0.0222  lr: 3.0446e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:07:10 d2.utils.events]: \u001b[0m eta: 1:37:30  iter: 6299  total_loss: 2.178  loss_cls_stage0: 0.2876  loss_box_reg_stage0: 0.2342  loss_cls_stage1: 0.2458  loss_box_reg_stage1: 0.3507  loss_cls_stage2: 0.1773  loss_box_reg_stage2: 0.2767  loss_mask: 0.5561  loss_rpn_cls: 0.05495  loss_rpn_loc: 0.03328  validation_loss: 2.046  time: 1.8205  data_time: 0.0235  lr: 3.0157e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:07:41 d2.utils.events]: \u001b[0m eta: 1:36:51  iter: 6319  total_loss: 2.505  loss_cls_stage0: 0.3671  loss_box_reg_stage0: 0.2825  loss_cls_stage1: 0.293  loss_box_reg_stage1: 0.3795  loss_cls_stage2: 0.2006  loss_box_reg_stage2: 0.3148  loss_mask: 0.5559  loss_rpn_cls: 0.06542  loss_rpn_loc: 0.03969  validation_loss: 2.046  time: 1.8197  data_time: 0.0247  lr: 2.9869e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:08:13 d2.utils.events]: \u001b[0m eta: 1:36:14  iter: 6339  total_loss: 2.558  loss_cls_stage0: 0.3893  loss_box_reg_stage0: 0.2844  loss_cls_stage1: 0.3201  loss_box_reg_stage1: 0.3696  loss_cls_stage2: 0.2264  loss_box_reg_stage2: 0.287  loss_mask: 0.5464  loss_rpn_cls: 0.07591  loss_rpn_loc: 0.04365  validation_loss: 2.046  time: 1.8189  data_time: 0.0238  lr: 2.9582e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:08:44 d2.utils.events]: \u001b[0m eta: 1:35:42  iter: 6359  total_loss: 2.389  loss_cls_stage0: 0.3502  loss_box_reg_stage0: 0.2714  loss_cls_stage1: 0.2624  loss_box_reg_stage1: 0.3638  loss_cls_stage2: 0.1893  loss_box_reg_stage2: 0.296  loss_mask: 0.5323  loss_rpn_cls: 0.06233  loss_rpn_loc: 0.04059  validation_loss: 2.046  time: 1.8181  data_time: 0.0223  lr: 2.9296e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:09:16 d2.utils.events]: \u001b[0m eta: 1:35:11  iter: 6379  total_loss: 2.411  loss_cls_stage0: 0.3435  loss_box_reg_stage0: 0.2652  loss_cls_stage1: 0.2862  loss_box_reg_stage1: 0.3645  loss_cls_stage2: 0.2086  loss_box_reg_stage2: 0.3186  loss_mask: 0.5806  loss_rpn_cls: 0.06496  loss_rpn_loc: 0.03819  validation_loss: 2.046  time: 1.8174  data_time: 0.0230  lr: 2.901e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:09:47 d2.utils.events]: \u001b[0m eta: 1:34:39  iter: 6399  total_loss: 2.409  loss_cls_stage0: 0.3314  loss_box_reg_stage0: 0.2519  loss_cls_stage1: 0.2699  loss_box_reg_stage1: 0.3526  loss_cls_stage2: 0.2056  loss_box_reg_stage2: 0.3088  loss_mask: 0.5089  loss_rpn_cls: 0.07378  loss_rpn_loc: 0.04144  validation_loss: 2.046  time: 1.8166  data_time: 0.0238  lr: 2.8725e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:10:18 d2.utils.events]: \u001b[0m eta: 1:34:08  iter: 6419  total_loss: 2.358  loss_cls_stage0: 0.3244  loss_box_reg_stage0: 0.2436  loss_cls_stage1: 0.268  loss_box_reg_stage1: 0.3367  loss_cls_stage2: 0.1934  loss_box_reg_stage2: 0.2971  loss_mask: 0.5463  loss_rpn_cls: 0.06825  loss_rpn_loc: 0.03508  validation_loss: 2.046  time: 1.8158  data_time: 0.0235  lr: 2.8441e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:10:49 d2.utils.events]: \u001b[0m eta: 1:33:36  iter: 6439  total_loss: 2.353  loss_cls_stage0: 0.3189  loss_box_reg_stage0: 0.2637  loss_cls_stage1: 0.2775  loss_box_reg_stage1: 0.3467  loss_cls_stage2: 0.1991  loss_box_reg_stage2: 0.2741  loss_mask: 0.5315  loss_rpn_cls: 0.0627  loss_rpn_loc: 0.03251  validation_loss: 2.046  time: 1.8150  data_time: 0.0237  lr: 2.8158e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:11:21 d2.utils.events]: \u001b[0m eta: 1:33:04  iter: 6459  total_loss: 2.38  loss_cls_stage0: 0.3282  loss_box_reg_stage0: 0.2561  loss_cls_stage1: 0.2775  loss_box_reg_stage1: 0.3755  loss_cls_stage2: 0.1845  loss_box_reg_stage2: 0.2824  loss_mask: 0.5548  loss_rpn_cls: 0.06235  loss_rpn_loc: 0.03569  validation_loss: 2.046  time: 1.8142  data_time: 0.0241  lr: 2.7876e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:11:52 d2.utils.events]: \u001b[0m eta: 1:32:32  iter: 6479  total_loss: 2.314  loss_cls_stage0: 0.3226  loss_box_reg_stage0: 0.2641  loss_cls_stage1: 0.2709  loss_box_reg_stage1: 0.3827  loss_cls_stage2: 0.1962  loss_box_reg_stage2: 0.2957  loss_mask: 0.5008  loss_rpn_cls: 0.05656  loss_rpn_loc: 0.03493  validation_loss: 2.046  time: 1.8134  data_time: 0.0258  lr: 2.7595e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:12:23 d2.utils.events]: \u001b[0m eta: 1:32:01  iter: 6499  total_loss: 2.432  loss_cls_stage0: 0.3255  loss_box_reg_stage0: 0.2482  loss_cls_stage1: 0.2702  loss_box_reg_stage1: 0.368  loss_cls_stage2: 0.1929  loss_box_reg_stage2: 0.3091  loss_mask: 0.533  loss_rpn_cls: 0.05538  loss_rpn_loc: 0.03559  validation_loss: 2.046  time: 1.8126  data_time: 0.0249  lr: 2.7314e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:12:55 d2.utils.events]: \u001b[0m eta: 1:31:25  iter: 6519  total_loss: 2.338  loss_cls_stage0: 0.3329  loss_box_reg_stage0: 0.2503  loss_cls_stage1: 0.2844  loss_box_reg_stage1: 0.3619  loss_cls_stage2: 0.1991  loss_box_reg_stage2: 0.3208  loss_mask: 0.5557  loss_rpn_cls: 0.06367  loss_rpn_loc: 0.03762  validation_loss: 2.046  time: 1.8119  data_time: 0.0241  lr: 2.7035e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:13:26 d2.utils.events]: \u001b[0m eta: 1:30:46  iter: 6539  total_loss: 2.238  loss_cls_stage0: 0.3084  loss_box_reg_stage0: 0.2352  loss_cls_stage1: 0.2597  loss_box_reg_stage1: 0.3287  loss_cls_stage2: 0.1814  loss_box_reg_stage2: 0.2497  loss_mask: 0.5824  loss_rpn_cls: 0.05386  loss_rpn_loc: 0.03057  validation_loss: 2.046  time: 1.8111  data_time: 0.0234  lr: 2.6756e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:13:57 d2.utils.events]: \u001b[0m eta: 1:30:10  iter: 6559  total_loss: 2.495  loss_cls_stage0: 0.3354  loss_box_reg_stage0: 0.2579  loss_cls_stage1: 0.2927  loss_box_reg_stage1: 0.3945  loss_cls_stage2: 0.2132  loss_box_reg_stage2: 0.3145  loss_mask: 0.5404  loss_rpn_cls: 0.05882  loss_rpn_loc: 0.03764  validation_loss: 2.046  time: 1.8104  data_time: 0.0224  lr: 2.6479e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:14:28 d2.utils.events]: \u001b[0m eta: 1:29:32  iter: 6579  total_loss: 2.318  loss_cls_stage0: 0.3226  loss_box_reg_stage0: 0.2344  loss_cls_stage1: 0.2666  loss_box_reg_stage1: 0.3582  loss_cls_stage2: 0.203  loss_box_reg_stage2: 0.2953  loss_mask: 0.5148  loss_rpn_cls: 0.05362  loss_rpn_loc: 0.03082  validation_loss: 2.046  time: 1.8096  data_time: 0.0237  lr: 2.6202e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:15:00 d2.utils.events]: \u001b[0m eta: 1:28:59  iter: 6599  total_loss: 2.491  loss_cls_stage0: 0.3539  loss_box_reg_stage0: 0.2629  loss_cls_stage1: 0.2941  loss_box_reg_stage1: 0.3684  loss_cls_stage2: 0.2032  loss_box_reg_stage2: 0.307  loss_mask: 0.531  loss_rpn_cls: 0.07455  loss_rpn_loc: 0.03838  validation_loss: 2.046  time: 1.8089  data_time: 0.0246  lr: 2.5926e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:15:31 d2.utils.events]: \u001b[0m eta: 1:28:22  iter: 6619  total_loss: 2.28  loss_cls_stage0: 0.3082  loss_box_reg_stage0: 0.2426  loss_cls_stage1: 0.2593  loss_box_reg_stage1: 0.3608  loss_cls_stage2: 0.189  loss_box_reg_stage2: 0.2985  loss_mask: 0.5809  loss_rpn_cls: 0.05376  loss_rpn_loc: 0.03593  validation_loss: 2.046  time: 1.8081  data_time: 0.0301  lr: 2.5651e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:16:02 d2.utils.events]: \u001b[0m eta: 1:27:48  iter: 6639  total_loss: 2.31  loss_cls_stage0: 0.3144  loss_box_reg_stage0: 0.2539  loss_cls_stage1: 0.2581  loss_box_reg_stage1: 0.3754  loss_cls_stage2: 0.1888  loss_box_reg_stage2: 0.287  loss_mask: 0.5708  loss_rpn_cls: 0.0636  loss_rpn_loc: 0.03714  validation_loss: 2.046  time: 1.8073  data_time: 0.0237  lr: 2.5377e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:16:33 d2.utils.events]: \u001b[0m eta: 1:27:16  iter: 6659  total_loss: 2.496  loss_cls_stage0: 0.3383  loss_box_reg_stage0: 0.2505  loss_cls_stage1: 0.2809  loss_box_reg_stage1: 0.3748  loss_cls_stage2: 0.2029  loss_box_reg_stage2: 0.3072  loss_mask: 0.5458  loss_rpn_cls: 0.05479  loss_rpn_loc: 0.03182  validation_loss: 2.046  time: 1.8066  data_time: 0.0230  lr: 2.5104e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:17:04 d2.utils.events]: \u001b[0m eta: 1:26:45  iter: 6679  total_loss: 2.199  loss_cls_stage0: 0.2894  loss_box_reg_stage0: 0.2166  loss_cls_stage1: 0.2348  loss_box_reg_stage1: 0.3273  loss_cls_stage2: 0.1755  loss_box_reg_stage2: 0.2758  loss_mask: 0.5708  loss_rpn_cls: 0.06797  loss_rpn_loc: 0.03317  validation_loss: 2.046  time: 1.8059  data_time: 0.0221  lr: 2.4832e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:17:36 d2.utils.events]: \u001b[0m eta: 1:26:14  iter: 6699  total_loss: 2.371  loss_cls_stage0: 0.3393  loss_box_reg_stage0: 0.2669  loss_cls_stage1: 0.2952  loss_box_reg_stage1: 0.3769  loss_cls_stage2: 0.2052  loss_box_reg_stage2: 0.3257  loss_mask: 0.499  loss_rpn_cls: 0.05747  loss_rpn_loc: 0.03187  validation_loss: 2.046  time: 1.8052  data_time: 0.0245  lr: 2.4561e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:18:07 d2.utils.events]: \u001b[0m eta: 1:25:44  iter: 6719  total_loss: 2.659  loss_cls_stage0: 0.382  loss_box_reg_stage0: 0.2997  loss_cls_stage1: 0.3186  loss_box_reg_stage1: 0.4035  loss_cls_stage2: 0.2174  loss_box_reg_stage2: 0.3047  loss_mask: 0.5505  loss_rpn_cls: 0.05407  loss_rpn_loc: 0.0354  validation_loss: 2.046  time: 1.8045  data_time: 0.0242  lr: 2.4291e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:18:39 d2.utils.events]: \u001b[0m eta: 1:25:14  iter: 6739  total_loss: 2.546  loss_cls_stage0: 0.3605  loss_box_reg_stage0: 0.2852  loss_cls_stage1: 0.3085  loss_box_reg_stage1: 0.3905  loss_cls_stage2: 0.2092  loss_box_reg_stage2: 0.3123  loss_mask: 0.5252  loss_rpn_cls: 0.06437  loss_rpn_loc: 0.03699  validation_loss: 2.046  time: 1.8038  data_time: 0.0233  lr: 2.4023e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:19:10 d2.utils.events]: \u001b[0m eta: 1:24:43  iter: 6759  total_loss: 2.455  loss_cls_stage0: 0.3358  loss_box_reg_stage0: 0.2667  loss_cls_stage1: 0.2842  loss_box_reg_stage1: 0.3737  loss_cls_stage2: 0.2155  loss_box_reg_stage2: 0.3057  loss_mask: 0.5945  loss_rpn_cls: 0.05899  loss_rpn_loc: 0.03877  validation_loss: 2.046  time: 1.8031  data_time: 0.0239  lr: 2.3755e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:19:41 d2.utils.events]: \u001b[0m eta: 1:24:10  iter: 6779  total_loss: 2.235  loss_cls_stage0: 0.28  loss_box_reg_stage0: 0.2265  loss_cls_stage1: 0.2333  loss_box_reg_stage1: 0.334  loss_cls_stage2: 0.1781  loss_box_reg_stage2: 0.2812  loss_mask: 0.5381  loss_rpn_cls: 0.06031  loss_rpn_loc: 0.03132  validation_loss: 2.046  time: 1.8023  data_time: 0.0249  lr: 2.3488e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:20:12 d2.utils.events]: \u001b[0m eta: 1:23:37  iter: 6799  total_loss: 2.22  loss_cls_stage0: 0.3202  loss_box_reg_stage0: 0.2617  loss_cls_stage1: 0.2657  loss_box_reg_stage1: 0.3497  loss_cls_stage2: 0.1886  loss_box_reg_stage2: 0.2906  loss_mask: 0.5088  loss_rpn_cls: 0.06506  loss_rpn_loc: 0.03255  validation_loss: 2.046  time: 1.8016  data_time: 0.0254  lr: 2.3222e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:20:44 d2.utils.events]: \u001b[0m eta: 1:23:03  iter: 6819  total_loss: 2.297  loss_cls_stage0: 0.3313  loss_box_reg_stage0: 0.2589  loss_cls_stage1: 0.2661  loss_box_reg_stage1: 0.3621  loss_cls_stage2: 0.199  loss_box_reg_stage2: 0.2994  loss_mask: 0.5353  loss_rpn_cls: 0.05891  loss_rpn_loc: 0.03561  validation_loss: 2.046  time: 1.8009  data_time: 0.0244  lr: 2.2957e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:21:15 d2.utils.events]: \u001b[0m eta: 1:22:29  iter: 6839  total_loss: 2.245  loss_cls_stage0: 0.2993  loss_box_reg_stage0: 0.2523  loss_cls_stage1: 0.2523  loss_box_reg_stage1: 0.3719  loss_cls_stage2: 0.1895  loss_box_reg_stage2: 0.3147  loss_mask: 0.5043  loss_rpn_cls: 0.0612  loss_rpn_loc: 0.03582  validation_loss: 2.046  time: 1.8003  data_time: 0.0234  lr: 2.2693e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:21:46 d2.utils.events]: \u001b[0m eta: 1:21:53  iter: 6859  total_loss: 2.222  loss_cls_stage0: 0.3035  loss_box_reg_stage0: 0.2442  loss_cls_stage1: 0.2564  loss_box_reg_stage1: 0.3305  loss_cls_stage2: 0.1828  loss_box_reg_stage2: 0.2902  loss_mask: 0.5277  loss_rpn_cls: 0.05923  loss_rpn_loc: 0.03443  validation_loss: 2.046  time: 1.7995  data_time: 0.0241  lr: 2.2431e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:22:17 d2.utils.events]: \u001b[0m eta: 1:21:20  iter: 6879  total_loss: 2.332  loss_cls_stage0: 0.3356  loss_box_reg_stage0: 0.2506  loss_cls_stage1: 0.2789  loss_box_reg_stage1: 0.3681  loss_cls_stage2: 0.2023  loss_box_reg_stage2: 0.3149  loss_mask: 0.547  loss_rpn_cls: 0.06987  loss_rpn_loc: 0.03677  validation_loss: 2.046  time: 1.7989  data_time: 0.0233  lr: 2.2169e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:22:49 d2.utils.events]: \u001b[0m eta: 1:20:46  iter: 6899  total_loss: 2.382  loss_cls_stage0: 0.3309  loss_box_reg_stage0: 0.2622  loss_cls_stage1: 0.266  loss_box_reg_stage1: 0.3612  loss_cls_stage2: 0.1897  loss_box_reg_stage2: 0.2887  loss_mask: 0.5361  loss_rpn_cls: 0.04977  loss_rpn_loc: 0.03239  validation_loss: 2.046  time: 1.7982  data_time: 0.0246  lr: 2.1909e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:23:20 d2.utils.events]: \u001b[0m eta: 1:20:15  iter: 6919  total_loss: 2.4  loss_cls_stage0: 0.3394  loss_box_reg_stage0: 0.2566  loss_cls_stage1: 0.2906  loss_box_reg_stage1: 0.3877  loss_cls_stage2: 0.2112  loss_box_reg_stage2: 0.3022  loss_mask: 0.5214  loss_rpn_cls: 0.06547  loss_rpn_loc: 0.03407  validation_loss: 2.046  time: 1.7975  data_time: 0.0236  lr: 2.1649e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:23:51 d2.utils.events]: \u001b[0m eta: 1:19:44  iter: 6939  total_loss: 2.278  loss_cls_stage0: 0.3101  loss_box_reg_stage0: 0.2562  loss_cls_stage1: 0.2567  loss_box_reg_stage1: 0.357  loss_cls_stage2: 0.1888  loss_box_reg_stage2: 0.2769  loss_mask: 0.5719  loss_rpn_cls: 0.06346  loss_rpn_loc: 0.0363  validation_loss: 2.046  time: 1.7968  data_time: 0.0251  lr: 2.1391e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:24:23 d2.utils.events]: \u001b[0m eta: 1:19:13  iter: 6959  total_loss: 2.381  loss_cls_stage0: 0.3205  loss_box_reg_stage0: 0.2309  loss_cls_stage1: 0.2871  loss_box_reg_stage1: 0.363  loss_cls_stage2: 0.2074  loss_box_reg_stage2: 0.3074  loss_mask: 0.4776  loss_rpn_cls: 0.05765  loss_rpn_loc: 0.03237  validation_loss: 2.046  time: 1.7962  data_time: 0.0254  lr: 2.1134e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:24:54 d2.utils.events]: \u001b[0m eta: 1:18:39  iter: 6979  total_loss: 2.254  loss_cls_stage0: 0.2969  loss_box_reg_stage0: 0.2296  loss_cls_stage1: 0.256  loss_box_reg_stage1: 0.3659  loss_cls_stage2: 0.1958  loss_box_reg_stage2: 0.3263  loss_mask: 0.4945  loss_rpn_cls: 0.05454  loss_rpn_loc: 0.0319  validation_loss: 2.046  time: 1.7955  data_time: 0.0241  lr: 2.0878e-05  max_mem: 11557M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/26 14:25:27 d2.data.common]: \u001b[0mSerializing 900 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/26 14:25:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.91 MiB\n",
      "\u001b[32m[03/26 14:25:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 900 images\n",
      "\u001b[32m[03/26 14:25:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/900. 0.0821 s / img. ETA=0:01:59\n",
      "\u001b[32m[03/26 14:25:34 d2.evaluation.evaluator]: \u001b[0mInference done 53/900. 0.0811 s / img. ETA=0:01:42\n",
      "\u001b[32m[03/26 14:25:39 d2.evaluation.evaluator]: \u001b[0mInference done 93/900. 0.0813 s / img. ETA=0:01:40\n",
      "\u001b[32m[03/26 14:25:45 d2.evaluation.evaluator]: \u001b[0mInference done 135/900. 0.0812 s / img. ETA=0:01:34\n",
      "\u001b[32m[03/26 14:25:50 d2.evaluation.evaluator]: \u001b[0mInference done 179/900. 0.0811 s / img. ETA=0:01:27\n",
      "\u001b[32m[03/26 14:25:55 d2.evaluation.evaluator]: \u001b[0mInference done 221/900. 0.0812 s / img. ETA=0:01:22\n",
      "\u001b[32m[03/26 14:26:00 d2.evaluation.evaluator]: \u001b[0mInference done 261/900. 0.0812 s / img. ETA=0:01:18\n",
      "\u001b[32m[03/26 14:26:05 d2.evaluation.evaluator]: \u001b[0mInference done 305/900. 0.0811 s / img. ETA=0:01:12\n",
      "\u001b[32m[03/26 14:26:10 d2.evaluation.evaluator]: \u001b[0mInference done 346/900. 0.0812 s / img. ETA=0:01:07\n",
      "\u001b[32m[03/26 14:26:15 d2.evaluation.evaluator]: \u001b[0mInference done 385/900. 0.0812 s / img. ETA=0:01:02\n",
      "\u001b[32m[03/26 14:26:20 d2.evaluation.evaluator]: \u001b[0mInference done 427/900. 0.0816 s / img. ETA=0:00:57\n",
      "\u001b[32m[03/26 14:26:25 d2.evaluation.evaluator]: \u001b[0mInference done 467/900. 0.0816 s / img. ETA=0:00:53\n",
      "\u001b[32m[03/26 14:26:30 d2.evaluation.evaluator]: \u001b[0mInference done 508/900. 0.0816 s / img. ETA=0:00:48\n",
      "\u001b[32m[03/26 14:26:35 d2.evaluation.evaluator]: \u001b[0mInference done 552/900. 0.0815 s / img. ETA=0:00:42\n",
      "\u001b[32m[03/26 14:26:40 d2.evaluation.evaluator]: \u001b[0mInference done 591/900. 0.0815 s / img. ETA=0:00:37\n",
      "\u001b[32m[03/26 14:26:46 d2.evaluation.evaluator]: \u001b[0mInference done 633/900. 0.0815 s / img. ETA=0:00:32\n",
      "\u001b[32m[03/26 14:26:51 d2.evaluation.evaluator]: \u001b[0mInference done 675/900. 0.0815 s / img. ETA=0:00:27\n",
      "\u001b[32m[03/26 14:26:56 d2.evaluation.evaluator]: \u001b[0mInference done 715/900. 0.0815 s / img. ETA=0:00:22\n",
      "\u001b[32m[03/26 14:27:01 d2.evaluation.evaluator]: \u001b[0mInference done 757/900. 0.0815 s / img. ETA=0:00:17\n",
      "\u001b[32m[03/26 14:27:06 d2.evaluation.evaluator]: \u001b[0mInference done 799/900. 0.0815 s / img. ETA=0:00:12\n",
      "\u001b[32m[03/26 14:27:11 d2.evaluation.evaluator]: \u001b[0mInference done 841/900. 0.0815 s / img. ETA=0:00:07\n",
      "\u001b[32m[03/26 14:27:16 d2.evaluation.evaluator]: \u001b[0mInference done 882/900. 0.0814 s / img. ETA=0:00:02\n",
      "\u001b[32m[03/26 14:27:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:49.843985 (0.122731 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/26 14:27:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:12 (0.081437 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.33 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.088\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.147\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.165\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.040\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.095\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.131\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.179\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.016\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.055\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.202\n",
      "\u001b[32m[03/26 14:27:19 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold1 in csv format:\n",
      "\u001b[32m[03/26 14:27:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/26 14:27:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/26 14:27:19 d2.evaluation.testing]: \u001b[0mcopypaste: 8.8467,14.6950,16.4597,1.0503,4.0199,9.4668\n",
      "validation do loss eval 2.379486963105155\n",
      "\u001b[32m[03/26 14:28:52 d2.utils.events]: \u001b[0m eta: 1:18:06  iter: 6999  total_loss: 2.349  loss_cls_stage0: 0.3424  loss_box_reg_stage0: 0.2815  loss_cls_stage1: 0.2579  loss_box_reg_stage1: 0.3739  loss_cls_stage2: 0.1848  loss_box_reg_stage2: 0.3158  loss_mask: 0.5349  loss_rpn_cls: 0.06491  loss_rpn_loc: 0.03825  validation_loss: 2.095  time: 1.7948  data_time: 0.0251  lr: 2.0623e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:29:23 d2.utils.events]: \u001b[0m eta: 1:17:36  iter: 7019  total_loss: 2.354  loss_cls_stage0: 0.3308  loss_box_reg_stage0: 0.2756  loss_cls_stage1: 0.2688  loss_box_reg_stage1: 0.3685  loss_cls_stage2: 0.1968  loss_box_reg_stage2: 0.2951  loss_mask: 0.4918  loss_rpn_cls: 0.06341  loss_rpn_loc: 0.03886  validation_loss: 2.095  time: 1.7941  data_time: 0.0240  lr: 2.037e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:29:55 d2.utils.events]: \u001b[0m eta: 1:17:05  iter: 7039  total_loss: 2.463  loss_cls_stage0: 0.3402  loss_box_reg_stage0: 0.2697  loss_cls_stage1: 0.2765  loss_box_reg_stage1: 0.3462  loss_cls_stage2: 0.1939  loss_box_reg_stage2: 0.2932  loss_mask: 0.5231  loss_rpn_cls: 0.06359  loss_rpn_loc: 0.03771  validation_loss: 2.095  time: 1.7935  data_time: 0.0226  lr: 2.0117e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:30:26 d2.utils.events]: \u001b[0m eta: 1:16:32  iter: 7059  total_loss: 2.196  loss_cls_stage0: 0.2976  loss_box_reg_stage0: 0.2288  loss_cls_stage1: 0.2527  loss_box_reg_stage1: 0.3417  loss_cls_stage2: 0.1821  loss_box_reg_stage2: 0.2631  loss_mask: 0.5006  loss_rpn_cls: 0.05915  loss_rpn_loc: 0.03136  validation_loss: 2.095  time: 1.7928  data_time: 0.0236  lr: 1.9866e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:30:57 d2.utils.events]: \u001b[0m eta: 1:16:01  iter: 7079  total_loss: 2.43  loss_cls_stage0: 0.3243  loss_box_reg_stage0: 0.2574  loss_cls_stage1: 0.2793  loss_box_reg_stage1: 0.373  loss_cls_stage2: 0.2115  loss_box_reg_stage2: 0.3029  loss_mask: 0.5286  loss_rpn_cls: 0.06407  loss_rpn_loc: 0.03867  validation_loss: 2.095  time: 1.7922  data_time: 0.0252  lr: 1.9616e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:31:28 d2.utils.events]: \u001b[0m eta: 1:15:29  iter: 7099  total_loss: 2.449  loss_cls_stage0: 0.3307  loss_box_reg_stage0: 0.2488  loss_cls_stage1: 0.282  loss_box_reg_stage1: 0.3539  loss_cls_stage2: 0.2028  loss_box_reg_stage2: 0.3007  loss_mask: 0.553  loss_rpn_cls: 0.06342  loss_rpn_loc: 0.0351  validation_loss: 2.095  time: 1.7916  data_time: 0.0227  lr: 1.9367e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:32:00 d2.utils.events]: \u001b[0m eta: 1:14:55  iter: 7119  total_loss: 2.161  loss_cls_stage0: 0.2771  loss_box_reg_stage0: 0.2308  loss_cls_stage1: 0.2318  loss_box_reg_stage1: 0.3337  loss_cls_stage2: 0.173  loss_box_reg_stage2: 0.29  loss_mask: 0.5054  loss_rpn_cls: 0.05628  loss_rpn_loc: 0.03065  validation_loss: 2.095  time: 1.7909  data_time: 0.0247  lr: 1.9119e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:32:31 d2.utils.events]: \u001b[0m eta: 1:14:23  iter: 7139  total_loss: 2.191  loss_cls_stage0: 0.2926  loss_box_reg_stage0: 0.2336  loss_cls_stage1: 0.2491  loss_box_reg_stage1: 0.3442  loss_cls_stage2: 0.1746  loss_box_reg_stage2: 0.2741  loss_mask: 0.5583  loss_rpn_cls: 0.05967  loss_rpn_loc: 0.03279  validation_loss: 2.095  time: 1.7902  data_time: 0.0324  lr: 1.8873e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:33:02 d2.utils.events]: \u001b[0m eta: 1:13:51  iter: 7159  total_loss: 2.556  loss_cls_stage0: 0.3521  loss_box_reg_stage0: 0.2814  loss_cls_stage1: 0.2911  loss_box_reg_stage1: 0.3953  loss_cls_stage2: 0.2037  loss_box_reg_stage2: 0.3139  loss_mask: 0.5291  loss_rpn_cls: 0.06899  loss_rpn_loc: 0.04257  validation_loss: 2.095  time: 1.7896  data_time: 0.0242  lr: 1.8628e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:33:34 d2.utils.events]: \u001b[0m eta: 1:13:21  iter: 7179  total_loss: 2.445  loss_cls_stage0: 0.3518  loss_box_reg_stage0: 0.2738  loss_cls_stage1: 0.2828  loss_box_reg_stage1: 0.3628  loss_cls_stage2: 0.1979  loss_box_reg_stage2: 0.3052  loss_mask: 0.5644  loss_rpn_cls: 0.06803  loss_rpn_loc: 0.03587  validation_loss: 2.095  time: 1.7890  data_time: 0.0231  lr: 1.8384e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:34:05 d2.utils.events]: \u001b[0m eta: 1:12:49  iter: 7199  total_loss: 2.275  loss_cls_stage0: 0.3252  loss_box_reg_stage0: 0.2659  loss_cls_stage1: 0.2663  loss_box_reg_stage1: 0.3377  loss_cls_stage2: 0.1785  loss_box_reg_stage2: 0.2644  loss_mask: 0.531  loss_rpn_cls: 0.06332  loss_rpn_loc: 0.03804  validation_loss: 2.095  time: 1.7884  data_time: 0.0214  lr: 1.8141e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:34:36 d2.utils.events]: \u001b[0m eta: 1:12:17  iter: 7219  total_loss: 2.206  loss_cls_stage0: 0.2884  loss_box_reg_stage0: 0.2338  loss_cls_stage1: 0.2477  loss_box_reg_stage1: 0.3465  loss_cls_stage2: 0.1893  loss_box_reg_stage2: 0.3101  loss_mask: 0.4984  loss_rpn_cls: 0.06061  loss_rpn_loc: 0.03657  validation_loss: 2.095  time: 1.7877  data_time: 0.0240  lr: 1.7899e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:35:07 d2.utils.events]: \u001b[0m eta: 1:11:43  iter: 7239  total_loss: 2.236  loss_cls_stage0: 0.3016  loss_box_reg_stage0: 0.2268  loss_cls_stage1: 0.2591  loss_box_reg_stage1: 0.3508  loss_cls_stage2: 0.1861  loss_box_reg_stage2: 0.2936  loss_mask: 0.5358  loss_rpn_cls: 0.07122  loss_rpn_loc: 0.03653  validation_loss: 2.095  time: 1.7871  data_time: 0.0231  lr: 1.7659e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:35:38 d2.utils.events]: \u001b[0m eta: 1:11:12  iter: 7259  total_loss: 2.438  loss_cls_stage0: 0.3461  loss_box_reg_stage0: 0.2644  loss_cls_stage1: 0.2792  loss_box_reg_stage1: 0.3754  loss_cls_stage2: 0.2039  loss_box_reg_stage2: 0.3085  loss_mask: 0.5705  loss_rpn_cls: 0.05732  loss_rpn_loc: 0.03495  validation_loss: 2.095  time: 1.7865  data_time: 0.0208  lr: 1.742e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:36:10 d2.utils.events]: \u001b[0m eta: 1:10:40  iter: 7279  total_loss: 2.271  loss_cls_stage0: 0.3369  loss_box_reg_stage0: 0.2614  loss_cls_stage1: 0.2812  loss_box_reg_stage1: 0.3583  loss_cls_stage2: 0.1925  loss_box_reg_stage2: 0.2864  loss_mask: 0.5244  loss_rpn_cls: 0.06146  loss_rpn_loc: 0.03384  validation_loss: 2.095  time: 1.7859  data_time: 0.0245  lr: 1.7183e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:36:41 d2.utils.events]: \u001b[0m eta: 1:10:09  iter: 7299  total_loss: 2.19  loss_cls_stage0: 0.2972  loss_box_reg_stage0: 0.2224  loss_cls_stage1: 0.2526  loss_box_reg_stage1: 0.3142  loss_cls_stage2: 0.1823  loss_box_reg_stage2: 0.2792  loss_mask: 0.5238  loss_rpn_cls: 0.04829  loss_rpn_loc: 0.0356  validation_loss: 2.095  time: 1.7852  data_time: 0.0245  lr: 1.6946e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:37:12 d2.utils.events]: \u001b[0m eta: 1:09:38  iter: 7319  total_loss: 2.362  loss_cls_stage0: 0.3222  loss_box_reg_stage0: 0.2668  loss_cls_stage1: 0.2709  loss_box_reg_stage1: 0.3458  loss_cls_stage2: 0.2059  loss_box_reg_stage2: 0.3071  loss_mask: 0.5356  loss_rpn_cls: 0.05516  loss_rpn_loc: 0.03656  validation_loss: 2.095  time: 1.7846  data_time: 0.0223  lr: 1.6711e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:37:44 d2.utils.events]: \u001b[0m eta: 1:09:08  iter: 7339  total_loss: 2.918  loss_cls_stage0: 0.4123  loss_box_reg_stage0: 0.3406  loss_cls_stage1: 0.3396  loss_box_reg_stage1: 0.4548  loss_cls_stage2: 0.24  loss_box_reg_stage2: 0.3409  loss_mask: 0.542  loss_rpn_cls: 0.06236  loss_rpn_loc: 0.03958  validation_loss: 2.095  time: 1.7841  data_time: 0.0236  lr: 1.6477e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:38:15 d2.utils.events]: \u001b[0m eta: 1:08:37  iter: 7359  total_loss: 2.252  loss_cls_stage0: 0.3169  loss_box_reg_stage0: 0.2474  loss_cls_stage1: 0.2524  loss_box_reg_stage1: 0.3524  loss_cls_stage2: 0.1938  loss_box_reg_stage2: 0.291  loss_mask: 0.5191  loss_rpn_cls: 0.05824  loss_rpn_loc: 0.03641  validation_loss: 2.095  time: 1.7835  data_time: 0.0231  lr: 1.6245e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:38:46 d2.utils.events]: \u001b[0m eta: 1:08:04  iter: 7379  total_loss: 2.394  loss_cls_stage0: 0.2987  loss_box_reg_stage0: 0.2381  loss_cls_stage1: 0.2677  loss_box_reg_stage1: 0.3518  loss_cls_stage2: 0.2021  loss_box_reg_stage2: 0.2996  loss_mask: 0.4985  loss_rpn_cls: 0.05679  loss_rpn_loc: 0.03422  validation_loss: 2.095  time: 1.7829  data_time: 0.0232  lr: 1.6014e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:39:18 d2.utils.events]: \u001b[0m eta: 1:07:33  iter: 7399  total_loss: 2.316  loss_cls_stage0: 0.3289  loss_box_reg_stage0: 0.2767  loss_cls_stage1: 0.2749  loss_box_reg_stage1: 0.3711  loss_cls_stage2: 0.1946  loss_box_reg_stage2: 0.2938  loss_mask: 0.4841  loss_rpn_cls: 0.05879  loss_rpn_loc: 0.03555  validation_loss: 2.095  time: 1.7823  data_time: 0.0235  lr: 1.5784e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:39:49 d2.utils.events]: \u001b[0m eta: 1:07:04  iter: 7419  total_loss: 2.397  loss_cls_stage0: 0.344  loss_box_reg_stage0: 0.2754  loss_cls_stage1: 0.2769  loss_box_reg_stage1: 0.3747  loss_cls_stage2: 0.1969  loss_box_reg_stage2: 0.2936  loss_mask: 0.5644  loss_rpn_cls: 0.05914  loss_rpn_loc: 0.0358  validation_loss: 2.095  time: 1.7817  data_time: 0.0225  lr: 1.5556e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:40:21 d2.utils.events]: \u001b[0m eta: 1:06:33  iter: 7439  total_loss: 2.51  loss_cls_stage0: 0.3495  loss_box_reg_stage0: 0.2798  loss_cls_stage1: 0.2862  loss_box_reg_stage1: 0.3981  loss_cls_stage2: 0.2093  loss_box_reg_stage2: 0.3317  loss_mask: 0.5754  loss_rpn_cls: 0.05698  loss_rpn_loc: 0.03271  validation_loss: 2.095  time: 1.7812  data_time: 0.0229  lr: 1.5329e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:40:52 d2.utils.events]: \u001b[0m eta: 1:06:01  iter: 7459  total_loss: 2.126  loss_cls_stage0: 0.272  loss_box_reg_stage0: 0.2139  loss_cls_stage1: 0.235  loss_box_reg_stage1: 0.3275  loss_cls_stage2: 0.1818  loss_box_reg_stage2: 0.2968  loss_mask: 0.5596  loss_rpn_cls: 0.05708  loss_rpn_loc: 0.03302  validation_loss: 2.095  time: 1.7806  data_time: 0.0236  lr: 1.5103e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:41:23 d2.utils.events]: \u001b[0m eta: 1:05:29  iter: 7479  total_loss: 2.449  loss_cls_stage0: 0.3336  loss_box_reg_stage0: 0.2594  loss_cls_stage1: 0.2818  loss_box_reg_stage1: 0.373  loss_cls_stage2: 0.2209  loss_box_reg_stage2: 0.3204  loss_mask: 0.5865  loss_rpn_cls: 0.05228  loss_rpn_loc: 0.03672  validation_loss: 2.095  time: 1.7800  data_time: 0.0243  lr: 1.4879e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:41:54 d2.utils.events]: \u001b[0m eta: 1:04:57  iter: 7499  total_loss: 2.259  loss_cls_stage0: 0.3099  loss_box_reg_stage0: 0.2226  loss_cls_stage1: 0.2812  loss_box_reg_stage1: 0.338  loss_cls_stage2: 0.2032  loss_box_reg_stage2: 0.2951  loss_mask: 0.5289  loss_rpn_cls: 0.05848  loss_rpn_loc: 0.03124  validation_loss: 2.095  time: 1.7794  data_time: 0.0247  lr: 1.4656e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:42:26 d2.utils.events]: \u001b[0m eta: 1:04:26  iter: 7519  total_loss: 2.195  loss_cls_stage0: 0.3171  loss_box_reg_stage0: 0.249  loss_cls_stage1: 0.2579  loss_box_reg_stage1: 0.3482  loss_cls_stage2: 0.1836  loss_box_reg_stage2: 0.2776  loss_mask: 0.4815  loss_rpn_cls: 0.05846  loss_rpn_loc: 0.034  validation_loss: 2.095  time: 1.7788  data_time: 0.0309  lr: 1.4434e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:42:57 d2.utils.events]: \u001b[0m eta: 1:03:58  iter: 7539  total_loss: 2.503  loss_cls_stage0: 0.3406  loss_box_reg_stage0: 0.2815  loss_cls_stage1: 0.2763  loss_box_reg_stage1: 0.3939  loss_cls_stage2: 0.205  loss_box_reg_stage2: 0.3244  loss_mask: 0.567  loss_rpn_cls: 0.06599  loss_rpn_loc: 0.03637  validation_loss: 2.095  time: 1.7783  data_time: 0.0239  lr: 1.4214e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:43:29 d2.utils.events]: \u001b[0m eta: 1:03:27  iter: 7559  total_loss: 2.421  loss_cls_stage0: 0.3468  loss_box_reg_stage0: 0.2745  loss_cls_stage1: 0.2817  loss_box_reg_stage1: 0.3851  loss_cls_stage2: 0.206  loss_box_reg_stage2: 0.3221  loss_mask: 0.5355  loss_rpn_cls: 0.05991  loss_rpn_loc: 0.03939  validation_loss: 2.095  time: 1.7778  data_time: 0.0235  lr: 1.3995e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:44:00 d2.utils.events]: \u001b[0m eta: 1:02:56  iter: 7579  total_loss: 2.283  loss_cls_stage0: 0.3235  loss_box_reg_stage0: 0.261  loss_cls_stage1: 0.2627  loss_box_reg_stage1: 0.364  loss_cls_stage2: 0.1924  loss_box_reg_stage2: 0.2849  loss_mask: 0.4774  loss_rpn_cls: 0.06506  loss_rpn_loc: 0.03642  validation_loss: 2.095  time: 1.7772  data_time: 0.0241  lr: 1.3778e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:44:31 d2.utils.events]: \u001b[0m eta: 1:02:25  iter: 7599  total_loss: 2.372  loss_cls_stage0: 0.3328  loss_box_reg_stage0: 0.268  loss_cls_stage1: 0.2716  loss_box_reg_stage1: 0.3664  loss_cls_stage2: 0.1888  loss_box_reg_stage2: 0.2862  loss_mask: 0.5362  loss_rpn_cls: 0.06818  loss_rpn_loc: 0.03778  validation_loss: 2.095  time: 1.7766  data_time: 0.0229  lr: 1.3562e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:45:02 d2.utils.events]: \u001b[0m eta: 1:01:55  iter: 7619  total_loss: 2.334  loss_cls_stage0: 0.3215  loss_box_reg_stage0: 0.2578  loss_cls_stage1: 0.2554  loss_box_reg_stage1: 0.3586  loss_cls_stage2: 0.1842  loss_box_reg_stage2: 0.3044  loss_mask: 0.5175  loss_rpn_cls: 0.06293  loss_rpn_loc: 0.03863  validation_loss: 2.095  time: 1.7761  data_time: 0.0236  lr: 1.3348e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:45:34 d2.utils.events]: \u001b[0m eta: 1:01:24  iter: 7639  total_loss: 2.294  loss_cls_stage0: 0.3149  loss_box_reg_stage0: 0.2495  loss_cls_stage1: 0.2664  loss_box_reg_stage1: 0.3564  loss_cls_stage2: 0.1981  loss_box_reg_stage2: 0.3203  loss_mask: 0.5072  loss_rpn_cls: 0.06352  loss_rpn_loc: 0.03594  validation_loss: 2.095  time: 1.7755  data_time: 0.0245  lr: 1.3135e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:46:05 d2.utils.events]: \u001b[0m eta: 1:00:51  iter: 7659  total_loss: 2.162  loss_cls_stage0: 0.2924  loss_box_reg_stage0: 0.234  loss_cls_stage1: 0.2418  loss_box_reg_stage1: 0.3266  loss_cls_stage2: 0.1791  loss_box_reg_stage2: 0.2847  loss_mask: 0.4817  loss_rpn_cls: 0.06155  loss_rpn_loc: 0.03099  validation_loss: 2.095  time: 1.7749  data_time: 0.0231  lr: 1.2923e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:46:36 d2.utils.events]: \u001b[0m eta: 1:00:21  iter: 7679  total_loss: 2.407  loss_cls_stage0: 0.3331  loss_box_reg_stage0: 0.2723  loss_cls_stage1: 0.2727  loss_box_reg_stage1: 0.3796  loss_cls_stage2: 0.1926  loss_box_reg_stage2: 0.3058  loss_mask: 0.5357  loss_rpn_cls: 0.0566  loss_rpn_loc: 0.03072  validation_loss: 2.095  time: 1.7744  data_time: 0.0241  lr: 1.2713e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:47:08 d2.utils.events]: \u001b[0m eta: 0:59:50  iter: 7699  total_loss: 2.504  loss_cls_stage0: 0.348  loss_box_reg_stage0: 0.2829  loss_cls_stage1: 0.2855  loss_box_reg_stage1: 0.3896  loss_cls_stage2: 0.2031  loss_box_reg_stage2: 0.3198  loss_mask: 0.5057  loss_rpn_cls: 0.07249  loss_rpn_loc: 0.03743  validation_loss: 2.095  time: 1.7739  data_time: 0.0235  lr: 1.2505e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:47:39 d2.utils.events]: \u001b[0m eta: 0:59:18  iter: 7719  total_loss: 2.337  loss_cls_stage0: 0.349  loss_box_reg_stage0: 0.2657  loss_cls_stage1: 0.2897  loss_box_reg_stage1: 0.3717  loss_cls_stage2: 0.2073  loss_box_reg_stage2: 0.2872  loss_mask: 0.5571  loss_rpn_cls: 0.06336  loss_rpn_loc: 0.03348  validation_loss: 2.095  time: 1.7733  data_time: 0.0245  lr: 1.2298e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:48:10 d2.utils.events]: \u001b[0m eta: 0:58:47  iter: 7739  total_loss: 2.417  loss_cls_stage0: 0.3423  loss_box_reg_stage0: 0.285  loss_cls_stage1: 0.2832  loss_box_reg_stage1: 0.403  loss_cls_stage2: 0.2043  loss_box_reg_stage2: 0.3074  loss_mask: 0.5243  loss_rpn_cls: 0.06452  loss_rpn_loc: 0.04037  validation_loss: 2.095  time: 1.7728  data_time: 0.0255  lr: 1.2092e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:48:42 d2.utils.events]: \u001b[0m eta: 0:58:15  iter: 7759  total_loss: 2.195  loss_cls_stage0: 0.2901  loss_box_reg_stage0: 0.2278  loss_cls_stage1: 0.2533  loss_box_reg_stage1: 0.3452  loss_cls_stage2: 0.1828  loss_box_reg_stage2: 0.2861  loss_mask: 0.5597  loss_rpn_cls: 0.06158  loss_rpn_loc: 0.03639  validation_loss: 2.095  time: 1.7723  data_time: 0.0252  lr: 1.1888e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:49:13 d2.utils.events]: \u001b[0m eta: 0:57:44  iter: 7779  total_loss: 2.249  loss_cls_stage0: 0.3042  loss_box_reg_stage0: 0.2288  loss_cls_stage1: 0.2573  loss_box_reg_stage1: 0.3414  loss_cls_stage2: 0.1872  loss_box_reg_stage2: 0.3263  loss_mask: 0.5043  loss_rpn_cls: 0.06548  loss_rpn_loc: 0.03462  validation_loss: 2.095  time: 1.7717  data_time: 0.0234  lr: 1.1685e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:49:45 d2.utils.events]: \u001b[0m eta: 0:57:15  iter: 7799  total_loss: 2.478  loss_cls_stage0: 0.3651  loss_box_reg_stage0: 0.2983  loss_cls_stage1: 0.2991  loss_box_reg_stage1: 0.3988  loss_cls_stage2: 0.2157  loss_box_reg_stage2: 0.3123  loss_mask: 0.4641  loss_rpn_cls: 0.06148  loss_rpn_loc: 0.04024  validation_loss: 2.095  time: 1.7712  data_time: 0.0237  lr: 1.1484e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:50:16 d2.utils.events]: \u001b[0m eta: 0:56:43  iter: 7819  total_loss: 2.365  loss_cls_stage0: 0.3142  loss_box_reg_stage0: 0.2779  loss_cls_stage1: 0.2612  loss_box_reg_stage1: 0.3835  loss_cls_stage2: 0.1822  loss_box_reg_stage2: 0.3037  loss_mask: 0.5116  loss_rpn_cls: 0.05673  loss_rpn_loc: 0.03209  validation_loss: 2.095  time: 1.7707  data_time: 0.0241  lr: 1.1285e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:50:48 d2.utils.events]: \u001b[0m eta: 0:56:13  iter: 7839  total_loss: 2.489  loss_cls_stage0: 0.3431  loss_box_reg_stage0: 0.275  loss_cls_stage1: 0.2813  loss_box_reg_stage1: 0.3533  loss_cls_stage2: 0.1962  loss_box_reg_stage2: 0.313  loss_mask: 0.5525  loss_rpn_cls: 0.06382  loss_rpn_loc: 0.03603  validation_loss: 2.095  time: 1.7702  data_time: 0.0234  lr: 1.1087e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:51:19 d2.utils.events]: \u001b[0m eta: 0:55:42  iter: 7859  total_loss: 2.393  loss_cls_stage0: 0.3262  loss_box_reg_stage0: 0.2666  loss_cls_stage1: 0.2756  loss_box_reg_stage1: 0.386  loss_cls_stage2: 0.196  loss_box_reg_stage2: 0.3499  loss_mask: 0.4948  loss_rpn_cls: 0.06026  loss_rpn_loc: 0.0333  validation_loss: 2.095  time: 1.7697  data_time: 0.0238  lr: 1.089e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:51:50 d2.utils.events]: \u001b[0m eta: 0:55:12  iter: 7879  total_loss: 2.492  loss_cls_stage0: 0.337  loss_box_reg_stage0: 0.2596  loss_cls_stage1: 0.2896  loss_box_reg_stage1: 0.3813  loss_cls_stage2: 0.2066  loss_box_reg_stage2: 0.3204  loss_mask: 0.5438  loss_rpn_cls: 0.0674  loss_rpn_loc: 0.03544  validation_loss: 2.095  time: 1.7692  data_time: 0.0233  lr: 1.0695e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:52:22 d2.utils.events]: \u001b[0m eta: 0:54:41  iter: 7899  total_loss: 2.39  loss_cls_stage0: 0.3432  loss_box_reg_stage0: 0.2801  loss_cls_stage1: 0.2868  loss_box_reg_stage1: 0.3812  loss_cls_stage2: 0.2109  loss_box_reg_stage2: 0.3144  loss_mask: 0.5052  loss_rpn_cls: 0.06475  loss_rpn_loc: 0.03844  validation_loss: 2.095  time: 1.7687  data_time: 0.0257  lr: 1.0502e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:52:53 d2.utils.events]: \u001b[0m eta: 0:54:09  iter: 7919  total_loss: 2.507  loss_cls_stage0: 0.3167  loss_box_reg_stage0: 0.2619  loss_cls_stage1: 0.2638  loss_box_reg_stage1: 0.3924  loss_cls_stage2: 0.2005  loss_box_reg_stage2: 0.3459  loss_mask: 0.5677  loss_rpn_cls: 0.0723  loss_rpn_loc: 0.03858  validation_loss: 2.095  time: 1.7682  data_time: 0.0251  lr: 1.031e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:53:25 d2.utils.events]: \u001b[0m eta: 0:53:38  iter: 7939  total_loss: 2.368  loss_cls_stage0: 0.3285  loss_box_reg_stage0: 0.2594  loss_cls_stage1: 0.2731  loss_box_reg_stage1: 0.3577  loss_cls_stage2: 0.2004  loss_box_reg_stage2: 0.3067  loss_mask: 0.5665  loss_rpn_cls: 0.0616  loss_rpn_loc: 0.03163  validation_loss: 2.095  time: 1.7677  data_time: 0.0252  lr: 1.012e-05  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:53:56 d2.utils.events]: \u001b[0m eta: 0:53:07  iter: 7959  total_loss: 2.49  loss_cls_stage0: 0.3482  loss_box_reg_stage0: 0.2965  loss_cls_stage1: 0.2836  loss_box_reg_stage1: 0.4142  loss_cls_stage2: 0.2078  loss_box_reg_stage2: 0.3239  loss_mask: 0.5484  loss_rpn_cls: 0.05655  loss_rpn_loc: 0.03912  validation_loss: 2.095  time: 1.7672  data_time: 0.0232  lr: 9.931e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:54:28 d2.utils.events]: \u001b[0m eta: 0:52:37  iter: 7979  total_loss: 2.423  loss_cls_stage0: 0.3529  loss_box_reg_stage0: 0.2722  loss_cls_stage1: 0.2888  loss_box_reg_stage1: 0.3979  loss_cls_stage2: 0.224  loss_box_reg_stage2: 0.3347  loss_mask: 0.5331  loss_rpn_cls: 0.06825  loss_rpn_loc: 0.03747  validation_loss: 2.095  time: 1.7667  data_time: 0.0226  lr: 9.7439e-06  max_mem: 11557M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/26 14:55:01 d2.data.common]: \u001b[0mSerializing 900 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/26 14:55:01 d2.data.common]: \u001b[0mSerialized dataset takes 0.91 MiB\n",
      "\u001b[32m[03/26 14:55:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 900 images\n",
      "\u001b[32m[03/26 14:55:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/900. 0.0826 s / img. ETA=0:02:07\n",
      "\u001b[32m[03/26 14:55:08 d2.evaluation.evaluator]: \u001b[0mInference done 51/900. 0.0843 s / img. ETA=0:01:48\n",
      "\u001b[32m[03/26 14:55:13 d2.evaluation.evaluator]: \u001b[0mInference done 90/900. 0.0832 s / img. ETA=0:01:45\n",
      "\u001b[32m[03/26 14:55:18 d2.evaluation.evaluator]: \u001b[0mInference done 130/900. 0.0827 s / img. ETA=0:01:38\n",
      "\u001b[32m[03/26 14:55:24 d2.evaluation.evaluator]: \u001b[0mInference done 173/900. 0.0822 s / img. ETA=0:01:31\n",
      "\u001b[32m[03/26 14:55:29 d2.evaluation.evaluator]: \u001b[0mInference done 215/900. 0.0820 s / img. ETA=0:01:25\n",
      "\u001b[32m[03/26 14:55:34 d2.evaluation.evaluator]: \u001b[0mInference done 253/900. 0.0820 s / img. ETA=0:01:21\n",
      "\u001b[32m[03/26 14:55:39 d2.evaluation.evaluator]: \u001b[0mInference done 295/900. 0.0819 s / img. ETA=0:01:15\n",
      "\u001b[32m[03/26 14:55:44 d2.evaluation.evaluator]: \u001b[0mInference done 335/900. 0.0819 s / img. ETA=0:01:10\n",
      "\u001b[32m[03/26 14:55:49 d2.evaluation.evaluator]: \u001b[0mInference done 374/900. 0.0819 s / img. ETA=0:01:06\n",
      "\u001b[32m[03/26 14:55:54 d2.evaluation.evaluator]: \u001b[0mInference done 415/900. 0.0818 s / img. ETA=0:01:00\n",
      "\u001b[32m[03/26 14:55:59 d2.evaluation.evaluator]: \u001b[0mInference done 455/900. 0.0818 s / img. ETA=0:00:55\n",
      "\u001b[32m[03/26 14:56:04 d2.evaluation.evaluator]: \u001b[0mInference done 492/900. 0.0818 s / img. ETA=0:00:51\n",
      "\u001b[32m[03/26 14:56:09 d2.evaluation.evaluator]: \u001b[0mInference done 535/900. 0.0817 s / img. ETA=0:00:45\n",
      "\u001b[32m[03/26 14:56:14 d2.evaluation.evaluator]: \u001b[0mInference done 573/900. 0.0817 s / img. ETA=0:00:41\n",
      "\u001b[32m[03/26 14:56:19 d2.evaluation.evaluator]: \u001b[0mInference done 614/900. 0.0817 s / img. ETA=0:00:36\n",
      "\u001b[32m[03/26 14:56:24 d2.evaluation.evaluator]: \u001b[0mInference done 655/900. 0.0817 s / img. ETA=0:00:30\n",
      "\u001b[32m[03/26 14:56:30 d2.evaluation.evaluator]: \u001b[0mInference done 698/900. 0.0817 s / img. ETA=0:00:25\n",
      "\u001b[32m[03/26 14:56:35 d2.evaluation.evaluator]: \u001b[0mInference done 737/900. 0.0817 s / img. ETA=0:00:20\n",
      "\u001b[32m[03/26 14:56:40 d2.evaluation.evaluator]: \u001b[0mInference done 777/900. 0.0817 s / img. ETA=0:00:15\n",
      "\u001b[32m[03/26 14:56:45 d2.evaluation.evaluator]: \u001b[0mInference done 817/900. 0.0816 s / img. ETA=0:00:10\n",
      "\u001b[32m[03/26 14:56:50 d2.evaluation.evaluator]: \u001b[0mInference done 857/900. 0.0816 s / img. ETA=0:00:05\n",
      "\u001b[32m[03/26 14:56:55 d2.evaluation.evaluator]: \u001b[0mInference done 898/900. 0.0816 s / img. ETA=0:00:00\n",
      "\u001b[32m[03/26 14:56:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:52.761752 (0.125991 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/26 14:56:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:13 (0.081628 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.54 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.149\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.168\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.043\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.096\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.133\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.182\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.183\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.059\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.206\n",
      "\u001b[32m[03/26 14:56:56 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold1 in csv format:\n",
      "\u001b[32m[03/26 14:56:56 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/26 14:56:56 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/26 14:56:56 d2.evaluation.testing]: \u001b[0mcopypaste: 8.9897,14.9225,16.7518,1.0989,4.2921,9.6085\n",
      "validation do loss eval 2.3610214218023207\n",
      "\u001b[32m[03/26 14:58:30 d2.utils.events]: \u001b[0m eta: 0:52:06  iter: 7999  total_loss: 2.568  loss_cls_stage0: 0.3461  loss_box_reg_stage0: 0.2801  loss_cls_stage1: 0.2822  loss_box_reg_stage1: 0.4059  loss_cls_stage2: 0.1925  loss_box_reg_stage2: 0.3317  loss_mask: 0.5842  loss_rpn_cls: 0.06196  loss_rpn_loc: 0.03767  validation_loss: 2.165  time: 1.7663  data_time: 0.0229  lr: 9.5584e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:59:00 d2.utils.events]: \u001b[0m eta: 0:51:34  iter: 8019  total_loss: 2.316  loss_cls_stage0: 0.3189  loss_box_reg_stage0: 0.2591  loss_cls_stage1: 0.2627  loss_box_reg_stage1: 0.3628  loss_cls_stage2: 0.192  loss_box_reg_stage2: 0.2964  loss_mask: 0.5494  loss_rpn_cls: 0.06541  loss_rpn_loc: 0.03934  validation_loss: 2.165  time: 1.7657  data_time: 0.0249  lr: 9.3744e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 14:59:32 d2.utils.events]: \u001b[0m eta: 0:51:02  iter: 8039  total_loss: 2.23  loss_cls_stage0: 0.3291  loss_box_reg_stage0: 0.2322  loss_cls_stage1: 0.2713  loss_box_reg_stage1: 0.3489  loss_cls_stage2: 0.1818  loss_box_reg_stage2: 0.2949  loss_mask: 0.5334  loss_rpn_cls: 0.06264  loss_rpn_loc: 0.03112  validation_loss: 2.165  time: 1.7652  data_time: 0.0255  lr: 9.1921e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:00:03 d2.utils.events]: \u001b[0m eta: 0:50:31  iter: 8059  total_loss: 2.38  loss_cls_stage0: 0.3418  loss_box_reg_stage0: 0.271  loss_cls_stage1: 0.2697  loss_box_reg_stage1: 0.3586  loss_cls_stage2: 0.1955  loss_box_reg_stage2: 0.3152  loss_mask: 0.5027  loss_rpn_cls: 0.05739  loss_rpn_loc: 0.03455  validation_loss: 2.165  time: 1.7647  data_time: 0.0243  lr: 9.0114e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:00:34 d2.utils.events]: \u001b[0m eta: 0:49:59  iter: 8079  total_loss: 2.327  loss_cls_stage0: 0.3092  loss_box_reg_stage0: 0.2475  loss_cls_stage1: 0.2794  loss_box_reg_stage1: 0.369  loss_cls_stage2: 0.1975  loss_box_reg_stage2: 0.3157  loss_mask: 0.528  loss_rpn_cls: 0.06371  loss_rpn_loc: 0.03723  validation_loss: 2.165  time: 1.7642  data_time: 0.0243  lr: 8.8323e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:01:06 d2.utils.events]: \u001b[0m eta: 0:49:28  iter: 8099  total_loss: 2.415  loss_cls_stage0: 0.3147  loss_box_reg_stage0: 0.2517  loss_cls_stage1: 0.2612  loss_box_reg_stage1: 0.3792  loss_cls_stage2: 0.1918  loss_box_reg_stage2: 0.3297  loss_mask: 0.5473  loss_rpn_cls: 0.0533  loss_rpn_loc: 0.03576  validation_loss: 2.165  time: 1.7637  data_time: 0.0234  lr: 8.6548e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:01:37 d2.utils.events]: \u001b[0m eta: 0:48:58  iter: 8119  total_loss: 2.367  loss_cls_stage0: 0.3055  loss_box_reg_stage0: 0.2456  loss_cls_stage1: 0.271  loss_box_reg_stage1: 0.3572  loss_cls_stage2: 0.1957  loss_box_reg_stage2: 0.3137  loss_mask: 0.527  loss_rpn_cls: 0.05679  loss_rpn_loc: 0.03337  validation_loss: 2.165  time: 1.7632  data_time: 0.0235  lr: 8.479e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:02:08 d2.utils.events]: \u001b[0m eta: 0:48:28  iter: 8139  total_loss: 2.49  loss_cls_stage0: 0.3213  loss_box_reg_stage0: 0.2748  loss_cls_stage1: 0.2782  loss_box_reg_stage1: 0.3987  loss_cls_stage2: 0.2052  loss_box_reg_stage2: 0.3297  loss_mask: 0.5647  loss_rpn_cls: 0.05445  loss_rpn_loc: 0.03357  validation_loss: 2.165  time: 1.7627  data_time: 0.0237  lr: 8.3047e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:02:40 d2.utils.events]: \u001b[0m eta: 0:47:56  iter: 8159  total_loss: 2.412  loss_cls_stage0: 0.3281  loss_box_reg_stage0: 0.2568  loss_cls_stage1: 0.2688  loss_box_reg_stage1: 0.3773  loss_cls_stage2: 0.213  loss_box_reg_stage2: 0.314  loss_mask: 0.5826  loss_rpn_cls: 0.06303  loss_rpn_loc: 0.03526  validation_loss: 2.165  time: 1.7623  data_time: 0.0235  lr: 8.1322e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:03:11 d2.utils.events]: \u001b[0m eta: 0:47:24  iter: 8179  total_loss: 2.432  loss_cls_stage0: 0.3327  loss_box_reg_stage0: 0.2607  loss_cls_stage1: 0.2815  loss_box_reg_stage1: 0.3935  loss_cls_stage2: 0.2045  loss_box_reg_stage2: 0.3245  loss_mask: 0.5209  loss_rpn_cls: 0.05864  loss_rpn_loc: 0.03865  validation_loss: 2.165  time: 1.7618  data_time: 0.0238  lr: 7.9613e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:03:43 d2.utils.events]: \u001b[0m eta: 0:46:54  iter: 8199  total_loss: 2.509  loss_cls_stage0: 0.352  loss_box_reg_stage0: 0.2907  loss_cls_stage1: 0.2956  loss_box_reg_stage1: 0.405  loss_cls_stage2: 0.2192  loss_box_reg_stage2: 0.3613  loss_mask: 0.5046  loss_rpn_cls: 0.05933  loss_rpn_loc: 0.04142  validation_loss: 2.165  time: 1.7614  data_time: 0.0245  lr: 7.792e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:04:14 d2.utils.events]: \u001b[0m eta: 0:46:24  iter: 8219  total_loss: 2.378  loss_cls_stage0: 0.3153  loss_box_reg_stage0: 0.2676  loss_cls_stage1: 0.2591  loss_box_reg_stage1: 0.3758  loss_cls_stage2: 0.19  loss_box_reg_stage2: 0.3137  loss_mask: 0.4787  loss_rpn_cls: 0.05415  loss_rpn_loc: 0.03433  validation_loss: 2.165  time: 1.7609  data_time: 0.0241  lr: 7.6244e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:04:46 d2.utils.events]: \u001b[0m eta: 0:45:53  iter: 8239  total_loss: 2.364  loss_cls_stage0: 0.3015  loss_box_reg_stage0: 0.2435  loss_cls_stage1: 0.2404  loss_box_reg_stage1: 0.3578  loss_cls_stage2: 0.1782  loss_box_reg_stage2: 0.323  loss_mask: 0.54  loss_rpn_cls: 0.05087  loss_rpn_loc: 0.03119  validation_loss: 2.165  time: 1.7604  data_time: 0.0239  lr: 7.4585e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:05:17 d2.utils.events]: \u001b[0m eta: 0:45:22  iter: 8259  total_loss: 2.423  loss_cls_stage0: 0.3538  loss_box_reg_stage0: 0.275  loss_cls_stage1: 0.3048  loss_box_reg_stage1: 0.3686  loss_cls_stage2: 0.2099  loss_box_reg_stage2: 0.3242  loss_mask: 0.51  loss_rpn_cls: 0.06206  loss_rpn_loc: 0.03345  validation_loss: 2.165  time: 1.7600  data_time: 0.0232  lr: 7.2943e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:05:48 d2.utils.events]: \u001b[0m eta: 0:44:51  iter: 8279  total_loss: 2.326  loss_cls_stage0: 0.3426  loss_box_reg_stage0: 0.2696  loss_cls_stage1: 0.2862  loss_box_reg_stage1: 0.3678  loss_cls_stage2: 0.2102  loss_box_reg_stage2: 0.3138  loss_mask: 0.5301  loss_rpn_cls: 0.06394  loss_rpn_loc: 0.03605  validation_loss: 2.165  time: 1.7595  data_time: 0.0233  lr: 7.1318e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:06:20 d2.utils.events]: \u001b[0m eta: 0:44:20  iter: 8299  total_loss: 2.414  loss_cls_stage0: 0.3522  loss_box_reg_stage0: 0.2724  loss_cls_stage1: 0.2802  loss_box_reg_stage1: 0.3565  loss_cls_stage2: 0.2023  loss_box_reg_stage2: 0.2792  loss_mask: 0.5156  loss_rpn_cls: 0.0629  loss_rpn_loc: 0.04129  validation_loss: 2.165  time: 1.7590  data_time: 0.0315  lr: 6.9709e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:06:51 d2.utils.events]: \u001b[0m eta: 0:43:48  iter: 8319  total_loss: 2.267  loss_cls_stage0: 0.3253  loss_box_reg_stage0: 0.2444  loss_cls_stage1: 0.2647  loss_box_reg_stage1: 0.3567  loss_cls_stage2: 0.1957  loss_box_reg_stage2: 0.3101  loss_mask: 0.5366  loss_rpn_cls: 0.05687  loss_rpn_loc: 0.03466  validation_loss: 2.165  time: 1.7586  data_time: 0.0226  lr: 6.8117e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:07:22 d2.utils.events]: \u001b[0m eta: 0:43:16  iter: 8339  total_loss: 2.567  loss_cls_stage0: 0.3668  loss_box_reg_stage0: 0.2765  loss_cls_stage1: 0.301  loss_box_reg_stage1: 0.3834  loss_cls_stage2: 0.2186  loss_box_reg_stage2: 0.3175  loss_mask: 0.5259  loss_rpn_cls: 0.0629  loss_rpn_loc: 0.03671  validation_loss: 2.165  time: 1.7581  data_time: 0.0244  lr: 6.6543e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:07:54 d2.utils.events]: \u001b[0m eta: 0:42:45  iter: 8359  total_loss: 2.531  loss_cls_stage0: 0.3582  loss_box_reg_stage0: 0.266  loss_cls_stage1: 0.2975  loss_box_reg_stage1: 0.3965  loss_cls_stage2: 0.2198  loss_box_reg_stage2: 0.3095  loss_mask: 0.5329  loss_rpn_cls: 0.07045  loss_rpn_loc: 0.03772  validation_loss: 2.165  time: 1.7577  data_time: 0.0217  lr: 6.4986e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:08:25 d2.utils.events]: \u001b[0m eta: 0:42:14  iter: 8379  total_loss: 2.463  loss_cls_stage0: 0.3375  loss_box_reg_stage0: 0.271  loss_cls_stage1: 0.2895  loss_box_reg_stage1: 0.3996  loss_cls_stage2: 0.208  loss_box_reg_stage2: 0.2938  loss_mask: 0.4755  loss_rpn_cls: 0.06582  loss_rpn_loc: 0.03884  validation_loss: 2.165  time: 1.7572  data_time: 0.0234  lr: 6.3445e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:08:57 d2.utils.events]: \u001b[0m eta: 0:41:43  iter: 8399  total_loss: 2.324  loss_cls_stage0: 0.3243  loss_box_reg_stage0: 0.2563  loss_cls_stage1: 0.2756  loss_box_reg_stage1: 0.3537  loss_cls_stage2: 0.1898  loss_box_reg_stage2: 0.295  loss_mask: 0.5592  loss_rpn_cls: 0.05626  loss_rpn_loc: 0.03548  validation_loss: 2.165  time: 1.7568  data_time: 0.0228  lr: 6.1922e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:09:28 d2.utils.events]: \u001b[0m eta: 0:41:11  iter: 8419  total_loss: 2.194  loss_cls_stage0: 0.3318  loss_box_reg_stage0: 0.2622  loss_cls_stage1: 0.2812  loss_box_reg_stage1: 0.3474  loss_cls_stage2: 0.1915  loss_box_reg_stage2: 0.2736  loss_mask: 0.5011  loss_rpn_cls: 0.05669  loss_rpn_loc: 0.03103  validation_loss: 2.165  time: 1.7563  data_time: 0.0232  lr: 6.0417e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:09:59 d2.utils.events]: \u001b[0m eta: 0:40:40  iter: 8439  total_loss: 2.137  loss_cls_stage0: 0.3108  loss_box_reg_stage0: 0.2368  loss_cls_stage1: 0.2581  loss_box_reg_stage1: 0.3436  loss_cls_stage2: 0.1808  loss_box_reg_stage2: 0.3032  loss_mask: 0.5109  loss_rpn_cls: 0.05531  loss_rpn_loc: 0.02946  validation_loss: 2.165  time: 1.7559  data_time: 0.0230  lr: 5.8928e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:10:31 d2.utils.events]: \u001b[0m eta: 0:40:09  iter: 8459  total_loss: 2.345  loss_cls_stage0: 0.3214  loss_box_reg_stage0: 0.2725  loss_cls_stage1: 0.2649  loss_box_reg_stage1: 0.397  loss_cls_stage2: 0.1903  loss_box_reg_stage2: 0.3232  loss_mask: 0.5565  loss_rpn_cls: 0.05965  loss_rpn_loc: 0.03615  validation_loss: 2.165  time: 1.7554  data_time: 0.0225  lr: 5.7457e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:11:02 d2.utils.events]: \u001b[0m eta: 0:39:38  iter: 8479  total_loss: 2.421  loss_cls_stage0: 0.3447  loss_box_reg_stage0: 0.2854  loss_cls_stage1: 0.2702  loss_box_reg_stage1: 0.391  loss_cls_stage2: 0.1948  loss_box_reg_stage2: 0.3084  loss_mask: 0.531  loss_rpn_cls: 0.06504  loss_rpn_loc: 0.03654  validation_loss: 2.165  time: 1.7550  data_time: 0.0244  lr: 5.6004e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:11:33 d2.utils.events]: \u001b[0m eta: 0:39:07  iter: 8499  total_loss: 2.291  loss_cls_stage0: 0.3284  loss_box_reg_stage0: 0.2487  loss_cls_stage1: 0.2866  loss_box_reg_stage1: 0.3532  loss_cls_stage2: 0.1924  loss_box_reg_stage2: 0.2977  loss_mask: 0.5158  loss_rpn_cls: 0.05484  loss_rpn_loc: 0.03315  validation_loss: 2.165  time: 1.7545  data_time: 0.0252  lr: 5.4568e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:12:05 d2.utils.events]: \u001b[0m eta: 0:38:36  iter: 8519  total_loss: 2.398  loss_cls_stage0: 0.307  loss_box_reg_stage0: 0.2518  loss_cls_stage1: 0.2616  loss_box_reg_stage1: 0.3778  loss_cls_stage2: 0.1992  loss_box_reg_stage2: 0.3079  loss_mask: 0.5474  loss_rpn_cls: 0.05562  loss_rpn_loc: 0.03475  validation_loss: 2.165  time: 1.7541  data_time: 0.0260  lr: 5.315e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:12:36 d2.utils.events]: \u001b[0m eta: 0:38:04  iter: 8539  total_loss: 2.323  loss_cls_stage0: 0.3182  loss_box_reg_stage0: 0.2562  loss_cls_stage1: 0.2477  loss_box_reg_stage1: 0.3765  loss_cls_stage2: 0.1875  loss_box_reg_stage2: 0.3286  loss_mask: 0.5338  loss_rpn_cls: 0.05865  loss_rpn_loc: 0.03275  validation_loss: 2.165  time: 1.7537  data_time: 0.0245  lr: 5.1749e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:13:07 d2.utils.events]: \u001b[0m eta: 0:37:32  iter: 8559  total_loss: 2.381  loss_cls_stage0: 0.3089  loss_box_reg_stage0: 0.2431  loss_cls_stage1: 0.266  loss_box_reg_stage1: 0.389  loss_cls_stage2: 0.1973  loss_box_reg_stage2: 0.3207  loss_mask: 0.5797  loss_rpn_cls: 0.05886  loss_rpn_loc: 0.03513  validation_loss: 2.165  time: 1.7532  data_time: 0.0233  lr: 5.0366e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:13:39 d2.utils.events]: \u001b[0m eta: 0:37:01  iter: 8579  total_loss: 2.269  loss_cls_stage0: 0.2985  loss_box_reg_stage0: 0.2399  loss_cls_stage1: 0.2607  loss_box_reg_stage1: 0.3559  loss_cls_stage2: 0.1945  loss_box_reg_stage2: 0.3179  loss_mask: 0.4886  loss_rpn_cls: 0.05458  loss_rpn_loc: 0.03228  validation_loss: 2.165  time: 1.7528  data_time: 0.0228  lr: 4.9001e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:14:10 d2.utils.events]: \u001b[0m eta: 0:36:29  iter: 8599  total_loss: 2.3  loss_cls_stage0: 0.3291  loss_box_reg_stage0: 0.2561  loss_cls_stage1: 0.2751  loss_box_reg_stage1: 0.3603  loss_cls_stage2: 0.1962  loss_box_reg_stage2: 0.3064  loss_mask: 0.5727  loss_rpn_cls: 0.06357  loss_rpn_loc: 0.03646  validation_loss: 2.165  time: 1.7523  data_time: 0.0240  lr: 4.7653e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:14:42 d2.utils.events]: \u001b[0m eta: 0:35:58  iter: 8619  total_loss: 2.406  loss_cls_stage0: 0.3237  loss_box_reg_stage0: 0.2641  loss_cls_stage1: 0.269  loss_box_reg_stage1: 0.3906  loss_cls_stage2: 0.2036  loss_box_reg_stage2: 0.3187  loss_mask: 0.5138  loss_rpn_cls: 0.06391  loss_rpn_loc: 0.03742  validation_loss: 2.165  time: 1.7519  data_time: 0.0232  lr: 4.6324e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:15:13 d2.utils.events]: \u001b[0m eta: 0:35:27  iter: 8639  total_loss: 2.329  loss_cls_stage0: 0.3193  loss_box_reg_stage0: 0.2693  loss_cls_stage1: 0.2623  loss_box_reg_stage1: 0.3583  loss_cls_stage2: 0.1858  loss_box_reg_stage2: 0.3026  loss_mask: 0.513  loss_rpn_cls: 0.0606  loss_rpn_loc: 0.03711  validation_loss: 2.165  time: 1.7515  data_time: 0.0228  lr: 4.5012e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:15:44 d2.utils.events]: \u001b[0m eta: 0:34:56  iter: 8659  total_loss: 2.447  loss_cls_stage0: 0.3374  loss_box_reg_stage0: 0.2743  loss_cls_stage1: 0.2775  loss_box_reg_stage1: 0.3761  loss_cls_stage2: 0.1901  loss_box_reg_stage2: 0.2937  loss_mask: 0.562  loss_rpn_cls: 0.06399  loss_rpn_loc: 0.03921  validation_loss: 2.165  time: 1.7511  data_time: 0.0236  lr: 4.3718e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:16:16 d2.utils.events]: \u001b[0m eta: 0:34:25  iter: 8679  total_loss: 2.383  loss_cls_stage0: 0.3181  loss_box_reg_stage0: 0.2535  loss_cls_stage1: 0.2633  loss_box_reg_stage1: 0.3679  loss_cls_stage2: 0.1992  loss_box_reg_stage2: 0.3365  loss_mask: 0.5232  loss_rpn_cls: 0.0528  loss_rpn_loc: 0.03041  validation_loss: 2.165  time: 1.7506  data_time: 0.0233  lr: 4.2443e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:16:47 d2.utils.events]: \u001b[0m eta: 0:33:53  iter: 8699  total_loss: 2.325  loss_cls_stage0: 0.3204  loss_box_reg_stage0: 0.2505  loss_cls_stage1: 0.2781  loss_box_reg_stage1: 0.3691  loss_cls_stage2: 0.1869  loss_box_reg_stage2: 0.3235  loss_mask: 0.597  loss_rpn_cls: 0.05464  loss_rpn_loc: 0.03306  validation_loss: 2.165  time: 1.7502  data_time: 0.0236  lr: 4.1185e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:17:18 d2.utils.events]: \u001b[0m eta: 0:33:22  iter: 8719  total_loss: 2.451  loss_cls_stage0: 0.3253  loss_box_reg_stage0: 0.2689  loss_cls_stage1: 0.2861  loss_box_reg_stage1: 0.3829  loss_cls_stage2: 0.2068  loss_box_reg_stage2: 0.306  loss_mask: 0.5227  loss_rpn_cls: 0.06555  loss_rpn_loc: 0.0377  validation_loss: 2.165  time: 1.7498  data_time: 0.0252  lr: 3.9946e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:17:49 d2.utils.events]: \u001b[0m eta: 0:32:50  iter: 8739  total_loss: 2.427  loss_cls_stage0: 0.3303  loss_box_reg_stage0: 0.2634  loss_cls_stage1: 0.2752  loss_box_reg_stage1: 0.3954  loss_cls_stage2: 0.205  loss_box_reg_stage2: 0.33  loss_mask: 0.5393  loss_rpn_cls: 0.05537  loss_rpn_loc: 0.03556  validation_loss: 2.165  time: 1.7493  data_time: 0.0240  lr: 3.8724e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:18:21 d2.utils.events]: \u001b[0m eta: 0:32:19  iter: 8759  total_loss: 2.223  loss_cls_stage0: 0.3207  loss_box_reg_stage0: 0.2381  loss_cls_stage1: 0.2578  loss_box_reg_stage1: 0.3462  loss_cls_stage2: 0.1695  loss_box_reg_stage2: 0.3011  loss_mask: 0.4848  loss_rpn_cls: 0.06655  loss_rpn_loc: 0.03141  validation_loss: 2.165  time: 1.7489  data_time: 0.0231  lr: 3.7521e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:18:52 d2.utils.events]: \u001b[0m eta: 0:31:48  iter: 8779  total_loss: 2.361  loss_cls_stage0: 0.3296  loss_box_reg_stage0: 0.2647  loss_cls_stage1: 0.2749  loss_box_reg_stage1: 0.3686  loss_cls_stage2: 0.196  loss_box_reg_stage2: 0.317  loss_mask: 0.5351  loss_rpn_cls: 0.05931  loss_rpn_loc: 0.03903  validation_loss: 2.165  time: 1.7485  data_time: 0.0240  lr: 3.6336e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:19:23 d2.utils.events]: \u001b[0m eta: 0:31:16  iter: 8799  total_loss: 2.362  loss_cls_stage0: 0.3157  loss_box_reg_stage0: 0.2479  loss_cls_stage1: 0.2711  loss_box_reg_stage1: 0.3701  loss_cls_stage2: 0.2042  loss_box_reg_stage2: 0.3012  loss_mask: 0.5216  loss_rpn_cls: 0.05559  loss_rpn_loc: 0.03417  validation_loss: 2.165  time: 1.7481  data_time: 0.0258  lr: 3.517e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:19:55 d2.utils.events]: \u001b[0m eta: 0:30:45  iter: 8819  total_loss: 2.397  loss_cls_stage0: 0.3361  loss_box_reg_stage0: 0.2583  loss_cls_stage1: 0.2805  loss_box_reg_stage1: 0.3724  loss_cls_stage2: 0.2063  loss_box_reg_stage2: 0.3366  loss_mask: 0.5298  loss_rpn_cls: 0.07065  loss_rpn_loc: 0.03569  validation_loss: 2.165  time: 1.7477  data_time: 0.0246  lr: 3.4021e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:20:26 d2.utils.events]: \u001b[0m eta: 0:30:14  iter: 8839  total_loss: 2.421  loss_cls_stage0: 0.3315  loss_box_reg_stage0: 0.2764  loss_cls_stage1: 0.2759  loss_box_reg_stage1: 0.4049  loss_cls_stage2: 0.2065  loss_box_reg_stage2: 0.3069  loss_mask: 0.5302  loss_rpn_cls: 0.06401  loss_rpn_loc: 0.03659  validation_loss: 2.165  time: 1.7473  data_time: 0.0225  lr: 3.2892e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:20:57 d2.utils.events]: \u001b[0m eta: 0:29:43  iter: 8859  total_loss: 2.368  loss_cls_stage0: 0.3153  loss_box_reg_stage0: 0.2719  loss_cls_stage1: 0.2767  loss_box_reg_stage1: 0.3853  loss_cls_stage2: 0.199  loss_box_reg_stage2: 0.3374  loss_mask: 0.5264  loss_rpn_cls: 0.05749  loss_rpn_loc: 0.03917  validation_loss: 2.165  time: 1.7469  data_time: 0.0235  lr: 3.178e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:21:29 d2.utils.events]: \u001b[0m eta: 0:29:11  iter: 8879  total_loss: 2.351  loss_cls_stage0: 0.3117  loss_box_reg_stage0: 0.2467  loss_cls_stage1: 0.2648  loss_box_reg_stage1: 0.3742  loss_cls_stage2: 0.203  loss_box_reg_stage2: 0.3106  loss_mask: 0.5045  loss_rpn_cls: 0.05572  loss_rpn_loc: 0.03581  validation_loss: 2.165  time: 1.7465  data_time: 0.0237  lr: 3.0687e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:22:00 d2.utils.events]: \u001b[0m eta: 0:28:40  iter: 8899  total_loss: 2.301  loss_cls_stage0: 0.297  loss_box_reg_stage0: 0.2458  loss_cls_stage1: 0.2597  loss_box_reg_stage1: 0.3647  loss_cls_stage2: 0.2113  loss_box_reg_stage2: 0.3146  loss_mask: 0.5439  loss_rpn_cls: 0.0576  loss_rpn_loc: 0.03385  validation_loss: 2.165  time: 1.7460  data_time: 0.0225  lr: 2.9613e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:22:32 d2.utils.events]: \u001b[0m eta: 0:28:09  iter: 8919  total_loss: 2.519  loss_cls_stage0: 0.3461  loss_box_reg_stage0: 0.2851  loss_cls_stage1: 0.2902  loss_box_reg_stage1: 0.4365  loss_cls_stage2: 0.1976  loss_box_reg_stage2: 0.3187  loss_mask: 0.5717  loss_rpn_cls: 0.05688  loss_rpn_loc: 0.03509  validation_loss: 2.165  time: 1.7457  data_time: 0.0238  lr: 2.8557e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:23:03 d2.utils.events]: \u001b[0m eta: 0:27:38  iter: 8939  total_loss: 2.461  loss_cls_stage0: 0.3484  loss_box_reg_stage0: 0.2687  loss_cls_stage1: 0.2957  loss_box_reg_stage1: 0.3909  loss_cls_stage2: 0.2158  loss_box_reg_stage2: 0.3156  loss_mask: 0.5244  loss_rpn_cls: 0.0649  loss_rpn_loc: 0.0414  validation_loss: 2.165  time: 1.7453  data_time: 0.0228  lr: 2.752e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:23:34 d2.utils.events]: \u001b[0m eta: 0:27:06  iter: 8959  total_loss: 2.381  loss_cls_stage0: 0.3545  loss_box_reg_stage0: 0.2426  loss_cls_stage1: 0.2889  loss_box_reg_stage1: 0.3389  loss_cls_stage2: 0.1933  loss_box_reg_stage2: 0.2849  loss_mask: 0.547  loss_rpn_cls: 0.06457  loss_rpn_loc: 0.03798  validation_loss: 2.165  time: 1.7449  data_time: 0.0216  lr: 2.6501e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:24:06 d2.utils.events]: \u001b[0m eta: 0:26:35  iter: 8979  total_loss: 2.393  loss_cls_stage0: 0.3508  loss_box_reg_stage0: 0.2628  loss_cls_stage1: 0.2963  loss_box_reg_stage1: 0.3804  loss_cls_stage2: 0.2099  loss_box_reg_stage2: 0.3216  loss_mask: 0.4705  loss_rpn_cls: 0.06603  loss_rpn_loc: 0.03969  validation_loss: 2.165  time: 1.7445  data_time: 0.0229  lr: 2.5501e-06  max_mem: 11557M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/26 15:24:39 d2.data.common]: \u001b[0mSerializing 900 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/26 15:24:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.91 MiB\n",
      "\u001b[32m[03/26 15:24:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 900 images\n",
      "\u001b[32m[03/26 15:24:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/900. 0.0818 s / img. ETA=0:01:55\n",
      "\u001b[32m[03/26 15:24:46 d2.evaluation.evaluator]: \u001b[0mInference done 55/900. 0.0810 s / img. ETA=0:01:39\n",
      "\u001b[32m[03/26 15:24:51 d2.evaluation.evaluator]: \u001b[0mInference done 96/900. 0.0812 s / img. ETA=0:01:36\n",
      "\u001b[32m[03/26 15:24:56 d2.evaluation.evaluator]: \u001b[0mInference done 142/900. 0.0809 s / img. ETA=0:01:28\n",
      "\u001b[32m[03/26 15:25:01 d2.evaluation.evaluator]: \u001b[0mInference done 187/900. 0.0807 s / img. ETA=0:01:22\n",
      "\u001b[32m[03/26 15:25:06 d2.evaluation.evaluator]: \u001b[0mInference done 230/900. 0.0808 s / img. ETA=0:01:17\n",
      "\u001b[32m[03/26 15:25:11 d2.evaluation.evaluator]: \u001b[0mInference done 273/900. 0.0808 s / img. ETA=0:01:12\n",
      "\u001b[32m[03/26 15:25:16 d2.evaluation.evaluator]: \u001b[0mInference done 319/900. 0.0807 s / img. ETA=0:01:06\n",
      "\u001b[32m[03/26 15:25:21 d2.evaluation.evaluator]: \u001b[0mInference done 360/900. 0.0808 s / img. ETA=0:01:02\n",
      "\u001b[32m[03/26 15:25:26 d2.evaluation.evaluator]: \u001b[0mInference done 404/900. 0.0808 s / img. ETA=0:00:57\n",
      "\u001b[32m[03/26 15:25:31 d2.evaluation.evaluator]: \u001b[0mInference done 446/900. 0.0808 s / img. ETA=0:00:52\n",
      "\u001b[32m[03/26 15:25:37 d2.evaluation.evaluator]: \u001b[0mInference done 488/900. 0.0809 s / img. ETA=0:00:48\n",
      "\u001b[32m[03/26 15:25:42 d2.evaluation.evaluator]: \u001b[0mInference done 533/900. 0.0809 s / img. ETA=0:00:42\n",
      "\u001b[32m[03/26 15:25:47 d2.evaluation.evaluator]: \u001b[0mInference done 575/900. 0.0809 s / img. ETA=0:00:37\n",
      "\u001b[32m[03/26 15:25:52 d2.evaluation.evaluator]: \u001b[0mInference done 619/900. 0.0809 s / img. ETA=0:00:32\n",
      "\u001b[32m[03/26 15:25:57 d2.evaluation.evaluator]: \u001b[0mInference done 661/900. 0.0809 s / img. ETA=0:00:27\n",
      "\u001b[32m[03/26 15:26:02 d2.evaluation.evaluator]: \u001b[0mInference done 706/900. 0.0809 s / img. ETA=0:00:22\n",
      "\u001b[32m[03/26 15:26:07 d2.evaluation.evaluator]: \u001b[0mInference done 749/900. 0.0809 s / img. ETA=0:00:17\n",
      "\u001b[32m[03/26 15:26:12 d2.evaluation.evaluator]: \u001b[0mInference done 791/900. 0.0809 s / img. ETA=0:00:12\n",
      "\u001b[32m[03/26 15:26:17 d2.evaluation.evaluator]: \u001b[0mInference done 836/900. 0.0809 s / img. ETA=0:00:07\n",
      "\u001b[32m[03/26 15:26:22 d2.evaluation.evaluator]: \u001b[0mInference done 878/900. 0.0809 s / img. ETA=0:00:02\n",
      "\u001b[32m[03/26 15:26:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:44.648813 (0.116926 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/26 15:26:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:12 (0.080909 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.56 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.150\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.167\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.041\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.097\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.134\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.179\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.180\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.016\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.060\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.201\n",
      "\u001b[32m[03/26 15:26:26 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold1 in csv format:\n",
      "\u001b[32m[03/26 15:26:26 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/26 15:26:26 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/26 15:26:26 d2.evaluation.testing]: \u001b[0mcopypaste: 9.1125,15.0408,16.7346,1.0759,4.1459,9.7247\n",
      "validation do loss eval 2.3794731722080744\n",
      "\u001b[32m[03/26 15:27:59 d2.utils.events]: \u001b[0m eta: 0:26:03  iter: 8999  total_loss: 2.278  loss_cls_stage0: 0.3048  loss_box_reg_stage0: 0.2452  loss_cls_stage1: 0.2509  loss_box_reg_stage1: 0.3385  loss_cls_stage2: 0.1876  loss_box_reg_stage2: 0.3069  loss_mask: 0.5358  loss_rpn_cls: 0.05589  loss_rpn_loc: 0.02767  validation_loss: 2.235  time: 1.7441  data_time: 0.0235  lr: 2.452e-06  max_mem: 11557M\n",
      "\u001b[32m[03/26 15:28:30 d2.utils.events]: \u001b[0m eta: 0:25:32  iter: 9019  total_loss: 2.51  loss_cls_stage0: 0.3348  loss_box_reg_stage0: 0.2584  loss_cls_stage1: 0.2899  loss_box_reg_stage1: 0.3975  loss_cls_stage2: 0.2171  loss_box_reg_stage2: 0.3348  loss_mask: 0.5215  loss_rpn_cls: 0.06259  loss_rpn_loc: 0.04017  validation_loss: 2.235  time: 1.7436  data_time: 0.0314  lr: 2.3558e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:29:01 d2.utils.events]: \u001b[0m eta: 0:25:01  iter: 9039  total_loss: 2.564  loss_cls_stage0: 0.3676  loss_box_reg_stage0: 0.2787  loss_cls_stage1: 0.2986  loss_box_reg_stage1: 0.3935  loss_cls_stage2: 0.2163  loss_box_reg_stage2: 0.3312  loss_mask: 0.4913  loss_rpn_cls: 0.06716  loss_rpn_loc: 0.0356  validation_loss: 2.235  time: 1.7432  data_time: 0.0248  lr: 2.2614e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:29:36 d2.utils.events]: \u001b[0m eta: 0:24:30  iter: 9059  total_loss: 2.422  loss_cls_stage0: 0.3347  loss_box_reg_stage0: 0.2807  loss_cls_stage1: 0.2869  loss_box_reg_stage1: 0.3891  loss_cls_stage2: 0.2035  loss_box_reg_stage2: 0.3216  loss_mask: 0.5357  loss_rpn_cls: 0.05294  loss_rpn_loc: 0.03572  validation_loss: 2.235  time: 1.7432  data_time: 0.0235  lr: 2.169e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:30:16 d2.utils.events]: \u001b[0m eta: 0:23:59  iter: 9079  total_loss: 2.4  loss_cls_stage0: 0.3127  loss_box_reg_stage0: 0.2623  loss_cls_stage1: 0.2789  loss_box_reg_stage1: 0.3794  loss_cls_stage2: 0.1994  loss_box_reg_stage2: 0.3014  loss_mask: 0.5308  loss_rpn_cls: 0.05632  loss_rpn_loc: 0.03385  validation_loss: 2.235  time: 1.7438  data_time: 0.0240  lr: 2.0784e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:31:08 d2.utils.events]: \u001b[0m eta: 0:23:29  iter: 9099  total_loss: 2.315  loss_cls_stage0: 0.3302  loss_box_reg_stage0: 0.2728  loss_cls_stage1: 0.256  loss_box_reg_stage1: 0.3779  loss_cls_stage2: 0.1874  loss_box_reg_stage2: 0.3015  loss_mask: 0.5107  loss_rpn_cls: 0.05394  loss_rpn_loc: 0.03462  validation_loss: 2.235  time: 1.7457  data_time: 0.0228  lr: 1.9897e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:31:59 d2.utils.events]: \u001b[0m eta: 0:22:58  iter: 9119  total_loss: 2.303  loss_cls_stage0: 0.3099  loss_box_reg_stage0: 0.2304  loss_cls_stage1: 0.2507  loss_box_reg_stage1: 0.3516  loss_cls_stage2: 0.1857  loss_box_reg_stage2: 0.3101  loss_mask: 0.5704  loss_rpn_cls: 0.05418  loss_rpn_loc: 0.0364  validation_loss: 2.235  time: 1.7475  data_time: 0.0243  lr: 1.9029e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:32:50 d2.utils.events]: \u001b[0m eta: 0:22:27  iter: 9139  total_loss: 2.499  loss_cls_stage0: 0.3528  loss_box_reg_stage0: 0.2637  loss_cls_stage1: 0.2993  loss_box_reg_stage1: 0.3952  loss_cls_stage2: 0.2064  loss_box_reg_stage2: 0.3068  loss_mask: 0.513  loss_rpn_cls: 0.05953  loss_rpn_loc: 0.0348  validation_loss: 2.235  time: 1.7492  data_time: 0.0235  lr: 1.818e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:33:42 d2.utils.events]: \u001b[0m eta: 0:21:56  iter: 9159  total_loss: 2.334  loss_cls_stage0: 0.3414  loss_box_reg_stage0: 0.2547  loss_cls_stage1: 0.28  loss_box_reg_stage1: 0.3611  loss_cls_stage2: 0.1911  loss_box_reg_stage2: 0.2751  loss_mask: 0.5359  loss_rpn_cls: 0.06367  loss_rpn_loc: 0.03679  validation_loss: 2.235  time: 1.7510  data_time: 0.0228  lr: 1.735e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:34:34 d2.utils.events]: \u001b[0m eta: 0:21:26  iter: 9179  total_loss: 2.514  loss_cls_stage0: 0.3395  loss_box_reg_stage0: 0.2717  loss_cls_stage1: 0.2911  loss_box_reg_stage1: 0.3858  loss_cls_stage2: 0.2108  loss_box_reg_stage2: 0.3237  loss_mask: 0.5392  loss_rpn_cls: 0.05865  loss_rpn_loc: 0.03915  validation_loss: 2.235  time: 1.7529  data_time: 0.0236  lr: 1.6539e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:35:25 d2.utils.events]: \u001b[0m eta: 0:20:55  iter: 9199  total_loss: 2.498  loss_cls_stage0: 0.3538  loss_box_reg_stage0: 0.2967  loss_cls_stage1: 0.2834  loss_box_reg_stage1: 0.3944  loss_cls_stage2: 0.2085  loss_box_reg_stage2: 0.3354  loss_mask: 0.5136  loss_rpn_cls: 0.063  loss_rpn_loc: 0.03763  validation_loss: 2.235  time: 1.7547  data_time: 0.0250  lr: 1.5748e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:36:17 d2.utils.events]: \u001b[0m eta: 0:20:25  iter: 9219  total_loss: 2.497  loss_cls_stage0: 0.3526  loss_box_reg_stage0: 0.2839  loss_cls_stage1: 0.2871  loss_box_reg_stage1: 0.3939  loss_cls_stage2: 0.2101  loss_box_reg_stage2: 0.3391  loss_mask: 0.5708  loss_rpn_cls: 0.06542  loss_rpn_loc: 0.03884  validation_loss: 2.235  time: 1.7565  data_time: 0.0229  lr: 1.4975e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:37:09 d2.utils.events]: \u001b[0m eta: 0:19:54  iter: 9239  total_loss: 2.47  loss_cls_stage0: 0.3621  loss_box_reg_stage0: 0.2789  loss_cls_stage1: 0.2999  loss_box_reg_stage1: 0.3988  loss_cls_stage2: 0.2053  loss_box_reg_stage2: 0.3168  loss_mask: 0.512  loss_rpn_cls: 0.05712  loss_rpn_loc: 0.03469  validation_loss: 2.235  time: 1.7582  data_time: 0.0245  lr: 1.4221e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:38:01 d2.utils.events]: \u001b[0m eta: 0:19:23  iter: 9259  total_loss: 2.3  loss_cls_stage0: 0.3035  loss_box_reg_stage0: 0.254  loss_cls_stage1: 0.2708  loss_box_reg_stage1: 0.3721  loss_cls_stage2: 0.1874  loss_box_reg_stage2: 0.3009  loss_mask: 0.5361  loss_rpn_cls: 0.05972  loss_rpn_loc: 0.03353  validation_loss: 2.235  time: 1.7601  data_time: 0.0245  lr: 1.3487e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:38:51 d2.utils.events]: \u001b[0m eta: 0:18:53  iter: 9279  total_loss: 2.535  loss_cls_stage0: 0.3463  loss_box_reg_stage0: 0.2847  loss_cls_stage1: 0.2946  loss_box_reg_stage1: 0.3855  loss_cls_stage2: 0.2159  loss_box_reg_stage2: 0.3197  loss_mask: 0.5485  loss_rpn_cls: 0.06552  loss_rpn_loc: 0.03867  validation_loss: 2.235  time: 1.7617  data_time: 0.0229  lr: 1.2772e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:39:43 d2.utils.events]: \u001b[0m eta: 0:18:22  iter: 9299  total_loss: 2.256  loss_cls_stage0: 0.319  loss_box_reg_stage0: 0.2282  loss_cls_stage1: 0.2629  loss_box_reg_stage1: 0.3379  loss_cls_stage2: 0.1838  loss_box_reg_stage2: 0.275  loss_mask: 0.552  loss_rpn_cls: 0.05364  loss_rpn_loc: 0.03148  validation_loss: 2.235  time: 1.7635  data_time: 0.0233  lr: 1.2076e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:40:35 d2.utils.events]: \u001b[0m eta: 0:17:52  iter: 9319  total_loss: 2.465  loss_cls_stage0: 0.3489  loss_box_reg_stage0: 0.2739  loss_cls_stage1: 0.2949  loss_box_reg_stage1: 0.4009  loss_cls_stage2: 0.213  loss_box_reg_stage2: 0.3095  loss_mask: 0.4782  loss_rpn_cls: 0.06211  loss_rpn_loc: 0.03901  validation_loss: 2.235  time: 1.7652  data_time: 0.0239  lr: 1.1399e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:41:26 d2.utils.events]: \u001b[0m eta: 0:17:21  iter: 9339  total_loss: 2.457  loss_cls_stage0: 0.3105  loss_box_reg_stage0: 0.264  loss_cls_stage1: 0.2541  loss_box_reg_stage1: 0.3946  loss_cls_stage2: 0.1905  loss_box_reg_stage2: 0.3232  loss_mask: 0.5389  loss_rpn_cls: 0.06538  loss_rpn_loc: 0.03654  validation_loss: 2.235  time: 1.7669  data_time: 0.0236  lr: 1.0742e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:42:17 d2.utils.events]: \u001b[0m eta: 0:16:50  iter: 9359  total_loss: 2.403  loss_cls_stage0: 0.3258  loss_box_reg_stage0: 0.2459  loss_cls_stage1: 0.2806  loss_box_reg_stage1: 0.3644  loss_cls_stage2: 0.2107  loss_box_reg_stage2: 0.2918  loss_mask: 0.5662  loss_rpn_cls: 0.05584  loss_rpn_loc: 0.03596  validation_loss: 2.235  time: 1.7687  data_time: 0.0235  lr: 1.0104e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:43:09 d2.utils.events]: \u001b[0m eta: 0:16:20  iter: 9379  total_loss: 2.586  loss_cls_stage0: 0.3689  loss_box_reg_stage0: 0.2825  loss_cls_stage1: 0.3079  loss_box_reg_stage1: 0.3938  loss_cls_stage2: 0.2248  loss_box_reg_stage2: 0.321  loss_mask: 0.5433  loss_rpn_cls: 0.05898  loss_rpn_loc: 0.04236  validation_loss: 2.235  time: 1.7704  data_time: 0.0235  lr: 9.4852e-07  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:43:47 d2.utils.events]: \u001b[0m eta: 0:15:48  iter: 9399  total_loss: 2.306  loss_cls_stage0: 0.3078  loss_box_reg_stage0: 0.2496  loss_cls_stage1: 0.2495  loss_box_reg_stage1: 0.3484  loss_cls_stage2: 0.202  loss_box_reg_stage2: 0.3028  loss_mask: 0.4936  loss_rpn_cls: 0.05863  loss_rpn_loc: 0.03145  validation_loss: 2.235  time: 1.7706  data_time: 0.0224  lr: 8.8858e-07  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:44:18 d2.utils.events]: \u001b[0m eta: 0:15:17  iter: 9419  total_loss: 2.492  loss_cls_stage0: 0.3356  loss_box_reg_stage0: 0.2804  loss_cls_stage1: 0.2926  loss_box_reg_stage1: 0.3875  loss_cls_stage2: 0.2188  loss_box_reg_stage2: 0.3175  loss_mask: 0.5526  loss_rpn_cls: 0.07092  loss_rpn_loc: 0.03794  validation_loss: 2.235  time: 1.7702  data_time: 0.0232  lr: 8.3059e-07  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:44:49 d2.utils.events]: \u001b[0m eta: 0:14:45  iter: 9439  total_loss: 2.238  loss_cls_stage0: 0.3059  loss_box_reg_stage0: 0.2469  loss_cls_stage1: 0.2451  loss_box_reg_stage1: 0.3509  loss_cls_stage2: 0.1806  loss_box_reg_stage2: 0.3129  loss_mask: 0.5268  loss_rpn_cls: 0.06107  loss_rpn_loc: 0.03532  validation_loss: 2.235  time: 1.7698  data_time: 0.0225  lr: 7.7453e-07  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:45:21 d2.utils.events]: \u001b[0m eta: 0:14:14  iter: 9459  total_loss: 2.594  loss_cls_stage0: 0.3487  loss_box_reg_stage0: 0.2761  loss_cls_stage1: 0.2875  loss_box_reg_stage1: 0.3991  loss_cls_stage2: 0.1991  loss_box_reg_stage2: 0.338  loss_mask: 0.5616  loss_rpn_cls: 0.06604  loss_rpn_loc: 0.04214  validation_loss: 2.235  time: 1.7694  data_time: 0.0232  lr: 7.2042e-07  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:45:52 d2.utils.events]: \u001b[0m eta: 0:13:42  iter: 9479  total_loss: 2.477  loss_cls_stage0: 0.3434  loss_box_reg_stage0: 0.2896  loss_cls_stage1: 0.2945  loss_box_reg_stage1: 0.4073  loss_cls_stage2: 0.2045  loss_box_reg_stage2: 0.323  loss_mask: 0.545  loss_rpn_cls: 0.05484  loss_rpn_loc: 0.03539  validation_loss: 2.235  time: 1.7690  data_time: 0.0223  lr: 6.6826e-07  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:46:24 d2.utils.events]: \u001b[0m eta: 0:13:10  iter: 9499  total_loss: 2.355  loss_cls_stage0: 0.308  loss_box_reg_stage0: 0.2533  loss_cls_stage1: 0.2647  loss_box_reg_stage1: 0.3769  loss_cls_stage2: 0.1953  loss_box_reg_stage2: 0.3269  loss_mask: 0.4796  loss_rpn_cls: 0.05982  loss_rpn_loc: 0.03419  validation_loss: 2.235  time: 1.7685  data_time: 0.0233  lr: 6.1804e-07  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:46:55 d2.utils.events]: \u001b[0m eta: 0:12:39  iter: 9519  total_loss: 2.312  loss_cls_stage0: 0.3357  loss_box_reg_stage0: 0.2589  loss_cls_stage1: 0.2716  loss_box_reg_stage1: 0.359  loss_cls_stage2: 0.1923  loss_box_reg_stage2: 0.3171  loss_mask: 0.4817  loss_rpn_cls: 0.06013  loss_rpn_loc: 0.0348  validation_loss: 2.235  time: 1.7681  data_time: 0.0237  lr: 5.6977e-07  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:47:26 d2.utils.events]: \u001b[0m eta: 0:12:07  iter: 9539  total_loss: 2.397  loss_cls_stage0: 0.3054  loss_box_reg_stage0: 0.2541  loss_cls_stage1: 0.2681  loss_box_reg_stage1: 0.3742  loss_cls_stage2: 0.2027  loss_box_reg_stage2: 0.305  loss_mask: 0.5252  loss_rpn_cls: 0.05655  loss_rpn_loc: 0.03174  validation_loss: 2.235  time: 1.7677  data_time: 0.0226  lr: 5.2346e-07  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:47:58 d2.utils.events]: \u001b[0m eta: 0:11:36  iter: 9559  total_loss: 2.224  loss_cls_stage0: 0.327  loss_box_reg_stage0: 0.2459  loss_cls_stage1: 0.2724  loss_box_reg_stage1: 0.3327  loss_cls_stage2: 0.1781  loss_box_reg_stage2: 0.2872  loss_mask: 0.526  loss_rpn_cls: 0.05749  loss_rpn_loc: 0.03358  validation_loss: 2.235  time: 1.7673  data_time: 0.0230  lr: 4.791e-07  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:48:29 d2.utils.events]: \u001b[0m eta: 0:11:04  iter: 9579  total_loss: 2.337  loss_cls_stage0: 0.3014  loss_box_reg_stage0: 0.2429  loss_cls_stage1: 0.2556  loss_box_reg_stage1: 0.3698  loss_cls_stage2: 0.1893  loss_box_reg_stage2: 0.3092  loss_mask: 0.5557  loss_rpn_cls: 0.05805  loss_rpn_loc: 0.03415  validation_loss: 2.235  time: 1.7668  data_time: 0.0231  lr: 4.3669e-07  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:49:00 d2.utils.events]: \u001b[0m eta: 0:10:32  iter: 9599  total_loss: 2.412  loss_cls_stage0: 0.345  loss_box_reg_stage0: 0.2678  loss_cls_stage1: 0.2899  loss_box_reg_stage1: 0.3884  loss_cls_stage2: 0.2012  loss_box_reg_stage2: 0.3477  loss_mask: 0.5323  loss_rpn_cls: 0.06299  loss_rpn_loc: 0.03589  validation_loss: 2.235  time: 1.7664  data_time: 0.0231  lr: 3.9624e-07  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:49:32 d2.utils.events]: \u001b[0m eta: 0:10:01  iter: 9619  total_loss: 2.334  loss_cls_stage0: 0.3222  loss_box_reg_stage0: 0.2449  loss_cls_stage1: 0.2749  loss_box_reg_stage1: 0.3636  loss_cls_stage2: 0.1976  loss_box_reg_stage2: 0.3089  loss_mask: 0.5949  loss_rpn_cls: 0.05594  loss_rpn_loc: 0.03135  validation_loss: 2.235  time: 1.7660  data_time: 0.0234  lr: 3.5774e-07  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:50:03 d2.utils.events]: \u001b[0m eta: 0:09:29  iter: 9639  total_loss: 2.384  loss_cls_stage0: 0.3096  loss_box_reg_stage0: 0.2529  loss_cls_stage1: 0.2712  loss_box_reg_stage1: 0.382  loss_cls_stage2: 0.2004  loss_box_reg_stage2: 0.3278  loss_mask: 0.5251  loss_rpn_cls: 0.05958  loss_rpn_loc: 0.03364  validation_loss: 2.235  time: 1.7656  data_time: 0.0240  lr: 3.2121e-07  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:50:34 d2.utils.events]: \u001b[0m eta: 0:08:57  iter: 9659  total_loss: 2.348  loss_cls_stage0: 0.3167  loss_box_reg_stage0: 0.2675  loss_cls_stage1: 0.2773  loss_box_reg_stage1: 0.3711  loss_cls_stage2: 0.1932  loss_box_reg_stage2: 0.2693  loss_mask: 0.5096  loss_rpn_cls: 0.05904  loss_rpn_loc: 0.03729  validation_loss: 2.235  time: 1.7652  data_time: 0.0235  lr: 2.8664e-07  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:51:06 d2.utils.events]: \u001b[0m eta: 0:08:26  iter: 9679  total_loss: 2.503  loss_cls_stage0: 0.3235  loss_box_reg_stage0: 0.2705  loss_cls_stage1: 0.2708  loss_box_reg_stage1: 0.3907  loss_cls_stage2: 0.1958  loss_box_reg_stage2: 0.3116  loss_mask: 0.5487  loss_rpn_cls: 0.06244  loss_rpn_loc: 0.03727  validation_loss: 2.235  time: 1.7648  data_time: 0.0236  lr: 2.5403e-07  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:51:37 d2.utils.events]: \u001b[0m eta: 0:07:54  iter: 9699  total_loss: 2.363  loss_cls_stage0: 0.3187  loss_box_reg_stage0: 0.2716  loss_cls_stage1: 0.2703  loss_box_reg_stage1: 0.387  loss_cls_stage2: 0.1939  loss_box_reg_stage2: 0.3145  loss_mask: 0.5022  loss_rpn_cls: 0.05994  loss_rpn_loc: 0.03575  validation_loss: 2.235  time: 1.7644  data_time: 0.0238  lr: 2.2338e-07  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:52:09 d2.utils.events]: \u001b[0m eta: 0:07:23  iter: 9719  total_loss: 2.37  loss_cls_stage0: 0.3256  loss_box_reg_stage0: 0.2555  loss_cls_stage1: 0.2654  loss_box_reg_stage1: 0.3744  loss_cls_stage2: 0.1943  loss_box_reg_stage2: 0.3321  loss_mask: 0.5132  loss_rpn_cls: 0.05408  loss_rpn_loc: 0.03359  validation_loss: 2.235  time: 1.7640  data_time: 0.0240  lr: 1.947e-07  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:52:59 d2.utils.events]: \u001b[0m eta: 0:06:52  iter: 9739  total_loss: 2.539  loss_cls_stage0: 0.3237  loss_box_reg_stage0: 0.2549  loss_cls_stage1: 0.2832  loss_box_reg_stage1: 0.3907  loss_cls_stage2: 0.2133  loss_box_reg_stage2: 0.3307  loss_mask: 0.546  loss_rpn_cls: 0.06819  loss_rpn_loc: 0.03791  validation_loss: 2.235  time: 1.7656  data_time: 0.0226  lr: 1.6799e-07  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:53:51 d2.utils.events]: \u001b[0m eta: 0:06:20  iter: 9759  total_loss: 2.538  loss_cls_stage0: 0.3397  loss_box_reg_stage0: 0.2973  loss_cls_stage1: 0.2903  loss_box_reg_stage1: 0.3905  loss_cls_stage2: 0.2081  loss_box_reg_stage2: 0.3076  loss_mask: 0.5377  loss_rpn_cls: 0.06445  loss_rpn_loc: 0.03869  validation_loss: 2.235  time: 1.7672  data_time: 0.0226  lr: 1.4324e-07  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:54:43 d2.utils.events]: \u001b[0m eta: 0:05:49  iter: 9779  total_loss: 2.222  loss_cls_stage0: 0.2919  loss_box_reg_stage0: 0.2232  loss_cls_stage1: 0.2422  loss_box_reg_stage1: 0.3549  loss_cls_stage2: 0.1835  loss_box_reg_stage2: 0.3092  loss_mask: 0.5295  loss_rpn_cls: 0.06289  loss_rpn_loc: 0.03687  validation_loss: 2.235  time: 1.7689  data_time: 0.0228  lr: 1.2046e-07  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:55:34 d2.utils.events]: \u001b[0m eta: 0:05:18  iter: 9799  total_loss: 2.358  loss_cls_stage0: 0.3223  loss_box_reg_stage0: 0.2576  loss_cls_stage1: 0.2644  loss_box_reg_stage1: 0.3554  loss_cls_stage2: 0.2058  loss_box_reg_stage2: 0.3116  loss_mask: 0.5317  loss_rpn_cls: 0.05519  loss_rpn_loc: 0.03442  validation_loss: 2.235  time: 1.7705  data_time: 0.0231  lr: 9.9652e-08  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:56:25 d2.utils.events]: \u001b[0m eta: 0:04:47  iter: 9819  total_loss: 2.326  loss_cls_stage0: 0.3065  loss_box_reg_stage0: 0.2278  loss_cls_stage1: 0.2718  loss_box_reg_stage1: 0.3509  loss_cls_stage2: 0.2025  loss_box_reg_stage2: 0.3082  loss_mask: 0.5803  loss_rpn_cls: 0.05734  loss_rpn_loc: 0.03413  validation_loss: 2.235  time: 1.7721  data_time: 0.0243  lr: 8.0813e-08  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:57:17 d2.utils.events]: \u001b[0m eta: 0:04:16  iter: 9839  total_loss: 2.406  loss_cls_stage0: 0.327  loss_box_reg_stage0: 0.2537  loss_cls_stage1: 0.2779  loss_box_reg_stage1: 0.3737  loss_cls_stage2: 0.1966  loss_box_reg_stage2: 0.304  loss_mask: 0.5317  loss_rpn_cls: 0.06241  loss_rpn_loc: 0.03418  validation_loss: 2.235  time: 1.7738  data_time: 0.0233  lr: 6.3944e-08  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:58:08 d2.utils.events]: \u001b[0m eta: 0:03:46  iter: 9859  total_loss: 2.453  loss_cls_stage0: 0.3239  loss_box_reg_stage0: 0.2435  loss_cls_stage1: 0.2756  loss_box_reg_stage1: 0.371  loss_cls_stage2: 0.2073  loss_box_reg_stage2: 0.3185  loss_mask: 0.5466  loss_rpn_cls: 0.0587  loss_rpn_loc: 0.03179  validation_loss: 2.235  time: 1.7753  data_time: 0.0254  lr: 4.9046e-08  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:59:00 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 9879  total_loss: 2.352  loss_cls_stage0: 0.3267  loss_box_reg_stage0: 0.2695  loss_cls_stage1: 0.2872  loss_box_reg_stage1: 0.3929  loss_cls_stage2: 0.2044  loss_box_reg_stage2: 0.3142  loss_mask: 0.5383  loss_rpn_cls: 0.05312  loss_rpn_loc: 0.03581  validation_loss: 2.235  time: 1.7770  data_time: 0.0225  lr: 3.6121e-08  max_mem: 11723M\n",
      "\u001b[32m[03/26 15:59:51 d2.utils.events]: \u001b[0m eta: 0:02:52  iter: 9899  total_loss: 2.199  loss_cls_stage0: 0.2978  loss_box_reg_stage0: 0.2434  loss_cls_stage1: 0.2557  loss_box_reg_stage1: 0.3576  loss_cls_stage2: 0.2012  loss_box_reg_stage2: 0.3053  loss_mask: 0.5349  loss_rpn_cls: 0.05435  loss_rpn_loc: 0.03495  validation_loss: 2.235  time: 1.7786  data_time: 0.0233  lr: 2.5168e-08  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:00:42 d2.utils.events]: \u001b[0m eta: 0:03:16  iter: 9919  total_loss: 2.402  loss_cls_stage0: 0.3359  loss_box_reg_stage0: 0.2613  loss_cls_stage1: 0.2757  loss_box_reg_stage1: 0.359  loss_cls_stage2: 0.1985  loss_box_reg_stage2: 0.306  loss_mask: 0.5466  loss_rpn_cls: 0.06661  loss_rpn_loc: 0.03548  validation_loss: 2.235  time: 1.7802  data_time: 0.0235  lr: 1.6188e-08  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:01:34 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 9939  total_loss: 2.301  loss_cls_stage0: 0.3075  loss_box_reg_stage0: 0.2577  loss_cls_stage1: 0.2617  loss_box_reg_stage1: 0.35  loss_cls_stage2: 0.1977  loss_box_reg_stage2: 0.2939  loss_mask: 0.5212  loss_rpn_cls: 0.05884  loss_rpn_loc: 0.03187  validation_loss: 2.235  time: 1.7818  data_time: 0.0231  lr: 9.1809e-09  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:02:26 d2.utils.events]: \u001b[0m eta: 0:01:40  iter: 9959  total_loss: 2.394  loss_cls_stage0: 0.3267  loss_box_reg_stage0: 0.2652  loss_cls_stage1: 0.2873  loss_box_reg_stage1: 0.3932  loss_cls_stage2: 0.2066  loss_box_reg_stage2: 0.3089  loss_mask: 0.5402  loss_rpn_cls: 0.06368  loss_rpn_loc: 0.03375  validation_loss: 2.235  time: 1.7834  data_time: 0.0246  lr: 4.1476e-09  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:03:17 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 9979  total_loss: 2.645  loss_cls_stage0: 0.3677  loss_box_reg_stage0: 0.2938  loss_cls_stage1: 0.3017  loss_box_reg_stage1: 0.4078  loss_cls_stage2: 0.2392  loss_box_reg_stage2: 0.3461  loss_mask: 0.5667  loss_rpn_cls: 0.05928  loss_rpn_loc: 0.03782  validation_loss: 2.235  time: 1.7850  data_time: 0.0240  lr: 1.0881e-09  max_mem: 11723M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/26 16:04:12 d2.data.common]: \u001b[0mSerializing 900 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/26 16:04:12 d2.data.common]: \u001b[0mSerialized dataset takes 0.91 MiB\n",
      "\u001b[32m[03/26 16:04:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 900 images\n",
      "\u001b[32m[03/26 16:04:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/900. 0.1849 s / img. ETA=0:03:38\n",
      "\u001b[32m[03/26 16:04:20 d2.evaluation.evaluator]: \u001b[0mInference done 33/900. 0.1886 s / img. ETA=0:03:24\n",
      "\u001b[32m[03/26 16:04:26 d2.evaluation.evaluator]: \u001b[0mInference done 55/900. 0.1887 s / img. ETA=0:03:18\n",
      "\u001b[32m[03/26 16:04:31 d2.evaluation.evaluator]: \u001b[0mInference done 78/900. 0.1866 s / img. ETA=0:03:09\n",
      "\u001b[32m[03/26 16:04:36 d2.evaluation.evaluator]: \u001b[0mInference done 98/900. 0.1873 s / img. ETA=0:03:08\n",
      "\u001b[32m[03/26 16:04:41 d2.evaluation.evaluator]: \u001b[0mInference done 121/900. 0.1855 s / img. ETA=0:03:00\n",
      "\u001b[32m[03/26 16:04:46 d2.evaluation.evaluator]: \u001b[0mInference done 143/900. 0.1866 s / img. ETA=0:02:55\n",
      "\u001b[32m[03/26 16:04:51 d2.evaluation.evaluator]: \u001b[0mInference done 165/900. 0.1867 s / img. ETA=0:02:50\n",
      "\u001b[32m[03/26 16:04:56 d2.evaluation.evaluator]: \u001b[0mInference done 187/900. 0.1880 s / img. ETA=0:02:45\n",
      "\u001b[32m[03/26 16:05:01 d2.evaluation.evaluator]: \u001b[0mInference done 210/900. 0.1879 s / img. ETA=0:02:39\n",
      "\u001b[32m[03/26 16:05:07 d2.evaluation.evaluator]: \u001b[0mInference done 232/900. 0.1873 s / img. ETA=0:02:34\n",
      "\u001b[32m[03/26 16:05:12 d2.evaluation.evaluator]: \u001b[0mInference done 264/900. 0.1779 s / img. ETA=0:02:21\n",
      "\u001b[32m[03/26 16:05:17 d2.evaluation.evaluator]: \u001b[0mInference done 306/900. 0.1644 s / img. ETA=0:02:04\n",
      "\u001b[32m[03/26 16:05:22 d2.evaluation.evaluator]: \u001b[0mInference done 346/900. 0.1547 s / img. ETA=0:01:50\n",
      "\u001b[32m[03/26 16:05:27 d2.evaluation.evaluator]: \u001b[0mInference done 384/900. 0.1474 s / img. ETA=0:01:39\n",
      "\u001b[32m[03/26 16:05:32 d2.evaluation.evaluator]: \u001b[0mInference done 424/900. 0.1411 s / img. ETA=0:01:28\n",
      "\u001b[32m[03/26 16:05:37 d2.evaluation.evaluator]: \u001b[0mInference done 464/900. 0.1359 s / img. ETA=0:01:18\n",
      "\u001b[32m[03/26 16:05:42 d2.evaluation.evaluator]: \u001b[0mInference done 502/900. 0.1321 s / img. ETA=0:01:10\n",
      "\u001b[32m[03/26 16:05:47 d2.evaluation.evaluator]: \u001b[0mInference done 544/900. 0.1281 s / img. ETA=0:01:01\n",
      "\u001b[32m[03/26 16:05:52 d2.evaluation.evaluator]: \u001b[0mInference done 581/900. 0.1252 s / img. ETA=0:00:54\n",
      "\u001b[32m[03/26 16:05:57 d2.evaluation.evaluator]: \u001b[0mInference done 622/900. 0.1223 s / img. ETA=0:00:46\n",
      "\u001b[32m[03/26 16:06:02 d2.evaluation.evaluator]: \u001b[0mInference done 660/900. 0.1199 s / img. ETA=0:00:39\n",
      "\u001b[32m[03/26 16:06:07 d2.evaluation.evaluator]: \u001b[0mInference done 702/900. 0.1176 s / img. ETA=0:00:32\n",
      "\u001b[32m[03/26 16:06:12 d2.evaluation.evaluator]: \u001b[0mInference done 740/900. 0.1157 s / img. ETA=0:00:25\n",
      "\u001b[32m[03/26 16:06:17 d2.evaluation.evaluator]: \u001b[0mInference done 780/900. 0.1140 s / img. ETA=0:00:19\n",
      "\u001b[32m[03/26 16:06:22 d2.evaluation.evaluator]: \u001b[0mInference done 820/900. 0.1124 s / img. ETA=0:00:12\n",
      "\u001b[32m[03/26 16:06:27 d2.evaluation.evaluator]: \u001b[0mInference done 859/900. 0.1109 s / img. ETA=0:00:06\n",
      "\u001b[32m[03/26 16:06:33 d2.evaluation.evaluator]: \u001b[0mInference done 899/900. 0.1096 s / img. ETA=0:00:00\n",
      "\u001b[32m[03/26 16:06:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:18.908562 (0.155205 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/26 16:06:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:38 (0.109600 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.33 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.151\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.168\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.041\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.097\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.133\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.183\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.184\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.016\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.060\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.207\n",
      "\u001b[32m[03/26 16:06:34 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold1 in csv format:\n",
      "\u001b[32m[03/26 16:06:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/26 16:06:34 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/26 16:06:34 d2.evaluation.testing]: \u001b[0mcopypaste: 9.1217,15.1021,16.8003,1.0812,4.1456,9.7443\n",
      "validation do loss eval 2.387299743145898\n",
      "\u001b[32m[03/26 16:08:08 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 2.381  loss_cls_stage0: 0.3357  loss_box_reg_stage0: 0.2757  loss_cls_stage1: 0.2678  loss_box_reg_stage1: 0.3735  loss_cls_stage2: 0.1923  loss_box_reg_stage2: 0.3002  loss_mask: 0.5341  loss_rpn_cls: 0.0602  loss_rpn_loc: 0.03941  validation_loss: 2.248  time: 1.7866  data_time: 0.0235  lr: 2.4674e-12  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:08:08 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 4:57:42 (1.7866 s / it)\n",
      "\u001b[32m[03/26 16:08:08 d2.engine.hooks]: \u001b[0mTotal training time: 5:34:49 (0:37:07 on hooks)\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/26 16:08:08 d2.data.common]: \u001b[0mSerializing 900 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/26 16:08:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.91 MiB\n",
      "\u001b[32m[03/26 16:08:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 900 images\n",
      "\u001b[32m[03/26 16:08:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/900. 0.0824 s / img. ETA=0:02:10\n",
      "\u001b[32m[03/26 16:08:15 d2.evaluation.evaluator]: \u001b[0mInference done 50/900. 0.0813 s / img. ETA=0:01:51\n",
      "\u001b[32m[03/26 16:08:20 d2.evaluation.evaluator]: \u001b[0mInference done 88/900. 0.0814 s / img. ETA=0:01:47\n",
      "\u001b[32m[03/26 16:08:25 d2.evaluation.evaluator]: \u001b[0mInference done 126/900. 0.0813 s / img. ETA=0:01:42\n",
      "\u001b[32m[03/26 16:08:30 d2.evaluation.evaluator]: \u001b[0mInference done 168/900. 0.0812 s / img. ETA=0:01:34\n",
      "\u001b[32m[03/26 16:08:35 d2.evaluation.evaluator]: \u001b[0mInference done 209/900. 0.0812 s / img. ETA=0:01:28\n",
      "\u001b[32m[03/26 16:08:41 d2.evaluation.evaluator]: \u001b[0mInference done 245/900. 0.0813 s / img. ETA=0:01:25\n",
      "\u001b[32m[03/26 16:08:46 d2.evaluation.evaluator]: \u001b[0mInference done 284/900. 0.0813 s / img. ETA=0:01:20\n",
      "\u001b[32m[03/26 16:08:51 d2.evaluation.evaluator]: \u001b[0mInference done 324/900. 0.0813 s / img. ETA=0:01:15\n",
      "\u001b[32m[03/26 16:08:56 d2.evaluation.evaluator]: \u001b[0mInference done 361/900. 0.0814 s / img. ETA=0:01:10\n",
      "\u001b[32m[03/26 16:09:01 d2.evaluation.evaluator]: \u001b[0mInference done 400/900. 0.0814 s / img. ETA=0:01:05\n",
      "\u001b[32m[03/26 16:09:06 d2.evaluation.evaluator]: \u001b[0mInference done 438/900. 0.0814 s / img. ETA=0:01:00\n",
      "\u001b[32m[03/26 16:09:11 d2.evaluation.evaluator]: \u001b[0mInference done 474/900. 0.0815 s / img. ETA=0:00:56\n",
      "\u001b[32m[03/26 16:09:16 d2.evaluation.evaluator]: \u001b[0mInference done 513/900. 0.0815 s / img. ETA=0:00:50\n",
      "\u001b[32m[03/26 16:09:21 d2.evaluation.evaluator]: \u001b[0mInference done 553/900. 0.0814 s / img. ETA=0:00:45\n",
      "\u001b[32m[03/26 16:09:26 d2.evaluation.evaluator]: \u001b[0mInference done 589/900. 0.0815 s / img. ETA=0:00:40\n",
      "\u001b[32m[03/26 16:09:31 d2.evaluation.evaluator]: \u001b[0mInference done 627/900. 0.0815 s / img. ETA=0:00:35\n",
      "\u001b[32m[03/26 16:09:36 d2.evaluation.evaluator]: \u001b[0mInference done 665/900. 0.0815 s / img. ETA=0:00:31\n",
      "\u001b[32m[03/26 16:09:41 d2.evaluation.evaluator]: \u001b[0mInference done 704/900. 0.0815 s / img. ETA=0:00:25\n",
      "\u001b[32m[03/26 16:09:46 d2.evaluation.evaluator]: \u001b[0mInference done 741/900. 0.0815 s / img. ETA=0:00:21\n",
      "\u001b[32m[03/26 16:09:51 d2.evaluation.evaluator]: \u001b[0mInference done 779/900. 0.0815 s / img. ETA=0:00:15\n",
      "\u001b[32m[03/26 16:09:57 d2.evaluation.evaluator]: \u001b[0mInference done 817/900. 0.0815 s / img. ETA=0:00:10\n",
      "\u001b[32m[03/26 16:10:02 d2.evaluation.evaluator]: \u001b[0mInference done 855/900. 0.0815 s / img. ETA=0:00:05\n",
      "\u001b[32m[03/26 16:10:07 d2.evaluation.evaluator]: \u001b[0mInference done 893/900. 0.0815 s / img. ETA=0:00:00\n",
      "\u001b[32m[03/26 16:10:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:58.417680 (0.132310 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/26 16:10:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:12 (0.081538 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.33 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.11 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.151\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.168\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.041\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.097\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.133\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.183\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.184\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.016\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.060\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.207\n",
      "\u001b[32m[03/26 16:10:08 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold1 in csv format:\n",
      "\u001b[32m[03/26 16:10:08 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/26 16:10:08 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/26 16:10:08 d2.evaluation.testing]: \u001b[0mcopypaste: 9.1217,15.1021,16.8003,1.0812,4.1456,9.7443\n",
      "cfg.OUTPUT_DIR ./output -> /home/yamaguchi-milkcocholate/VinBigData/src/VinBigData-ObjectDetection/detectron2_results/results01/fold-2\n",
      "\u001b[32m[03/26 16:10:10 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): CascadeROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): ModuleList(\n",
      "      (0): FastRCNNConvFCHead(\n",
      "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "        (fc_relu1): ReLU()\n",
      "        (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (fc_relu2): ReLU()\n",
      "      )\n",
      "      (1): FastRCNNConvFCHead(\n",
      "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "        (fc_relu1): ReLU()\n",
      "        (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (fc_relu2): ReLU()\n",
      "      )\n",
      "      (2): FastRCNNConvFCHead(\n",
      "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "        (fc_relu1): ReLU()\n",
      "        (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (fc_relu2): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (box_predictor): ModuleList(\n",
      "      (0): FastRCNNOutputLayers(\n",
      "        (cls_score): Linear(in_features=1024, out_features=15, bias=True)\n",
      "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      )\n",
      "      (1): FastRCNNOutputLayers(\n",
      "        (cls_score): Linear(in_features=1024, out_features=15, bias=True)\n",
      "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      )\n",
      "      (2): FastRCNNOutputLayers(\n",
      "        (cls_score): Linear(in_features=1024, out_features=15, bias=True)\n",
      "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 14, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[AlbumentationsMapper] Augmentations used in training: Compose([\n",
      "  HorizontalFlip(always_apply=False, p=0.5),\n",
      "  ShiftScaleRotate(always_apply=False, p=0.5, shift_limit_x=(-0.0625, 0.0625), shift_limit_y=(-0.0625, 0.0625), scale_limit=(-0.15000000000000002, 0.1499999999999999), rotate_limit=(-10, 10), interpolation=1, border_mode=4, value=None, mask_value=None),\n",
      "  RandomBrightnessContrast(always_apply=False, p=0.5, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), brightness_by_max=True),\n",
      "  Blur(always_apply=False, p=0.4, blur_limit=(3, 10)),\n",
      "  IAAAffine(always_apply=False, p=0.5, scale=(1.0, 1.0), translate_percent=None, translate_px=None, rotate=(-0.0, 0.0), shear=(-0.0, 0.0), order=1, cval=0, mode='reflect'),\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/26 16:10:10 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 3519 images left.\n",
      "\u001b[32m[03/26 16:10:10 d2.data.build]: \u001b[0mDistribution of instances among all 14 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "| Aortic enla.. | 2698         |  Atelectasis  | 186          | Calcification | 578          |\n",
      "| Cardiomegaly  | 1897         | Consolidation | 331          |      ILD      | 575          |\n",
      "| Infiltration  | 759          | Lung Opacity  | 1578         |  Nodule/Mass  | 1418         |\n",
      "| Other lesion  | 1487         | Pleural eff.. | 1398         | Pleural thi.. | 3232         |\n",
      "| Pneumothorax  | 105          | Pulmonary f.. | 2678         |               |              |\n",
      "|     total     | 18920        |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/26 16:10:10 d2.data.common]: \u001b[0mSerializing 3519 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/26 16:10:11 d2.data.common]: \u001b[0mSerialized dataset takes 3.61 MiB\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/26 16:10:11 d2.data.build]: \u001b[0mDistribution of instances among all 14 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "| Aortic enla.. | 677          |  Atelectasis  | 46           | Calcification | 165          |\n",
      "| Cardiomegaly  | 486          | Consolidation | 92           |      ILD      | 146          |\n",
      "| Infiltration  | 184          | Lung Opacity  | 401          |  Nodule/Mass  | 434          |\n",
      "| Other lesion  | 320          | Pleural eff.. | 350          | Pleural thi.. | 793          |\n",
      "| Pneumothorax  | 24           | Pulmonary f.. | 676          |               |              |\n",
      "|     total     | 4794         |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/26 16:10:11 d2.data.common]: \u001b[0mSerializing 859 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/26 16:10:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.90 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'proposal_generator.anchor_generator.cell_anchors.0' to the model due to incompatible shapes: (3, 4) in the checkpoint but (5, 4) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.anchor_generator.cell_anchors.1' to the model due to incompatible shapes: (3, 4) in the checkpoint but (5, 4) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.anchor_generator.cell_anchors.2' to the model due to incompatible shapes: (3, 4) in the checkpoint but (5, 4) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.anchor_generator.cell_anchors.3' to the model due to incompatible shapes: (3, 4) in the checkpoint but (5, 4) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.anchor_generator.cell_anchors.4' to the model due to incompatible shapes: (3, 4) in the checkpoint but (5, 4) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.objectness_logits.weight' to the model due to incompatible shapes: (3, 256, 1, 1) in the checkpoint but (5, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.objectness_logits.bias' to the model due to incompatible shapes: (3,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.anchor_deltas.weight' to the model due to incompatible shapes: (12, 256, 1, 1) in the checkpoint but (20, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.anchor_deltas.bias' to the model due to incompatible shapes: (12,) in the checkpoint but (20,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.0.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (15, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.0.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (15,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.1.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (15, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.1.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (15,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.2.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (15, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.2.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (15,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (14, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (14,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/26 16:10:11 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/26 16:10:38 d2.utils.events]: \u001b[0m eta: 3:43:09  iter: 19  total_loss: 10.09  loss_cls_stage0: 2.801  loss_box_reg_stage0: 0.01917  loss_cls_stage1: 2.971  loss_box_reg_stage1: 0.04547  loss_cls_stage2: 2.671  loss_box_reg_stage2: 0.02836  loss_mask: 0.693  loss_rpn_cls: 0.8002  loss_rpn_loc: 0.04619  time: 1.3418  data_time: 0.0474  lr: 1.9981e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:11:05 d2.utils.events]: \u001b[0m eta: 3:43:01  iter: 39  total_loss: 9.506  loss_cls_stage0: 2.608  loss_box_reg_stage0: 0.0213  loss_cls_stage1: 2.77  loss_box_reg_stage1: 0.04888  loss_cls_stage2: 2.472  loss_box_reg_stage2: 0.03555  loss_mask: 0.6929  loss_rpn_cls: 0.7912  loss_rpn_loc: 0.05175  time: 1.3471  data_time: 0.0256  lr: 3.996e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:11:32 d2.utils.events]: \u001b[0m eta: 3:42:34  iter: 59  total_loss: 8.206  loss_cls_stage0: 2.212  loss_box_reg_stage0: 0.02346  loss_cls_stage1: 2.318  loss_box_reg_stage1: 0.05066  loss_cls_stage2: 2.06  loss_box_reg_stage2: 0.0378  loss_mask: 0.6929  loss_rpn_cls: 0.7672  loss_rpn_loc: 0.05035  time: 1.3467  data_time: 0.0248  lr: 5.9936e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:11:59 d2.utils.events]: \u001b[0m eta: 3:42:20  iter: 79  total_loss: 6.598  loss_cls_stage0: 1.674  loss_box_reg_stage0: 0.02188  loss_cls_stage1: 1.744  loss_box_reg_stage1: 0.04828  loss_cls_stage2: 1.513  loss_box_reg_stage2: 0.03515  loss_mask: 0.6931  loss_rpn_cls: 0.7388  loss_rpn_loc: 0.05097  time: 1.3472  data_time: 0.0266  lr: 7.9909e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:12:26 d2.utils.events]: \u001b[0m eta: 3:42:00  iter: 99  total_loss: 4.561  loss_cls_stage0: 1.063  loss_box_reg_stage0: 0.02342  loss_cls_stage1: 1.065  loss_box_reg_stage1: 0.05206  loss_cls_stage2: 0.894  loss_box_reg_stage2: 0.03313  loss_mask: 0.693  loss_rpn_cls: 0.7006  loss_rpn_loc: 0.05993  time: 1.3487  data_time: 0.0249  lr: 9.9877e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:12:53 d2.utils.events]: \u001b[0m eta: 3:41:45  iter: 119  total_loss: 3.087  loss_cls_stage0: 0.5745  loss_box_reg_stage0: 0.02407  loss_cls_stage1: 0.5683  loss_box_reg_stage1: 0.04834  loss_cls_stage2: 0.4569  loss_box_reg_stage2: 0.02902  loss_mask: 0.692  loss_rpn_cls: 0.647  loss_rpn_loc: 0.04799  time: 1.3494  data_time: 0.0248  lr: 1.1984e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:13:21 d2.utils.events]: \u001b[0m eta: 3:41:40  iter: 139  total_loss: 2.504  loss_cls_stage0: 0.3609  loss_box_reg_stage0: 0.02627  loss_cls_stage1: 0.3698  loss_box_reg_stage1: 0.05603  loss_cls_stage2: 0.3018  loss_box_reg_stage2: 0.03268  loss_mask: 0.691  loss_rpn_cls: 0.5912  loss_rpn_loc: 0.05441  time: 1.3534  data_time: 0.0268  lr: 1.3979e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:13:49 d2.utils.events]: \u001b[0m eta: 3:41:34  iter: 159  total_loss: 2.413  loss_cls_stage0: 0.3215  loss_box_reg_stage0: 0.03537  loss_cls_stage1: 0.3683  loss_box_reg_stage1: 0.05481  loss_cls_stage2: 0.3115  loss_box_reg_stage2: 0.0406  loss_mask: 0.6902  loss_rpn_cls: 0.5265  loss_rpn_loc: 0.05964  time: 1.3615  data_time: 0.0248  lr: 1.5974e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:14:18 d2.utils.events]: \u001b[0m eta: 3:41:27  iter: 179  total_loss: 2.437  loss_cls_stage0: 0.334  loss_box_reg_stage0: 0.06207  loss_cls_stage1: 0.3929  loss_box_reg_stage1: 0.06717  loss_cls_stage2: 0.3506  loss_box_reg_stage2: 0.03747  loss_mask: 0.6891  loss_rpn_cls: 0.4635  loss_rpn_loc: 0.05399  time: 1.3711  data_time: 0.0247  lr: 1.7968e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:14:47 d2.utils.events]: \u001b[0m eta: 3:41:18  iter: 199  total_loss: 2.343  loss_cls_stage0: 0.3209  loss_box_reg_stage0: 0.08888  loss_cls_stage1: 0.369  loss_box_reg_stage1: 0.08207  loss_cls_stage2: 0.3416  loss_box_reg_stage2: 0.04395  loss_mask: 0.6879  loss_rpn_cls: 0.3931  loss_rpn_loc: 0.04457  time: 1.3807  data_time: 0.0253  lr: 1.9961e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:15:17 d2.utils.events]: \u001b[0m eta: 3:41:14  iter: 219  total_loss: 2.143  loss_cls_stage0: 0.2939  loss_box_reg_stage0: 0.1043  loss_cls_stage1: 0.2713  loss_box_reg_stage1: 0.1011  loss_cls_stage2: 0.2571  loss_box_reg_stage2: 0.03969  loss_mask: 0.6908  loss_rpn_cls: 0.3287  loss_rpn_loc: 0.04921  time: 1.3896  data_time: 0.0308  lr: 2.1952e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:15:47 d2.utils.events]: \u001b[0m eta: 3:42:31  iter: 239  total_loss: 2.002  loss_cls_stage0: 0.2712  loss_box_reg_stage0: 0.1176  loss_cls_stage1: 0.2314  loss_box_reg_stage1: 0.09667  loss_cls_stage2: 0.2122  loss_box_reg_stage2: 0.04928  loss_mask: 0.6858  loss_rpn_cls: 0.2943  loss_rpn_loc: 0.05533  time: 1.3976  data_time: 0.0236  lr: 2.3942e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:16:16 d2.utils.events]: \u001b[0m eta: 3:43:58  iter: 259  total_loss: 1.858  loss_cls_stage0: 0.2473  loss_box_reg_stage0: 0.1007  loss_cls_stage1: 0.1975  loss_box_reg_stage1: 0.09195  loss_cls_stage2: 0.17  loss_box_reg_stage2: 0.04623  loss_mask: 0.6914  loss_rpn_cls: 0.2568  loss_rpn_loc: 0.05128  time: 1.4044  data_time: 0.0242  lr: 2.5931e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:16:46 d2.utils.events]: \u001b[0m eta: 3:46:25  iter: 279  total_loss: 1.805  loss_cls_stage0: 0.2382  loss_box_reg_stage0: 0.1086  loss_cls_stage1: 0.1937  loss_box_reg_stage1: 0.09685  loss_cls_stage2: 0.1532  loss_box_reg_stage2: 0.0554  loss_mask: 0.6829  loss_rpn_cls: 0.2249  loss_rpn_loc: 0.05216  time: 1.4109  data_time: 0.0238  lr: 2.7918e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:17:16 d2.utils.events]: \u001b[0m eta: 3:48:43  iter: 299  total_loss: 1.711  loss_cls_stage0: 0.2333  loss_box_reg_stage0: 0.1034  loss_cls_stage1: 0.1736  loss_box_reg_stage1: 0.1074  loss_cls_stage2: 0.1277  loss_box_reg_stage2: 0.06186  loss_mask: 0.6799  loss_rpn_cls: 0.2057  loss_rpn_loc: 0.04566  time: 1.4162  data_time: 0.0228  lr: 2.9904e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:17:46 d2.utils.events]: \u001b[0m eta: 3:51:52  iter: 319  total_loss: 1.754  loss_cls_stage0: 0.2191  loss_box_reg_stage0: 0.08936  loss_cls_stage1: 0.1811  loss_box_reg_stage1: 0.09126  loss_cls_stage2: 0.1333  loss_box_reg_stage2: 0.06087  loss_mask: 0.6829  loss_rpn_cls: 0.1931  loss_rpn_loc: 0.04877  time: 1.4207  data_time: 0.0248  lr: 3.1888e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:18:16 d2.utils.events]: \u001b[0m eta: 3:53:20  iter: 339  total_loss: 1.747  loss_cls_stage0: 0.247  loss_box_reg_stage0: 0.1292  loss_cls_stage1: 0.1754  loss_box_reg_stage1: 0.1081  loss_cls_stage2: 0.1236  loss_box_reg_stage2: 0.05764  loss_mask: 0.6769  loss_rpn_cls: 0.1883  loss_rpn_loc: 0.04484  time: 1.4254  data_time: 0.0240  lr: 3.387e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:18:46 d2.utils.events]: \u001b[0m eta: 3:54:49  iter: 359  total_loss: 1.79  loss_cls_stage0: 0.2521  loss_box_reg_stage0: 0.1203  loss_cls_stage1: 0.1918  loss_box_reg_stage1: 0.1052  loss_cls_stage2: 0.1417  loss_box_reg_stage2: 0.06481  loss_mask: 0.6747  loss_rpn_cls: 0.1848  loss_rpn_loc: 0.04996  time: 1.4294  data_time: 0.0232  lr: 3.585e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:19:16 d2.utils.events]: \u001b[0m eta: 3:55:09  iter: 379  total_loss: 1.728  loss_cls_stage0: 0.2575  loss_box_reg_stage0: 0.1167  loss_cls_stage1: 0.1835  loss_box_reg_stage1: 0.1018  loss_cls_stage2: 0.1368  loss_box_reg_stage2: 0.06403  loss_mask: 0.6707  loss_rpn_cls: 0.1842  loss_rpn_loc: 0.05339  time: 1.4334  data_time: 0.0240  lr: 3.7828e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:19:46 d2.utils.events]: \u001b[0m eta: 3:55:16  iter: 399  total_loss: 1.674  loss_cls_stage0: 0.2401  loss_box_reg_stage0: 0.09742  loss_cls_stage1: 0.177  loss_box_reg_stage1: 0.08736  loss_cls_stage2: 0.127  loss_box_reg_stage2: 0.0551  loss_mask: 0.6807  loss_rpn_cls: 0.1735  loss_rpn_loc: 0.04374  time: 1.4365  data_time: 0.0230  lr: 3.9803e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:20:16 d2.utils.events]: \u001b[0m eta: 3:55:13  iter: 419  total_loss: 1.737  loss_cls_stage0: 0.2576  loss_box_reg_stage0: 0.1187  loss_cls_stage1: 0.1865  loss_box_reg_stage1: 0.1064  loss_cls_stage2: 0.1228  loss_box_reg_stage2: 0.05762  loss_mask: 0.6672  loss_rpn_cls: 0.1585  loss_rpn_loc: 0.04085  time: 1.4396  data_time: 0.0228  lr: 4.1777e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:20:46 d2.utils.events]: \u001b[0m eta: 3:54:50  iter: 439  total_loss: 1.81  loss_cls_stage0: 0.2604  loss_box_reg_stage0: 0.1109  loss_cls_stage1: 0.1944  loss_box_reg_stage1: 0.09774  loss_cls_stage2: 0.1365  loss_box_reg_stage2: 0.06625  loss_mask: 0.6697  loss_rpn_cls: 0.1778  loss_rpn_loc: 0.05072  time: 1.4425  data_time: 0.0229  lr: 4.3747e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:21:16 d2.utils.events]: \u001b[0m eta: 3:54:47  iter: 459  total_loss: 1.697  loss_cls_stage0: 0.2532  loss_box_reg_stage0: 0.1221  loss_cls_stage1: 0.1661  loss_box_reg_stage1: 0.09245  loss_cls_stage2: 0.1177  loss_box_reg_stage2: 0.05808  loss_mask: 0.659  loss_rpn_cls: 0.1594  loss_rpn_loc: 0.04225  time: 1.4452  data_time: 0.0252  lr: 4.5716e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:21:46 d2.utils.events]: \u001b[0m eta: 3:54:32  iter: 479  total_loss: 1.695  loss_cls_stage0: 0.2824  loss_box_reg_stage0: 0.1442  loss_cls_stage1: 0.1804  loss_box_reg_stage1: 0.1158  loss_cls_stage2: 0.1181  loss_box_reg_stage2: 0.06547  loss_mask: 0.6628  loss_rpn_cls: 0.1426  loss_rpn_loc: 0.03928  time: 1.4478  data_time: 0.0235  lr: 4.7681e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:22:16 d2.utils.events]: \u001b[0m eta: 3:54:18  iter: 499  total_loss: 1.848  loss_cls_stage0: 0.3154  loss_box_reg_stage0: 0.1536  loss_cls_stage1: 0.2037  loss_box_reg_stage1: 0.1293  loss_cls_stage2: 0.1331  loss_box_reg_stage2: 0.07165  loss_mask: 0.6716  loss_rpn_cls: 0.1602  loss_rpn_loc: 0.0446  time: 1.4502  data_time: 0.0228  lr: 4.9644e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:22:47 d2.utils.events]: \u001b[0m eta: 3:53:55  iter: 519  total_loss: 1.738  loss_cls_stage0: 0.2856  loss_box_reg_stage0: 0.1382  loss_cls_stage1: 0.1878  loss_box_reg_stage1: 0.1054  loss_cls_stage2: 0.1321  loss_box_reg_stage2: 0.06536  loss_mask: 0.6484  loss_rpn_cls: 0.1581  loss_rpn_loc: 0.03972  time: 1.4526  data_time: 0.0230  lr: 5.1604e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:23:17 d2.utils.events]: \u001b[0m eta: 3:53:39  iter: 539  total_loss: 1.825  loss_cls_stage0: 0.294  loss_box_reg_stage0: 0.1427  loss_cls_stage1: 0.197  loss_box_reg_stage1: 0.1157  loss_cls_stage2: 0.1262  loss_box_reg_stage2: 0.07062  loss_mask: 0.6666  loss_rpn_cls: 0.1428  loss_rpn_loc: 0.03654  time: 1.4545  data_time: 0.0229  lr: 5.356e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:23:47 d2.utils.events]: \u001b[0m eta: 3:53:17  iter: 559  total_loss: 1.961  loss_cls_stage0: 0.3256  loss_box_reg_stage0: 0.1623  loss_cls_stage1: 0.2285  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.1345  loss_box_reg_stage2: 0.07884  loss_mask: 0.6527  loss_rpn_cls: 0.1367  loss_rpn_loc: 0.0411  time: 1.4564  data_time: 0.0224  lr: 5.5514e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:24:17 d2.utils.events]: \u001b[0m eta: 3:52:58  iter: 579  total_loss: 1.883  loss_cls_stage0: 0.3235  loss_box_reg_stage0: 0.1507  loss_cls_stage1: 0.2134  loss_box_reg_stage1: 0.1238  loss_cls_stage2: 0.1345  loss_box_reg_stage2: 0.0741  loss_mask: 0.6713  loss_rpn_cls: 0.1526  loss_rpn_loc: 0.04352  time: 1.4584  data_time: 0.0237  lr: 5.7464e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:24:47 d2.utils.events]: \u001b[0m eta: 3:52:35  iter: 599  total_loss: 1.881  loss_cls_stage0: 0.3091  loss_box_reg_stage0: 0.1588  loss_cls_stage1: 0.2126  loss_box_reg_stage1: 0.1387  loss_cls_stage2: 0.1401  loss_box_reg_stage2: 0.0844  loss_mask: 0.6488  loss_rpn_cls: 0.1379  loss_rpn_loc: 0.04201  time: 1.4600  data_time: 0.0227  lr: 5.9411e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:25:17 d2.utils.events]: \u001b[0m eta: 3:52:08  iter: 619  total_loss: 1.877  loss_cls_stage0: 0.3084  loss_box_reg_stage0: 0.1541  loss_cls_stage1: 0.1889  loss_box_reg_stage1: 0.1218  loss_cls_stage2: 0.1266  loss_box_reg_stage2: 0.06973  loss_mask: 0.6441  loss_rpn_cls: 0.1357  loss_rpn_loc: 0.0415  time: 1.4613  data_time: 0.0232  lr: 6.1354e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:25:47 d2.utils.events]: \u001b[0m eta: 3:51:42  iter: 639  total_loss: 1.878  loss_cls_stage0: 0.3026  loss_box_reg_stage0: 0.1466  loss_cls_stage1: 0.2032  loss_box_reg_stage1: 0.1229  loss_cls_stage2: 0.1269  loss_box_reg_stage2: 0.07495  loss_mask: 0.6526  loss_rpn_cls: 0.1491  loss_rpn_loc: 0.04263  time: 1.4626  data_time: 0.0306  lr: 6.3294e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:26:17 d2.utils.events]: \u001b[0m eta: 3:51:19  iter: 659  total_loss: 1.852  loss_cls_stage0: 0.311  loss_box_reg_stage0: 0.1479  loss_cls_stage1: 0.2055  loss_box_reg_stage1: 0.1266  loss_cls_stage2: 0.1383  loss_box_reg_stage2: 0.07819  loss_mask: 0.6397  loss_rpn_cls: 0.1487  loss_rpn_loc: 0.04634  time: 1.4638  data_time: 0.0251  lr: 6.523e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:26:48 d2.utils.events]: \u001b[0m eta: 3:50:56  iter: 679  total_loss: 1.8  loss_cls_stage0: 0.3082  loss_box_reg_stage0: 0.1509  loss_cls_stage1: 0.2136  loss_box_reg_stage1: 0.1328  loss_cls_stage2: 0.1316  loss_box_reg_stage2: 0.07475  loss_mask: 0.6507  loss_rpn_cls: 0.1395  loss_rpn_loc: 0.04217  time: 1.4650  data_time: 0.0247  lr: 6.7162e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:27:18 d2.utils.events]: \u001b[0m eta: 3:50:27  iter: 699  total_loss: 1.975  loss_cls_stage0: 0.3478  loss_box_reg_stage0: 0.1655  loss_cls_stage1: 0.2226  loss_box_reg_stage1: 0.1252  loss_cls_stage2: 0.1527  loss_box_reg_stage2: 0.08454  loss_mask: 0.6685  loss_rpn_cls: 0.147  loss_rpn_loc: 0.04179  time: 1.4660  data_time: 0.0235  lr: 6.909e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:27:47 d2.utils.events]: \u001b[0m eta: 3:49:59  iter: 719  total_loss: 1.827  loss_cls_stage0: 0.2958  loss_box_reg_stage0: 0.1462  loss_cls_stage1: 0.1976  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.1265  loss_box_reg_stage2: 0.06433  loss_mask: 0.6479  loss_rpn_cls: 0.147  loss_rpn_loc: 0.0416  time: 1.4668  data_time: 0.0241  lr: 7.1015e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:28:17 d2.utils.events]: \u001b[0m eta: 3:49:35  iter: 739  total_loss: 1.882  loss_cls_stage0: 0.3174  loss_box_reg_stage0: 0.1623  loss_cls_stage1: 0.2088  loss_box_reg_stage1: 0.1309  loss_cls_stage2: 0.1355  loss_box_reg_stage2: 0.07775  loss_mask: 0.6678  loss_rpn_cls: 0.1374  loss_rpn_loc: 0.04222  time: 1.4676  data_time: 0.0304  lr: 7.2934e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:28:47 d2.utils.events]: \u001b[0m eta: 3:49:12  iter: 759  total_loss: 1.827  loss_cls_stage0: 0.308  loss_box_reg_stage0: 0.1533  loss_cls_stage1: 0.2125  loss_box_reg_stage1: 0.1313  loss_cls_stage2: 0.1349  loss_box_reg_stage2: 0.07962  loss_mask: 0.6751  loss_rpn_cls: 0.142  loss_rpn_loc: 0.04062  time: 1.4684  data_time: 0.0232  lr: 7.485e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:29:17 d2.utils.events]: \u001b[0m eta: 3:48:43  iter: 779  total_loss: 1.845  loss_cls_stage0: 0.2997  loss_box_reg_stage0: 0.1446  loss_cls_stage1: 0.2015  loss_box_reg_stage1: 0.1254  loss_cls_stage2: 0.1267  loss_box_reg_stage2: 0.06932  loss_mask: 0.652  loss_rpn_cls: 0.1206  loss_rpn_loc: 0.03491  time: 1.4692  data_time: 0.0243  lr: 7.6761e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:29:47 d2.utils.events]: \u001b[0m eta: 3:48:18  iter: 799  total_loss: 1.93  loss_cls_stage0: 0.3212  loss_box_reg_stage0: 0.1616  loss_cls_stage1: 0.2223  loss_box_reg_stage1: 0.1426  loss_cls_stage2: 0.1489  loss_box_reg_stage2: 0.08247  loss_mask: 0.6388  loss_rpn_cls: 0.1341  loss_rpn_loc: 0.04121  time: 1.4699  data_time: 0.0235  lr: 7.8668e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:30:17 d2.utils.events]: \u001b[0m eta: 3:47:52  iter: 819  total_loss: 1.928  loss_cls_stage0: 0.3121  loss_box_reg_stage0: 0.1552  loss_cls_stage1: 0.2294  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.1465  loss_box_reg_stage2: 0.08077  loss_mask: 0.6754  loss_rpn_cls: 0.1323  loss_rpn_loc: 0.04146  time: 1.4706  data_time: 0.0228  lr: 8.057e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:30:47 d2.utils.events]: \u001b[0m eta: 3:47:24  iter: 839  total_loss: 1.959  loss_cls_stage0: 0.3431  loss_box_reg_stage0: 0.18  loss_cls_stage1: 0.2272  loss_box_reg_stage1: 0.1479  loss_cls_stage2: 0.1482  loss_box_reg_stage2: 0.085  loss_mask: 0.639  loss_rpn_cls: 0.1356  loss_rpn_loc: 0.04197  time: 1.4715  data_time: 0.0240  lr: 8.2467e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:31:17 d2.utils.events]: \u001b[0m eta: 3:46:56  iter: 859  total_loss: 1.904  loss_cls_stage0: 0.3178  loss_box_reg_stage0: 0.1664  loss_cls_stage1: 0.2192  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.1492  loss_box_reg_stage2: 0.08259  loss_mask: 0.6486  loss_rpn_cls: 0.1356  loss_rpn_loc: 0.04161  time: 1.4721  data_time: 0.0228  lr: 8.4359e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:31:47 d2.utils.events]: \u001b[0m eta: 3:46:27  iter: 879  total_loss: 1.978  loss_cls_stage0: 0.3333  loss_box_reg_stage0: 0.1673  loss_cls_stage1: 0.2275  loss_box_reg_stage1: 0.1495  loss_cls_stage2: 0.1474  loss_box_reg_stage2: 0.0859  loss_mask: 0.6495  loss_rpn_cls: 0.1416  loss_rpn_loc: 0.044  time: 1.4728  data_time: 0.0248  lr: 8.6247e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:32:18 d2.utils.events]: \u001b[0m eta: 3:46:00  iter: 899  total_loss: 2.05  loss_cls_stage0: 0.3511  loss_box_reg_stage0: 0.1555  loss_cls_stage1: 0.2407  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.1585  loss_box_reg_stage2: 0.09771  loss_mask: 0.6378  loss_rpn_cls: 0.1684  loss_rpn_loc: 0.04982  time: 1.4735  data_time: 0.0232  lr: 8.8129e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:32:47 d2.utils.events]: \u001b[0m eta: 3:45:31  iter: 919  total_loss: 1.936  loss_cls_stage0: 0.3192  loss_box_reg_stage0: 0.1458  loss_cls_stage1: 0.2295  loss_box_reg_stage1: 0.1396  loss_cls_stage2: 0.1433  loss_box_reg_stage2: 0.07905  loss_mask: 0.6499  loss_rpn_cls: 0.1332  loss_rpn_loc: 0.04101  time: 1.4739  data_time: 0.0234  lr: 9.0006e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:33:17 d2.utils.events]: \u001b[0m eta: 3:45:01  iter: 939  total_loss: 1.883  loss_cls_stage0: 0.317  loss_box_reg_stage0: 0.1488  loss_cls_stage1: 0.2191  loss_box_reg_stage1: 0.1421  loss_cls_stage2: 0.1529  loss_box_reg_stage2: 0.09241  loss_mask: 0.6644  loss_rpn_cls: 0.1359  loss_rpn_loc: 0.04039  time: 1.4745  data_time: 0.0238  lr: 9.1878e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:33:47 d2.utils.events]: \u001b[0m eta: 3:44:31  iter: 959  total_loss: 1.838  loss_cls_stage0: 0.2888  loss_box_reg_stage0: 0.1479  loss_cls_stage1: 0.1948  loss_box_reg_stage1: 0.1206  loss_cls_stage2: 0.1274  loss_box_reg_stage2: 0.06627  loss_mask: 0.6566  loss_rpn_cls: 0.1444  loss_rpn_loc: 0.04264  time: 1.4748  data_time: 0.0232  lr: 9.3744e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:34:17 d2.utils.events]: \u001b[0m eta: 3:44:01  iter: 979  total_loss: 1.83  loss_cls_stage0: 0.2978  loss_box_reg_stage0: 0.1389  loss_cls_stage1: 0.2102  loss_box_reg_stage1: 0.1299  loss_cls_stage2: 0.1349  loss_box_reg_stage2: 0.07759  loss_mask: 0.6419  loss_rpn_cls: 0.1281  loss_rpn_loc: 0.04086  time: 1.4751  data_time: 0.0238  lr: 9.5605e-05  max_mem: 11723M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/26 16:34:49 d2.data.common]: \u001b[0mSerializing 859 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/26 16:34:49 d2.data.common]: \u001b[0mSerialized dataset takes 0.90 MiB\n",
      "\u001b[32m[03/26 16:34:49 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'vinbigdata_valid_fold2' to COCO format ...)\n",
      "\u001b[32m[03/26 16:34:49 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
      "\u001b[32m[03/26 16:34:50 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 859, #annotations: 4794\n",
      "\u001b[32m[03/26 16:34:50 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at '/home/yamaguchi-milkcocholate/VinBigData/src/VinBigData-ObjectDetection/detectron2_results/results01/fold-2/inference/vinbigdata_valid_fold2_coco_format.json' ...\n",
      "\u001b[32m[03/26 16:34:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 859 images\n",
      "\u001b[32m[03/26 16:34:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/859. 0.0761 s / img. ETA=0:01:06\n",
      "\u001b[32m[03/26 16:34:56 d2.evaluation.evaluator]: \u001b[0mInference done 75/859. 0.0760 s / img. ETA=0:01:01\n",
      "\u001b[32m[03/26 16:35:01 d2.evaluation.evaluator]: \u001b[0mInference done 139/859. 0.0760 s / img. ETA=0:00:56\n",
      "\u001b[32m[03/26 16:35:06 d2.evaluation.evaluator]: \u001b[0mInference done 203/859. 0.0760 s / img. ETA=0:00:51\n",
      "\u001b[32m[03/26 16:35:11 d2.evaluation.evaluator]: \u001b[0mInference done 266/859. 0.0762 s / img. ETA=0:00:46\n",
      "\u001b[32m[03/26 16:35:17 d2.evaluation.evaluator]: \u001b[0mInference done 330/859. 0.0762 s / img. ETA=0:00:41\n",
      "\u001b[32m[03/26 16:35:22 d2.evaluation.evaluator]: \u001b[0mInference done 394/859. 0.0762 s / img. ETA=0:00:36\n",
      "\u001b[32m[03/26 16:35:27 d2.evaluation.evaluator]: \u001b[0mInference done 458/859. 0.0762 s / img. ETA=0:00:31\n",
      "\u001b[32m[03/26 16:35:32 d2.evaluation.evaluator]: \u001b[0mInference done 522/859. 0.0762 s / img. ETA=0:00:26\n",
      "\u001b[32m[03/26 16:35:37 d2.evaluation.evaluator]: \u001b[0mInference done 586/859. 0.0761 s / img. ETA=0:00:21\n",
      "\u001b[32m[03/26 16:35:42 d2.evaluation.evaluator]: \u001b[0mInference done 650/859. 0.0761 s / img. ETA=0:00:16\n",
      "\u001b[32m[03/26 16:35:47 d2.evaluation.evaluator]: \u001b[0mInference done 714/859. 0.0761 s / img. ETA=0:00:11\n",
      "\u001b[32m[03/26 16:35:52 d2.evaluation.evaluator]: \u001b[0mInference done 778/859. 0.0761 s / img. ETA=0:00:06\n",
      "\u001b[32m[03/26 16:35:57 d2.evaluation.evaluator]: \u001b[0mInference done 841/859. 0.0762 s / img. ETA=0:00:01\n",
      "\u001b[32m[03/26 16:35:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:07.505031 (0.079046 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/26 16:35:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:05 (0.076191 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "\u001b[32m[03/26 16:35:59 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold2 in csv format:\n",
      "\u001b[32m[03/26 16:35:59 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/26 16:35:59 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/26 16:35:59 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n",
      "validation do loss eval 1.9800376978398455\n",
      "\u001b[32m[03/26 16:37:25 d2.utils.events]: \u001b[0m eta: 3:43:31  iter: 999  total_loss: 1.942  loss_cls_stage0: 0.3212  loss_box_reg_stage0: 0.1592  loss_cls_stage1: 0.2177  loss_box_reg_stage1: 0.1454  loss_cls_stage2: 0.1475  loss_box_reg_stage2: 0.0764  loss_mask: 0.6594  loss_rpn_cls: 0.1281  loss_rpn_loc: 0.04231  validation_loss: 1.98  time: 1.4757  data_time: 0.0232  lr: 9.746e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:37:55 d2.utils.events]: \u001b[0m eta: 3:43:06  iter: 1019  total_loss: 1.818  loss_cls_stage0: 0.3108  loss_box_reg_stage0: 0.1607  loss_cls_stage1: 0.2068  loss_box_reg_stage1: 0.1425  loss_cls_stage2: 0.1457  loss_box_reg_stage2: 0.08365  loss_mask: 0.6481  loss_rpn_cls: 0.1194  loss_rpn_loc: 0.03939  validation_loss: 1.98  time: 1.4756  data_time: 0.0240  lr: 9.746e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:38:25 d2.utils.events]: \u001b[0m eta: 3:42:42  iter: 1039  total_loss: 1.95  loss_cls_stage0: 0.3229  loss_box_reg_stage0: 0.1552  loss_cls_stage1: 0.2382  loss_box_reg_stage1: 0.1565  loss_cls_stage2: 0.1593  loss_box_reg_stage2: 0.09792  loss_mask: 0.6491  loss_rpn_cls: 0.1384  loss_rpn_loc: 0.04404  validation_loss: 1.98  time: 1.4759  data_time: 0.0301  lr: 9.736e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:38:54 d2.utils.events]: \u001b[0m eta: 3:42:18  iter: 1059  total_loss: 1.795  loss_cls_stage0: 0.2927  loss_box_reg_stage0: 0.1484  loss_cls_stage1: 0.2146  loss_box_reg_stage1: 0.1394  loss_cls_stage2: 0.1436  loss_box_reg_stage2: 0.08854  loss_mask: 0.6344  loss_rpn_cls: 0.1164  loss_rpn_loc: 0.03785  validation_loss: 1.98  time: 1.4763  data_time: 0.0226  lr: 9.7258e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:39:24 d2.utils.events]: \u001b[0m eta: 3:41:53  iter: 1079  total_loss: 1.895  loss_cls_stage0: 0.2982  loss_box_reg_stage0: 0.1529  loss_cls_stage1: 0.2201  loss_box_reg_stage1: 0.1445  loss_cls_stage2: 0.1472  loss_box_reg_stage2: 0.09015  loss_mask: 0.6666  loss_rpn_cls: 0.1272  loss_rpn_loc: 0.04083  validation_loss: 1.98  time: 1.4767  data_time: 0.0238  lr: 9.7155e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:39:55 d2.utils.events]: \u001b[0m eta: 3:41:29  iter: 1099  total_loss: 1.938  loss_cls_stage0: 0.319  loss_box_reg_stage0: 0.1556  loss_cls_stage1: 0.2245  loss_box_reg_stage1: 0.1524  loss_cls_stage2: 0.1535  loss_box_reg_stage2: 0.1007  loss_mask: 0.6686  loss_rpn_cls: 0.1152  loss_rpn_loc: 0.03813  validation_loss: 1.98  time: 1.4772  data_time: 0.0237  lr: 9.7049e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:40:24 d2.utils.events]: \u001b[0m eta: 3:41:03  iter: 1119  total_loss: 1.847  loss_cls_stage0: 0.2833  loss_box_reg_stage0: 0.1514  loss_cls_stage1: 0.2068  loss_box_reg_stage1: 0.1465  loss_cls_stage2: 0.1447  loss_box_reg_stage2: 0.08642  loss_mask: 0.6586  loss_rpn_cls: 0.1077  loss_rpn_loc: 0.03371  validation_loss: 1.98  time: 1.4775  data_time: 0.0244  lr: 9.6942e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:40:55 d2.utils.events]: \u001b[0m eta: 3:40:43  iter: 1139  total_loss: 1.921  loss_cls_stage0: 0.3195  loss_box_reg_stage0: 0.1475  loss_cls_stage1: 0.2328  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.1546  loss_box_reg_stage2: 0.09775  loss_mask: 0.6079  loss_rpn_cls: 0.1293  loss_rpn_loc: 0.04205  validation_loss: 1.98  time: 1.4780  data_time: 0.0244  lr: 9.6833e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:41:25 d2.utils.events]: \u001b[0m eta: 3:40:17  iter: 1159  total_loss: 1.845  loss_cls_stage0: 0.3055  loss_box_reg_stage0: 0.155  loss_cls_stage1: 0.2244  loss_box_reg_stage1: 0.1563  loss_cls_stage2: 0.1452  loss_box_reg_stage2: 0.09757  loss_mask: 0.6339  loss_rpn_cls: 0.1245  loss_rpn_loc: 0.03481  validation_loss: 1.98  time: 1.4784  data_time: 0.0254  lr: 9.6722e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:41:55 d2.utils.events]: \u001b[0m eta: 3:39:53  iter: 1179  total_loss: 1.89  loss_cls_stage0: 0.3131  loss_box_reg_stage0: 0.1502  loss_cls_stage1: 0.2379  loss_box_reg_stage1: 0.1565  loss_cls_stage2: 0.1546  loss_box_reg_stage2: 0.09377  loss_mask: 0.6259  loss_rpn_cls: 0.1289  loss_rpn_loc: 0.03858  validation_loss: 1.98  time: 1.4788  data_time: 0.0264  lr: 9.6609e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:42:25 d2.utils.events]: \u001b[0m eta: 3:39:27  iter: 1199  total_loss: 1.887  loss_cls_stage0: 0.3131  loss_box_reg_stage0: 0.1629  loss_cls_stage1: 0.2358  loss_box_reg_stage1: 0.1614  loss_cls_stage2: 0.1555  loss_box_reg_stage2: 0.0971  loss_mask: 0.6425  loss_rpn_cls: 0.1203  loss_rpn_loc: 0.03857  validation_loss: 1.98  time: 1.4791  data_time: 0.0239  lr: 9.6495e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:42:55 d2.utils.events]: \u001b[0m eta: 3:38:58  iter: 1219  total_loss: 1.855  loss_cls_stage0: 0.2951  loss_box_reg_stage0: 0.146  loss_cls_stage1: 0.2119  loss_box_reg_stage1: 0.1467  loss_cls_stage2: 0.1393  loss_box_reg_stage2: 0.08404  loss_mask: 0.6103  loss_rpn_cls: 0.1156  loss_rpn_loc: 0.03855  validation_loss: 1.98  time: 1.4795  data_time: 0.0246  lr: 9.6378e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:43:25 d2.utils.events]: \u001b[0m eta: 3:38:31  iter: 1239  total_loss: 1.996  loss_cls_stage0: 0.3007  loss_box_reg_stage0: 0.1536  loss_cls_stage1: 0.2325  loss_box_reg_stage1: 0.1533  loss_cls_stage2: 0.158  loss_box_reg_stage2: 0.09495  loss_mask: 0.663  loss_rpn_cls: 0.1167  loss_rpn_loc: 0.03844  validation_loss: 1.98  time: 1.4797  data_time: 0.0243  lr: 9.626e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:43:55 d2.utils.events]: \u001b[0m eta: 3:38:03  iter: 1259  total_loss: 1.894  loss_cls_stage0: 0.3247  loss_box_reg_stage0: 0.1643  loss_cls_stage1: 0.2243  loss_box_reg_stage1: 0.16  loss_cls_stage2: 0.1494  loss_box_reg_stage2: 0.09556  loss_mask: 0.6318  loss_rpn_cls: 0.1226  loss_rpn_loc: 0.03696  validation_loss: 1.98  time: 1.4801  data_time: 0.0251  lr: 9.614e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:44:25 d2.utils.events]: \u001b[0m eta: 3:37:36  iter: 1279  total_loss: 2.1  loss_cls_stage0: 0.342  loss_box_reg_stage0: 0.1754  loss_cls_stage1: 0.257  loss_box_reg_stage1: 0.1826  loss_cls_stage2: 0.1704  loss_box_reg_stage2: 0.1204  loss_mask: 0.6384  loss_rpn_cls: 0.1289  loss_rpn_loc: 0.04251  validation_loss: 1.98  time: 1.4804  data_time: 0.0240  lr: 9.6018e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:44:55 d2.utils.events]: \u001b[0m eta: 3:37:07  iter: 1299  total_loss: 1.898  loss_cls_stage0: 0.3009  loss_box_reg_stage0: 0.1598  loss_cls_stage1: 0.2279  loss_box_reg_stage1: 0.1655  loss_cls_stage2: 0.1476  loss_box_reg_stage2: 0.09377  loss_mask: 0.6308  loss_rpn_cls: 0.1184  loss_rpn_loc: 0.03625  validation_loss: 1.98  time: 1.4806  data_time: 0.0232  lr: 9.5894e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:45:25 d2.utils.events]: \u001b[0m eta: 3:36:39  iter: 1319  total_loss: 1.911  loss_cls_stage0: 0.3001  loss_box_reg_stage0: 0.1521  loss_cls_stage1: 0.2335  loss_box_reg_stage1: 0.1683  loss_cls_stage2: 0.1575  loss_box_reg_stage2: 0.09489  loss_mask: 0.6587  loss_rpn_cls: 0.1193  loss_rpn_loc: 0.03742  validation_loss: 1.98  time: 1.4809  data_time: 0.0231  lr: 9.5768e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:45:55 d2.utils.events]: \u001b[0m eta: 3:36:09  iter: 1339  total_loss: 1.915  loss_cls_stage0: 0.3121  loss_box_reg_stage0: 0.1602  loss_cls_stage1: 0.2402  loss_box_reg_stage1: 0.1673  loss_cls_stage2: 0.1462  loss_box_reg_stage2: 0.1051  loss_mask: 0.643  loss_rpn_cls: 0.1044  loss_rpn_loc: 0.03726  validation_loss: 1.98  time: 1.4812  data_time: 0.0241  lr: 9.5641e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:46:25 d2.utils.events]: \u001b[0m eta: 3:35:40  iter: 1359  total_loss: 2.015  loss_cls_stage0: 0.3262  loss_box_reg_stage0: 0.1776  loss_cls_stage1: 0.2461  loss_box_reg_stage1: 0.19  loss_cls_stage2: 0.159  loss_box_reg_stage2: 0.1042  loss_mask: 0.6261  loss_rpn_cls: 0.1216  loss_rpn_loc: 0.04033  validation_loss: 1.98  time: 1.4815  data_time: 0.0232  lr: 9.5512e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:46:55 d2.utils.events]: \u001b[0m eta: 3:35:10  iter: 1379  total_loss: 1.892  loss_cls_stage0: 0.312  loss_box_reg_stage0: 0.1514  loss_cls_stage1: 0.2348  loss_box_reg_stage1: 0.1537  loss_cls_stage2: 0.1586  loss_box_reg_stage2: 0.1083  loss_mask: 0.6121  loss_rpn_cls: 0.1121  loss_rpn_loc: 0.03955  validation_loss: 1.98  time: 1.4818  data_time: 0.0252  lr: 9.5381e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:47:25 d2.utils.events]: \u001b[0m eta: 3:34:41  iter: 1399  total_loss: 1.883  loss_cls_stage0: 0.3173  loss_box_reg_stage0: 0.1635  loss_cls_stage1: 0.2343  loss_box_reg_stage1: 0.1587  loss_cls_stage2: 0.1598  loss_box_reg_stage2: 0.1084  loss_mask: 0.5995  loss_rpn_cls: 0.1222  loss_rpn_loc: 0.03981  validation_loss: 1.98  time: 1.4820  data_time: 0.0231  lr: 9.5248e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:47:55 d2.utils.events]: \u001b[0m eta: 3:34:11  iter: 1419  total_loss: 1.925  loss_cls_stage0: 0.3055  loss_box_reg_stage0: 0.1556  loss_cls_stage1: 0.2271  loss_box_reg_stage1: 0.1573  loss_cls_stage2: 0.1525  loss_box_reg_stage2: 0.1044  loss_mask: 0.6303  loss_rpn_cls: 0.1019  loss_rpn_loc: 0.03427  validation_loss: 1.98  time: 1.4822  data_time: 0.0232  lr: 9.5113e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:48:25 d2.utils.events]: \u001b[0m eta: 3:33:41  iter: 1439  total_loss: 1.839  loss_cls_stage0: 0.2967  loss_box_reg_stage0: 0.1569  loss_cls_stage1: 0.2232  loss_box_reg_stage1: 0.16  loss_cls_stage2: 0.1554  loss_box_reg_stage2: 0.09891  loss_mask: 0.5871  loss_rpn_cls: 0.114  loss_rpn_loc: 0.03807  validation_loss: 1.98  time: 1.4825  data_time: 0.0229  lr: 9.4977e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:48:55 d2.utils.events]: \u001b[0m eta: 3:33:12  iter: 1459  total_loss: 1.971  loss_cls_stage0: 0.3186  loss_box_reg_stage0: 0.1684  loss_cls_stage1: 0.2408  loss_box_reg_stage1: 0.1733  loss_cls_stage2: 0.1525  loss_box_reg_stage2: 0.1053  loss_mask: 0.637  loss_rpn_cls: 0.1229  loss_rpn_loc: 0.04336  validation_loss: 1.98  time: 1.4827  data_time: 0.0251  lr: 9.4839e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:49:25 d2.utils.events]: \u001b[0m eta: 3:32:41  iter: 1479  total_loss: 1.854  loss_cls_stage0: 0.299  loss_box_reg_stage0: 0.1549  loss_cls_stage1: 0.2272  loss_box_reg_stage1: 0.1576  loss_cls_stage2: 0.1608  loss_box_reg_stage2: 0.09941  loss_mask: 0.5793  loss_rpn_cls: 0.1121  loss_rpn_loc: 0.0391  validation_loss: 1.98  time: 1.4831  data_time: 0.0233  lr: 9.4699e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:49:55 d2.utils.events]: \u001b[0m eta: 3:32:07  iter: 1499  total_loss: 1.814  loss_cls_stage0: 0.2856  loss_box_reg_stage0: 0.1453  loss_cls_stage1: 0.214  loss_box_reg_stage1: 0.1578  loss_cls_stage2: 0.15  loss_box_reg_stage2: 0.1014  loss_mask: 0.6227  loss_rpn_cls: 0.1032  loss_rpn_loc: 0.03502  validation_loss: 1.98  time: 1.4832  data_time: 0.0230  lr: 9.4557e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:50:25 d2.utils.events]: \u001b[0m eta: 3:31:37  iter: 1519  total_loss: 2.001  loss_cls_stage0: 0.3239  loss_box_reg_stage0: 0.1703  loss_cls_stage1: 0.2431  loss_box_reg_stage1: 0.1785  loss_cls_stage2: 0.1716  loss_box_reg_stage2: 0.1146  loss_mask: 0.6259  loss_rpn_cls: 0.1181  loss_rpn_loc: 0.03899  validation_loss: 1.98  time: 1.4835  data_time: 0.0238  lr: 9.4414e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:50:55 d2.utils.events]: \u001b[0m eta: 3:31:06  iter: 1539  total_loss: 1.939  loss_cls_stage0: 0.3006  loss_box_reg_stage0: 0.156  loss_cls_stage1: 0.2369  loss_box_reg_stage1: 0.1722  loss_cls_stage2: 0.1579  loss_box_reg_stage2: 0.1101  loss_mask: 0.5794  loss_rpn_cls: 0.1096  loss_rpn_loc: 0.03558  validation_loss: 1.98  time: 1.4838  data_time: 0.0241  lr: 9.4269e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:51:25 d2.utils.events]: \u001b[0m eta: 3:30:35  iter: 1559  total_loss: 1.886  loss_cls_stage0: 0.2857  loss_box_reg_stage0: 0.1551  loss_cls_stage1: 0.2162  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.1534  loss_box_reg_stage2: 0.1043  loss_mask: 0.6395  loss_rpn_cls: 0.1065  loss_rpn_loc: 0.03771  validation_loss: 1.98  time: 1.4840  data_time: 0.0224  lr: 9.4122e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:51:55 d2.utils.events]: \u001b[0m eta: 3:30:04  iter: 1579  total_loss: 2.042  loss_cls_stage0: 0.3337  loss_box_reg_stage0: 0.1601  loss_cls_stage1: 0.2567  loss_box_reg_stage1: 0.1813  loss_cls_stage2: 0.1659  loss_box_reg_stage2: 0.1142  loss_mask: 0.6525  loss_rpn_cls: 0.118  loss_rpn_loc: 0.04298  validation_loss: 1.98  time: 1.4842  data_time: 0.0241  lr: 9.3973e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:52:25 d2.utils.events]: \u001b[0m eta: 3:29:33  iter: 1599  total_loss: 1.926  loss_cls_stage0: 0.3193  loss_box_reg_stage0: 0.1754  loss_cls_stage1: 0.2321  loss_box_reg_stage1: 0.1733  loss_cls_stage2: 0.1629  loss_box_reg_stage2: 0.1139  loss_mask: 0.6171  loss_rpn_cls: 0.1173  loss_rpn_loc: 0.04298  validation_loss: 1.98  time: 1.4845  data_time: 0.0233  lr: 9.3823e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:52:55 d2.utils.events]: \u001b[0m eta: 3:29:03  iter: 1619  total_loss: 1.979  loss_cls_stage0: 0.3098  loss_box_reg_stage0: 0.1612  loss_cls_stage1: 0.2394  loss_box_reg_stage1: 0.1715  loss_cls_stage2: 0.1663  loss_box_reg_stage2: 0.1139  loss_mask: 0.6146  loss_rpn_cls: 0.1117  loss_rpn_loc: 0.03978  validation_loss: 1.98  time: 1.4847  data_time: 0.0234  lr: 9.3671e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:53:25 d2.utils.events]: \u001b[0m eta: 3:28:33  iter: 1639  total_loss: 1.928  loss_cls_stage0: 0.3081  loss_box_reg_stage0: 0.1685  loss_cls_stage1: 0.2348  loss_box_reg_stage1: 0.1752  loss_cls_stage2: 0.1576  loss_box_reg_stage2: 0.1061  loss_mask: 0.6192  loss_rpn_cls: 0.1183  loss_rpn_loc: 0.04333  validation_loss: 1.98  time: 1.4850  data_time: 0.0245  lr: 9.3517e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:53:55 d2.utils.events]: \u001b[0m eta: 3:28:03  iter: 1659  total_loss: 1.817  loss_cls_stage0: 0.2905  loss_box_reg_stage0: 0.1515  loss_cls_stage1: 0.2241  loss_box_reg_stage1: 0.1649  loss_cls_stage2: 0.1556  loss_box_reg_stage2: 0.1066  loss_mask: 0.5815  loss_rpn_cls: 0.09864  loss_rpn_loc: 0.03385  validation_loss: 1.98  time: 1.4851  data_time: 0.0232  lr: 9.3361e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:54:25 d2.utils.events]: \u001b[0m eta: 3:27:33  iter: 1679  total_loss: 1.869  loss_cls_stage0: 0.2864  loss_box_reg_stage0: 0.1482  loss_cls_stage1: 0.2244  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.1564  loss_box_reg_stage2: 0.1111  loss_mask: 0.5683  loss_rpn_cls: 0.1148  loss_rpn_loc: 0.03988  validation_loss: 1.98  time: 1.4852  data_time: 0.0242  lr: 9.3204e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:54:56 d2.utils.events]: \u001b[0m eta: 3:27:03  iter: 1699  total_loss: 2.023  loss_cls_stage0: 0.3376  loss_box_reg_stage0: 0.1768  loss_cls_stage1: 0.2615  loss_box_reg_stage1: 0.1907  loss_cls_stage2: 0.1709  loss_box_reg_stage2: 0.1181  loss_mask: 0.5972  loss_rpn_cls: 0.1147  loss_rpn_loc: 0.04343  validation_loss: 1.98  time: 1.4856  data_time: 0.0223  lr: 9.3045e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:55:26 d2.utils.events]: \u001b[0m eta: 3:26:36  iter: 1719  total_loss: 1.959  loss_cls_stage0: 0.3241  loss_box_reg_stage0: 0.1663  loss_cls_stage1: 0.2412  loss_box_reg_stage1: 0.1822  loss_cls_stage2: 0.1711  loss_box_reg_stage2: 0.1146  loss_mask: 0.5966  loss_rpn_cls: 0.1102  loss_rpn_loc: 0.03999  validation_loss: 1.98  time: 1.4858  data_time: 0.0222  lr: 9.2884e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:55:56 d2.utils.events]: \u001b[0m eta: 3:26:04  iter: 1739  total_loss: 1.75  loss_cls_stage0: 0.2595  loss_box_reg_stage0: 0.1323  loss_cls_stage1: 0.2055  loss_box_reg_stage1: 0.1584  loss_cls_stage2: 0.1418  loss_box_reg_stage2: 0.09689  loss_mask: 0.6281  loss_rpn_cls: 0.1238  loss_rpn_loc: 0.04156  validation_loss: 1.98  time: 1.4860  data_time: 0.0239  lr: 9.2722e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:56:26 d2.utils.events]: \u001b[0m eta: 3:25:35  iter: 1759  total_loss: 1.938  loss_cls_stage0: 0.3128  loss_box_reg_stage0: 0.169  loss_cls_stage1: 0.2435  loss_box_reg_stage1: 0.1843  loss_cls_stage2: 0.1777  loss_box_reg_stage2: 0.1269  loss_mask: 0.5824  loss_rpn_cls: 0.109  loss_rpn_loc: 0.03833  validation_loss: 1.98  time: 1.4862  data_time: 0.0240  lr: 9.2558e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:56:56 d2.utils.events]: \u001b[0m eta: 3:25:05  iter: 1779  total_loss: 1.917  loss_cls_stage0: 0.2869  loss_box_reg_stage0: 0.1576  loss_cls_stage1: 0.2348  loss_box_reg_stage1: 0.1788  loss_cls_stage2: 0.1601  loss_box_reg_stage2: 0.1094  loss_mask: 0.5999  loss_rpn_cls: 0.1067  loss_rpn_loc: 0.0353  validation_loss: 1.98  time: 1.4865  data_time: 0.0241  lr: 9.2392e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:57:26 d2.utils.events]: \u001b[0m eta: 3:24:34  iter: 1799  total_loss: 1.83  loss_cls_stage0: 0.2821  loss_box_reg_stage0: 0.1476  loss_cls_stage1: 0.2116  loss_box_reg_stage1: 0.1598  loss_cls_stage2: 0.1441  loss_box_reg_stage2: 0.1042  loss_mask: 0.5729  loss_rpn_cls: 0.1111  loss_rpn_loc: 0.0406  validation_loss: 1.98  time: 1.4866  data_time: 0.0241  lr: 9.2225e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:57:56 d2.utils.events]: \u001b[0m eta: 3:24:05  iter: 1819  total_loss: 1.943  loss_cls_stage0: 0.31  loss_box_reg_stage0: 0.1674  loss_cls_stage1: 0.2338  loss_box_reg_stage1: 0.1771  loss_cls_stage2: 0.1636  loss_box_reg_stage2: 0.1131  loss_mask: 0.6357  loss_rpn_cls: 0.1114  loss_rpn_loc: 0.03998  validation_loss: 1.98  time: 1.4868  data_time: 0.0232  lr: 9.2056e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:58:26 d2.utils.events]: \u001b[0m eta: 3:23:34  iter: 1839  total_loss: 1.717  loss_cls_stage0: 0.2705  loss_box_reg_stage0: 0.1417  loss_cls_stage1: 0.2165  loss_box_reg_stage1: 0.1562  loss_cls_stage2: 0.1482  loss_box_reg_stage2: 0.0984  loss_mask: 0.5875  loss_rpn_cls: 0.1046  loss_rpn_loc: 0.03456  validation_loss: 1.98  time: 1.4870  data_time: 0.0248  lr: 9.1885e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:58:56 d2.utils.events]: \u001b[0m eta: 3:23:04  iter: 1859  total_loss: 1.848  loss_cls_stage0: 0.2956  loss_box_reg_stage0: 0.1628  loss_cls_stage1: 0.2341  loss_box_reg_stage1: 0.1696  loss_cls_stage2: 0.1605  loss_box_reg_stage2: 0.1201  loss_mask: 0.6073  loss_rpn_cls: 0.106  loss_rpn_loc: 0.03777  validation_loss: 1.98  time: 1.4871  data_time: 0.0252  lr: 9.1713e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:59:26 d2.utils.events]: \u001b[0m eta: 3:22:36  iter: 1879  total_loss: 2.016  loss_cls_stage0: 0.3176  loss_box_reg_stage0: 0.1718  loss_cls_stage1: 0.2511  loss_box_reg_stage1: 0.1929  loss_cls_stage2: 0.1686  loss_box_reg_stage2: 0.1222  loss_mask: 0.6114  loss_rpn_cls: 0.1019  loss_rpn_loc: 0.03727  validation_loss: 1.98  time: 1.4874  data_time: 0.0239  lr: 9.1539e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 16:59:57 d2.utils.events]: \u001b[0m eta: 3:22:07  iter: 1899  total_loss: 2.013  loss_cls_stage0: 0.3292  loss_box_reg_stage0: 0.181  loss_cls_stage1: 0.2467  loss_box_reg_stage1: 0.1932  loss_cls_stage2: 0.1717  loss_box_reg_stage2: 0.1227  loss_mask: 0.5951  loss_rpn_cls: 0.1151  loss_rpn_loc: 0.0405  validation_loss: 1.98  time: 1.4876  data_time: 0.0246  lr: 9.1363e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:00:27 d2.utils.events]: \u001b[0m eta: 3:21:37  iter: 1919  total_loss: 1.887  loss_cls_stage0: 0.284  loss_box_reg_stage0: 0.151  loss_cls_stage1: 0.2225  loss_box_reg_stage1: 0.1876  loss_cls_stage2: 0.1581  loss_box_reg_stage2: 0.1271  loss_mask: 0.5965  loss_rpn_cls: 0.1102  loss_rpn_loc: 0.03937  validation_loss: 1.98  time: 1.4878  data_time: 0.0247  lr: 9.1186e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:00:57 d2.utils.events]: \u001b[0m eta: 3:21:09  iter: 1939  total_loss: 1.892  loss_cls_stage0: 0.301  loss_box_reg_stage0: 0.1637  loss_cls_stage1: 0.2293  loss_box_reg_stage1: 0.1858  loss_cls_stage2: 0.1574  loss_box_reg_stage2: 0.1206  loss_mask: 0.5939  loss_rpn_cls: 0.1144  loss_rpn_loc: 0.03954  validation_loss: 1.98  time: 1.4880  data_time: 0.0246  lr: 9.1007e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:01:27 d2.utils.events]: \u001b[0m eta: 3:20:42  iter: 1959  total_loss: 1.925  loss_cls_stage0: 0.313  loss_box_reg_stage0: 0.1634  loss_cls_stage1: 0.2405  loss_box_reg_stage1: 0.1707  loss_cls_stage2: 0.1542  loss_box_reg_stage2: 0.1123  loss_mask: 0.5911  loss_rpn_cls: 0.115  loss_rpn_loc: 0.03957  validation_loss: 1.98  time: 1.4882  data_time: 0.0260  lr: 9.0826e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:01:57 d2.utils.events]: \u001b[0m eta: 3:20:17  iter: 1979  total_loss: 1.925  loss_cls_stage0: 0.2783  loss_box_reg_stage0: 0.1454  loss_cls_stage1: 0.2308  loss_box_reg_stage1: 0.1705  loss_cls_stage2: 0.1632  loss_box_reg_stage2: 0.1189  loss_mask: 0.5946  loss_rpn_cls: 0.1082  loss_rpn_loc: 0.03907  validation_loss: 1.98  time: 1.4885  data_time: 0.0265  lr: 9.0644e-05  max_mem: 11723M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/26 17:02:30 d2.data.common]: \u001b[0mSerializing 859 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/26 17:02:30 d2.data.common]: \u001b[0mSerialized dataset takes 0.90 MiB\n",
      "\u001b[32m[03/26 17:02:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 859 images\n",
      "\u001b[32m[03/26 17:02:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/859. 0.0788 s / img. ETA=0:01:14\n",
      "\u001b[32m[03/26 17:02:36 d2.evaluation.evaluator]: \u001b[0mInference done 68/859. 0.0789 s / img. ETA=0:01:09\n",
      "\u001b[32m[03/26 17:02:41 d2.evaluation.evaluator]: \u001b[0mInference done 126/859. 0.0787 s / img. ETA=0:01:03\n",
      "\u001b[32m[03/26 17:02:46 d2.evaluation.evaluator]: \u001b[0mInference done 184/859. 0.0786 s / img. ETA=0:00:58\n",
      "\u001b[32m[03/26 17:02:51 d2.evaluation.evaluator]: \u001b[0mInference done 243/859. 0.0784 s / img. ETA=0:00:53\n",
      "\u001b[32m[03/26 17:02:56 d2.evaluation.evaluator]: \u001b[0mInference done 301/859. 0.0784 s / img. ETA=0:00:48\n",
      "\u001b[32m[03/26 17:03:01 d2.evaluation.evaluator]: \u001b[0mInference done 359/859. 0.0784 s / img. ETA=0:00:43\n",
      "\u001b[32m[03/26 17:03:06 d2.evaluation.evaluator]: \u001b[0mInference done 417/859. 0.0785 s / img. ETA=0:00:38\n",
      "\u001b[32m[03/26 17:03:11 d2.evaluation.evaluator]: \u001b[0mInference done 475/859. 0.0785 s / img. ETA=0:00:33\n",
      "\u001b[32m[03/26 17:03:17 d2.evaluation.evaluator]: \u001b[0mInference done 533/859. 0.0785 s / img. ETA=0:00:28\n",
      "\u001b[32m[03/26 17:03:22 d2.evaluation.evaluator]: \u001b[0mInference done 590/859. 0.0786 s / img. ETA=0:00:23\n",
      "\u001b[32m[03/26 17:03:27 d2.evaluation.evaluator]: \u001b[0mInference done 648/859. 0.0786 s / img. ETA=0:00:18\n",
      "\u001b[32m[03/26 17:03:32 d2.evaluation.evaluator]: \u001b[0mInference done 706/859. 0.0786 s / img. ETA=0:00:13\n",
      "\u001b[32m[03/26 17:03:37 d2.evaluation.evaluator]: \u001b[0mInference done 764/859. 0.0786 s / img. ETA=0:00:08\n",
      "\u001b[32m[03/26 17:03:42 d2.evaluation.evaluator]: \u001b[0mInference done 822/859. 0.0786 s / img. ETA=0:00:03\n",
      "\u001b[32m[03/26 17:03:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:14.412347 (0.087134 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/26 17:03:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:07 (0.078632 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.36 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.029\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.054\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.059\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.019\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.030\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.041\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.045\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.045\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.028\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.046\n",
      "\u001b[32m[03/26 17:03:46 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold2 in csv format:\n",
      "\u001b[32m[03/26 17:03:46 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/26 17:03:46 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/26 17:03:46 d2.evaluation.testing]: \u001b[0mcopypaste: 2.8677,5.4340,5.8649,0.2406,1.9133,2.9608\n",
      "validation do loss eval 1.966152831167064\n",
      "\u001b[32m[03/26 17:05:13 d2.utils.events]: \u001b[0m eta: 3:19:49  iter: 1999  total_loss: 1.948  loss_cls_stage0: 0.2976  loss_box_reg_stage0: 0.1526  loss_cls_stage1: 0.231  loss_box_reg_stage1: 0.18  loss_cls_stage2: 0.1661  loss_box_reg_stage2: 0.128  loss_mask: 0.5971  loss_rpn_cls: 0.1163  loss_rpn_loc: 0.04071  validation_loss: 1.973  time: 1.4887  data_time: 0.0260  lr: 9.046e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:05:43 d2.utils.events]: \u001b[0m eta: 3:19:21  iter: 2019  total_loss: 2.008  loss_cls_stage0: 0.3178  loss_box_reg_stage0: 0.163  loss_cls_stage1: 0.2439  loss_box_reg_stage1: 0.1979  loss_cls_stage2: 0.1716  loss_box_reg_stage2: 0.1273  loss_mask: 0.605  loss_rpn_cls: 0.1175  loss_rpn_loc: 0.04503  validation_loss: 1.973  time: 1.4886  data_time: 0.0252  lr: 9.0275e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:06:13 d2.utils.events]: \u001b[0m eta: 3:18:55  iter: 2039  total_loss: 1.987  loss_cls_stage0: 0.3286  loss_box_reg_stage0: 0.1735  loss_cls_stage1: 0.2481  loss_box_reg_stage1: 0.1938  loss_cls_stage2: 0.1779  loss_box_reg_stage2: 0.1563  loss_mask: 0.6042  loss_rpn_cls: 0.1178  loss_rpn_loc: 0.04133  validation_loss: 1.973  time: 1.4889  data_time: 0.0242  lr: 9.0088e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:06:43 d2.utils.events]: \u001b[0m eta: 3:18:28  iter: 2059  total_loss: 2.025  loss_cls_stage0: 0.3215  loss_box_reg_stage0: 0.1808  loss_cls_stage1: 0.2512  loss_box_reg_stage1: 0.2003  loss_cls_stage2: 0.1885  loss_box_reg_stage2: 0.1402  loss_mask: 0.5569  loss_rpn_cls: 0.1014  loss_rpn_loc: 0.04323  validation_loss: 1.973  time: 1.4891  data_time: 0.0253  lr: 8.9899e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:07:14 d2.utils.events]: \u001b[0m eta: 3:18:01  iter: 2079  total_loss: 1.996  loss_cls_stage0: 0.3096  loss_box_reg_stage0: 0.1616  loss_cls_stage1: 0.251  loss_box_reg_stage1: 0.2004  loss_cls_stage2: 0.1737  loss_box_reg_stage2: 0.1402  loss_mask: 0.5896  loss_rpn_cls: 0.1084  loss_rpn_loc: 0.04343  validation_loss: 1.973  time: 1.4894  data_time: 0.0249  lr: 8.9709e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:07:44 d2.utils.events]: \u001b[0m eta: 3:17:33  iter: 2099  total_loss: 1.893  loss_cls_stage0: 0.2813  loss_box_reg_stage0: 0.153  loss_cls_stage1: 0.2282  loss_box_reg_stage1: 0.1846  loss_cls_stage2: 0.1632  loss_box_reg_stage2: 0.1254  loss_mask: 0.5774  loss_rpn_cls: 0.1005  loss_rpn_loc: 0.03988  validation_loss: 1.973  time: 1.4895  data_time: 0.0254  lr: 8.9517e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:08:14 d2.utils.events]: \u001b[0m eta: 3:17:04  iter: 2119  total_loss: 1.929  loss_cls_stage0: 0.3068  loss_box_reg_stage0: 0.1646  loss_cls_stage1: 0.2359  loss_box_reg_stage1: 0.1934  loss_cls_stage2: 0.1622  loss_box_reg_stage2: 0.1213  loss_mask: 0.6007  loss_rpn_cls: 0.1034  loss_rpn_loc: 0.04142  validation_loss: 1.973  time: 1.4897  data_time: 0.0238  lr: 8.9324e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:08:44 d2.utils.events]: \u001b[0m eta: 3:16:36  iter: 2139  total_loss: 1.918  loss_cls_stage0: 0.2984  loss_box_reg_stage0: 0.1642  loss_cls_stage1: 0.2315  loss_box_reg_stage1: 0.1967  loss_cls_stage2: 0.1617  loss_box_reg_stage2: 0.1317  loss_mask: 0.6229  loss_rpn_cls: 0.102  loss_rpn_loc: 0.03752  validation_loss: 1.973  time: 1.4899  data_time: 0.0245  lr: 8.9129e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:09:14 d2.utils.events]: \u001b[0m eta: 3:16:08  iter: 2159  total_loss: 1.793  loss_cls_stage0: 0.271  loss_box_reg_stage0: 0.161  loss_cls_stage1: 0.2212  loss_box_reg_stage1: 0.1866  loss_cls_stage2: 0.1645  loss_box_reg_stage2: 0.1202  loss_mask: 0.5636  loss_rpn_cls: 0.0933  loss_rpn_loc: 0.03943  validation_loss: 1.973  time: 1.4901  data_time: 0.0248  lr: 8.8933e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:09:45 d2.utils.events]: \u001b[0m eta: 3:15:40  iter: 2179  total_loss: 1.981  loss_cls_stage0: 0.3053  loss_box_reg_stage0: 0.1715  loss_cls_stage1: 0.25  loss_box_reg_stage1: 0.2022  loss_cls_stage2: 0.1768  loss_box_reg_stage2: 0.1409  loss_mask: 0.5996  loss_rpn_cls: 0.1044  loss_rpn_loc: 0.03818  validation_loss: 1.973  time: 1.4903  data_time: 0.0238  lr: 8.8735e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:10:15 d2.utils.events]: \u001b[0m eta: 3:15:10  iter: 2199  total_loss: 1.831  loss_cls_stage0: 0.2703  loss_box_reg_stage0: 0.1472  loss_cls_stage1: 0.2208  loss_box_reg_stage1: 0.1753  loss_cls_stage2: 0.1564  loss_box_reg_stage2: 0.1274  loss_mask: 0.5783  loss_rpn_cls: 0.09608  loss_rpn_loc: 0.03216  validation_loss: 1.973  time: 1.4904  data_time: 0.0254  lr: 8.8536e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:10:45 d2.utils.events]: \u001b[0m eta: 3:14:42  iter: 2219  total_loss: 1.887  loss_cls_stage0: 0.2719  loss_box_reg_stage0: 0.148  loss_cls_stage1: 0.2241  loss_box_reg_stage1: 0.1792  loss_cls_stage2: 0.1617  loss_box_reg_stage2: 0.134  loss_mask: 0.6331  loss_rpn_cls: 0.09772  loss_rpn_loc: 0.03761  validation_loss: 1.973  time: 1.4905  data_time: 0.0250  lr: 8.8335e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:11:15 d2.utils.events]: \u001b[0m eta: 3:14:12  iter: 2239  total_loss: 1.961  loss_cls_stage0: 0.3066  loss_box_reg_stage0: 0.1677  loss_cls_stage1: 0.2452  loss_box_reg_stage1: 0.2049  loss_cls_stage2: 0.1677  loss_box_reg_stage2: 0.145  loss_mask: 0.5919  loss_rpn_cls: 0.1107  loss_rpn_loc: 0.03889  validation_loss: 1.973  time: 1.4907  data_time: 0.0251  lr: 8.8132e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:11:45 d2.utils.events]: \u001b[0m eta: 3:13:43  iter: 2259  total_loss: 2.032  loss_cls_stage0: 0.3094  loss_box_reg_stage0: 0.1754  loss_cls_stage1: 0.2395  loss_box_reg_stage1: 0.1845  loss_cls_stage2: 0.1658  loss_box_reg_stage2: 0.124  loss_mask: 0.5795  loss_rpn_cls: 0.1034  loss_rpn_loc: 0.04123  validation_loss: 1.973  time: 1.4909  data_time: 0.0246  lr: 8.7928e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:12:15 d2.utils.events]: \u001b[0m eta: 3:13:12  iter: 2279  total_loss: 1.71  loss_cls_stage0: 0.242  loss_box_reg_stage0: 0.1335  loss_cls_stage1: 0.1917  loss_box_reg_stage1: 0.1531  loss_cls_stage2: 0.1431  loss_box_reg_stage2: 0.1153  loss_mask: 0.6099  loss_rpn_cls: 0.09821  loss_rpn_loc: 0.03899  validation_loss: 1.973  time: 1.4910  data_time: 0.0226  lr: 8.7723e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:12:45 d2.utils.events]: \u001b[0m eta: 3:12:43  iter: 2299  total_loss: 1.93  loss_cls_stage0: 0.2938  loss_box_reg_stage0: 0.1588  loss_cls_stage1: 0.2227  loss_box_reg_stage1: 0.1934  loss_cls_stage2: 0.1521  loss_box_reg_stage2: 0.1305  loss_mask: 0.5926  loss_rpn_cls: 0.09734  loss_rpn_loc: 0.03952  validation_loss: 1.973  time: 1.4912  data_time: 0.0256  lr: 8.7516e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:13:16 d2.utils.events]: \u001b[0m eta: 3:12:15  iter: 2319  total_loss: 1.975  loss_cls_stage0: 0.2985  loss_box_reg_stage0: 0.1707  loss_cls_stage1: 0.2477  loss_box_reg_stage1: 0.2051  loss_cls_stage2: 0.1737  loss_box_reg_stage2: 0.1406  loss_mask: 0.6158  loss_rpn_cls: 0.09651  loss_rpn_loc: 0.03773  validation_loss: 1.973  time: 1.4914  data_time: 0.0249  lr: 8.7308e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:13:46 d2.utils.events]: \u001b[0m eta: 3:11:48  iter: 2339  total_loss: 1.867  loss_cls_stage0: 0.2906  loss_box_reg_stage0: 0.1659  loss_cls_stage1: 0.2337  loss_box_reg_stage1: 0.1992  loss_cls_stage2: 0.1584  loss_box_reg_stage2: 0.1239  loss_mask: 0.5894  loss_rpn_cls: 0.09408  loss_rpn_loc: 0.03471  validation_loss: 1.973  time: 1.4916  data_time: 0.0235  lr: 8.7098e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:14:16 d2.utils.events]: \u001b[0m eta: 3:11:19  iter: 2359  total_loss: 1.865  loss_cls_stage0: 0.2904  loss_box_reg_stage0: 0.1656  loss_cls_stage1: 0.2356  loss_box_reg_stage1: 0.1962  loss_cls_stage2: 0.1651  loss_box_reg_stage2: 0.1291  loss_mask: 0.592  loss_rpn_cls: 0.09456  loss_rpn_loc: 0.03851  validation_loss: 1.973  time: 1.4917  data_time: 0.0241  lr: 8.6886e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:14:47 d2.utils.events]: \u001b[0m eta: 3:10:53  iter: 2379  total_loss: 1.952  loss_cls_stage0: 0.2996  loss_box_reg_stage0: 0.1741  loss_cls_stage1: 0.2348  loss_box_reg_stage1: 0.2015  loss_cls_stage2: 0.174  loss_box_reg_stage2: 0.1487  loss_mask: 0.6103  loss_rpn_cls: 0.1024  loss_rpn_loc: 0.04401  validation_loss: 1.973  time: 1.4920  data_time: 0.0235  lr: 8.6673e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:15:17 d2.utils.events]: \u001b[0m eta: 3:10:25  iter: 2399  total_loss: 1.878  loss_cls_stage0: 0.2783  loss_box_reg_stage0: 0.1523  loss_cls_stage1: 0.2329  loss_box_reg_stage1: 0.1813  loss_cls_stage2: 0.1673  loss_box_reg_stage2: 0.1385  loss_mask: 0.579  loss_rpn_cls: 0.09071  loss_rpn_loc: 0.03643  validation_loss: 1.973  time: 1.4921  data_time: 0.0257  lr: 8.6459e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:15:47 d2.utils.events]: \u001b[0m eta: 3:09:56  iter: 2419  total_loss: 1.848  loss_cls_stage0: 0.2903  loss_box_reg_stage0: 0.1681  loss_cls_stage1: 0.2311  loss_box_reg_stage1: 0.1944  loss_cls_stage2: 0.1576  loss_box_reg_stage2: 0.1285  loss_mask: 0.5804  loss_rpn_cls: 0.08508  loss_rpn_loc: 0.03401  validation_loss: 1.973  time: 1.4923  data_time: 0.0238  lr: 8.6243e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:16:17 d2.utils.events]: \u001b[0m eta: 3:09:27  iter: 2439  total_loss: 1.781  loss_cls_stage0: 0.2718  loss_box_reg_stage0: 0.1505  loss_cls_stage1: 0.2217  loss_box_reg_stage1: 0.1893  loss_cls_stage2: 0.1599  loss_box_reg_stage2: 0.1358  loss_mask: 0.5486  loss_rpn_cls: 0.09817  loss_rpn_loc: 0.03427  validation_loss: 1.973  time: 1.4924  data_time: 0.0247  lr: 8.6026e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:16:48 d2.utils.events]: \u001b[0m eta: 3:08:58  iter: 2459  total_loss: 1.833  loss_cls_stage0: 0.2902  loss_box_reg_stage0: 0.1678  loss_cls_stage1: 0.2264  loss_box_reg_stage1: 0.2033  loss_cls_stage2: 0.157  loss_box_reg_stage2: 0.1388  loss_mask: 0.5594  loss_rpn_cls: 0.09742  loss_rpn_loc: 0.04074  validation_loss: 1.973  time: 1.4926  data_time: 0.0244  lr: 8.5808e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:17:18 d2.utils.events]: \u001b[0m eta: 3:08:30  iter: 2479  total_loss: 2.012  loss_cls_stage0: 0.2916  loss_box_reg_stage0: 0.1838  loss_cls_stage1: 0.2322  loss_box_reg_stage1: 0.2022  loss_cls_stage2: 0.171  loss_box_reg_stage2: 0.162  loss_mask: 0.6473  loss_rpn_cls: 0.09729  loss_rpn_loc: 0.0421  validation_loss: 1.973  time: 1.4928  data_time: 0.0249  lr: 8.5588e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:17:48 d2.utils.events]: \u001b[0m eta: 3:08:02  iter: 2499  total_loss: 1.915  loss_cls_stage0: 0.2986  loss_box_reg_stage0: 0.1756  loss_cls_stage1: 0.2452  loss_box_reg_stage1: 0.2043  loss_cls_stage2: 0.17  loss_box_reg_stage2: 0.1421  loss_mask: 0.5704  loss_rpn_cls: 0.09871  loss_rpn_loc: 0.03863  validation_loss: 1.973  time: 1.4930  data_time: 0.0240  lr: 8.5366e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:18:19 d2.utils.events]: \u001b[0m eta: 3:07:31  iter: 2519  total_loss: 1.731  loss_cls_stage0: 0.2585  loss_box_reg_stage0: 0.1399  loss_cls_stage1: 0.2056  loss_box_reg_stage1: 0.1793  loss_cls_stage2: 0.1585  loss_box_reg_stage2: 0.1368  loss_mask: 0.5572  loss_rpn_cls: 0.09349  loss_rpn_loc: 0.03312  validation_loss: 1.973  time: 1.4931  data_time: 0.0237  lr: 8.5144e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:18:49 d2.utils.events]: \u001b[0m eta: 3:07:06  iter: 2539  total_loss: 2.062  loss_cls_stage0: 0.3086  loss_box_reg_stage0: 0.185  loss_cls_stage1: 0.2464  loss_box_reg_stage1: 0.2148  loss_cls_stage2: 0.1797  loss_box_reg_stage2: 0.1569  loss_mask: 0.5853  loss_rpn_cls: 0.09957  loss_rpn_loc: 0.03753  validation_loss: 1.973  time: 1.4933  data_time: 0.0236  lr: 8.492e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:19:20 d2.utils.events]: \u001b[0m eta: 3:06:39  iter: 2559  total_loss: 1.989  loss_cls_stage0: 0.2983  loss_box_reg_stage0: 0.1798  loss_cls_stage1: 0.2483  loss_box_reg_stage1: 0.2283  loss_cls_stage2: 0.1835  loss_box_reg_stage2: 0.1635  loss_mask: 0.5865  loss_rpn_cls: 0.1037  loss_rpn_loc: 0.04064  validation_loss: 1.973  time: 1.4936  data_time: 0.0240  lr: 8.4694e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:19:50 d2.utils.events]: \u001b[0m eta: 3:06:10  iter: 2579  total_loss: 1.98  loss_cls_stage0: 0.2943  loss_box_reg_stage0: 0.1742  loss_cls_stage1: 0.2372  loss_box_reg_stage1: 0.2273  loss_cls_stage2: 0.1632  loss_box_reg_stage2: 0.1634  loss_mask: 0.5656  loss_rpn_cls: 0.0816  loss_rpn_loc: 0.03224  validation_loss: 1.973  time: 1.4937  data_time: 0.0242  lr: 8.4467e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:20:20 d2.utils.events]: \u001b[0m eta: 3:05:42  iter: 2599  total_loss: 1.98  loss_cls_stage0: 0.3219  loss_box_reg_stage0: 0.194  loss_cls_stage1: 0.2448  loss_box_reg_stage1: 0.2215  loss_cls_stage2: 0.1781  loss_box_reg_stage2: 0.1573  loss_mask: 0.5622  loss_rpn_cls: 0.09224  loss_rpn_loc: 0.04105  validation_loss: 1.973  time: 1.4940  data_time: 0.0251  lr: 8.4239e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:20:51 d2.utils.events]: \u001b[0m eta: 3:05:13  iter: 2619  total_loss: 1.968  loss_cls_stage0: 0.3077  loss_box_reg_stage0: 0.1792  loss_cls_stage1: 0.2383  loss_box_reg_stage1: 0.2071  loss_cls_stage2: 0.1735  loss_box_reg_stage2: 0.148  loss_mask: 0.5791  loss_rpn_cls: 0.1025  loss_rpn_loc: 0.0398  validation_loss: 1.973  time: 1.4941  data_time: 0.0244  lr: 8.4009e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:21:21 d2.utils.events]: \u001b[0m eta: 3:04:44  iter: 2639  total_loss: 1.833  loss_cls_stage0: 0.2707  loss_box_reg_stage0: 0.1568  loss_cls_stage1: 0.2002  loss_box_reg_stage1: 0.1928  loss_cls_stage2: 0.1555  loss_box_reg_stage2: 0.1472  loss_mask: 0.5534  loss_rpn_cls: 0.09711  loss_rpn_loc: 0.03768  validation_loss: 1.973  time: 1.4943  data_time: 0.0241  lr: 8.3778e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:21:51 d2.utils.events]: \u001b[0m eta: 3:04:16  iter: 2659  total_loss: 1.89  loss_cls_stage0: 0.277  loss_box_reg_stage0: 0.1564  loss_cls_stage1: 0.2165  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.1607  loss_box_reg_stage2: 0.1435  loss_mask: 0.5855  loss_rpn_cls: 0.0913  loss_rpn_loc: 0.03936  validation_loss: 1.973  time: 1.4944  data_time: 0.0300  lr: 8.3546e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:22:21 d2.utils.events]: \u001b[0m eta: 3:03:47  iter: 2679  total_loss: 1.881  loss_cls_stage0: 0.2644  loss_box_reg_stage0: 0.1528  loss_cls_stage1: 0.2127  loss_box_reg_stage1: 0.1904  loss_cls_stage2: 0.1536  loss_box_reg_stage2: 0.1403  loss_mask: 0.5706  loss_rpn_cls: 0.08587  loss_rpn_loc: 0.03229  validation_loss: 1.973  time: 1.4945  data_time: 0.0250  lr: 8.3312e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:22:52 d2.utils.events]: \u001b[0m eta: 3:03:18  iter: 2699  total_loss: 1.931  loss_cls_stage0: 0.2946  loss_box_reg_stage0: 0.1692  loss_cls_stage1: 0.2255  loss_box_reg_stage1: 0.2103  loss_cls_stage2: 0.1609  loss_box_reg_stage2: 0.1487  loss_mask: 0.6032  loss_rpn_cls: 0.09474  loss_rpn_loc: 0.03836  validation_loss: 1.973  time: 1.4947  data_time: 0.0250  lr: 8.3077e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:23:22 d2.utils.events]: \u001b[0m eta: 3:02:49  iter: 2719  total_loss: 1.89  loss_cls_stage0: 0.2883  loss_box_reg_stage0: 0.1659  loss_cls_stage1: 0.2321  loss_box_reg_stage1: 0.2024  loss_cls_stage2: 0.1612  loss_box_reg_stage2: 0.1495  loss_mask: 0.5732  loss_rpn_cls: 0.09005  loss_rpn_loc: 0.03693  validation_loss: 1.973  time: 1.4948  data_time: 0.0241  lr: 8.2841e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:23:52 d2.utils.events]: \u001b[0m eta: 3:02:21  iter: 2739  total_loss: 1.819  loss_cls_stage0: 0.3032  loss_box_reg_stage0: 0.1749  loss_cls_stage1: 0.2124  loss_box_reg_stage1: 0.2034  loss_cls_stage2: 0.1554  loss_box_reg_stage2: 0.1521  loss_mask: 0.5258  loss_rpn_cls: 0.08499  loss_rpn_loc: 0.03608  validation_loss: 1.973  time: 1.4949  data_time: 0.0247  lr: 8.2604e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:24:22 d2.utils.events]: \u001b[0m eta: 3:01:52  iter: 2759  total_loss: 1.834  loss_cls_stage0: 0.2736  loss_box_reg_stage0: 0.1659  loss_cls_stage1: 0.2117  loss_box_reg_stage1: 0.1999  loss_cls_stage2: 0.1522  loss_box_reg_stage2: 0.1414  loss_mask: 0.526  loss_rpn_cls: 0.09204  loss_rpn_loc: 0.03994  validation_loss: 1.973  time: 1.4951  data_time: 0.0239  lr: 8.2365e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:24:53 d2.utils.events]: \u001b[0m eta: 3:01:21  iter: 2779  total_loss: 1.889  loss_cls_stage0: 0.2959  loss_box_reg_stage0: 0.1691  loss_cls_stage1: 0.2245  loss_box_reg_stage1: 0.2194  loss_cls_stage2: 0.1608  loss_box_reg_stage2: 0.1565  loss_mask: 0.5602  loss_rpn_cls: 0.09412  loss_rpn_loc: 0.03874  validation_loss: 1.973  time: 1.4952  data_time: 0.0241  lr: 8.2125e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:25:23 d2.utils.events]: \u001b[0m eta: 3:00:55  iter: 2799  total_loss: 1.968  loss_cls_stage0: 0.2878  loss_box_reg_stage0: 0.1683  loss_cls_stage1: 0.2229  loss_box_reg_stage1: 0.2027  loss_cls_stage2: 0.1681  loss_box_reg_stage2: 0.1529  loss_mask: 0.5532  loss_rpn_cls: 0.1093  loss_rpn_loc: 0.04145  validation_loss: 1.973  time: 1.4954  data_time: 0.0246  lr: 8.1883e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:25:53 d2.utils.events]: \u001b[0m eta: 3:00:27  iter: 2819  total_loss: 1.893  loss_cls_stage0: 0.2979  loss_box_reg_stage0: 0.1911  loss_cls_stage1: 0.2316  loss_box_reg_stage1: 0.2197  loss_cls_stage2: 0.1591  loss_box_reg_stage2: 0.1455  loss_mask: 0.5056  loss_rpn_cls: 0.0839  loss_rpn_loc: 0.03397  validation_loss: 1.973  time: 1.4955  data_time: 0.0244  lr: 8.1641e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:26:24 d2.utils.events]: \u001b[0m eta: 2:59:58  iter: 2839  total_loss: 2.03  loss_cls_stage0: 0.3338  loss_box_reg_stage0: 0.1984  loss_cls_stage1: 0.2394  loss_box_reg_stage1: 0.2146  loss_cls_stage2: 0.1747  loss_box_reg_stage2: 0.1425  loss_mask: 0.6208  loss_rpn_cls: 0.09837  loss_rpn_loc: 0.04054  validation_loss: 1.973  time: 1.4957  data_time: 0.0238  lr: 8.1397e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:26:54 d2.utils.events]: \u001b[0m eta: 2:59:29  iter: 2859  total_loss: 2.051  loss_cls_stage0: 0.2983  loss_box_reg_stage0: 0.1616  loss_cls_stage1: 0.254  loss_box_reg_stage1: 0.2263  loss_cls_stage2: 0.1777  loss_box_reg_stage2: 0.1639  loss_mask: 0.5347  loss_rpn_cls: 0.08925  loss_rpn_loc: 0.03777  validation_loss: 1.973  time: 1.4959  data_time: 0.0240  lr: 8.1152e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:27:25 d2.utils.events]: \u001b[0m eta: 2:58:59  iter: 2879  total_loss: 2.027  loss_cls_stage0: 0.2916  loss_box_reg_stage0: 0.1743  loss_cls_stage1: 0.2389  loss_box_reg_stage1: 0.2262  loss_cls_stage2: 0.1809  loss_box_reg_stage2: 0.1628  loss_mask: 0.5764  loss_rpn_cls: 0.09227  loss_rpn_loc: 0.03938  validation_loss: 1.973  time: 1.4960  data_time: 0.0244  lr: 8.0905e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:27:55 d2.utils.events]: \u001b[0m eta: 2:58:28  iter: 2899  total_loss: 1.796  loss_cls_stage0: 0.2588  loss_box_reg_stage0: 0.1573  loss_cls_stage1: 0.2125  loss_box_reg_stage1: 0.1859  loss_cls_stage2: 0.1535  loss_box_reg_stage2: 0.1388  loss_mask: 0.5936  loss_rpn_cls: 0.0801  loss_rpn_loc: 0.03135  validation_loss: 1.973  time: 1.4960  data_time: 0.0233  lr: 8.0658e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:28:25 d2.utils.events]: \u001b[0m eta: 2:57:59  iter: 2919  total_loss: 2.11  loss_cls_stage0: 0.3266  loss_box_reg_stage0: 0.2035  loss_cls_stage1: 0.2619  loss_box_reg_stage1: 0.2416  loss_cls_stage2: 0.1815  loss_box_reg_stage2: 0.1669  loss_mask: 0.5747  loss_rpn_cls: 0.08707  loss_rpn_loc: 0.03886  validation_loss: 1.973  time: 1.4962  data_time: 0.0235  lr: 8.0409e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:28:56 d2.utils.events]: \u001b[0m eta: 2:57:31  iter: 2939  total_loss: 1.937  loss_cls_stage0: 0.2988  loss_box_reg_stage0: 0.1893  loss_cls_stage1: 0.2297  loss_box_reg_stage1: 0.2349  loss_cls_stage2: 0.1638  loss_box_reg_stage2: 0.157  loss_mask: 0.5691  loss_rpn_cls: 0.08079  loss_rpn_loc: 0.03665  validation_loss: 1.973  time: 1.4964  data_time: 0.0228  lr: 8.0159e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:29:26 d2.utils.events]: \u001b[0m eta: 2:57:02  iter: 2959  total_loss: 1.847  loss_cls_stage0: 0.2806  loss_box_reg_stage0: 0.173  loss_cls_stage1: 0.219  loss_box_reg_stage1: 0.209  loss_cls_stage2: 0.1626  loss_box_reg_stage2: 0.1667  loss_mask: 0.5426  loss_rpn_cls: 0.09197  loss_rpn_loc: 0.0384  validation_loss: 1.973  time: 1.4966  data_time: 0.0235  lr: 7.9908e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:29:56 d2.utils.events]: \u001b[0m eta: 2:56:34  iter: 2979  total_loss: 1.949  loss_cls_stage0: 0.2941  loss_box_reg_stage0: 0.1843  loss_cls_stage1: 0.2398  loss_box_reg_stage1: 0.2186  loss_cls_stage2: 0.1722  loss_box_reg_stage2: 0.1847  loss_mask: 0.5521  loss_rpn_cls: 0.0906  loss_rpn_loc: 0.03498  validation_loss: 1.973  time: 1.4967  data_time: 0.0243  lr: 7.9655e-05  max_mem: 11723M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/26 17:30:29 d2.data.common]: \u001b[0mSerializing 859 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/26 17:30:29 d2.data.common]: \u001b[0mSerialized dataset takes 0.90 MiB\n",
      "\u001b[32m[03/26 17:30:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 859 images\n",
      "\u001b[32m[03/26 17:30:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/859. 0.0797 s / img. ETA=0:01:31\n",
      "\u001b[32m[03/26 17:30:36 d2.evaluation.evaluator]: \u001b[0mInference done 58/859. 0.0800 s / img. ETA=0:01:26\n",
      "\u001b[32m[03/26 17:30:41 d2.evaluation.evaluator]: \u001b[0mInference done 104/859. 0.0800 s / img. ETA=0:01:22\n",
      "\u001b[32m[03/26 17:30:46 d2.evaluation.evaluator]: \u001b[0mInference done 151/859. 0.0801 s / img. ETA=0:01:17\n",
      "\u001b[32m[03/26 17:30:51 d2.evaluation.evaluator]: \u001b[0mInference done 198/859. 0.0800 s / img. ETA=0:01:11\n",
      "\u001b[32m[03/26 17:30:56 d2.evaluation.evaluator]: \u001b[0mInference done 245/859. 0.0800 s / img. ETA=0:01:06\n",
      "\u001b[32m[03/26 17:31:01 d2.evaluation.evaluator]: \u001b[0mInference done 291/859. 0.0801 s / img. ETA=0:01:01\n",
      "\u001b[32m[03/26 17:31:06 d2.evaluation.evaluator]: \u001b[0mInference done 338/859. 0.0802 s / img. ETA=0:00:56\n",
      "\u001b[32m[03/26 17:31:11 d2.evaluation.evaluator]: \u001b[0mInference done 385/859. 0.0802 s / img. ETA=0:00:51\n",
      "\u001b[32m[03/26 17:31:16 d2.evaluation.evaluator]: \u001b[0mInference done 431/859. 0.0802 s / img. ETA=0:00:46\n",
      "\u001b[32m[03/26 17:31:21 d2.evaluation.evaluator]: \u001b[0mInference done 477/859. 0.0803 s / img. ETA=0:00:41\n",
      "\u001b[32m[03/26 17:31:26 d2.evaluation.evaluator]: \u001b[0mInference done 524/859. 0.0803 s / img. ETA=0:00:36\n",
      "\u001b[32m[03/26 17:31:31 d2.evaluation.evaluator]: \u001b[0mInference done 571/859. 0.0802 s / img. ETA=0:00:31\n",
      "\u001b[32m[03/26 17:31:36 d2.evaluation.evaluator]: \u001b[0mInference done 618/859. 0.0802 s / img. ETA=0:00:26\n",
      "\u001b[32m[03/26 17:31:41 d2.evaluation.evaluator]: \u001b[0mInference done 666/859. 0.0802 s / img. ETA=0:00:20\n",
      "\u001b[32m[03/26 17:31:46 d2.evaluation.evaluator]: \u001b[0mInference done 713/859. 0.0801 s / img. ETA=0:00:15\n",
      "\u001b[32m[03/26 17:31:51 d2.evaluation.evaluator]: \u001b[0mInference done 759/859. 0.0801 s / img. ETA=0:00:10\n",
      "\u001b[32m[03/26 17:31:56 d2.evaluation.evaluator]: \u001b[0mInference done 807/859. 0.0801 s / img. ETA=0:00:05\n",
      "\u001b[32m[03/26 17:32:01 d2.evaluation.evaluator]: \u001b[0mInference done 854/859. 0.0801 s / img. ETA=0:00:00\n",
      "\u001b[32m[03/26 17:32:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:32.318000 (0.108101 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/26 17:32:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:08 (0.080081 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.41 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.053\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.094\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.098\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.029\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.052\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.078\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.088\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.088\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.038\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.089\n",
      "\u001b[32m[03/26 17:32:03 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold2 in csv format:\n",
      "\u001b[32m[03/26 17:32:03 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/26 17:32:03 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/26 17:32:03 d2.evaluation.testing]: \u001b[0mcopypaste: 5.2783,9.3997,9.8451,0.2785,2.8697,5.2436\n",
      "validation do loss eval 2.0757885186955205\n",
      "\u001b[32m[03/26 17:33:31 d2.utils.events]: \u001b[0m eta: 2:56:04  iter: 2999  total_loss: 1.774  loss_cls_stage0: 0.2544  loss_box_reg_stage0: 0.1733  loss_cls_stage1: 0.2017  loss_box_reg_stage1: 0.1907  loss_cls_stage2: 0.1485  loss_box_reg_stage2: 0.1645  loss_mask: 0.5511  loss_rpn_cls: 0.08403  loss_rpn_loc: 0.0328  validation_loss: 1.98  time: 1.4968  data_time: 0.0242  lr: 7.9402e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:34:01 d2.utils.events]: \u001b[0m eta: 2:55:35  iter: 3019  total_loss: 2.039  loss_cls_stage0: 0.2935  loss_box_reg_stage0: 0.1846  loss_cls_stage1: 0.2253  loss_box_reg_stage1: 0.2335  loss_cls_stage2: 0.1609  loss_box_reg_stage2: 0.1605  loss_mask: 0.5655  loss_rpn_cls: 0.08811  loss_rpn_loc: 0.03909  validation_loss: 1.98  time: 1.4968  data_time: 0.0247  lr: 7.9147e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:34:31 d2.utils.events]: \u001b[0m eta: 2:55:05  iter: 3039  total_loss: 1.936  loss_cls_stage0: 0.2912  loss_box_reg_stage0: 0.1829  loss_cls_stage1: 0.2288  loss_box_reg_stage1: 0.2205  loss_cls_stage2: 0.1552  loss_box_reg_stage2: 0.1575  loss_mask: 0.5554  loss_rpn_cls: 0.07906  loss_rpn_loc: 0.03367  validation_loss: 1.98  time: 1.4969  data_time: 0.0240  lr: 7.8891e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:35:01 d2.utils.events]: \u001b[0m eta: 2:54:35  iter: 3059  total_loss: 2.034  loss_cls_stage0: 0.2991  loss_box_reg_stage0: 0.2003  loss_cls_stage1: 0.2304  loss_box_reg_stage1: 0.239  loss_cls_stage2: 0.174  loss_box_reg_stage2: 0.1708  loss_mask: 0.5908  loss_rpn_cls: 0.08385  loss_rpn_loc: 0.0366  validation_loss: 1.98  time: 1.4971  data_time: 0.0241  lr: 7.8634e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:35:32 d2.utils.events]: \u001b[0m eta: 2:54:07  iter: 3079  total_loss: 2.076  loss_cls_stage0: 0.3073  loss_box_reg_stage0: 0.1944  loss_cls_stage1: 0.2417  loss_box_reg_stage1: 0.2367  loss_cls_stage2: 0.1791  loss_box_reg_stage2: 0.1853  loss_mask: 0.5639  loss_rpn_cls: 0.09832  loss_rpn_loc: 0.04237  validation_loss: 1.98  time: 1.4973  data_time: 0.0243  lr: 7.8376e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:36:03 d2.utils.events]: \u001b[0m eta: 2:53:39  iter: 3099  total_loss: 2.016  loss_cls_stage0: 0.3067  loss_box_reg_stage0: 0.1974  loss_cls_stage1: 0.2371  loss_box_reg_stage1: 0.2348  loss_cls_stage2: 0.165  loss_box_reg_stage2: 0.171  loss_mask: 0.5744  loss_rpn_cls: 0.08961  loss_rpn_loc: 0.04004  validation_loss: 1.98  time: 1.4974  data_time: 0.0238  lr: 7.8117e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:36:33 d2.utils.events]: \u001b[0m eta: 2:53:11  iter: 3119  total_loss: 1.973  loss_cls_stage0: 0.2927  loss_box_reg_stage0: 0.1906  loss_cls_stage1: 0.2249  loss_box_reg_stage1: 0.2315  loss_cls_stage2: 0.1611  loss_box_reg_stage2: 0.1828  loss_mask: 0.576  loss_rpn_cls: 0.08532  loss_rpn_loc: 0.03453  validation_loss: 1.98  time: 1.4976  data_time: 0.0237  lr: 7.7857e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:37:03 d2.utils.events]: \u001b[0m eta: 2:52:41  iter: 3139  total_loss: 1.916  loss_cls_stage0: 0.2869  loss_box_reg_stage0: 0.1695  loss_cls_stage1: 0.2313  loss_box_reg_stage1: 0.2206  loss_cls_stage2: 0.1632  loss_box_reg_stage2: 0.1635  loss_mask: 0.5721  loss_rpn_cls: 0.08292  loss_rpn_loc: 0.03693  validation_loss: 1.98  time: 1.4977  data_time: 0.0313  lr: 7.7595e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:37:34 d2.utils.events]: \u001b[0m eta: 2:52:15  iter: 3159  total_loss: 2.004  loss_cls_stage0: 0.3262  loss_box_reg_stage0: 0.2055  loss_cls_stage1: 0.2548  loss_box_reg_stage1: 0.2379  loss_cls_stage2: 0.1793  loss_box_reg_stage2: 0.1924  loss_mask: 0.5766  loss_rpn_cls: 0.07958  loss_rpn_loc: 0.03898  validation_loss: 1.98  time: 1.4979  data_time: 0.0244  lr: 7.7333e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:38:05 d2.utils.events]: \u001b[0m eta: 2:51:45  iter: 3179  total_loss: 2.179  loss_cls_stage0: 0.3378  loss_box_reg_stage0: 0.2068  loss_cls_stage1: 0.2682  loss_box_reg_stage1: 0.2657  loss_cls_stage2: 0.202  loss_box_reg_stage2: 0.1817  loss_mask: 0.5623  loss_rpn_cls: 0.08991  loss_rpn_loc: 0.03855  validation_loss: 1.98  time: 1.4981  data_time: 0.0246  lr: 7.7069e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:38:35 d2.utils.events]: \u001b[0m eta: 2:51:19  iter: 3199  total_loss: 1.952  loss_cls_stage0: 0.3107  loss_box_reg_stage0: 0.1789  loss_cls_stage1: 0.2438  loss_box_reg_stage1: 0.2282  loss_cls_stage2: 0.1791  loss_box_reg_stage2: 0.1818  loss_mask: 0.5565  loss_rpn_cls: 0.09206  loss_rpn_loc: 0.04104  validation_loss: 1.98  time: 1.4983  data_time: 0.0236  lr: 7.6805e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:39:05 d2.utils.events]: \u001b[0m eta: 2:50:52  iter: 3219  total_loss: 2.063  loss_cls_stage0: 0.3111  loss_box_reg_stage0: 0.2018  loss_cls_stage1: 0.2307  loss_box_reg_stage1: 0.2429  loss_cls_stage2: 0.1598  loss_box_reg_stage2: 0.1684  loss_mask: 0.5873  loss_rpn_cls: 0.07899  loss_rpn_loc: 0.03384  validation_loss: 1.98  time: 1.4984  data_time: 0.0237  lr: 7.6539e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:39:36 d2.utils.events]: \u001b[0m eta: 2:50:24  iter: 3239  total_loss: 1.841  loss_cls_stage0: 0.2943  loss_box_reg_stage0: 0.182  loss_cls_stage1: 0.2283  loss_box_reg_stage1: 0.2186  loss_cls_stage2: 0.1556  loss_box_reg_stage2: 0.1679  loss_mask: 0.5574  loss_rpn_cls: 0.08521  loss_rpn_loc: 0.03538  validation_loss: 1.98  time: 1.4986  data_time: 0.0236  lr: 7.6272e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:40:07 d2.utils.events]: \u001b[0m eta: 2:49:54  iter: 3259  total_loss: 2.024  loss_cls_stage0: 0.3027  loss_box_reg_stage0: 0.2045  loss_cls_stage1: 0.2233  loss_box_reg_stage1: 0.24  loss_cls_stage2: 0.1579  loss_box_reg_stage2: 0.1788  loss_mask: 0.5516  loss_rpn_cls: 0.08341  loss_rpn_loc: 0.03571  validation_loss: 1.98  time: 1.4987  data_time: 0.0238  lr: 7.6004e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:40:37 d2.utils.events]: \u001b[0m eta: 2:49:25  iter: 3279  total_loss: 1.978  loss_cls_stage0: 0.3006  loss_box_reg_stage0: 0.1876  loss_cls_stage1: 0.2428  loss_box_reg_stage1: 0.2425  loss_cls_stage2: 0.1799  loss_box_reg_stage2: 0.1795  loss_mask: 0.5527  loss_rpn_cls: 0.08111  loss_rpn_loc: 0.0359  validation_loss: 1.98  time: 1.4989  data_time: 0.0234  lr: 7.5735e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:41:07 d2.utils.events]: \u001b[0m eta: 2:48:57  iter: 3299  total_loss: 1.972  loss_cls_stage0: 0.278  loss_box_reg_stage0: 0.1893  loss_cls_stage1: 0.2312  loss_box_reg_stage1: 0.2395  loss_cls_stage2: 0.1607  loss_box_reg_stage2: 0.1837  loss_mask: 0.5448  loss_rpn_cls: 0.07274  loss_rpn_loc: 0.03517  validation_loss: 1.98  time: 1.4990  data_time: 0.0227  lr: 7.5466e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:41:38 d2.utils.events]: \u001b[0m eta: 2:48:27  iter: 3319  total_loss: 2.059  loss_cls_stage0: 0.3183  loss_box_reg_stage0: 0.1965  loss_cls_stage1: 0.2469  loss_box_reg_stage1: 0.2389  loss_cls_stage2: 0.1739  loss_box_reg_stage2: 0.1883  loss_mask: 0.5522  loss_rpn_cls: 0.08882  loss_rpn_loc: 0.03467  validation_loss: 1.98  time: 1.4991  data_time: 0.0248  lr: 7.5195e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:42:08 d2.utils.events]: \u001b[0m eta: 2:47:59  iter: 3339  total_loss: 2.018  loss_cls_stage0: 0.3132  loss_box_reg_stage0: 0.197  loss_cls_stage1: 0.2358  loss_box_reg_stage1: 0.2343  loss_cls_stage2: 0.1677  loss_box_reg_stage2: 0.1751  loss_mask: 0.5381  loss_rpn_cls: 0.08723  loss_rpn_loc: 0.03796  validation_loss: 1.98  time: 1.4993  data_time: 0.0236  lr: 7.4923e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:42:39 d2.utils.events]: \u001b[0m eta: 2:47:31  iter: 3359  total_loss: 2.021  loss_cls_stage0: 0.2923  loss_box_reg_stage0: 0.1917  loss_cls_stage1: 0.2413  loss_box_reg_stage1: 0.2574  loss_cls_stage2: 0.1784  loss_box_reg_stage2: 0.1768  loss_mask: 0.5722  loss_rpn_cls: 0.07823  loss_rpn_loc: 0.03707  validation_loss: 1.98  time: 1.4994  data_time: 0.0253  lr: 7.465e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:43:09 d2.utils.events]: \u001b[0m eta: 2:47:03  iter: 3379  total_loss: 2.08  loss_cls_stage0: 0.3136  loss_box_reg_stage0: 0.2152  loss_cls_stage1: 0.2465  loss_box_reg_stage1: 0.2709  loss_cls_stage2: 0.1681  loss_box_reg_stage2: 0.2011  loss_mask: 0.594  loss_rpn_cls: 0.07404  loss_rpn_loc: 0.03746  validation_loss: 1.98  time: 1.4996  data_time: 0.0248  lr: 7.4376e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:43:40 d2.utils.events]: \u001b[0m eta: 2:46:35  iter: 3399  total_loss: 2.014  loss_cls_stage0: 0.3261  loss_box_reg_stage0: 0.204  loss_cls_stage1: 0.254  loss_box_reg_stage1: 0.2564  loss_cls_stage2: 0.1697  loss_box_reg_stage2: 0.1934  loss_mask: 0.5212  loss_rpn_cls: 0.08415  loss_rpn_loc: 0.03587  validation_loss: 1.98  time: 1.4998  data_time: 0.0253  lr: 7.4101e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:44:11 d2.utils.events]: \u001b[0m eta: 2:46:10  iter: 3419  total_loss: 2.107  loss_cls_stage0: 0.3151  loss_box_reg_stage0: 0.2058  loss_cls_stage1: 0.255  loss_box_reg_stage1: 0.2711  loss_cls_stage2: 0.1863  loss_box_reg_stage2: 0.2199  loss_mask: 0.5312  loss_rpn_cls: 0.07158  loss_rpn_loc: 0.03811  validation_loss: 1.98  time: 1.5000  data_time: 0.0229  lr: 7.3826e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:44:41 d2.utils.events]: \u001b[0m eta: 2:45:41  iter: 3439  total_loss: 1.872  loss_cls_stage0: 0.2594  loss_box_reg_stage0: 0.1639  loss_cls_stage1: 0.2053  loss_box_reg_stage1: 0.2212  loss_cls_stage2: 0.1591  loss_box_reg_stage2: 0.1817  loss_mask: 0.5397  loss_rpn_cls: 0.08072  loss_rpn_loc: 0.03251  validation_loss: 1.98  time: 1.5001  data_time: 0.0238  lr: 7.3549e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:45:12 d2.utils.events]: \u001b[0m eta: 2:45:13  iter: 3459  total_loss: 1.903  loss_cls_stage0: 0.2837  loss_box_reg_stage0: 0.1875  loss_cls_stage1: 0.2235  loss_box_reg_stage1: 0.2364  loss_cls_stage2: 0.158  loss_box_reg_stage2: 0.187  loss_mask: 0.5601  loss_rpn_cls: 0.08674  loss_rpn_loc: 0.03919  validation_loss: 1.98  time: 1.5002  data_time: 0.0247  lr: 7.3271e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:45:42 d2.utils.events]: \u001b[0m eta: 2:44:43  iter: 3479  total_loss: 1.995  loss_cls_stage0: 0.2936  loss_box_reg_stage0: 0.2065  loss_cls_stage1: 0.2288  loss_box_reg_stage1: 0.2557  loss_cls_stage2: 0.1558  loss_box_reg_stage2: 0.1997  loss_mask: 0.5532  loss_rpn_cls: 0.0678  loss_rpn_loc: 0.03478  validation_loss: 1.98  time: 1.5004  data_time: 0.0239  lr: 7.2993e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:46:13 d2.utils.events]: \u001b[0m eta: 2:44:14  iter: 3499  total_loss: 2.021  loss_cls_stage0: 0.2982  loss_box_reg_stage0: 0.2044  loss_cls_stage1: 0.2397  loss_box_reg_stage1: 0.2481  loss_cls_stage2: 0.1641  loss_box_reg_stage2: 0.1878  loss_mask: 0.5565  loss_rpn_cls: 0.07937  loss_rpn_loc: 0.03837  validation_loss: 1.98  time: 1.5005  data_time: 0.0227  lr: 7.2714e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:46:43 d2.utils.events]: \u001b[0m eta: 2:43:45  iter: 3519  total_loss: 1.986  loss_cls_stage0: 0.2644  loss_box_reg_stage0: 0.179  loss_cls_stage1: 0.2206  loss_box_reg_stage1: 0.2333  loss_cls_stage2: 0.1632  loss_box_reg_stage2: 0.1803  loss_mask: 0.5817  loss_rpn_cls: 0.08059  loss_rpn_loc: 0.03149  validation_loss: 1.98  time: 1.5007  data_time: 0.0229  lr: 7.2433e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:47:14 d2.utils.events]: \u001b[0m eta: 2:43:15  iter: 3539  total_loss: 1.993  loss_cls_stage0: 0.3131  loss_box_reg_stage0: 0.2009  loss_cls_stage1: 0.2458  loss_box_reg_stage1: 0.257  loss_cls_stage2: 0.1756  loss_box_reg_stage2: 0.2004  loss_mask: 0.5203  loss_rpn_cls: 0.08701  loss_rpn_loc: 0.03611  validation_loss: 1.98  time: 1.5008  data_time: 0.0251  lr: 7.2152e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:47:44 d2.utils.events]: \u001b[0m eta: 2:42:48  iter: 3559  total_loss: 1.981  loss_cls_stage0: 0.303  loss_box_reg_stage0: 0.2037  loss_cls_stage1: 0.2291  loss_box_reg_stage1: 0.2423  loss_cls_stage2: 0.1611  loss_box_reg_stage2: 0.1825  loss_mask: 0.5714  loss_rpn_cls: 0.08285  loss_rpn_loc: 0.03589  validation_loss: 1.98  time: 1.5010  data_time: 0.0247  lr: 7.187e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:48:15 d2.utils.events]: \u001b[0m eta: 2:42:20  iter: 3579  total_loss: 2.144  loss_cls_stage0: 0.3335  loss_box_reg_stage0: 0.2303  loss_cls_stage1: 0.2454  loss_box_reg_stage1: 0.287  loss_cls_stage2: 0.1758  loss_box_reg_stage2: 0.2126  loss_mask: 0.6083  loss_rpn_cls: 0.0804  loss_rpn_loc: 0.03638  validation_loss: 1.98  time: 1.5011  data_time: 0.0241  lr: 7.1587e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:48:45 d2.utils.events]: \u001b[0m eta: 2:41:50  iter: 3599  total_loss: 2.038  loss_cls_stage0: 0.272  loss_box_reg_stage0: 0.1776  loss_cls_stage1: 0.2259  loss_box_reg_stage1: 0.2682  loss_cls_stage2: 0.1638  loss_box_reg_stage2: 0.2155  loss_mask: 0.5779  loss_rpn_cls: 0.07752  loss_rpn_loc: 0.03428  validation_loss: 1.98  time: 1.5013  data_time: 0.0245  lr: 7.1303e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:49:16 d2.utils.events]: \u001b[0m eta: 2:41:21  iter: 3619  total_loss: 2.039  loss_cls_stage0: 0.2749  loss_box_reg_stage0: 0.1899  loss_cls_stage1: 0.226  loss_box_reg_stage1: 0.2511  loss_cls_stage2: 0.1637  loss_box_reg_stage2: 0.1996  loss_mask: 0.5668  loss_rpn_cls: 0.07598  loss_rpn_loc: 0.03672  validation_loss: 1.98  time: 1.5014  data_time: 0.0233  lr: 7.1019e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:49:47 d2.utils.events]: \u001b[0m eta: 2:40:53  iter: 3639  total_loss: 2.114  loss_cls_stage0: 0.3257  loss_box_reg_stage0: 0.2117  loss_cls_stage1: 0.2515  loss_box_reg_stage1: 0.2514  loss_cls_stage2: 0.1715  loss_box_reg_stage2: 0.2071  loss_mask: 0.5733  loss_rpn_cls: 0.08369  loss_rpn_loc: 0.03884  validation_loss: 1.98  time: 1.5016  data_time: 0.0230  lr: 7.0733e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:50:17 d2.utils.events]: \u001b[0m eta: 2:40:25  iter: 3659  total_loss: 2.108  loss_cls_stage0: 0.2986  loss_box_reg_stage0: 0.2013  loss_cls_stage1: 0.2497  loss_box_reg_stage1: 0.258  loss_cls_stage2: 0.1725  loss_box_reg_stage2: 0.2105  loss_mask: 0.557  loss_rpn_cls: 0.06448  loss_rpn_loc: 0.03436  validation_loss: 1.98  time: 1.5018  data_time: 0.0244  lr: 7.0447e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:50:48 d2.utils.events]: \u001b[0m eta: 2:40:00  iter: 3679  total_loss: 2.055  loss_cls_stage0: 0.3047  loss_box_reg_stage0: 0.2168  loss_cls_stage1: 0.2349  loss_box_reg_stage1: 0.2545  loss_cls_stage2: 0.1699  loss_box_reg_stage2: 0.1921  loss_mask: 0.5599  loss_rpn_cls: 0.08224  loss_rpn_loc: 0.03909  validation_loss: 1.98  time: 1.5019  data_time: 0.0231  lr: 7.016e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:51:19 d2.utils.events]: \u001b[0m eta: 2:39:32  iter: 3699  total_loss: 2.073  loss_cls_stage0: 0.3162  loss_box_reg_stage0: 0.2198  loss_cls_stage1: 0.2548  loss_box_reg_stage1: 0.2654  loss_cls_stage2: 0.1782  loss_box_reg_stage2: 0.205  loss_mask: 0.5163  loss_rpn_cls: 0.06831  loss_rpn_loc: 0.03893  validation_loss: 1.98  time: 1.5021  data_time: 0.0239  lr: 6.9872e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:51:49 d2.utils.events]: \u001b[0m eta: 2:39:04  iter: 3719  total_loss: 2.191  loss_cls_stage0: 0.3479  loss_box_reg_stage0: 0.2408  loss_cls_stage1: 0.2641  loss_box_reg_stage1: 0.2685  loss_cls_stage2: 0.1801  loss_box_reg_stage2: 0.2046  loss_mask: 0.5029  loss_rpn_cls: 0.08281  loss_rpn_loc: 0.04253  validation_loss: 1.98  time: 1.5023  data_time: 0.0238  lr: 6.9583e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:52:20 d2.utils.events]: \u001b[0m eta: 2:38:37  iter: 3739  total_loss: 2.141  loss_cls_stage0: 0.3043  loss_box_reg_stage0: 0.2141  loss_cls_stage1: 0.2585  loss_box_reg_stage1: 0.2855  loss_cls_stage2: 0.1823  loss_box_reg_stage2: 0.2261  loss_mask: 0.6264  loss_rpn_cls: 0.08197  loss_rpn_loc: 0.03622  validation_loss: 1.98  time: 1.5025  data_time: 0.0252  lr: 6.9294e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:52:51 d2.utils.events]: \u001b[0m eta: 2:38:07  iter: 3759  total_loss: 2.137  loss_cls_stage0: 0.3153  loss_box_reg_stage0: 0.2035  loss_cls_stage1: 0.2544  loss_box_reg_stage1: 0.267  loss_cls_stage2: 0.1769  loss_box_reg_stage2: 0.2066  loss_mask: 0.5804  loss_rpn_cls: 0.07067  loss_rpn_loc: 0.03413  validation_loss: 1.98  time: 1.5026  data_time: 0.0318  lr: 6.9003e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:53:21 d2.utils.events]: \u001b[0m eta: 2:37:39  iter: 3779  total_loss: 2.044  loss_cls_stage0: 0.3075  loss_box_reg_stage0: 0.2034  loss_cls_stage1: 0.2484  loss_box_reg_stage1: 0.249  loss_cls_stage2: 0.1707  loss_box_reg_stage2: 0.1977  loss_mask: 0.5502  loss_rpn_cls: 0.08314  loss_rpn_loc: 0.0368  validation_loss: 1.98  time: 1.5027  data_time: 0.0248  lr: 6.8713e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:53:52 d2.utils.events]: \u001b[0m eta: 2:37:09  iter: 3799  total_loss: 2.006  loss_cls_stage0: 0.3105  loss_box_reg_stage0: 0.187  loss_cls_stage1: 0.2409  loss_box_reg_stage1: 0.2631  loss_cls_stage2: 0.1658  loss_box_reg_stage2: 0.2077  loss_mask: 0.5595  loss_rpn_cls: 0.07719  loss_rpn_loc: 0.0358  validation_loss: 1.98  time: 1.5029  data_time: 0.0254  lr: 6.8421e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:54:23 d2.utils.events]: \u001b[0m eta: 2:36:41  iter: 3819  total_loss: 2.16  loss_cls_stage0: 0.2982  loss_box_reg_stage0: 0.2106  loss_cls_stage1: 0.2498  loss_box_reg_stage1: 0.2721  loss_cls_stage2: 0.1789  loss_box_reg_stage2: 0.2269  loss_mask: 0.5975  loss_rpn_cls: 0.08034  loss_rpn_loc: 0.03869  validation_loss: 1.98  time: 1.5030  data_time: 0.0271  lr: 6.8128e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:54:53 d2.utils.events]: \u001b[0m eta: 2:36:11  iter: 3839  total_loss: 2.037  loss_cls_stage0: 0.2966  loss_box_reg_stage0: 0.1944  loss_cls_stage1: 0.2336  loss_box_reg_stage1: 0.2458  loss_cls_stage2: 0.1631  loss_box_reg_stage2: 0.1994  loss_mask: 0.5337  loss_rpn_cls: 0.06903  loss_rpn_loc: 0.03489  validation_loss: 1.98  time: 1.5032  data_time: 0.0247  lr: 6.7835e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:55:24 d2.utils.events]: \u001b[0m eta: 2:35:41  iter: 3859  total_loss: 2.057  loss_cls_stage0: 0.2892  loss_box_reg_stage0: 0.1959  loss_cls_stage1: 0.2292  loss_box_reg_stage1: 0.2728  loss_cls_stage2: 0.1657  loss_box_reg_stage2: 0.207  loss_mask: 0.5743  loss_rpn_cls: 0.07146  loss_rpn_loc: 0.0336  validation_loss: 1.98  time: 1.5033  data_time: 0.0239  lr: 6.7541e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:55:54 d2.utils.events]: \u001b[0m eta: 2:35:11  iter: 3879  total_loss: 2.041  loss_cls_stage0: 0.288  loss_box_reg_stage0: 0.2018  loss_cls_stage1: 0.2235  loss_box_reg_stage1: 0.2594  loss_cls_stage2: 0.1604  loss_box_reg_stage2: 0.2021  loss_mask: 0.5338  loss_rpn_cls: 0.07141  loss_rpn_loc: 0.03537  validation_loss: 1.98  time: 1.5034  data_time: 0.0238  lr: 6.7247e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:56:25 d2.utils.events]: \u001b[0m eta: 2:34:42  iter: 3899  total_loss: 2.079  loss_cls_stage0: 0.2947  loss_box_reg_stage0: 0.2052  loss_cls_stage1: 0.2277  loss_box_reg_stage1: 0.2795  loss_cls_stage2: 0.169  loss_box_reg_stage2: 0.2396  loss_mask: 0.5481  loss_rpn_cls: 0.0812  loss_rpn_loc: 0.03481  validation_loss: 1.98  time: 1.5036  data_time: 0.0240  lr: 6.6952e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:56:56 d2.utils.events]: \u001b[0m eta: 2:34:12  iter: 3919  total_loss: 2.162  loss_cls_stage0: 0.3316  loss_box_reg_stage0: 0.2345  loss_cls_stage1: 0.2574  loss_box_reg_stage1: 0.2716  loss_cls_stage2: 0.1891  loss_box_reg_stage2: 0.2231  loss_mask: 0.5264  loss_rpn_cls: 0.07622  loss_rpn_loc: 0.03507  validation_loss: 1.98  time: 1.5037  data_time: 0.0235  lr: 6.6656e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:57:26 d2.utils.events]: \u001b[0m eta: 2:33:43  iter: 3939  total_loss: 2.074  loss_cls_stage0: 0.2977  loss_box_reg_stage0: 0.211  loss_cls_stage1: 0.2402  loss_box_reg_stage1: 0.2788  loss_cls_stage2: 0.1607  loss_box_reg_stage2: 0.207  loss_mask: 0.5724  loss_rpn_cls: 0.08354  loss_rpn_loc: 0.04049  validation_loss: 1.98  time: 1.5038  data_time: 0.0297  lr: 6.6359e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:57:57 d2.utils.events]: \u001b[0m eta: 2:33:15  iter: 3959  total_loss: 2.213  loss_cls_stage0: 0.2993  loss_box_reg_stage0: 0.2248  loss_cls_stage1: 0.244  loss_box_reg_stage1: 0.3081  loss_cls_stage2: 0.1726  loss_box_reg_stage2: 0.2176  loss_mask: 0.5645  loss_rpn_cls: 0.07868  loss_rpn_loc: 0.03698  validation_loss: 1.98  time: 1.5040  data_time: 0.0250  lr: 6.6062e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 17:58:28 d2.utils.events]: \u001b[0m eta: 2:32:47  iter: 3979  total_loss: 2.283  loss_cls_stage0: 0.3369  loss_box_reg_stage0: 0.2323  loss_cls_stage1: 0.2746  loss_box_reg_stage1: 0.2814  loss_cls_stage2: 0.1926  loss_box_reg_stage2: 0.22  loss_mask: 0.5503  loss_rpn_cls: 0.08223  loss_rpn_loc: 0.03858  validation_loss: 1.98  time: 1.5042  data_time: 0.0252  lr: 6.5764e-05  max_mem: 11723M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/26 17:59:00 d2.data.common]: \u001b[0mSerializing 859 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/26 17:59:00 d2.data.common]: \u001b[0mSerialized dataset takes 0.90 MiB\n",
      "\u001b[32m[03/26 17:59:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 859 images\n",
      "\u001b[32m[03/26 17:59:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/859. 0.0806 s / img. ETA=0:01:29\n",
      "\u001b[32m[03/26 17:59:07 d2.evaluation.evaluator]: \u001b[0mInference done 60/859. 0.0795 s / img. ETA=0:01:22\n",
      "\u001b[32m[03/26 17:59:12 d2.evaluation.evaluator]: \u001b[0mInference done 107/859. 0.0796 s / img. ETA=0:01:19\n",
      "\u001b[32m[03/26 17:59:17 d2.evaluation.evaluator]: \u001b[0mInference done 155/859. 0.0796 s / img. ETA=0:01:14\n",
      "\u001b[32m[03/26 17:59:22 d2.evaluation.evaluator]: \u001b[0mInference done 202/859. 0.0797 s / img. ETA=0:01:09\n",
      "\u001b[32m[03/26 17:59:28 d2.evaluation.evaluator]: \u001b[0mInference done 250/859. 0.0796 s / img. ETA=0:01:04\n",
      "\u001b[32m[03/26 17:59:33 d2.evaluation.evaluator]: \u001b[0mInference done 298/859. 0.0796 s / img. ETA=0:00:59\n",
      "\u001b[32m[03/26 17:59:38 d2.evaluation.evaluator]: \u001b[0mInference done 347/859. 0.0796 s / img. ETA=0:00:53\n",
      "\u001b[32m[03/26 17:59:43 d2.evaluation.evaluator]: \u001b[0mInference done 396/859. 0.0795 s / img. ETA=0:00:48\n",
      "\u001b[32m[03/26 17:59:48 d2.evaluation.evaluator]: \u001b[0mInference done 443/859. 0.0795 s / img. ETA=0:00:43\n",
      "\u001b[32m[03/26 17:59:53 d2.evaluation.evaluator]: \u001b[0mInference done 491/859. 0.0795 s / img. ETA=0:00:38\n",
      "\u001b[32m[03/26 17:59:58 d2.evaluation.evaluator]: \u001b[0mInference done 540/859. 0.0795 s / img. ETA=0:00:33\n",
      "\u001b[32m[03/26 18:00:03 d2.evaluation.evaluator]: \u001b[0mInference done 587/859. 0.0795 s / img. ETA=0:00:28\n",
      "\u001b[32m[03/26 18:00:08 d2.evaluation.evaluator]: \u001b[0mInference done 637/859. 0.0795 s / img. ETA=0:00:23\n",
      "\u001b[32m[03/26 18:00:13 d2.evaluation.evaluator]: \u001b[0mInference done 683/859. 0.0797 s / img. ETA=0:00:18\n",
      "\u001b[32m[03/26 18:00:18 d2.evaluation.evaluator]: \u001b[0mInference done 730/859. 0.0797 s / img. ETA=0:00:13\n",
      "\u001b[32m[03/26 18:00:23 d2.evaluation.evaluator]: \u001b[0mInference done 778/859. 0.0797 s / img. ETA=0:00:08\n",
      "\u001b[32m[03/26 18:00:28 d2.evaluation.evaluator]: \u001b[0mInference done 827/859. 0.0797 s / img. ETA=0:00:03\n",
      "\u001b[32m[03/26 18:00:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:30.186520 (0.105605 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/26 18:00:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:08 (0.079694 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.28 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.064\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.110\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.118\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.029\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.065\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.094\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.111\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.111\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.011\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.038\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.114\n",
      "\u001b[32m[03/26 18:00:32 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold2 in csv format:\n",
      "\u001b[32m[03/26 18:00:32 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/26 18:00:32 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/26 18:00:32 d2.evaluation.testing]: \u001b[0mcopypaste: 6.4160,10.9975,11.7516,0.4861,2.9232,6.5271\n",
      "validation do loss eval 2.1347561964501054\n",
      "\u001b[32m[03/26 18:02:00 d2.utils.events]: \u001b[0m eta: 2:32:21  iter: 3999  total_loss: 2.2  loss_cls_stage0: 0.3162  loss_box_reg_stage0: 0.2118  loss_cls_stage1: 0.2555  loss_box_reg_stage1: 0.2885  loss_cls_stage2: 0.1837  loss_box_reg_stage2: 0.2299  loss_mask: 0.5918  loss_rpn_cls: 0.08008  loss_rpn_loc: 0.03555  validation_loss: 2.028  time: 1.5043  data_time: 0.0239  lr: 6.5466e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:02:30 d2.utils.events]: \u001b[0m eta: 2:31:54  iter: 4019  total_loss: 2.115  loss_cls_stage0: 0.3106  loss_box_reg_stage0: 0.2269  loss_cls_stage1: 0.2332  loss_box_reg_stage1: 0.3003  loss_cls_stage2: 0.1695  loss_box_reg_stage2: 0.2184  loss_mask: 0.5455  loss_rpn_cls: 0.07581  loss_rpn_loc: 0.03709  validation_loss: 2.028  time: 1.5044  data_time: 0.0245  lr: 6.5167e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:03:01 d2.utils.events]: \u001b[0m eta: 2:31:26  iter: 4039  total_loss: 2.186  loss_cls_stage0: 0.2975  loss_box_reg_stage0: 0.2108  loss_cls_stage1: 0.2454  loss_box_reg_stage1: 0.2793  loss_cls_stage2: 0.1948  loss_box_reg_stage2: 0.2414  loss_mask: 0.5736  loss_rpn_cls: 0.07231  loss_rpn_loc: 0.0305  validation_loss: 2.028  time: 1.5045  data_time: 0.0251  lr: 6.4867e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:03:32 d2.utils.events]: \u001b[0m eta: 2:30:56  iter: 4059  total_loss: 2.186  loss_cls_stage0: 0.2993  loss_box_reg_stage0: 0.2116  loss_cls_stage1: 0.2565  loss_box_reg_stage1: 0.3073  loss_cls_stage2: 0.192  loss_box_reg_stage2: 0.2372  loss_mask: 0.5769  loss_rpn_cls: 0.06814  loss_rpn_loc: 0.03315  validation_loss: 2.028  time: 1.5047  data_time: 0.0320  lr: 6.4567e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:04:02 d2.utils.events]: \u001b[0m eta: 2:30:27  iter: 4079  total_loss: 2.029  loss_cls_stage0: 0.3047  loss_box_reg_stage0: 0.2121  loss_cls_stage1: 0.2371  loss_box_reg_stage1: 0.2654  loss_cls_stage2: 0.1649  loss_box_reg_stage2: 0.2093  loss_mask: 0.5881  loss_rpn_cls: 0.07811  loss_rpn_loc: 0.03804  validation_loss: 2.028  time: 1.5048  data_time: 0.0240  lr: 6.4266e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:04:33 d2.utils.events]: \u001b[0m eta: 2:29:57  iter: 4099  total_loss: 2.03  loss_cls_stage0: 0.2979  loss_box_reg_stage0: 0.2139  loss_cls_stage1: 0.2408  loss_box_reg_stage1: 0.29  loss_cls_stage2: 0.1739  loss_box_reg_stage2: 0.2354  loss_mask: 0.5094  loss_rpn_cls: 0.06644  loss_rpn_loc: 0.03515  validation_loss: 2.028  time: 1.5049  data_time: 0.0234  lr: 6.3965e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:05:04 d2.utils.events]: \u001b[0m eta: 2:29:29  iter: 4119  total_loss: 2.031  loss_cls_stage0: 0.2912  loss_box_reg_stage0: 0.2092  loss_cls_stage1: 0.2309  loss_box_reg_stage1: 0.2671  loss_cls_stage2: 0.1735  loss_box_reg_stage2: 0.2185  loss_mask: 0.5096  loss_rpn_cls: 0.07081  loss_rpn_loc: 0.03388  validation_loss: 2.028  time: 1.5051  data_time: 0.0235  lr: 6.3663e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:05:34 d2.utils.events]: \u001b[0m eta: 2:29:00  iter: 4139  total_loss: 2.098  loss_cls_stage0: 0.3025  loss_box_reg_stage0: 0.2191  loss_cls_stage1: 0.2426  loss_box_reg_stage1: 0.2982  loss_cls_stage2: 0.1767  loss_box_reg_stage2: 0.2449  loss_mask: 0.5533  loss_rpn_cls: 0.06748  loss_rpn_loc: 0.03423  validation_loss: 2.028  time: 1.5052  data_time: 0.0244  lr: 6.336e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:06:05 d2.utils.events]: \u001b[0m eta: 2:28:29  iter: 4159  total_loss: 2.079  loss_cls_stage0: 0.2705  loss_box_reg_stage0: 0.1895  loss_cls_stage1: 0.2249  loss_box_reg_stage1: 0.2406  loss_cls_stage2: 0.1626  loss_box_reg_stage2: 0.2212  loss_mask: 0.5533  loss_rpn_cls: 0.07302  loss_rpn_loc: 0.0312  validation_loss: 2.028  time: 1.5053  data_time: 0.0248  lr: 6.3057e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:06:35 d2.utils.events]: \u001b[0m eta: 2:28:00  iter: 4179  total_loss: 2.065  loss_cls_stage0: 0.2848  loss_box_reg_stage0: 0.2022  loss_cls_stage1: 0.2334  loss_box_reg_stage1: 0.2871  loss_cls_stage2: 0.1693  loss_box_reg_stage2: 0.251  loss_mask: 0.5613  loss_rpn_cls: 0.06038  loss_rpn_loc: 0.03315  validation_loss: 2.028  time: 1.5054  data_time: 0.0242  lr: 6.2754e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:07:11 d2.utils.events]: \u001b[0m eta: 2:27:30  iter: 4199  total_loss: 2.237  loss_cls_stage0: 0.3187  loss_box_reg_stage0: 0.2352  loss_cls_stage1: 0.2483  loss_box_reg_stage1: 0.3046  loss_cls_stage2: 0.1779  loss_box_reg_stage2: 0.2488  loss_mask: 0.5477  loss_rpn_cls: 0.07661  loss_rpn_loc: 0.03526  validation_loss: 2.028  time: 1.5068  data_time: 0.0240  lr: 6.245e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:08:02 d2.utils.events]: \u001b[0m eta: 2:27:04  iter: 4219  total_loss: 2.037  loss_cls_stage0: 0.2924  loss_box_reg_stage0: 0.2078  loss_cls_stage1: 0.2405  loss_box_reg_stage1: 0.2892  loss_cls_stage2: 0.1797  loss_box_reg_stage2: 0.2575  loss_mask: 0.5054  loss_rpn_cls: 0.06899  loss_rpn_loc: 0.03193  validation_loss: 2.028  time: 1.5118  data_time: 0.0230  lr: 6.2145e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:08:54 d2.utils.events]: \u001b[0m eta: 2:26:36  iter: 4239  total_loss: 2.266  loss_cls_stage0: 0.3262  loss_box_reg_stage0: 0.2275  loss_cls_stage1: 0.2684  loss_box_reg_stage1: 0.2949  loss_cls_stage2: 0.1901  loss_box_reg_stage2: 0.2551  loss_mask: 0.5502  loss_rpn_cls: 0.08385  loss_rpn_loc: 0.0404  validation_loss: 2.028  time: 1.5168  data_time: 0.0239  lr: 6.184e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:09:47 d2.utils.events]: \u001b[0m eta: 2:26:09  iter: 4259  total_loss: 2.169  loss_cls_stage0: 0.3138  loss_box_reg_stage0: 0.224  loss_cls_stage1: 0.2496  loss_box_reg_stage1: 0.2969  loss_cls_stage2: 0.1838  loss_box_reg_stage2: 0.2438  loss_mask: 0.54  loss_rpn_cls: 0.07689  loss_rpn_loc: 0.03716  validation_loss: 2.028  time: 1.5220  data_time: 0.0246  lr: 6.1535e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:10:56 d2.utils.events]: \u001b[0m eta: 2:25:44  iter: 4279  total_loss: 2.174  loss_cls_stage0: 0.3137  loss_box_reg_stage0: 0.2301  loss_cls_stage1: 0.2592  loss_box_reg_stage1: 0.3008  loss_cls_stage2: 0.1858  loss_box_reg_stage2: 0.2488  loss_mask: 0.5431  loss_rpn_cls: 0.0716  loss_rpn_loc: 0.03794  validation_loss: 2.028  time: 1.5311  data_time: 0.0242  lr: 6.1229e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:12:06 d2.utils.events]: \u001b[0m eta: 2:25:18  iter: 4299  total_loss: 2.3  loss_cls_stage0: 0.3524  loss_box_reg_stage0: 0.2583  loss_cls_stage1: 0.2706  loss_box_reg_stage1: 0.3349  loss_cls_stage2: 0.1921  loss_box_reg_stage2: 0.2645  loss_mask: 0.5408  loss_rpn_cls: 0.08005  loss_rpn_loc: 0.04459  validation_loss: 2.028  time: 1.5402  data_time: 0.0238  lr: 6.0922e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:13:15 d2.utils.events]: \u001b[0m eta: 2:24:53  iter: 4319  total_loss: 2.028  loss_cls_stage0: 0.3126  loss_box_reg_stage0: 0.2155  loss_cls_stage1: 0.2432  loss_box_reg_stage1: 0.2796  loss_cls_stage2: 0.1703  loss_box_reg_stage2: 0.232  loss_mask: 0.5759  loss_rpn_cls: 0.06744  loss_rpn_loc: 0.0354  validation_loss: 2.028  time: 1.5491  data_time: 0.0240  lr: 6.0616e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:14:23 d2.utils.events]: \u001b[0m eta: 2:24:31  iter: 4339  total_loss: 2.307  loss_cls_stage0: 0.3395  loss_box_reg_stage0: 0.2308  loss_cls_stage1: 0.2711  loss_box_reg_stage1: 0.3018  loss_cls_stage2: 0.1838  loss_box_reg_stage2: 0.2405  loss_mask: 0.595  loss_rpn_cls: 0.07248  loss_rpn_loc: 0.04063  validation_loss: 2.028  time: 1.5576  data_time: 0.0254  lr: 6.0309e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:15:32 d2.utils.events]: \u001b[0m eta: 2:24:05  iter: 4359  total_loss: 2.042  loss_cls_stage0: 0.2802  loss_box_reg_stage0: 0.1938  loss_cls_stage1: 0.2435  loss_box_reg_stage1: 0.2887  loss_cls_stage2: 0.1724  loss_box_reg_stage2: 0.2267  loss_mask: 0.546  loss_rpn_cls: 0.06938  loss_rpn_loc: 0.03272  validation_loss: 2.028  time: 1.5664  data_time: 0.0259  lr: 6.0001e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:16:42 d2.utils.events]: \u001b[0m eta: 2:23:40  iter: 4379  total_loss: 2.138  loss_cls_stage0: 0.2954  loss_box_reg_stage0: 0.2204  loss_cls_stage1: 0.2413  loss_box_reg_stage1: 0.294  loss_cls_stage2: 0.1715  loss_box_reg_stage2: 0.2396  loss_mask: 0.5326  loss_rpn_cls: 0.07493  loss_rpn_loc: 0.0356  validation_loss: 2.028  time: 1.5751  data_time: 0.0251  lr: 5.9693e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:17:49 d2.utils.events]: \u001b[0m eta: 2:23:15  iter: 4399  total_loss: 2.1  loss_cls_stage0: 0.2911  loss_box_reg_stage0: 0.1893  loss_cls_stage1: 0.2387  loss_box_reg_stage1: 0.2788  loss_cls_stage2: 0.1759  loss_box_reg_stage2: 0.2155  loss_mask: 0.5606  loss_rpn_cls: 0.07312  loss_rpn_loc: 0.03313  validation_loss: 2.028  time: 1.5834  data_time: 0.0238  lr: 5.9384e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:18:59 d2.utils.events]: \u001b[0m eta: 2:22:53  iter: 4419  total_loss: 2.325  loss_cls_stage0: 0.3314  loss_box_reg_stage0: 0.2268  loss_cls_stage1: 0.2681  loss_box_reg_stage1: 0.314  loss_cls_stage2: 0.2038  loss_box_reg_stage2: 0.2556  loss_mask: 0.5523  loss_rpn_cls: 0.07509  loss_rpn_loc: 0.0382  validation_loss: 2.028  time: 1.5919  data_time: 0.0257  lr: 5.9076e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:20:08 d2.utils.events]: \u001b[0m eta: 2:22:34  iter: 4439  total_loss: 2.189  loss_cls_stage0: 0.3138  loss_box_reg_stage0: 0.224  loss_cls_stage1: 0.2592  loss_box_reg_stage1: 0.2964  loss_cls_stage2: 0.1891  loss_box_reg_stage2: 0.2204  loss_mask: 0.5585  loss_rpn_cls: 0.08448  loss_rpn_loc: 0.04064  validation_loss: 2.028  time: 1.6003  data_time: 0.0238  lr: 5.8767e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:21:17 d2.utils.events]: \u001b[0m eta: 2:22:13  iter: 4459  total_loss: 2.323  loss_cls_stage0: 0.3346  loss_box_reg_stage0: 0.2381  loss_cls_stage1: 0.2754  loss_box_reg_stage1: 0.33  loss_cls_stage2: 0.1992  loss_box_reg_stage2: 0.2609  loss_mask: 0.5848  loss_rpn_cls: 0.07795  loss_rpn_loc: 0.04184  validation_loss: 2.028  time: 1.6085  data_time: 0.0247  lr: 5.8457e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:22:26 d2.utils.events]: \u001b[0m eta: 2:21:47  iter: 4479  total_loss: 2.103  loss_cls_stage0: 0.3027  loss_box_reg_stage0: 0.2279  loss_cls_stage1: 0.2447  loss_box_reg_stage1: 0.3121  loss_cls_stage2: 0.175  loss_box_reg_stage2: 0.2244  loss_mask: 0.5277  loss_rpn_cls: 0.06665  loss_rpn_loc: 0.03306  validation_loss: 2.028  time: 1.6168  data_time: 0.0237  lr: 5.8147e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:23:36 d2.utils.events]: \u001b[0m eta: 2:21:27  iter: 4499  total_loss: 2.079  loss_cls_stage0: 0.2991  loss_box_reg_stage0: 0.2222  loss_cls_stage1: 0.2349  loss_box_reg_stage1: 0.2778  loss_cls_stage2: 0.1678  loss_box_reg_stage2: 0.2375  loss_mask: 0.533  loss_rpn_cls: 0.07438  loss_rpn_loc: 0.03269  validation_loss: 2.028  time: 1.6251  data_time: 0.0239  lr: 5.7837e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:24:36 d2.utils.events]: \u001b[0m eta: 2:21:08  iter: 4519  total_loss: 2.107  loss_cls_stage0: 0.2775  loss_box_reg_stage0: 0.2213  loss_cls_stage1: 0.2247  loss_box_reg_stage1: 0.2782  loss_cls_stage2: 0.1538  loss_box_reg_stage2: 0.2315  loss_mask: 0.5149  loss_rpn_cls: 0.06552  loss_rpn_loc: 0.03466  validation_loss: 2.028  time: 1.6314  data_time: 0.0232  lr: 5.7527e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:25:28 d2.utils.events]: \u001b[0m eta: 2:20:50  iter: 4539  total_loss: 2.105  loss_cls_stage0: 0.2908  loss_box_reg_stage0: 0.1999  loss_cls_stage1: 0.2263  loss_box_reg_stage1: 0.2801  loss_cls_stage2: 0.1678  loss_box_reg_stage2: 0.2216  loss_mask: 0.5269  loss_rpn_cls: 0.0687  loss_rpn_loc: 0.03157  validation_loss: 2.028  time: 1.6354  data_time: 0.0235  lr: 5.7216e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:26:30 d2.utils.events]: \u001b[0m eta: 2:20:32  iter: 4559  total_loss: 2.09  loss_cls_stage0: 0.2869  loss_box_reg_stage0: 0.2156  loss_cls_stage1: 0.2388  loss_box_reg_stage1: 0.3046  loss_cls_stage2: 0.1694  loss_box_reg_stage2: 0.242  loss_mask: 0.5832  loss_rpn_cls: 0.06531  loss_rpn_loc: 0.0296  validation_loss: 2.028  time: 1.6419  data_time: 0.0250  lr: 5.6905e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:27:42 d2.utils.events]: \u001b[0m eta: 2:20:15  iter: 4579  total_loss: 2.162  loss_cls_stage0: 0.2979  loss_box_reg_stage0: 0.2229  loss_cls_stage1: 0.2461  loss_box_reg_stage1: 0.3001  loss_cls_stage2: 0.1891  loss_box_reg_stage2: 0.2543  loss_mask: 0.5586  loss_rpn_cls: 0.07219  loss_rpn_loc: 0.03786  validation_loss: 2.028  time: 1.6504  data_time: 0.0240  lr: 5.6594e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:28:41 d2.utils.events]: \u001b[0m eta: 2:19:55  iter: 4599  total_loss: 2.241  loss_cls_stage0: 0.2984  loss_box_reg_stage0: 0.2067  loss_cls_stage1: 0.2536  loss_box_reg_stage1: 0.305  loss_cls_stage2: 0.1828  loss_box_reg_stage2: 0.2617  loss_mask: 0.5308  loss_rpn_cls: 0.08034  loss_rpn_loc: 0.03925  validation_loss: 2.028  time: 1.6562  data_time: 0.0249  lr: 5.6282e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:29:39 d2.utils.events]: \u001b[0m eta: 2:19:39  iter: 4619  total_loss: 2.204  loss_cls_stage0: 0.31  loss_box_reg_stage0: 0.2305  loss_cls_stage1: 0.2577  loss_box_reg_stage1: 0.3176  loss_cls_stage2: 0.1893  loss_box_reg_stage2: 0.2458  loss_mask: 0.5459  loss_rpn_cls: 0.07032  loss_rpn_loc: 0.04007  validation_loss: 2.028  time: 1.6615  data_time: 0.0241  lr: 5.597e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:30:39 d2.utils.events]: \u001b[0m eta: 2:19:36  iter: 4639  total_loss: 2.211  loss_cls_stage0: 0.3068  loss_box_reg_stage0: 0.2374  loss_cls_stage1: 0.2605  loss_box_reg_stage1: 0.3091  loss_cls_stage2: 0.1829  loss_box_reg_stage2: 0.2516  loss_mask: 0.5179  loss_rpn_cls: 0.06469  loss_rpn_loc: 0.03457  validation_loss: 2.028  time: 1.6672  data_time: 0.0241  lr: 5.5658e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:31:38 d2.utils.events]: \u001b[0m eta: 2:19:38  iter: 4659  total_loss: 2.202  loss_cls_stage0: 0.3152  loss_box_reg_stage0: 0.2425  loss_cls_stage1: 0.2625  loss_box_reg_stage1: 0.3294  loss_cls_stage2: 0.1887  loss_box_reg_stage2: 0.2741  loss_mask: 0.531  loss_rpn_cls: 0.07572  loss_rpn_loc: 0.03791  validation_loss: 2.028  time: 1.6729  data_time: 0.0243  lr: 5.5346e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:32:36 d2.utils.events]: \u001b[0m eta: 2:20:54  iter: 4679  total_loss: 2.323  loss_cls_stage0: 0.3396  loss_box_reg_stage0: 0.2356  loss_cls_stage1: 0.2881  loss_box_reg_stage1: 0.32  loss_cls_stage2: 0.2088  loss_box_reg_stage2: 0.2615  loss_mask: 0.5733  loss_rpn_cls: 0.0743  loss_rpn_loc: 0.03997  validation_loss: 2.028  time: 1.6781  data_time: 0.0246  lr: 5.5034e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:33:36 d2.utils.events]: \u001b[0m eta: 3:25:23  iter: 4699  total_loss: 2.154  loss_cls_stage0: 0.3103  loss_box_reg_stage0: 0.2283  loss_cls_stage1: 0.2475  loss_box_reg_stage1: 0.2843  loss_cls_stage2: 0.1763  loss_box_reg_stage2: 0.2351  loss_mask: 0.5432  loss_rpn_cls: 0.07213  loss_rpn_loc: 0.03361  validation_loss: 2.028  time: 1.6836  data_time: 0.0244  lr: 5.4721e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:34:35 d2.utils.events]: \u001b[0m eta: 3:41:16  iter: 4719  total_loss: 2.136  loss_cls_stage0: 0.3121  loss_box_reg_stage0: 0.2236  loss_cls_stage1: 0.2564  loss_box_reg_stage1: 0.293  loss_cls_stage2: 0.1895  loss_box_reg_stage2: 0.2228  loss_mask: 0.5479  loss_rpn_cls: 0.06371  loss_rpn_loc: 0.0325  validation_loss: 2.028  time: 1.6890  data_time: 0.0244  lr: 5.4408e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:35:33 d2.utils.events]: \u001b[0m eta: 3:43:22  iter: 4739  total_loss: 2.172  loss_cls_stage0: 0.3139  loss_box_reg_stage0: 0.2275  loss_cls_stage1: 0.2515  loss_box_reg_stage1: 0.2897  loss_cls_stage2: 0.1761  loss_box_reg_stage2: 0.2323  loss_mask: 0.5432  loss_rpn_cls: 0.07159  loss_rpn_loc: 0.03966  validation_loss: 2.028  time: 1.6941  data_time: 0.0228  lr: 5.4095e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:36:32 d2.utils.events]: \u001b[0m eta: 3:44:29  iter: 4759  total_loss: 2.166  loss_cls_stage0: 0.2839  loss_box_reg_stage0: 0.2254  loss_cls_stage1: 0.2476  loss_box_reg_stage1: 0.324  loss_cls_stage2: 0.181  loss_box_reg_stage2: 0.2614  loss_mask: 0.5204  loss_rpn_cls: 0.05945  loss_rpn_loc: 0.03734  validation_loss: 2.028  time: 1.6994  data_time: 0.0242  lr: 5.3782e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:37:30 d2.utils.events]: \u001b[0m eta: 3:45:21  iter: 4779  total_loss: 2.141  loss_cls_stage0: 0.2935  loss_box_reg_stage0: 0.1998  loss_cls_stage1: 0.2525  loss_box_reg_stage1: 0.3014  loss_cls_stage2: 0.1823  loss_box_reg_stage2: 0.248  loss_mask: 0.5614  loss_rpn_cls: 0.06381  loss_rpn_loc: 0.03479  validation_loss: 2.028  time: 1.7044  data_time: 0.0243  lr: 5.3469e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:38:29 d2.utils.events]: \u001b[0m eta: 3:50:12  iter: 4799  total_loss: 2.256  loss_cls_stage0: 0.3271  loss_box_reg_stage0: 0.2424  loss_cls_stage1: 0.2624  loss_box_reg_stage1: 0.3199  loss_cls_stage2: 0.1929  loss_box_reg_stage2: 0.2524  loss_mask: 0.5302  loss_rpn_cls: 0.07736  loss_rpn_loc: 0.0384  validation_loss: 2.028  time: 1.7097  data_time: 0.0235  lr: 5.3155e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:39:29 d2.utils.events]: \u001b[0m eta: 4:07:28  iter: 4819  total_loss: 2.416  loss_cls_stage0: 0.3307  loss_box_reg_stage0: 0.2311  loss_cls_stage1: 0.2794  loss_box_reg_stage1: 0.3465  loss_cls_stage2: 0.2055  loss_box_reg_stage2: 0.2804  loss_mask: 0.5917  loss_rpn_cls: 0.06733  loss_rpn_loc: 0.03675  validation_loss: 2.028  time: 1.7150  data_time: 0.0241  lr: 5.2842e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:40:19 d2.utils.events]: \u001b[0m eta: 4:08:34  iter: 4839  total_loss: 2.397  loss_cls_stage0: 0.3738  loss_box_reg_stage0: 0.2621  loss_cls_stage1: 0.304  loss_box_reg_stage1: 0.3128  loss_cls_stage2: 0.2065  loss_box_reg_stage2: 0.252  loss_mask: 0.5704  loss_rpn_cls: 0.07772  loss_rpn_loc: 0.03994  validation_loss: 2.028  time: 1.7182  data_time: 0.0246  lr: 5.2528e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:40:50 d2.utils.events]: \u001b[0m eta: 4:07:36  iter: 4859  total_loss: 2.272  loss_cls_stage0: 0.3228  loss_box_reg_stage0: 0.2362  loss_cls_stage1: 0.2518  loss_box_reg_stage1: 0.3332  loss_cls_stage2: 0.1722  loss_box_reg_stage2: 0.2692  loss_mask: 0.5885  loss_rpn_cls: 0.07128  loss_rpn_loc: 0.03595  validation_loss: 2.028  time: 1.7175  data_time: 0.0230  lr: 5.2214e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:41:21 d2.utils.events]: \u001b[0m eta: 4:06:38  iter: 4879  total_loss: 2.247  loss_cls_stage0: 0.3298  loss_box_reg_stage0: 0.2418  loss_cls_stage1: 0.2542  loss_box_reg_stage1: 0.3186  loss_cls_stage2: 0.1953  loss_box_reg_stage2: 0.2503  loss_mask: 0.5694  loss_rpn_cls: 0.07658  loss_rpn_loc: 0.03773  validation_loss: 2.028  time: 1.7168  data_time: 0.0245  lr: 5.19e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:41:52 d2.utils.events]: \u001b[0m eta: 4:05:41  iter: 4899  total_loss: 2.39  loss_cls_stage0: 0.3423  loss_box_reg_stage0: 0.2485  loss_cls_stage1: 0.3055  loss_box_reg_stage1: 0.3411  loss_cls_stage2: 0.2051  loss_box_reg_stage2: 0.2742  loss_mask: 0.5453  loss_rpn_cls: 0.06657  loss_rpn_loc: 0.03595  validation_loss: 2.028  time: 1.7161  data_time: 0.0258  lr: 5.1586e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:42:23 d2.utils.events]: \u001b[0m eta: 4:04:43  iter: 4919  total_loss: 2.132  loss_cls_stage0: 0.3111  loss_box_reg_stage0: 0.2229  loss_cls_stage1: 0.2536  loss_box_reg_stage1: 0.309  loss_cls_stage2: 0.1729  loss_box_reg_stage2: 0.2397  loss_mask: 0.5324  loss_rpn_cls: 0.06228  loss_rpn_loc: 0.03302  validation_loss: 2.028  time: 1.7154  data_time: 0.0259  lr: 5.1272e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:42:54 d2.utils.events]: \u001b[0m eta: 4:03:45  iter: 4939  total_loss: 2.262  loss_cls_stage0: 0.3538  loss_box_reg_stage0: 0.2648  loss_cls_stage1: 0.2758  loss_box_reg_stage1: 0.3377  loss_cls_stage2: 0.1871  loss_box_reg_stage2: 0.2538  loss_mask: 0.5522  loss_rpn_cls: 0.07728  loss_rpn_loc: 0.03872  validation_loss: 2.028  time: 1.7147  data_time: 0.0245  lr: 5.0958e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:43:25 d2.utils.events]: \u001b[0m eta: 4:02:47  iter: 4959  total_loss: 2.209  loss_cls_stage0: 0.3148  loss_box_reg_stage0: 0.2346  loss_cls_stage1: 0.2625  loss_box_reg_stage1: 0.3217  loss_cls_stage2: 0.195  loss_box_reg_stage2: 0.2494  loss_mask: 0.5442  loss_rpn_cls: 0.07522  loss_rpn_loc: 0.03744  validation_loss: 2.028  time: 1.7141  data_time: 0.0232  lr: 5.0644e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:44:03 d2.utils.events]: \u001b[0m eta: 4:01:49  iter: 4979  total_loss: 2.062  loss_cls_stage0: 0.2786  loss_box_reg_stage0: 0.2048  loss_cls_stage1: 0.2324  loss_box_reg_stage1: 0.2913  loss_cls_stage2: 0.1733  loss_box_reg_stage2: 0.2577  loss_mask: 0.5591  loss_rpn_cls: 0.06505  loss_rpn_loc: 0.03796  validation_loss: 2.028  time: 1.7149  data_time: 0.0244  lr: 5.033e-05  max_mem: 11723M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/26 18:44:55 d2.data.common]: \u001b[0mSerializing 859 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/26 18:44:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.90 MiB\n",
      "\u001b[32m[03/26 18:44:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 859 images\n",
      "\u001b[32m[03/26 18:44:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/859. 0.1480 s / img. ETA=0:02:29\n",
      "\u001b[32m[03/26 18:45:03 d2.evaluation.evaluator]: \u001b[0mInference done 40/859. 0.1509 s / img. ETA=0:02:24\n",
      "\u001b[32m[03/26 18:45:08 d2.evaluation.evaluator]: \u001b[0mInference done 67/859. 0.1523 s / img. ETA=0:02:23\n",
      "\u001b[32m[03/26 18:45:13 d2.evaluation.evaluator]: \u001b[0mInference done 94/859. 0.1538 s / img. ETA=0:02:20\n",
      "\u001b[32m[03/26 18:45:18 d2.evaluation.evaluator]: \u001b[0mInference done 123/859. 0.1531 s / img. ETA=0:02:14\n",
      "\u001b[32m[03/26 18:45:23 d2.evaluation.evaluator]: \u001b[0mInference done 150/859. 0.1531 s / img. ETA=0:02:09\n",
      "\u001b[32m[03/26 18:45:28 d2.evaluation.evaluator]: \u001b[0mInference done 177/859. 0.1536 s / img. ETA=0:02:05\n",
      "\u001b[32m[03/26 18:45:34 d2.evaluation.evaluator]: \u001b[0mInference done 205/859. 0.1533 s / img. ETA=0:02:00\n",
      "\u001b[32m[03/26 18:45:39 d2.evaluation.evaluator]: \u001b[0mInference done 233/859. 0.1529 s / img. ETA=0:01:54\n",
      "\u001b[32m[03/26 18:45:44 d2.evaluation.evaluator]: \u001b[0mInference done 264/859. 0.1505 s / img. ETA=0:01:47\n",
      "\u001b[32m[03/26 18:45:49 d2.evaluation.evaluator]: \u001b[0mInference done 290/859. 0.1510 s / img. ETA=0:01:43\n",
      "\u001b[32m[03/26 18:45:54 d2.evaluation.evaluator]: \u001b[0mInference done 318/859. 0.1515 s / img. ETA=0:01:38\n",
      "\u001b[32m[03/26 18:45:59 d2.evaluation.evaluator]: \u001b[0mInference done 346/859. 0.1519 s / img. ETA=0:01:33\n",
      "\u001b[32m[03/26 18:46:04 d2.evaluation.evaluator]: \u001b[0mInference done 374/859. 0.1522 s / img. ETA=0:01:28\n",
      "\u001b[32m[03/26 18:46:09 d2.evaluation.evaluator]: \u001b[0mInference done 400/859. 0.1527 s / img. ETA=0:01:23\n",
      "\u001b[32m[03/26 18:46:14 d2.evaluation.evaluator]: \u001b[0mInference done 428/859. 0.1527 s / img. ETA=0:01:18\n",
      "\u001b[32m[03/26 18:46:19 d2.evaluation.evaluator]: \u001b[0mInference done 455/859. 0.1529 s / img. ETA=0:01:13\n",
      "\u001b[32m[03/26 18:46:24 d2.evaluation.evaluator]: \u001b[0mInference done 483/859. 0.1528 s / img. ETA=0:01:08\n",
      "\u001b[32m[03/26 18:46:29 d2.evaluation.evaluator]: \u001b[0mInference done 513/859. 0.1519 s / img. ETA=0:01:02\n",
      "\u001b[32m[03/26 18:46:34 d2.evaluation.evaluator]: \u001b[0mInference done 541/859. 0.1518 s / img. ETA=0:00:57\n",
      "\u001b[32m[03/26 18:46:39 d2.evaluation.evaluator]: \u001b[0mInference done 567/859. 0.1520 s / img. ETA=0:00:53\n",
      "\u001b[32m[03/26 18:46:45 d2.evaluation.evaluator]: \u001b[0mInference done 595/859. 0.1522 s / img. ETA=0:00:48\n",
      "\u001b[32m[03/26 18:46:50 d2.evaluation.evaluator]: \u001b[0mInference done 623/859. 0.1523 s / img. ETA=0:00:43\n",
      "\u001b[32m[03/26 18:46:55 d2.evaluation.evaluator]: \u001b[0mInference done 651/859. 0.1524 s / img. ETA=0:00:37\n",
      "\u001b[32m[03/26 18:47:00 d2.evaluation.evaluator]: \u001b[0mInference done 679/859. 0.1523 s / img. ETA=0:00:32\n",
      "\u001b[32m[03/26 18:47:05 d2.evaluation.evaluator]: \u001b[0mInference done 706/859. 0.1526 s / img. ETA=0:00:27\n",
      "\u001b[32m[03/26 18:47:10 d2.evaluation.evaluator]: \u001b[0mInference done 736/859. 0.1518 s / img. ETA=0:00:22\n",
      "\u001b[32m[03/26 18:47:15 d2.evaluation.evaluator]: \u001b[0mInference done 763/859. 0.1520 s / img. ETA=0:00:17\n",
      "\u001b[32m[03/26 18:47:20 d2.evaluation.evaluator]: \u001b[0mInference done 790/859. 0.1521 s / img. ETA=0:00:12\n",
      "\u001b[32m[03/26 18:47:25 d2.evaluation.evaluator]: \u001b[0mInference done 817/859. 0.1522 s / img. ETA=0:00:07\n",
      "\u001b[32m[03/26 18:47:30 d2.evaluation.evaluator]: \u001b[0mInference done 844/859. 0.1523 s / img. ETA=0:00:02\n",
      "\u001b[32m[03/26 18:47:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:36.317098 (0.183041 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/26 18:47:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:10 (0.152367 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.43 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.077\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.128\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.140\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.034\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.080\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.111\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.138\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.139\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.043\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.148\n",
      "\u001b[32m[03/26 18:47:34 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold2 in csv format:\n",
      "\u001b[32m[03/26 18:47:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/26 18:47:34 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/26 18:47:34 d2.evaluation.testing]: \u001b[0mcopypaste: 7.7419,12.7918,14.0234,0.3656,3.3990,7.9815\n",
      "validation do loss eval 2.264535105672293\n",
      "\u001b[32m[03/26 18:49:12 d2.utils.events]: \u001b[0m eta: 4:00:51  iter: 4999  total_loss: 2.439  loss_cls_stage0: 0.3526  loss_box_reg_stage0: 0.2419  loss_cls_stage1: 0.3008  loss_box_reg_stage1: 0.3681  loss_cls_stage2: 0.2121  loss_box_reg_stage2: 0.2845  loss_mask: 0.593  loss_rpn_cls: 0.06268  loss_rpn_loc: 0.03212  validation_loss: 2.076  time: 1.7181  data_time: 0.0233  lr: 5.0016e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:49:43 d2.utils.events]: \u001b[0m eta: 3:59:54  iter: 5019  total_loss: 2.207  loss_cls_stage0: 0.3041  loss_box_reg_stage0: 0.2211  loss_cls_stage1: 0.2624  loss_box_reg_stage1: 0.3213  loss_cls_stage2: 0.1891  loss_box_reg_stage2: 0.2531  loss_mask: 0.5362  loss_rpn_cls: 0.06444  loss_rpn_loc: 0.03088  validation_loss: 2.076  time: 1.7172  data_time: 0.0242  lr: 4.9702e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:50:13 d2.utils.events]: \u001b[0m eta: 3:58:56  iter: 5039  total_loss: 2.218  loss_cls_stage0: 0.31  loss_box_reg_stage0: 0.2325  loss_cls_stage1: 0.2577  loss_box_reg_stage1: 0.3337  loss_cls_stage2: 0.1916  loss_box_reg_stage2: 0.2509  loss_mask: 0.6001  loss_rpn_cls: 0.06449  loss_rpn_loc: 0.03643  validation_loss: 2.076  time: 1.7166  data_time: 0.0323  lr: 4.9387e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:50:44 d2.utils.events]: \u001b[0m eta: 3:57:58  iter: 5059  total_loss: 2.285  loss_cls_stage0: 0.3107  loss_box_reg_stage0: 0.2383  loss_cls_stage1: 0.2668  loss_box_reg_stage1: 0.3256  loss_cls_stage2: 0.1839  loss_box_reg_stage2: 0.2768  loss_mask: 0.5374  loss_rpn_cls: 0.08158  loss_rpn_loc: 0.03914  validation_loss: 2.076  time: 1.7159  data_time: 0.0241  lr: 4.9073e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:51:16 d2.utils.events]: \u001b[0m eta: 3:57:00  iter: 5079  total_loss: 2.287  loss_cls_stage0: 0.3024  loss_box_reg_stage0: 0.2338  loss_cls_stage1: 0.2559  loss_box_reg_stage1: 0.3274  loss_cls_stage2: 0.1975  loss_box_reg_stage2: 0.2724  loss_mask: 0.5519  loss_rpn_cls: 0.07499  loss_rpn_loc: 0.04134  validation_loss: 2.076  time: 1.7153  data_time: 0.0227  lr: 4.8759e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:51:46 d2.utils.events]: \u001b[0m eta: 3:56:02  iter: 5099  total_loss: 2.173  loss_cls_stage0: 0.3113  loss_box_reg_stage0: 0.2172  loss_cls_stage1: 0.2539  loss_box_reg_stage1: 0.3068  loss_cls_stage2: 0.1885  loss_box_reg_stage2: 0.2598  loss_mask: 0.5401  loss_rpn_cls: 0.06425  loss_rpn_loc: 0.03207  validation_loss: 2.076  time: 1.7146  data_time: 0.0233  lr: 4.8445e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:52:17 d2.utils.events]: \u001b[0m eta: 3:55:05  iter: 5119  total_loss: 2.256  loss_cls_stage0: 0.3192  loss_box_reg_stage0: 0.2263  loss_cls_stage1: 0.2663  loss_box_reg_stage1: 0.3226  loss_cls_stage2: 0.1915  loss_box_reg_stage2: 0.2646  loss_mask: 0.5306  loss_rpn_cls: 0.07352  loss_rpn_loc: 0.03671  validation_loss: 2.076  time: 1.7139  data_time: 0.0238  lr: 4.8131e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:52:48 d2.utils.events]: \u001b[0m eta: 3:54:07  iter: 5139  total_loss: 2.013  loss_cls_stage0: 0.2796  loss_box_reg_stage0: 0.2155  loss_cls_stage1: 0.2227  loss_box_reg_stage1: 0.284  loss_cls_stage2: 0.1623  loss_box_reg_stage2: 0.2356  loss_mask: 0.5426  loss_rpn_cls: 0.06474  loss_rpn_loc: 0.02996  validation_loss: 2.076  time: 1.7133  data_time: 0.0239  lr: 4.7817e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:53:19 d2.utils.events]: \u001b[0m eta: 3:53:09  iter: 5159  total_loss: 2.241  loss_cls_stage0: 0.326  loss_box_reg_stage0: 0.243  loss_cls_stage1: 0.2652  loss_box_reg_stage1: 0.3252  loss_cls_stage2: 0.1859  loss_box_reg_stage2: 0.2545  loss_mask: 0.5613  loss_rpn_cls: 0.06856  loss_rpn_loc: 0.03753  validation_loss: 2.076  time: 1.7126  data_time: 0.0255  lr: 4.7503e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:53:50 d2.utils.events]: \u001b[0m eta: 3:52:11  iter: 5179  total_loss: 2.255  loss_cls_stage0: 0.3173  loss_box_reg_stage0: 0.2285  loss_cls_stage1: 0.2509  loss_box_reg_stage1: 0.3359  loss_cls_stage2: 0.1846  loss_box_reg_stage2: 0.2703  loss_mask: 0.5667  loss_rpn_cls: 0.06764  loss_rpn_loc: 0.03693  validation_loss: 2.076  time: 1.7120  data_time: 0.0247  lr: 4.719e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:54:21 d2.utils.events]: \u001b[0m eta: 3:51:13  iter: 5199  total_loss: 2.08  loss_cls_stage0: 0.2881  loss_box_reg_stage0: 0.2141  loss_cls_stage1: 0.231  loss_box_reg_stage1: 0.305  loss_cls_stage2: 0.1671  loss_box_reg_stage2: 0.2492  loss_mask: 0.4891  loss_rpn_cls: 0.07313  loss_rpn_loc: 0.03448  validation_loss: 2.076  time: 1.7114  data_time: 0.0248  lr: 4.6876e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:54:53 d2.utils.events]: \u001b[0m eta: 3:50:16  iter: 5219  total_loss: 2.271  loss_cls_stage0: 0.3006  loss_box_reg_stage0: 0.2315  loss_cls_stage1: 0.2572  loss_box_reg_stage1: 0.3245  loss_cls_stage2: 0.1782  loss_box_reg_stage2: 0.2642  loss_mask: 0.5898  loss_rpn_cls: 0.06559  loss_rpn_loc: 0.03583  validation_loss: 2.076  time: 1.7108  data_time: 0.0252  lr: 4.6563e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:55:24 d2.utils.events]: \u001b[0m eta: 3:49:18  iter: 5239  total_loss: 2.202  loss_cls_stage0: 0.308  loss_box_reg_stage0: 0.2298  loss_cls_stage1: 0.2514  loss_box_reg_stage1: 0.3208  loss_cls_stage2: 0.1871  loss_box_reg_stage2: 0.2628  loss_mask: 0.526  loss_rpn_cls: 0.07521  loss_rpn_loc: 0.03837  validation_loss: 2.076  time: 1.7102  data_time: 0.0230  lr: 4.6249e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:55:55 d2.utils.events]: \u001b[0m eta: 3:48:08  iter: 5259  total_loss: 2.392  loss_cls_stage0: 0.3247  loss_box_reg_stage0: 0.2529  loss_cls_stage1: 0.2742  loss_box_reg_stage1: 0.3694  loss_cls_stage2: 0.1898  loss_box_reg_stage2: 0.2891  loss_mask: 0.5621  loss_rpn_cls: 0.0732  loss_rpn_loc: 0.03894  validation_loss: 2.076  time: 1.7096  data_time: 0.0238  lr: 4.5936e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:56:26 d2.utils.events]: \u001b[0m eta: 3:42:03  iter: 5279  total_loss: 2.247  loss_cls_stage0: 0.2993  loss_box_reg_stage0: 0.2441  loss_cls_stage1: 0.2514  loss_box_reg_stage1: 0.3429  loss_cls_stage2: 0.1918  loss_box_reg_stage2: 0.2711  loss_mask: 0.5584  loss_rpn_cls: 0.06117  loss_rpn_loc: 0.03454  validation_loss: 2.076  time: 1.7090  data_time: 0.0240  lr: 4.5623e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:56:57 d2.utils.events]: \u001b[0m eta: 3:22:14  iter: 5299  total_loss: 2.229  loss_cls_stage0: 0.2918  loss_box_reg_stage0: 0.1978  loss_cls_stage1: 0.2455  loss_box_reg_stage1: 0.3106  loss_cls_stage2: 0.1809  loss_box_reg_stage2: 0.2671  loss_mask: 0.5111  loss_rpn_cls: 0.06399  loss_rpn_loc: 0.03307  validation_loss: 2.076  time: 1.7084  data_time: 0.0248  lr: 4.531e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:57:28 d2.utils.events]: \u001b[0m eta: 3:18:06  iter: 5319  total_loss: 2.213  loss_cls_stage0: 0.3117  loss_box_reg_stage0: 0.2337  loss_cls_stage1: 0.2594  loss_box_reg_stage1: 0.3328  loss_cls_stage2: 0.1809  loss_box_reg_stage2: 0.2778  loss_mask: 0.5161  loss_rpn_cls: 0.06167  loss_rpn_loc: 0.03258  validation_loss: 2.076  time: 1.7078  data_time: 0.0236  lr: 4.4998e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:57:59 d2.utils.events]: \u001b[0m eta: 3:12:41  iter: 5339  total_loss: 2.255  loss_cls_stage0: 0.3191  loss_box_reg_stage0: 0.2209  loss_cls_stage1: 0.2699  loss_box_reg_stage1: 0.3218  loss_cls_stage2: 0.1794  loss_box_reg_stage2: 0.2609  loss_mask: 0.5479  loss_rpn_cls: 0.07173  loss_rpn_loc: 0.03741  validation_loss: 2.076  time: 1.7073  data_time: 0.0240  lr: 4.4685e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:58:30 d2.utils.events]: \u001b[0m eta: 2:13:56  iter: 5359  total_loss: 2.077  loss_cls_stage0: 0.2937  loss_box_reg_stage0: 0.2251  loss_cls_stage1: 0.2456  loss_box_reg_stage1: 0.3084  loss_cls_stage2: 0.1802  loss_box_reg_stage2: 0.2804  loss_mask: 0.5013  loss_rpn_cls: 0.07117  loss_rpn_loc: 0.03765  validation_loss: 2.076  time: 1.7067  data_time: 0.0241  lr: 4.4373e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:59:01 d2.utils.events]: \u001b[0m eta: 2:04:07  iter: 5379  total_loss: 2.239  loss_cls_stage0: 0.3257  loss_box_reg_stage0: 0.233  loss_cls_stage1: 0.2635  loss_box_reg_stage1: 0.3196  loss_cls_stage2: 0.1913  loss_box_reg_stage2: 0.2541  loss_mask: 0.5738  loss_rpn_cls: 0.06756  loss_rpn_loc: 0.03577  validation_loss: 2.076  time: 1.7061  data_time: 0.0237  lr: 4.4061e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 18:59:32 d2.utils.events]: \u001b[0m eta: 2:02:11  iter: 5399  total_loss: 2.18  loss_cls_stage0: 0.3081  loss_box_reg_stage0: 0.23  loss_cls_stage1: 0.2615  loss_box_reg_stage1: 0.3344  loss_cls_stage2: 0.1877  loss_box_reg_stage2: 0.2757  loss_mask: 0.5506  loss_rpn_cls: 0.06247  loss_rpn_loc: 0.03554  validation_loss: 2.076  time: 1.7055  data_time: 0.0230  lr: 4.3749e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:00:03 d2.utils.events]: \u001b[0m eta: 2:01:09  iter: 5419  total_loss: 2.266  loss_cls_stage0: 0.303  loss_box_reg_stage0: 0.2263  loss_cls_stage1: 0.2524  loss_box_reg_stage1: 0.3226  loss_cls_stage2: 0.189  loss_box_reg_stage2: 0.2728  loss_mask: 0.5697  loss_rpn_cls: 0.06493  loss_rpn_loc: 0.03536  validation_loss: 2.076  time: 1.7049  data_time: 0.0240  lr: 4.3437e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:00:34 d2.utils.events]: \u001b[0m eta: 2:00:03  iter: 5439  total_loss: 2.165  loss_cls_stage0: 0.2719  loss_box_reg_stage0: 0.2173  loss_cls_stage1: 0.2383  loss_box_reg_stage1: 0.3376  loss_cls_stage2: 0.1772  loss_box_reg_stage2: 0.2748  loss_mask: 0.5517  loss_rpn_cls: 0.06108  loss_rpn_loc: 0.03199  validation_loss: 2.076  time: 1.7043  data_time: 0.0242  lr: 4.3126e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:01:05 d2.utils.events]: \u001b[0m eta: 1:59:10  iter: 5459  total_loss: 2.26  loss_cls_stage0: 0.3207  loss_box_reg_stage0: 0.2239  loss_cls_stage1: 0.2687  loss_box_reg_stage1: 0.3095  loss_cls_stage2: 0.2033  loss_box_reg_stage2: 0.2648  loss_mask: 0.5702  loss_rpn_cls: 0.06449  loss_rpn_loc: 0.03678  validation_loss: 2.076  time: 1.7038  data_time: 0.0254  lr: 4.2815e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:01:37 d2.utils.events]: \u001b[0m eta: 1:58:28  iter: 5479  total_loss: 2.245  loss_cls_stage0: 0.3166  loss_box_reg_stage0: 0.2446  loss_cls_stage1: 0.2583  loss_box_reg_stage1: 0.3439  loss_cls_stage2: 0.1865  loss_box_reg_stage2: 0.2622  loss_mask: 0.5203  loss_rpn_cls: 0.05948  loss_rpn_loc: 0.03336  validation_loss: 2.076  time: 1.7033  data_time: 0.0231  lr: 4.2504e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:02:08 d2.utils.events]: \u001b[0m eta: 1:57:47  iter: 5499  total_loss: 2.233  loss_cls_stage0: 0.3095  loss_box_reg_stage0: 0.24  loss_cls_stage1: 0.2471  loss_box_reg_stage1: 0.3253  loss_cls_stage2: 0.1805  loss_box_reg_stage2: 0.2561  loss_mask: 0.5338  loss_rpn_cls: 0.06978  loss_rpn_loc: 0.04326  validation_loss: 2.076  time: 1.7027  data_time: 0.0249  lr: 4.2194e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:02:39 d2.utils.events]: \u001b[0m eta: 1:57:05  iter: 5519  total_loss: 2.276  loss_cls_stage0: 0.3133  loss_box_reg_stage0: 0.2422  loss_cls_stage1: 0.2834  loss_box_reg_stage1: 0.3516  loss_cls_stage2: 0.2003  loss_box_reg_stage2: 0.2991  loss_mask: 0.5382  loss_rpn_cls: 0.06498  loss_rpn_loc: 0.03771  validation_loss: 2.076  time: 1.7023  data_time: 0.0248  lr: 4.1884e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:03:10 d2.utils.events]: \u001b[0m eta: 1:56:22  iter: 5539  total_loss: 2.306  loss_cls_stage0: 0.2985  loss_box_reg_stage0: 0.2374  loss_cls_stage1: 0.251  loss_box_reg_stage1: 0.3388  loss_cls_stage2: 0.1908  loss_box_reg_stage2: 0.2887  loss_mask: 0.5012  loss_rpn_cls: 0.07029  loss_rpn_loc: 0.03466  validation_loss: 2.076  time: 1.7017  data_time: 0.0241  lr: 4.1574e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:03:41 d2.utils.events]: \u001b[0m eta: 1:55:43  iter: 5559  total_loss: 2.397  loss_cls_stage0: 0.32  loss_box_reg_stage0: 0.2402  loss_cls_stage1: 0.2686  loss_box_reg_stage1: 0.3421  loss_cls_stage2: 0.1979  loss_box_reg_stage2: 0.2818  loss_mask: 0.5305  loss_rpn_cls: 0.07243  loss_rpn_loc: 0.03618  validation_loss: 2.076  time: 1.7012  data_time: 0.0236  lr: 4.1264e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:04:13 d2.utils.events]: \u001b[0m eta: 1:55:06  iter: 5579  total_loss: 2.177  loss_cls_stage0: 0.3131  loss_box_reg_stage0: 0.2538  loss_cls_stage1: 0.2561  loss_box_reg_stage1: 0.3489  loss_cls_stage2: 0.1961  loss_box_reg_stage2: 0.2695  loss_mask: 0.4933  loss_rpn_cls: 0.062  loss_rpn_loc: 0.03807  validation_loss: 2.076  time: 1.7007  data_time: 0.0225  lr: 4.0955e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:04:44 d2.utils.events]: \u001b[0m eta: 1:54:26  iter: 5599  total_loss: 2.129  loss_cls_stage0: 0.2924  loss_box_reg_stage0: 0.2219  loss_cls_stage1: 0.2417  loss_box_reg_stage1: 0.3063  loss_cls_stage2: 0.1769  loss_box_reg_stage2: 0.2664  loss_mask: 0.5653  loss_rpn_cls: 0.06411  loss_rpn_loc: 0.03189  validation_loss: 2.076  time: 1.7001  data_time: 0.0241  lr: 4.0646e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:05:15 d2.utils.events]: \u001b[0m eta: 1:53:51  iter: 5619  total_loss: 2.383  loss_cls_stage0: 0.3433  loss_box_reg_stage0: 0.2511  loss_cls_stage1: 0.2884  loss_box_reg_stage1: 0.3232  loss_cls_stage2: 0.1954  loss_box_reg_stage2: 0.2722  loss_mask: 0.5183  loss_rpn_cls: 0.06629  loss_rpn_loc: 0.0338  validation_loss: 2.076  time: 1.6996  data_time: 0.0254  lr: 4.0338e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:05:46 d2.utils.events]: \u001b[0m eta: 1:53:13  iter: 5639  total_loss: 2.265  loss_cls_stage0: 0.3067  loss_box_reg_stage0: 0.237  loss_cls_stage1: 0.2532  loss_box_reg_stage1: 0.3352  loss_cls_stage2: 0.178  loss_box_reg_stage2: 0.2678  loss_mask: 0.5473  loss_rpn_cls: 0.07019  loss_rpn_loc: 0.04047  validation_loss: 2.076  time: 1.6991  data_time: 0.0261  lr: 4.003e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:06:17 d2.utils.events]: \u001b[0m eta: 1:52:37  iter: 5659  total_loss: 2.26  loss_cls_stage0: 0.3284  loss_box_reg_stage0: 0.2393  loss_cls_stage1: 0.2805  loss_box_reg_stage1: 0.3226  loss_cls_stage2: 0.2031  loss_box_reg_stage2: 0.2745  loss_mask: 0.5739  loss_rpn_cls: 0.06979  loss_rpn_loc: 0.03521  validation_loss: 2.076  time: 1.6986  data_time: 0.0261  lr: 3.9722e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:06:48 d2.utils.events]: \u001b[0m eta: 1:52:00  iter: 5679  total_loss: 2.282  loss_cls_stage0: 0.2899  loss_box_reg_stage0: 0.226  loss_cls_stage1: 0.2615  loss_box_reg_stage1: 0.3093  loss_cls_stage2: 0.1961  loss_box_reg_stage2: 0.2769  loss_mask: 0.5086  loss_rpn_cls: 0.07453  loss_rpn_loc: 0.03451  validation_loss: 2.076  time: 1.6981  data_time: 0.0238  lr: 3.9415e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:07:19 d2.utils.events]: \u001b[0m eta: 1:51:21  iter: 5699  total_loss: 2.195  loss_cls_stage0: 0.2928  loss_box_reg_stage0: 0.2328  loss_cls_stage1: 0.2479  loss_box_reg_stage1: 0.3372  loss_cls_stage2: 0.1786  loss_box_reg_stage2: 0.2509  loss_mask: 0.5251  loss_rpn_cls: 0.07223  loss_rpn_loc: 0.03933  validation_loss: 2.076  time: 1.6976  data_time: 0.0235  lr: 3.9108e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:07:50 d2.utils.events]: \u001b[0m eta: 1:50:46  iter: 5719  total_loss: 2.285  loss_cls_stage0: 0.3108  loss_box_reg_stage0: 0.2429  loss_cls_stage1: 0.2627  loss_box_reg_stage1: 0.3498  loss_cls_stage2: 0.1879  loss_box_reg_stage2: 0.302  loss_mask: 0.519  loss_rpn_cls: 0.06215  loss_rpn_loc: 0.03522  validation_loss: 2.076  time: 1.6971  data_time: 0.0240  lr: 3.8802e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:08:21 d2.utils.events]: \u001b[0m eta: 1:50:12  iter: 5739  total_loss: 2.345  loss_cls_stage0: 0.3136  loss_box_reg_stage0: 0.2159  loss_cls_stage1: 0.2415  loss_box_reg_stage1: 0.3306  loss_cls_stage2: 0.1804  loss_box_reg_stage2: 0.259  loss_mask: 0.5481  loss_rpn_cls: 0.05481  loss_rpn_loc: 0.03285  validation_loss: 2.076  time: 1.6966  data_time: 0.0250  lr: 3.8496e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:08:52 d2.utils.events]: \u001b[0m eta: 1:49:36  iter: 5759  total_loss: 2.247  loss_cls_stage0: 0.3439  loss_box_reg_stage0: 0.2517  loss_cls_stage1: 0.2612  loss_box_reg_stage1: 0.3402  loss_cls_stage2: 0.1858  loss_box_reg_stage2: 0.2791  loss_mask: 0.4713  loss_rpn_cls: 0.07271  loss_rpn_loc: 0.03764  validation_loss: 2.076  time: 1.6961  data_time: 0.0230  lr: 3.819e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:09:23 d2.utils.events]: \u001b[0m eta: 1:49:04  iter: 5779  total_loss: 2.331  loss_cls_stage0: 0.3567  loss_box_reg_stage0: 0.2705  loss_cls_stage1: 0.2698  loss_box_reg_stage1: 0.3473  loss_cls_stage2: 0.1881  loss_box_reg_stage2: 0.2634  loss_mask: 0.479  loss_rpn_cls: 0.07818  loss_rpn_loc: 0.03826  validation_loss: 2.076  time: 1.6956  data_time: 0.0238  lr: 3.7885e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:09:54 d2.utils.events]: \u001b[0m eta: 1:48:29  iter: 5799  total_loss: 2.236  loss_cls_stage0: 0.3142  loss_box_reg_stage0: 0.2299  loss_cls_stage1: 0.2572  loss_box_reg_stage1: 0.3283  loss_cls_stage2: 0.1728  loss_box_reg_stage2: 0.2512  loss_mask: 0.5784  loss_rpn_cls: 0.06893  loss_rpn_loc: 0.03432  validation_loss: 2.076  time: 1.6951  data_time: 0.0250  lr: 3.7581e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:10:26 d2.utils.events]: \u001b[0m eta: 1:47:56  iter: 5819  total_loss: 2.408  loss_cls_stage0: 0.3401  loss_box_reg_stage0: 0.2661  loss_cls_stage1: 0.2833  loss_box_reg_stage1: 0.3723  loss_cls_stage2: 0.208  loss_box_reg_stage2: 0.2913  loss_mask: 0.5471  loss_rpn_cls: 0.05885  loss_rpn_loc: 0.04245  validation_loss: 2.076  time: 1.6947  data_time: 0.0257  lr: 3.7277e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:10:57 d2.utils.events]: \u001b[0m eta: 1:47:21  iter: 5839  total_loss: 2.321  loss_cls_stage0: 0.3056  loss_box_reg_stage0: 0.2428  loss_cls_stage1: 0.2406  loss_box_reg_stage1: 0.3389  loss_cls_stage2: 0.1716  loss_box_reg_stage2: 0.2735  loss_mask: 0.5871  loss_rpn_cls: 0.07486  loss_rpn_loc: 0.03306  validation_loss: 2.076  time: 1.6942  data_time: 0.0235  lr: 3.6973e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:11:28 d2.utils.events]: \u001b[0m eta: 1:46:52  iter: 5859  total_loss: 2.491  loss_cls_stage0: 0.3639  loss_box_reg_stage0: 0.2837  loss_cls_stage1: 0.3078  loss_box_reg_stage1: 0.3731  loss_cls_stage2: 0.217  loss_box_reg_stage2: 0.2892  loss_mask: 0.5279  loss_rpn_cls: 0.07508  loss_rpn_loc: 0.04174  validation_loss: 2.076  time: 1.6938  data_time: 0.0231  lr: 3.667e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:11:59 d2.utils.events]: \u001b[0m eta: 1:46:22  iter: 5879  total_loss: 2.207  loss_cls_stage0: 0.2737  loss_box_reg_stage0: 0.2281  loss_cls_stage1: 0.2372  loss_box_reg_stage1: 0.3306  loss_cls_stage2: 0.1719  loss_box_reg_stage2: 0.3015  loss_mask: 0.533  loss_rpn_cls: 0.05801  loss_rpn_loc: 0.03518  validation_loss: 2.076  time: 1.6933  data_time: 0.0225  lr: 3.6368e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:12:31 d2.utils.events]: \u001b[0m eta: 1:45:52  iter: 5899  total_loss: 2.262  loss_cls_stage0: 0.3007  loss_box_reg_stage0: 0.2293  loss_cls_stage1: 0.2564  loss_box_reg_stage1: 0.3311  loss_cls_stage2: 0.1872  loss_box_reg_stage2: 0.2837  loss_mask: 0.5452  loss_rpn_cls: 0.06795  loss_rpn_loc: 0.03407  validation_loss: 2.076  time: 1.6928  data_time: 0.0246  lr: 3.6066e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:13:02 d2.utils.events]: \u001b[0m eta: 1:45:23  iter: 5919  total_loss: 2.176  loss_cls_stage0: 0.3201  loss_box_reg_stage0: 0.2434  loss_cls_stage1: 0.2464  loss_box_reg_stage1: 0.3148  loss_cls_stage2: 0.1694  loss_box_reg_stage2: 0.2709  loss_mask: 0.5435  loss_rpn_cls: 0.05615  loss_rpn_loc: 0.03348  validation_loss: 2.076  time: 1.6923  data_time: 0.0232  lr: 3.5764e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:13:33 d2.utils.events]: \u001b[0m eta: 1:44:52  iter: 5939  total_loss: 2.271  loss_cls_stage0: 0.3136  loss_box_reg_stage0: 0.2452  loss_cls_stage1: 0.2655  loss_box_reg_stage1: 0.3417  loss_cls_stage2: 0.1928  loss_box_reg_stage2: 0.275  loss_mask: 0.5372  loss_rpn_cls: 0.05988  loss_rpn_loc: 0.03611  validation_loss: 2.076  time: 1.6919  data_time: 0.0291  lr: 3.5463e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:14:04 d2.utils.events]: \u001b[0m eta: 1:44:23  iter: 5959  total_loss: 2.448  loss_cls_stage0: 0.341  loss_box_reg_stage0: 0.2825  loss_cls_stage1: 0.2813  loss_box_reg_stage1: 0.3855  loss_cls_stage2: 0.1963  loss_box_reg_stage2: 0.3083  loss_mask: 0.5374  loss_rpn_cls: 0.07238  loss_rpn_loc: 0.03769  validation_loss: 2.076  time: 1.6915  data_time: 0.0230  lr: 3.5163e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:14:35 d2.utils.events]: \u001b[0m eta: 1:43:50  iter: 5979  total_loss: 2.174  loss_cls_stage0: 0.3024  loss_box_reg_stage0: 0.2285  loss_cls_stage1: 0.2454  loss_box_reg_stage1: 0.3064  loss_cls_stage2: 0.1794  loss_box_reg_stage2: 0.2619  loss_mask: 0.5323  loss_rpn_cls: 0.06693  loss_rpn_loc: 0.03329  validation_loss: 2.076  time: 1.6910  data_time: 0.0247  lr: 3.4863e-05  max_mem: 11723M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/26 19:15:08 d2.data.common]: \u001b[0mSerializing 859 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/26 19:15:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.90 MiB\n",
      "\u001b[32m[03/26 19:15:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 859 images\n",
      "\u001b[32m[03/26 19:15:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/859. 0.0801 s / img. ETA=0:01:36\n",
      "\u001b[32m[03/26 19:15:15 d2.evaluation.evaluator]: \u001b[0mInference done 56/859. 0.0798 s / img. ETA=0:01:29\n",
      "\u001b[32m[03/26 19:15:20 d2.evaluation.evaluator]: \u001b[0mInference done 101/859. 0.0799 s / img. ETA=0:01:24\n",
      "\u001b[32m[03/26 19:15:26 d2.evaluation.evaluator]: \u001b[0mInference done 147/859. 0.0799 s / img. ETA=0:01:19\n",
      "\u001b[32m[03/26 19:15:31 d2.evaluation.evaluator]: \u001b[0mInference done 192/859. 0.0799 s / img. ETA=0:01:14\n",
      "\u001b[32m[03/26 19:15:36 d2.evaluation.evaluator]: \u001b[0mInference done 235/859. 0.0800 s / img. ETA=0:01:10\n",
      "\u001b[32m[03/26 19:15:41 d2.evaluation.evaluator]: \u001b[0mInference done 279/859. 0.0801 s / img. ETA=0:01:05\n",
      "\u001b[32m[03/26 19:15:46 d2.evaluation.evaluator]: \u001b[0mInference done 322/859. 0.0802 s / img. ETA=0:01:01\n",
      "\u001b[32m[03/26 19:15:51 d2.evaluation.evaluator]: \u001b[0mInference done 368/859. 0.0802 s / img. ETA=0:00:55\n",
      "\u001b[32m[03/26 19:15:56 d2.evaluation.evaluator]: \u001b[0mInference done 410/859. 0.0803 s / img. ETA=0:00:51\n",
      "\u001b[32m[03/26 19:16:01 d2.evaluation.evaluator]: \u001b[0mInference done 452/859. 0.0803 s / img. ETA=0:00:46\n",
      "\u001b[32m[03/26 19:16:06 d2.evaluation.evaluator]: \u001b[0mInference done 496/859. 0.0803 s / img. ETA=0:00:41\n",
      "\u001b[32m[03/26 19:16:11 d2.evaluation.evaluator]: \u001b[0mInference done 539/859. 0.0803 s / img. ETA=0:00:36\n",
      "\u001b[32m[03/26 19:16:16 d2.evaluation.evaluator]: \u001b[0mInference done 578/859. 0.0804 s / img. ETA=0:00:32\n",
      "\u001b[32m[03/26 19:16:21 d2.evaluation.evaluator]: \u001b[0mInference done 620/859. 0.0806 s / img. ETA=0:00:27\n",
      "\u001b[32m[03/26 19:16:26 d2.evaluation.evaluator]: \u001b[0mInference done 663/859. 0.0806 s / img. ETA=0:00:22\n",
      "\u001b[32m[03/26 19:16:31 d2.evaluation.evaluator]: \u001b[0mInference done 705/859. 0.0806 s / img. ETA=0:00:17\n",
      "\u001b[32m[03/26 19:16:36 d2.evaluation.evaluator]: \u001b[0mInference done 745/859. 0.0806 s / img. ETA=0:00:13\n",
      "\u001b[32m[03/26 19:16:41 d2.evaluation.evaluator]: \u001b[0mInference done 788/859. 0.0806 s / img. ETA=0:00:08\n",
      "\u001b[32m[03/26 19:16:46 d2.evaluation.evaluator]: \u001b[0mInference done 830/859. 0.0806 s / img. ETA=0:00:03\n",
      "\u001b[32m[03/26 19:16:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:40.476471 (0.117654 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/26 19:16:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:08 (0.080629 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.138\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.152\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.038\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.087\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.122\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.156\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.157\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.049\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.170\n",
      "\u001b[32m[03/26 19:16:51 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold2 in csv format:\n",
      "\u001b[32m[03/26 19:16:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/26 19:16:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/26 19:16:51 d2.evaluation.testing]: \u001b[0mcopypaste: 8.3777,13.7741,15.2318,0.5051,3.8082,8.7296\n",
      "validation do loss eval 2.325789334365165\n",
      "\u001b[32m[03/26 19:18:20 d2.utils.events]: \u001b[0m eta: 1:43:16  iter: 5999  total_loss: 2.299  loss_cls_stage0: 0.3165  loss_box_reg_stage0: 0.2449  loss_cls_stage1: 0.2682  loss_box_reg_stage1: 0.3529  loss_cls_stage2: 0.1914  loss_box_reg_stage2: 0.277  loss_mask: 0.564  loss_rpn_cls: 0.0711  loss_rpn_loc: 0.03619  validation_loss: 2.105  time: 1.6906  data_time: 0.0240  lr: 3.4564e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:18:51 d2.utils.events]: \u001b[0m eta: 1:42:47  iter: 6019  total_loss: 2.324  loss_cls_stage0: 0.3386  loss_box_reg_stage0: 0.2556  loss_cls_stage1: 0.2788  loss_box_reg_stage1: 0.3413  loss_cls_stage2: 0.2112  loss_box_reg_stage2: 0.3024  loss_mask: 0.5451  loss_rpn_cls: 0.06048  loss_rpn_loc: 0.03241  validation_loss: 2.105  time: 1.6901  data_time: 0.0245  lr: 3.4266e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:19:22 d2.utils.events]: \u001b[0m eta: 1:42:17  iter: 6039  total_loss: 2.354  loss_cls_stage0: 0.3174  loss_box_reg_stage0: 0.2403  loss_cls_stage1: 0.2662  loss_box_reg_stage1: 0.3443  loss_cls_stage2: 0.1926  loss_box_reg_stage2: 0.2823  loss_mask: 0.5713  loss_rpn_cls: 0.06011  loss_rpn_loc: 0.03362  validation_loss: 2.105  time: 1.6896  data_time: 0.0266  lr: 3.3968e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:19:53 d2.utils.events]: \u001b[0m eta: 1:41:45  iter: 6059  total_loss: 2.257  loss_cls_stage0: 0.3057  loss_box_reg_stage0: 0.2321  loss_cls_stage1: 0.2507  loss_box_reg_stage1: 0.3295  loss_cls_stage2: 0.1849  loss_box_reg_stage2: 0.271  loss_mask: 0.5188  loss_rpn_cls: 0.06293  loss_rpn_loc: 0.03223  validation_loss: 2.105  time: 1.6892  data_time: 0.0239  lr: 3.367e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:20:24 d2.utils.events]: \u001b[0m eta: 1:41:15  iter: 6079  total_loss: 2.312  loss_cls_stage0: 0.3288  loss_box_reg_stage0: 0.2526  loss_cls_stage1: 0.2628  loss_box_reg_stage1: 0.3675  loss_cls_stage2: 0.1933  loss_box_reg_stage2: 0.2935  loss_mask: 0.5072  loss_rpn_cls: 0.06338  loss_rpn_loc: 0.03493  validation_loss: 2.105  time: 1.6888  data_time: 0.0235  lr: 3.3374e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:20:56 d2.utils.events]: \u001b[0m eta: 1:40:46  iter: 6099  total_loss: 2.532  loss_cls_stage0: 0.3503  loss_box_reg_stage0: 0.2673  loss_cls_stage1: 0.2861  loss_box_reg_stage1: 0.38  loss_cls_stage2: 0.2136  loss_box_reg_stage2: 0.2928  loss_mask: 0.5588  loss_rpn_cls: 0.07475  loss_rpn_loc: 0.04267  validation_loss: 2.105  time: 1.6884  data_time: 0.0244  lr: 3.3078e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:21:27 d2.utils.events]: \u001b[0m eta: 1:40:17  iter: 6119  total_loss: 2.414  loss_cls_stage0: 0.351  loss_box_reg_stage0: 0.2625  loss_cls_stage1: 0.2882  loss_box_reg_stage1: 0.3596  loss_cls_stage2: 0.2093  loss_box_reg_stage2: 0.2815  loss_mask: 0.5233  loss_rpn_cls: 0.06782  loss_rpn_loc: 0.03667  validation_loss: 2.105  time: 1.6880  data_time: 0.0246  lr: 3.2783e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:21:58 d2.utils.events]: \u001b[0m eta: 1:39:46  iter: 6139  total_loss: 2.201  loss_cls_stage0: 0.2942  loss_box_reg_stage0: 0.2265  loss_cls_stage1: 0.24  loss_box_reg_stage1: 0.334  loss_cls_stage2: 0.1725  loss_box_reg_stage2: 0.2611  loss_mask: 0.5442  loss_rpn_cls: 0.06084  loss_rpn_loc: 0.03135  validation_loss: 2.105  time: 1.6875  data_time: 0.0235  lr: 3.2488e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:22:30 d2.utils.events]: \u001b[0m eta: 1:39:17  iter: 6159  total_loss: 2.327  loss_cls_stage0: 0.3589  loss_box_reg_stage0: 0.2704  loss_cls_stage1: 0.2817  loss_box_reg_stage1: 0.3542  loss_cls_stage2: 0.1948  loss_box_reg_stage2: 0.2824  loss_mask: 0.589  loss_rpn_cls: 0.0598  loss_rpn_loc: 0.03835  validation_loss: 2.105  time: 1.6871  data_time: 0.0243  lr: 3.2194e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:23:01 d2.utils.events]: \u001b[0m eta: 1:38:47  iter: 6179  total_loss: 2.433  loss_cls_stage0: 0.3472  loss_box_reg_stage0: 0.2629  loss_cls_stage1: 0.2997  loss_box_reg_stage1: 0.3917  loss_cls_stage2: 0.2097  loss_box_reg_stage2: 0.2988  loss_mask: 0.5451  loss_rpn_cls: 0.07762  loss_rpn_loc: 0.04092  validation_loss: 2.105  time: 1.6867  data_time: 0.0230  lr: 3.1901e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:23:32 d2.utils.events]: \u001b[0m eta: 1:38:16  iter: 6199  total_loss: 2.162  loss_cls_stage0: 0.286  loss_box_reg_stage0: 0.2166  loss_cls_stage1: 0.2392  loss_box_reg_stage1: 0.3157  loss_cls_stage2: 0.1849  loss_box_reg_stage2: 0.2799  loss_mask: 0.5485  loss_rpn_cls: 0.06571  loss_rpn_loc: 0.03585  validation_loss: 2.105  time: 1.6863  data_time: 0.0239  lr: 3.1608e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:24:03 d2.utils.events]: \u001b[0m eta: 1:37:46  iter: 6219  total_loss: 2.365  loss_cls_stage0: 0.2944  loss_box_reg_stage0: 0.2528  loss_cls_stage1: 0.26  loss_box_reg_stage1: 0.3698  loss_cls_stage2: 0.2018  loss_box_reg_stage2: 0.3233  loss_mask: 0.5506  loss_rpn_cls: 0.0665  loss_rpn_loc: 0.03766  validation_loss: 2.105  time: 1.6859  data_time: 0.0254  lr: 3.1317e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:24:35 d2.utils.events]: \u001b[0m eta: 1:37:16  iter: 6239  total_loss: 2.197  loss_cls_stage0: 0.3125  loss_box_reg_stage0: 0.2435  loss_cls_stage1: 0.2568  loss_box_reg_stage1: 0.3595  loss_cls_stage2: 0.1829  loss_box_reg_stage2: 0.2813  loss_mask: 0.5209  loss_rpn_cls: 0.05393  loss_rpn_loc: 0.03619  validation_loss: 2.105  time: 1.6855  data_time: 0.0238  lr: 3.1026e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:25:06 d2.utils.events]: \u001b[0m eta: 1:36:47  iter: 6259  total_loss: 2.772  loss_cls_stage0: 0.3993  loss_box_reg_stage0: 0.3192  loss_cls_stage1: 0.3243  loss_box_reg_stage1: 0.4118  loss_cls_stage2: 0.2211  loss_box_reg_stage2: 0.3117  loss_mask: 0.5722  loss_rpn_cls: 0.06248  loss_rpn_loc: 0.04043  validation_loss: 2.105  time: 1.6852  data_time: 0.0243  lr: 3.0735e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:25:37 d2.utils.events]: \u001b[0m eta: 1:36:15  iter: 6279  total_loss: 2.185  loss_cls_stage0: 0.289  loss_box_reg_stage0: 0.2217  loss_cls_stage1: 0.2358  loss_box_reg_stage1: 0.3399  loss_cls_stage2: 0.1725  loss_box_reg_stage2: 0.2826  loss_mask: 0.4866  loss_rpn_cls: 0.06251  loss_rpn_loc: 0.03178  validation_loss: 2.105  time: 1.6848  data_time: 0.0241  lr: 3.0446e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:26:09 d2.utils.events]: \u001b[0m eta: 1:35:45  iter: 6299  total_loss: 2.395  loss_cls_stage0: 0.3279  loss_box_reg_stage0: 0.257  loss_cls_stage1: 0.2732  loss_box_reg_stage1: 0.3531  loss_cls_stage2: 0.1939  loss_box_reg_stage2: 0.2884  loss_mask: 0.5485  loss_rpn_cls: 0.07717  loss_rpn_loc: 0.0376  validation_loss: 2.105  time: 1.6844  data_time: 0.0246  lr: 3.0157e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:26:40 d2.utils.events]: \u001b[0m eta: 1:35:14  iter: 6319  total_loss: 2.379  loss_cls_stage0: 0.316  loss_box_reg_stage0: 0.2451  loss_cls_stage1: 0.2791  loss_box_reg_stage1: 0.3736  loss_cls_stage2: 0.2013  loss_box_reg_stage2: 0.3123  loss_mask: 0.5293  loss_rpn_cls: 0.06413  loss_rpn_loc: 0.03721  validation_loss: 2.105  time: 1.6840  data_time: 0.0237  lr: 2.9869e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:27:11 d2.utils.events]: \u001b[0m eta: 1:34:45  iter: 6339  total_loss: 2.355  loss_cls_stage0: 0.3143  loss_box_reg_stage0: 0.2563  loss_cls_stage1: 0.2579  loss_box_reg_stage1: 0.3548  loss_cls_stage2: 0.1914  loss_box_reg_stage2: 0.3171  loss_mask: 0.5399  loss_rpn_cls: 0.07034  loss_rpn_loc: 0.03605  validation_loss: 2.105  time: 1.6836  data_time: 0.0241  lr: 2.9582e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:27:42 d2.utils.events]: \u001b[0m eta: 1:34:14  iter: 6359  total_loss: 2.374  loss_cls_stage0: 0.3347  loss_box_reg_stage0: 0.2615  loss_cls_stage1: 0.2812  loss_box_reg_stage1: 0.3432  loss_cls_stage2: 0.1993  loss_box_reg_stage2: 0.2765  loss_mask: 0.5483  loss_rpn_cls: 0.06629  loss_rpn_loc: 0.03406  validation_loss: 2.105  time: 1.6832  data_time: 0.0237  lr: 2.9296e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:28:13 d2.utils.events]: \u001b[0m eta: 1:33:43  iter: 6379  total_loss: 2.334  loss_cls_stage0: 0.3223  loss_box_reg_stage0: 0.2563  loss_cls_stage1: 0.263  loss_box_reg_stage1: 0.3557  loss_cls_stage2: 0.1963  loss_box_reg_stage2: 0.2995  loss_mask: 0.5768  loss_rpn_cls: 0.06189  loss_rpn_loc: 0.03122  validation_loss: 2.105  time: 1.6828  data_time: 0.0246  lr: 2.901e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:28:44 d2.utils.events]: \u001b[0m eta: 1:33:12  iter: 6399  total_loss: 2.097  loss_cls_stage0: 0.2846  loss_box_reg_stage0: 0.2356  loss_cls_stage1: 0.2319  loss_box_reg_stage1: 0.3513  loss_cls_stage2: 0.178  loss_box_reg_stage2: 0.2811  loss_mask: 0.505  loss_rpn_cls: 0.05774  loss_rpn_loc: 0.03105  validation_loss: 2.105  time: 1.6824  data_time: 0.0248  lr: 2.8725e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:29:16 d2.utils.events]: \u001b[0m eta: 1:32:43  iter: 6419  total_loss: 2.267  loss_cls_stage0: 0.2988  loss_box_reg_stage0: 0.2285  loss_cls_stage1: 0.2536  loss_box_reg_stage1: 0.3377  loss_cls_stage2: 0.1772  loss_box_reg_stage2: 0.2765  loss_mask: 0.5539  loss_rpn_cls: 0.06173  loss_rpn_loc: 0.0362  validation_loss: 2.105  time: 1.6821  data_time: 0.0244  lr: 2.8441e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:29:47 d2.utils.events]: \u001b[0m eta: 1:32:13  iter: 6439  total_loss: 2.437  loss_cls_stage0: 0.351  loss_box_reg_stage0: 0.2637  loss_cls_stage1: 0.2945  loss_box_reg_stage1: 0.3376  loss_cls_stage2: 0.2073  loss_box_reg_stage2: 0.2787  loss_mask: 0.5545  loss_rpn_cls: 0.0654  loss_rpn_loc: 0.03361  validation_loss: 2.105  time: 1.6817  data_time: 0.0241  lr: 2.8158e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:30:18 d2.utils.events]: \u001b[0m eta: 1:31:43  iter: 6459  total_loss: 2.202  loss_cls_stage0: 0.2903  loss_box_reg_stage0: 0.2357  loss_cls_stage1: 0.2469  loss_box_reg_stage1: 0.3267  loss_cls_stage2: 0.1772  loss_box_reg_stage2: 0.2833  loss_mask: 0.5346  loss_rpn_cls: 0.06034  loss_rpn_loc: 0.03424  validation_loss: 2.105  time: 1.6813  data_time: 0.0245  lr: 2.7876e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:30:50 d2.utils.events]: \u001b[0m eta: 1:31:13  iter: 6479  total_loss: 2.252  loss_cls_stage0: 0.3422  loss_box_reg_stage0: 0.2691  loss_cls_stage1: 0.2581  loss_box_reg_stage1: 0.3272  loss_cls_stage2: 0.1793  loss_box_reg_stage2: 0.2912  loss_mask: 0.4995  loss_rpn_cls: 0.06678  loss_rpn_loc: 0.03525  validation_loss: 2.105  time: 1.6809  data_time: 0.0235  lr: 2.7595e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:31:21 d2.utils.events]: \u001b[0m eta: 1:30:41  iter: 6499  total_loss: 2.226  loss_cls_stage0: 0.3151  loss_box_reg_stage0: 0.2446  loss_cls_stage1: 0.2552  loss_box_reg_stage1: 0.3332  loss_cls_stage2: 0.1971  loss_box_reg_stage2: 0.2794  loss_mask: 0.5183  loss_rpn_cls: 0.06711  loss_rpn_loc: 0.03474  validation_loss: 2.105  time: 1.6806  data_time: 0.0238  lr: 2.7314e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:31:52 d2.utils.events]: \u001b[0m eta: 1:30:10  iter: 6519  total_loss: 2.353  loss_cls_stage0: 0.3119  loss_box_reg_stage0: 0.2516  loss_cls_stage1: 0.2679  loss_box_reg_stage1: 0.3793  loss_cls_stage2: 0.2025  loss_box_reg_stage2: 0.314  loss_mask: 0.5627  loss_rpn_cls: 0.06408  loss_rpn_loc: 0.03851  validation_loss: 2.105  time: 1.6802  data_time: 0.0237  lr: 2.7035e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:32:23 d2.utils.events]: \u001b[0m eta: 1:29:39  iter: 6539  total_loss: 2.248  loss_cls_stage0: 0.3252  loss_box_reg_stage0: 0.2568  loss_cls_stage1: 0.2365  loss_box_reg_stage1: 0.3207  loss_cls_stage2: 0.189  loss_box_reg_stage2: 0.2747  loss_mask: 0.524  loss_rpn_cls: 0.07205  loss_rpn_loc: 0.03673  validation_loss: 2.105  time: 1.6798  data_time: 0.0233  lr: 2.6756e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:32:54 d2.utils.events]: \u001b[0m eta: 1:29:08  iter: 6559  total_loss: 2.273  loss_cls_stage0: 0.3248  loss_box_reg_stage0: 0.2531  loss_cls_stage1: 0.2624  loss_box_reg_stage1: 0.3526  loss_cls_stage2: 0.183  loss_box_reg_stage2: 0.29  loss_mask: 0.5326  loss_rpn_cls: 0.06762  loss_rpn_loc: 0.03724  validation_loss: 2.105  time: 1.6795  data_time: 0.0247  lr: 2.6479e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:33:26 d2.utils.events]: \u001b[0m eta: 1:28:39  iter: 6579  total_loss: 2.481  loss_cls_stage0: 0.3602  loss_box_reg_stage0: 0.2792  loss_cls_stage1: 0.3006  loss_box_reg_stage1: 0.3599  loss_cls_stage2: 0.2005  loss_box_reg_stage2: 0.2797  loss_mask: 0.568  loss_rpn_cls: 0.07484  loss_rpn_loc: 0.0427  validation_loss: 2.105  time: 1.6791  data_time: 0.0240  lr: 2.6202e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:33:57 d2.utils.events]: \u001b[0m eta: 1:28:08  iter: 6599  total_loss: 2.18  loss_cls_stage0: 0.2937  loss_box_reg_stage0: 0.2462  loss_cls_stage1: 0.2364  loss_box_reg_stage1: 0.3299  loss_cls_stage2: 0.1678  loss_box_reg_stage2: 0.2761  loss_mask: 0.5376  loss_rpn_cls: 0.05184  loss_rpn_loc: 0.03521  validation_loss: 2.105  time: 1.6787  data_time: 0.0247  lr: 2.5926e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:34:28 d2.utils.events]: \u001b[0m eta: 1:27:37  iter: 6619  total_loss: 2.494  loss_cls_stage0: 0.3588  loss_box_reg_stage0: 0.268  loss_cls_stage1: 0.304  loss_box_reg_stage1: 0.3669  loss_cls_stage2: 0.2106  loss_box_reg_stage2: 0.2949  loss_mask: 0.5543  loss_rpn_cls: 0.0626  loss_rpn_loc: 0.03549  validation_loss: 2.105  time: 1.6784  data_time: 0.0241  lr: 2.5651e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:35:00 d2.utils.events]: \u001b[0m eta: 1:27:07  iter: 6639  total_loss: 2.473  loss_cls_stage0: 0.3458  loss_box_reg_stage0: 0.2709  loss_cls_stage1: 0.2986  loss_box_reg_stage1: 0.3655  loss_cls_stage2: 0.2126  loss_box_reg_stage2: 0.3122  loss_mask: 0.5426  loss_rpn_cls: 0.06456  loss_rpn_loc: 0.03482  validation_loss: 2.105  time: 1.6781  data_time: 0.0240  lr: 2.5377e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:35:31 d2.utils.events]: \u001b[0m eta: 1:26:38  iter: 6659  total_loss: 2.371  loss_cls_stage0: 0.333  loss_box_reg_stage0: 0.2753  loss_cls_stage1: 0.2653  loss_box_reg_stage1: 0.3705  loss_cls_stage2: 0.1951  loss_box_reg_stage2: 0.3001  loss_mask: 0.558  loss_rpn_cls: 0.07208  loss_rpn_loc: 0.04385  validation_loss: 2.105  time: 1.6778  data_time: 0.0239  lr: 2.5104e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:36:02 d2.utils.events]: \u001b[0m eta: 1:26:07  iter: 6679  total_loss: 2.321  loss_cls_stage0: 0.3109  loss_box_reg_stage0: 0.2361  loss_cls_stage1: 0.2613  loss_box_reg_stage1: 0.3351  loss_cls_stage2: 0.1782  loss_box_reg_stage2: 0.2696  loss_mask: 0.5318  loss_rpn_cls: 0.06207  loss_rpn_loc: 0.03228  validation_loss: 2.105  time: 1.6774  data_time: 0.0225  lr: 2.4832e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:36:34 d2.utils.events]: \u001b[0m eta: 1:25:36  iter: 6699  total_loss: 2.297  loss_cls_stage0: 0.3454  loss_box_reg_stage0: 0.2692  loss_cls_stage1: 0.2633  loss_box_reg_stage1: 0.3417  loss_cls_stage2: 0.1965  loss_box_reg_stage2: 0.28  loss_mask: 0.5253  loss_rpn_cls: 0.06261  loss_rpn_loc: 0.03959  validation_loss: 2.105  time: 1.6771  data_time: 0.0234  lr: 2.4561e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:37:05 d2.utils.events]: \u001b[0m eta: 1:25:06  iter: 6719  total_loss: 2.382  loss_cls_stage0: 0.3246  loss_box_reg_stage0: 0.2456  loss_cls_stage1: 0.2712  loss_box_reg_stage1: 0.3631  loss_cls_stage2: 0.2061  loss_box_reg_stage2: 0.2923  loss_mask: 0.5814  loss_rpn_cls: 0.06285  loss_rpn_loc: 0.0362  validation_loss: 2.105  time: 1.6767  data_time: 0.0244  lr: 2.4291e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:37:36 d2.utils.events]: \u001b[0m eta: 1:24:36  iter: 6739  total_loss: 2.388  loss_cls_stage0: 0.3274  loss_box_reg_stage0: 0.2485  loss_cls_stage1: 0.2888  loss_box_reg_stage1: 0.352  loss_cls_stage2: 0.1964  loss_box_reg_stage2: 0.2809  loss_mask: 0.5811  loss_rpn_cls: 0.05915  loss_rpn_loc: 0.03556  validation_loss: 2.105  time: 1.6764  data_time: 0.0230  lr: 2.4023e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:38:07 d2.utils.events]: \u001b[0m eta: 1:24:06  iter: 6759  total_loss: 2.373  loss_cls_stage0: 0.3164  loss_box_reg_stage0: 0.2648  loss_cls_stage1: 0.2589  loss_box_reg_stage1: 0.3598  loss_cls_stage2: 0.2105  loss_box_reg_stage2: 0.2867  loss_mask: 0.5677  loss_rpn_cls: 0.06192  loss_rpn_loc: 0.03245  validation_loss: 2.105  time: 1.6761  data_time: 0.0228  lr: 2.3755e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:38:39 d2.utils.events]: \u001b[0m eta: 1:23:35  iter: 6779  total_loss: 2.545  loss_cls_stage0: 0.3596  loss_box_reg_stage0: 0.2643  loss_cls_stage1: 0.2924  loss_box_reg_stage1: 0.3576  loss_cls_stage2: 0.212  loss_box_reg_stage2: 0.2883  loss_mask: 0.5444  loss_rpn_cls: 0.06715  loss_rpn_loc: 0.03793  validation_loss: 2.105  time: 1.6757  data_time: 0.0231  lr: 2.3488e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:39:10 d2.utils.events]: \u001b[0m eta: 1:23:04  iter: 6799  total_loss: 2.29  loss_cls_stage0: 0.3205  loss_box_reg_stage0: 0.2524  loss_cls_stage1: 0.2709  loss_box_reg_stage1: 0.3544  loss_cls_stage2: 0.1969  loss_box_reg_stage2: 0.2838  loss_mask: 0.5635  loss_rpn_cls: 0.06465  loss_rpn_loc: 0.03734  validation_loss: 2.105  time: 1.6754  data_time: 0.0235  lr: 2.3222e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:39:41 d2.utils.events]: \u001b[0m eta: 1:22:32  iter: 6819  total_loss: 2.267  loss_cls_stage0: 0.3209  loss_box_reg_stage0: 0.2302  loss_cls_stage1: 0.2663  loss_box_reg_stage1: 0.3433  loss_cls_stage2: 0.1958  loss_box_reg_stage2: 0.312  loss_mask: 0.4922  loss_rpn_cls: 0.05431  loss_rpn_loc: 0.03323  validation_loss: 2.105  time: 1.6751  data_time: 0.0234  lr: 2.2957e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:40:13 d2.utils.events]: \u001b[0m eta: 1:22:01  iter: 6839  total_loss: 2.294  loss_cls_stage0: 0.3409  loss_box_reg_stage0: 0.2509  loss_cls_stage1: 0.2851  loss_box_reg_stage1: 0.3522  loss_cls_stage2: 0.2024  loss_box_reg_stage2: 0.2999  loss_mask: 0.5467  loss_rpn_cls: 0.05363  loss_rpn_loc: 0.03409  validation_loss: 2.105  time: 1.6748  data_time: 0.0235  lr: 2.2693e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:40:44 d2.utils.events]: \u001b[0m eta: 1:21:30  iter: 6859  total_loss: 2.151  loss_cls_stage0: 0.2898  loss_box_reg_stage0: 0.2214  loss_cls_stage1: 0.2354  loss_box_reg_stage1: 0.3121  loss_cls_stage2: 0.1727  loss_box_reg_stage2: 0.2691  loss_mask: 0.5256  loss_rpn_cls: 0.06471  loss_rpn_loc: 0.03093  validation_loss: 2.105  time: 1.6744  data_time: 0.0233  lr: 2.2431e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:41:15 d2.utils.events]: \u001b[0m eta: 1:20:59  iter: 6879  total_loss: 2.472  loss_cls_stage0: 0.3432  loss_box_reg_stage0: 0.2745  loss_cls_stage1: 0.2882  loss_box_reg_stage1: 0.394  loss_cls_stage2: 0.2083  loss_box_reg_stage2: 0.3078  loss_mask: 0.5626  loss_rpn_cls: 0.05361  loss_rpn_loc: 0.03317  validation_loss: 2.105  time: 1.6741  data_time: 0.0239  lr: 2.2169e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:41:46 d2.utils.events]: \u001b[0m eta: 1:20:28  iter: 6899  total_loss: 2.279  loss_cls_stage0: 0.3004  loss_box_reg_stage0: 0.2334  loss_cls_stage1: 0.2423  loss_box_reg_stage1: 0.3529  loss_cls_stage2: 0.1759  loss_box_reg_stage2: 0.2992  loss_mask: 0.5642  loss_rpn_cls: 0.05951  loss_rpn_loc: 0.03336  validation_loss: 2.105  time: 1.6738  data_time: 0.0255  lr: 2.1909e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:42:18 d2.utils.events]: \u001b[0m eta: 1:19:59  iter: 6919  total_loss: 2.275  loss_cls_stage0: 0.3335  loss_box_reg_stage0: 0.2543  loss_cls_stage1: 0.2607  loss_box_reg_stage1: 0.3583  loss_cls_stage2: 0.1953  loss_box_reg_stage2: 0.2967  loss_mask: 0.5318  loss_rpn_cls: 0.05957  loss_rpn_loc: 0.03516  validation_loss: 2.105  time: 1.6735  data_time: 0.0226  lr: 2.1649e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:42:49 d2.utils.events]: \u001b[0m eta: 1:19:28  iter: 6939  total_loss: 2.386  loss_cls_stage0: 0.3142  loss_box_reg_stage0: 0.2519  loss_cls_stage1: 0.2651  loss_box_reg_stage1: 0.3584  loss_cls_stage2: 0.1992  loss_box_reg_stage2: 0.2962  loss_mask: 0.5075  loss_rpn_cls: 0.06079  loss_rpn_loc: 0.03533  validation_loss: 2.105  time: 1.6732  data_time: 0.0237  lr: 2.1391e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:43:20 d2.utils.events]: \u001b[0m eta: 1:18:56  iter: 6959  total_loss: 2.419  loss_cls_stage0: 0.3191  loss_box_reg_stage0: 0.2613  loss_cls_stage1: 0.283  loss_box_reg_stage1: 0.3741  loss_cls_stage2: 0.2009  loss_box_reg_stage2: 0.3164  loss_mask: 0.4996  loss_rpn_cls: 0.06032  loss_rpn_loc: 0.03141  validation_loss: 2.105  time: 1.6728  data_time: 0.0237  lr: 2.1134e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:43:52 d2.utils.events]: \u001b[0m eta: 1:18:27  iter: 6979  total_loss: 2.3  loss_cls_stage0: 0.3473  loss_box_reg_stage0: 0.261  loss_cls_stage1: 0.2775  loss_box_reg_stage1: 0.3543  loss_cls_stage2: 0.2005  loss_box_reg_stage2: 0.2809  loss_mask: 0.5307  loss_rpn_cls: 0.06553  loss_rpn_loc: 0.03609  validation_loss: 2.105  time: 1.6726  data_time: 0.0228  lr: 2.0878e-05  max_mem: 11723M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/26 19:44:25 d2.data.common]: \u001b[0mSerializing 859 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/26 19:44:25 d2.data.common]: \u001b[0mSerialized dataset takes 0.90 MiB\n",
      "\u001b[32m[03/26 19:44:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 859 images\n",
      "\u001b[32m[03/26 19:44:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/859. 0.0803 s / img. ETA=0:01:51\n",
      "\u001b[32m[03/26 19:44:32 d2.evaluation.evaluator]: \u001b[0mInference done 50/859. 0.0802 s / img. ETA=0:01:45\n",
      "\u001b[32m[03/26 19:44:37 d2.evaluation.evaluator]: \u001b[0mInference done 88/859. 0.0803 s / img. ETA=0:01:42\n",
      "\u001b[32m[03/26 19:44:43 d2.evaluation.evaluator]: \u001b[0mInference done 128/859. 0.0803 s / img. ETA=0:01:36\n",
      "\u001b[32m[03/26 19:44:48 d2.evaluation.evaluator]: \u001b[0mInference done 167/859. 0.0804 s / img. ETA=0:01:31\n",
      "\u001b[32m[03/26 19:44:53 d2.evaluation.evaluator]: \u001b[0mInference done 205/859. 0.0805 s / img. ETA=0:01:26\n",
      "\u001b[32m[03/26 19:44:58 d2.evaluation.evaluator]: \u001b[0mInference done 245/859. 0.0805 s / img. ETA=0:01:20\n",
      "\u001b[32m[03/26 19:45:03 d2.evaluation.evaluator]: \u001b[0mInference done 286/859. 0.0806 s / img. ETA=0:01:14\n",
      "\u001b[32m[03/26 19:45:08 d2.evaluation.evaluator]: \u001b[0mInference done 328/859. 0.0806 s / img. ETA=0:01:08\n",
      "\u001b[32m[03/26 19:45:13 d2.evaluation.evaluator]: \u001b[0mInference done 374/859. 0.0805 s / img. ETA=0:01:01\n",
      "\u001b[32m[03/26 19:45:18 d2.evaluation.evaluator]: \u001b[0mInference done 416/859. 0.0805 s / img. ETA=0:00:55\n",
      "\u001b[32m[03/26 19:45:23 d2.evaluation.evaluator]: \u001b[0mInference done 458/859. 0.0805 s / img. ETA=0:00:50\n",
      "\u001b[32m[03/26 19:45:28 d2.evaluation.evaluator]: \u001b[0mInference done 501/859. 0.0805 s / img. ETA=0:00:44\n",
      "\u001b[32m[03/26 19:45:33 d2.evaluation.evaluator]: \u001b[0mInference done 543/859. 0.0805 s / img. ETA=0:00:39\n",
      "\u001b[32m[03/26 19:45:38 d2.evaluation.evaluator]: \u001b[0mInference done 584/859. 0.0805 s / img. ETA=0:00:34\n",
      "\u001b[32m[03/26 19:45:43 d2.evaluation.evaluator]: \u001b[0mInference done 628/859. 0.0805 s / img. ETA=0:00:28\n",
      "\u001b[32m[03/26 19:45:49 d2.evaluation.evaluator]: \u001b[0mInference done 670/859. 0.0805 s / img. ETA=0:00:23\n",
      "\u001b[32m[03/26 19:45:54 d2.evaluation.evaluator]: \u001b[0mInference done 712/859. 0.0805 s / img. ETA=0:00:18\n",
      "\u001b[32m[03/26 19:45:59 d2.evaluation.evaluator]: \u001b[0mInference done 751/859. 0.0805 s / img. ETA=0:00:13\n",
      "\u001b[32m[03/26 19:46:04 d2.evaluation.evaluator]: \u001b[0mInference done 794/859. 0.0805 s / img. ETA=0:00:08\n",
      "\u001b[32m[03/26 19:46:09 d2.evaluation.evaluator]: \u001b[0mInference done 835/859. 0.0805 s / img. ETA=0:00:02\n",
      "\u001b[32m[03/26 19:46:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:45.343372 (0.123353 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/26 19:46:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:08 (0.080552 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.46 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.087\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.144\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.162\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.041\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.090\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.126\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.164\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.165\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.050\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.182\n",
      "\u001b[32m[03/26 19:46:13 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold2 in csv format:\n",
      "\u001b[32m[03/26 19:46:13 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/26 19:46:13 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/26 19:46:13 d2.evaluation.testing]: \u001b[0mcopypaste: 8.6541,14.4061,16.1982,0.5606,4.1000,9.0147\n",
      "validation do loss eval 2.418202722348366\n",
      "\u001b[32m[03/26 19:47:42 d2.utils.events]: \u001b[0m eta: 1:17:55  iter: 6999  total_loss: 2.427  loss_cls_stage0: 0.3375  loss_box_reg_stage0: 0.2684  loss_cls_stage1: 0.2799  loss_box_reg_stage1: 0.3707  loss_cls_stage2: 0.1982  loss_box_reg_stage2: 0.2925  loss_mask: 0.54  loss_rpn_cls: 0.05664  loss_rpn_loc: 0.03614  validation_loss: 2.135  time: 1.6722  data_time: 0.0243  lr: 2.0623e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:48:12 d2.utils.events]: \u001b[0m eta: 1:17:24  iter: 7019  total_loss: 2.274  loss_cls_stage0: 0.3134  loss_box_reg_stage0: 0.2475  loss_cls_stage1: 0.2678  loss_box_reg_stage1: 0.3643  loss_cls_stage2: 0.1856  loss_box_reg_stage2: 0.3002  loss_mask: 0.5315  loss_rpn_cls: 0.05811  loss_rpn_loc: 0.03317  validation_loss: 2.135  time: 1.6718  data_time: 0.0239  lr: 2.037e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:48:44 d2.utils.events]: \u001b[0m eta: 1:16:55  iter: 7039  total_loss: 2.384  loss_cls_stage0: 0.3446  loss_box_reg_stage0: 0.263  loss_cls_stage1: 0.2866  loss_box_reg_stage1: 0.3709  loss_cls_stage2: 0.2085  loss_box_reg_stage2: 0.3137  loss_mask: 0.5173  loss_rpn_cls: 0.05713  loss_rpn_loc: 0.03353  validation_loss: 2.135  time: 1.6716  data_time: 0.0244  lr: 2.0117e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:49:15 d2.utils.events]: \u001b[0m eta: 1:16:24  iter: 7059  total_loss: 2.292  loss_cls_stage0: 0.3114  loss_box_reg_stage0: 0.2332  loss_cls_stage1: 0.2478  loss_box_reg_stage1: 0.3659  loss_cls_stage2: 0.1866  loss_box_reg_stage2: 0.3069  loss_mask: 0.537  loss_rpn_cls: 0.06123  loss_rpn_loc: 0.03341  validation_loss: 2.135  time: 1.6713  data_time: 0.0238  lr: 1.9866e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:49:47 d2.utils.events]: \u001b[0m eta: 1:15:53  iter: 7079  total_loss: 2.354  loss_cls_stage0: 0.335  loss_box_reg_stage0: 0.2572  loss_cls_stage1: 0.2818  loss_box_reg_stage1: 0.339  loss_cls_stage2: 0.1966  loss_box_reg_stage2: 0.2946  loss_mask: 0.4577  loss_rpn_cls: 0.0585  loss_rpn_loc: 0.03564  validation_loss: 2.135  time: 1.6710  data_time: 0.0249  lr: 1.9616e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:50:18 d2.utils.events]: \u001b[0m eta: 1:15:21  iter: 7099  total_loss: 2.424  loss_cls_stage0: 0.3303  loss_box_reg_stage0: 0.2595  loss_cls_stage1: 0.28  loss_box_reg_stage1: 0.3543  loss_cls_stage2: 0.2024  loss_box_reg_stage2: 0.2929  loss_mask: 0.5404  loss_rpn_cls: 0.06403  loss_rpn_loc: 0.03585  validation_loss: 2.135  time: 1.6707  data_time: 0.0239  lr: 1.9367e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:50:49 d2.utils.events]: \u001b[0m eta: 1:14:49  iter: 7119  total_loss: 2.284  loss_cls_stage0: 0.3125  loss_box_reg_stage0: 0.2397  loss_cls_stage1: 0.2615  loss_box_reg_stage1: 0.3373  loss_cls_stage2: 0.1835  loss_box_reg_stage2: 0.2798  loss_mask: 0.5203  loss_rpn_cls: 0.05798  loss_rpn_loc: 0.0325  validation_loss: 2.135  time: 1.6704  data_time: 0.0238  lr: 1.9119e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:51:21 d2.utils.events]: \u001b[0m eta: 1:14:20  iter: 7139  total_loss: 2.296  loss_cls_stage0: 0.3272  loss_box_reg_stage0: 0.2497  loss_cls_stage1: 0.2627  loss_box_reg_stage1: 0.3422  loss_cls_stage2: 0.184  loss_box_reg_stage2: 0.2768  loss_mask: 0.5434  loss_rpn_cls: 0.06364  loss_rpn_loc: 0.03572  validation_loss: 2.135  time: 1.6701  data_time: 0.0245  lr: 1.8873e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:51:52 d2.utils.events]: \u001b[0m eta: 1:13:48  iter: 7159  total_loss: 2.367  loss_cls_stage0: 0.3473  loss_box_reg_stage0: 0.2679  loss_cls_stage1: 0.2847  loss_box_reg_stage1: 0.3565  loss_cls_stage2: 0.2053  loss_box_reg_stage2: 0.3064  loss_mask: 0.5198  loss_rpn_cls: 0.05809  loss_rpn_loc: 0.03183  validation_loss: 2.135  time: 1.6698  data_time: 0.0237  lr: 1.8628e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:52:23 d2.utils.events]: \u001b[0m eta: 1:13:16  iter: 7179  total_loss: 2.265  loss_cls_stage0: 0.3137  loss_box_reg_stage0: 0.2314  loss_cls_stage1: 0.2801  loss_box_reg_stage1: 0.3322  loss_cls_stage2: 0.2079  loss_box_reg_stage2: 0.3084  loss_mask: 0.5453  loss_rpn_cls: 0.05378  loss_rpn_loc: 0.03123  validation_loss: 2.135  time: 1.6695  data_time: 0.0243  lr: 1.8384e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:52:55 d2.utils.events]: \u001b[0m eta: 1:12:45  iter: 7199  total_loss: 2.252  loss_cls_stage0: 0.2992  loss_box_reg_stage0: 0.23  loss_cls_stage1: 0.2463  loss_box_reg_stage1: 0.3406  loss_cls_stage2: 0.1828  loss_box_reg_stage2: 0.3203  loss_mask: 0.5214  loss_rpn_cls: 0.05634  loss_rpn_loc: 0.03371  validation_loss: 2.135  time: 1.6692  data_time: 0.0241  lr: 1.8141e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:53:26 d2.utils.events]: \u001b[0m eta: 1:12:14  iter: 7219  total_loss: 2.296  loss_cls_stage0: 0.3178  loss_box_reg_stage0: 0.2628  loss_cls_stage1: 0.2722  loss_box_reg_stage1: 0.3742  loss_cls_stage2: 0.1931  loss_box_reg_stage2: 0.286  loss_mask: 0.5226  loss_rpn_cls: 0.06152  loss_rpn_loc: 0.03765  validation_loss: 2.135  time: 1.6689  data_time: 0.0249  lr: 1.7899e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:53:57 d2.utils.events]: \u001b[0m eta: 1:11:44  iter: 7239  total_loss: 2.333  loss_cls_stage0: 0.3255  loss_box_reg_stage0: 0.2552  loss_cls_stage1: 0.2655  loss_box_reg_stage1: 0.3312  loss_cls_stage2: 0.188  loss_box_reg_stage2: 0.2953  loss_mask: 0.5795  loss_rpn_cls: 0.06994  loss_rpn_loc: 0.03559  validation_loss: 2.135  time: 1.6687  data_time: 0.0230  lr: 1.7659e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:54:29 d2.utils.events]: \u001b[0m eta: 1:11:12  iter: 7259  total_loss: 2.426  loss_cls_stage0: 0.3189  loss_box_reg_stage0: 0.2518  loss_cls_stage1: 0.2647  loss_box_reg_stage1: 0.3625  loss_cls_stage2: 0.2069  loss_box_reg_stage2: 0.3228  loss_mask: 0.5757  loss_rpn_cls: 0.05556  loss_rpn_loc: 0.03117  validation_loss: 2.135  time: 1.6684  data_time: 0.0239  lr: 1.742e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:55:00 d2.utils.events]: \u001b[0m eta: 1:10:40  iter: 7279  total_loss: 2.327  loss_cls_stage0: 0.3098  loss_box_reg_stage0: 0.259  loss_cls_stage1: 0.251  loss_box_reg_stage1: 0.344  loss_cls_stage2: 0.1837  loss_box_reg_stage2: 0.3058  loss_mask: 0.5232  loss_rpn_cls: 0.05635  loss_rpn_loc: 0.03296  validation_loss: 2.135  time: 1.6681  data_time: 0.0318  lr: 1.7183e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:55:31 d2.utils.events]: \u001b[0m eta: 1:10:10  iter: 7299  total_loss: 2.455  loss_cls_stage0: 0.3628  loss_box_reg_stage0: 0.28  loss_cls_stage1: 0.2994  loss_box_reg_stage1: 0.3798  loss_cls_stage2: 0.2094  loss_box_reg_stage2: 0.2954  loss_mask: 0.5636  loss_rpn_cls: 0.07185  loss_rpn_loc: 0.04393  validation_loss: 2.135  time: 1.6678  data_time: 0.0247  lr: 1.6946e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:56:03 d2.utils.events]: \u001b[0m eta: 1:09:38  iter: 7319  total_loss: 2.433  loss_cls_stage0: 0.3457  loss_box_reg_stage0: 0.2544  loss_cls_stage1: 0.2843  loss_box_reg_stage1: 0.3547  loss_cls_stage2: 0.2106  loss_box_reg_stage2: 0.2765  loss_mask: 0.5375  loss_rpn_cls: 0.07001  loss_rpn_loc: 0.03944  validation_loss: 2.135  time: 1.6676  data_time: 0.0224  lr: 1.6711e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:56:34 d2.utils.events]: \u001b[0m eta: 1:09:07  iter: 7339  total_loss: 2.161  loss_cls_stage0: 0.3124  loss_box_reg_stage0: 0.2554  loss_cls_stage1: 0.2543  loss_box_reg_stage1: 0.3248  loss_cls_stage2: 0.184  loss_box_reg_stage2: 0.3059  loss_mask: 0.5357  loss_rpn_cls: 0.06104  loss_rpn_loc: 0.03235  validation_loss: 2.135  time: 1.6673  data_time: 0.0243  lr: 1.6477e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:57:05 d2.utils.events]: \u001b[0m eta: 1:08:37  iter: 7359  total_loss: 2.397  loss_cls_stage0: 0.3344  loss_box_reg_stage0: 0.2716  loss_cls_stage1: 0.2751  loss_box_reg_stage1: 0.3745  loss_cls_stage2: 0.1954  loss_box_reg_stage2: 0.3035  loss_mask: 0.492  loss_rpn_cls: 0.06031  loss_rpn_loc: 0.03861  validation_loss: 2.135  time: 1.6670  data_time: 0.0243  lr: 1.6245e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:57:37 d2.utils.events]: \u001b[0m eta: 1:08:06  iter: 7379  total_loss: 2.202  loss_cls_stage0: 0.3236  loss_box_reg_stage0: 0.2651  loss_cls_stage1: 0.2558  loss_box_reg_stage1: 0.3643  loss_cls_stage2: 0.1851  loss_box_reg_stage2: 0.2757  loss_mask: 0.5117  loss_rpn_cls: 0.06502  loss_rpn_loc: 0.03342  validation_loss: 2.135  time: 1.6667  data_time: 0.0233  lr: 1.6014e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:58:08 d2.utils.events]: \u001b[0m eta: 1:07:38  iter: 7399  total_loss: 2.537  loss_cls_stage0: 0.3569  loss_box_reg_stage0: 0.274  loss_cls_stage1: 0.2858  loss_box_reg_stage1: 0.4066  loss_cls_stage2: 0.2033  loss_box_reg_stage2: 0.311  loss_mask: 0.5454  loss_rpn_cls: 0.06477  loss_rpn_loc: 0.04031  validation_loss: 2.135  time: 1.6665  data_time: 0.0232  lr: 1.5784e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:58:40 d2.utils.events]: \u001b[0m eta: 1:07:07  iter: 7419  total_loss: 2.328  loss_cls_stage0: 0.3305  loss_box_reg_stage0: 0.2741  loss_cls_stage1: 0.2624  loss_box_reg_stage1: 0.3795  loss_cls_stage2: 0.1882  loss_box_reg_stage2: 0.3076  loss_mask: 0.5647  loss_rpn_cls: 0.05585  loss_rpn_loc: 0.03915  validation_loss: 2.135  time: 1.6662  data_time: 0.0245  lr: 1.5556e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:59:11 d2.utils.events]: \u001b[0m eta: 1:06:37  iter: 7439  total_loss: 2.504  loss_cls_stage0: 0.3397  loss_box_reg_stage0: 0.2925  loss_cls_stage1: 0.28  loss_box_reg_stage1: 0.4024  loss_cls_stage2: 0.1895  loss_box_reg_stage2: 0.3356  loss_mask: 0.5788  loss_rpn_cls: 0.06044  loss_rpn_loc: 0.03773  validation_loss: 2.135  time: 1.6660  data_time: 0.0236  lr: 1.5329e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 19:59:43 d2.utils.events]: \u001b[0m eta: 1:06:05  iter: 7459  total_loss: 2.35  loss_cls_stage0: 0.3291  loss_box_reg_stage0: 0.2392  loss_cls_stage1: 0.2739  loss_box_reg_stage1: 0.3557  loss_cls_stage2: 0.1954  loss_box_reg_stage2: 0.2876  loss_mask: 0.5255  loss_rpn_cls: 0.05971  loss_rpn_loc: 0.03652  validation_loss: 2.135  time: 1.6657  data_time: 0.0245  lr: 1.5103e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:00:14 d2.utils.events]: \u001b[0m eta: 1:05:34  iter: 7479  total_loss: 2.442  loss_cls_stage0: 0.3289  loss_box_reg_stage0: 0.2665  loss_cls_stage1: 0.2665  loss_box_reg_stage1: 0.3893  loss_cls_stage2: 0.1942  loss_box_reg_stage2: 0.3224  loss_mask: 0.5567  loss_rpn_cls: 0.06268  loss_rpn_loc: 0.03675  validation_loss: 2.135  time: 1.6654  data_time: 0.0247  lr: 1.4879e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:00:45 d2.utils.events]: \u001b[0m eta: 1:05:03  iter: 7499  total_loss: 2.364  loss_cls_stage0: 0.3304  loss_box_reg_stage0: 0.2503  loss_cls_stage1: 0.2699  loss_box_reg_stage1: 0.3374  loss_cls_stage2: 0.2015  loss_box_reg_stage2: 0.3152  loss_mask: 0.5314  loss_rpn_cls: 0.06054  loss_rpn_loc: 0.03714  validation_loss: 2.135  time: 1.6652  data_time: 0.0238  lr: 1.4656e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:01:17 d2.utils.events]: \u001b[0m eta: 1:04:33  iter: 7519  total_loss: 2.502  loss_cls_stage0: 0.339  loss_box_reg_stage0: 0.2732  loss_cls_stage1: 0.2929  loss_box_reg_stage1: 0.3778  loss_cls_stage2: 0.1997  loss_box_reg_stage2: 0.3332  loss_mask: 0.533  loss_rpn_cls: 0.06617  loss_rpn_loc: 0.04331  validation_loss: 2.135  time: 1.6649  data_time: 0.0249  lr: 1.4434e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:01:48 d2.utils.events]: \u001b[0m eta: 1:04:02  iter: 7539  total_loss: 2.275  loss_cls_stage0: 0.3075  loss_box_reg_stage0: 0.2497  loss_cls_stage1: 0.26  loss_box_reg_stage1: 0.335  loss_cls_stage2: 0.1955  loss_box_reg_stage2: 0.2767  loss_mask: 0.5769  loss_rpn_cls: 0.05681  loss_rpn_loc: 0.03741  validation_loss: 2.135  time: 1.6646  data_time: 0.0230  lr: 1.4214e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:02:19 d2.utils.events]: \u001b[0m eta: 1:03:31  iter: 7559  total_loss: 2.191  loss_cls_stage0: 0.3104  loss_box_reg_stage0: 0.2646  loss_cls_stage1: 0.2468  loss_box_reg_stage1: 0.3621  loss_cls_stage2: 0.1759  loss_box_reg_stage2: 0.3024  loss_mask: 0.5369  loss_rpn_cls: 0.05266  loss_rpn_loc: 0.03076  validation_loss: 2.135  time: 1.6644  data_time: 0.0240  lr: 1.3995e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:02:50 d2.utils.events]: \u001b[0m eta: 1:03:01  iter: 7579  total_loss: 2.461  loss_cls_stage0: 0.3601  loss_box_reg_stage0: 0.2838  loss_cls_stage1: 0.2985  loss_box_reg_stage1: 0.4002  loss_cls_stage2: 0.2131  loss_box_reg_stage2: 0.2958  loss_mask: 0.5465  loss_rpn_cls: 0.06075  loss_rpn_loc: 0.03777  validation_loss: 2.135  time: 1.6641  data_time: 0.0227  lr: 1.3778e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:03:22 d2.utils.events]: \u001b[0m eta: 1:02:29  iter: 7599  total_loss: 2.279  loss_cls_stage0: 0.3316  loss_box_reg_stage0: 0.2378  loss_cls_stage1: 0.2641  loss_box_reg_stage1: 0.3341  loss_cls_stage2: 0.1924  loss_box_reg_stage2: 0.2846  loss_mask: 0.5519  loss_rpn_cls: 0.05721  loss_rpn_loc: 0.03006  validation_loss: 2.135  time: 1.6638  data_time: 0.0234  lr: 1.3562e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:03:53 d2.utils.events]: \u001b[0m eta: 1:01:57  iter: 7619  total_loss: 2.34  loss_cls_stage0: 0.3202  loss_box_reg_stage0: 0.2552  loss_cls_stage1: 0.2584  loss_box_reg_stage1: 0.3643  loss_cls_stage2: 0.1877  loss_box_reg_stage2: 0.2982  loss_mask: 0.5577  loss_rpn_cls: 0.05087  loss_rpn_loc: 0.03654  validation_loss: 2.135  time: 1.6636  data_time: 0.0234  lr: 1.3348e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:04:25 d2.utils.events]: \u001b[0m eta: 1:01:26  iter: 7639  total_loss: 2.454  loss_cls_stage0: 0.3578  loss_box_reg_stage0: 0.2956  loss_cls_stage1: 0.2989  loss_box_reg_stage1: 0.3877  loss_cls_stage2: 0.2087  loss_box_reg_stage2: 0.3001  loss_mask: 0.5107  loss_rpn_cls: 0.06552  loss_rpn_loc: 0.04528  validation_loss: 2.135  time: 1.6634  data_time: 0.0242  lr: 1.3135e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:04:56 d2.utils.events]: \u001b[0m eta: 1:00:54  iter: 7659  total_loss: 2.445  loss_cls_stage0: 0.3612  loss_box_reg_stage0: 0.2581  loss_cls_stage1: 0.2967  loss_box_reg_stage1: 0.3804  loss_cls_stage2: 0.1937  loss_box_reg_stage2: 0.2882  loss_mask: 0.5554  loss_rpn_cls: 0.07217  loss_rpn_loc: 0.03781  validation_loss: 2.135  time: 1.6631  data_time: 0.0234  lr: 1.2923e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:05:27 d2.utils.events]: \u001b[0m eta: 1:00:23  iter: 7679  total_loss: 2.34  loss_cls_stage0: 0.308  loss_box_reg_stage0: 0.2517  loss_cls_stage1: 0.2683  loss_box_reg_stage1: 0.3681  loss_cls_stage2: 0.196  loss_box_reg_stage2: 0.2981  loss_mask: 0.5129  loss_rpn_cls: 0.05917  loss_rpn_loc: 0.03868  validation_loss: 2.135  time: 1.6629  data_time: 0.0251  lr: 1.2713e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:05:59 d2.utils.events]: \u001b[0m eta: 0:59:54  iter: 7699  total_loss: 2.436  loss_cls_stage0: 0.3279  loss_box_reg_stage0: 0.2648  loss_cls_stage1: 0.2709  loss_box_reg_stage1: 0.3856  loss_cls_stage2: 0.2048  loss_box_reg_stage2: 0.3088  loss_mask: 0.5091  loss_rpn_cls: 0.05682  loss_rpn_loc: 0.0405  validation_loss: 2.135  time: 1.6627  data_time: 0.0234  lr: 1.2505e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:06:30 d2.utils.events]: \u001b[0m eta: 0:59:22  iter: 7719  total_loss: 2.36  loss_cls_stage0: 0.3086  loss_box_reg_stage0: 0.2426  loss_cls_stage1: 0.2645  loss_box_reg_stage1: 0.3626  loss_cls_stage2: 0.1914  loss_box_reg_stage2: 0.32  loss_mask: 0.5259  loss_rpn_cls: 0.06357  loss_rpn_loc: 0.03589  validation_loss: 2.135  time: 1.6624  data_time: 0.0237  lr: 1.2298e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:07:02 d2.utils.events]: \u001b[0m eta: 0:58:51  iter: 7739  total_loss: 2.343  loss_cls_stage0: 0.3429  loss_box_reg_stage0: 0.2737  loss_cls_stage1: 0.2843  loss_box_reg_stage1: 0.3583  loss_cls_stage2: 0.2016  loss_box_reg_stage2: 0.31  loss_mask: 0.4997  loss_rpn_cls: 0.06005  loss_rpn_loc: 0.03428  validation_loss: 2.135  time: 1.6622  data_time: 0.0226  lr: 1.2092e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:07:33 d2.utils.events]: \u001b[0m eta: 0:58:20  iter: 7759  total_loss: 2.352  loss_cls_stage0: 0.3161  loss_box_reg_stage0: 0.2521  loss_cls_stage1: 0.2604  loss_box_reg_stage1: 0.3557  loss_cls_stage2: 0.1929  loss_box_reg_stage2: 0.3054  loss_mask: 0.5688  loss_rpn_cls: 0.06051  loss_rpn_loc: 0.03665  validation_loss: 2.135  time: 1.6619  data_time: 0.0242  lr: 1.1888e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:08:04 d2.utils.events]: \u001b[0m eta: 0:57:48  iter: 7779  total_loss: 2.234  loss_cls_stage0: 0.3343  loss_box_reg_stage0: 0.2479  loss_cls_stage1: 0.282  loss_box_reg_stage1: 0.3516  loss_cls_stage2: 0.1959  loss_box_reg_stage2: 0.3091  loss_mask: 0.4975  loss_rpn_cls: 0.05661  loss_rpn_loc: 0.03374  validation_loss: 2.135  time: 1.6617  data_time: 0.0241  lr: 1.1685e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:08:36 d2.utils.events]: \u001b[0m eta: 0:57:18  iter: 7799  total_loss: 2.48  loss_cls_stage0: 0.3461  loss_box_reg_stage0: 0.2782  loss_cls_stage1: 0.2817  loss_box_reg_stage1: 0.3831  loss_cls_stage2: 0.2051  loss_box_reg_stage2: 0.2926  loss_mask: 0.5391  loss_rpn_cls: 0.06393  loss_rpn_loc: 0.0391  validation_loss: 2.135  time: 1.6614  data_time: 0.0234  lr: 1.1484e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:09:07 d2.utils.events]: \u001b[0m eta: 0:56:47  iter: 7819  total_loss: 2.29  loss_cls_stage0: 0.317  loss_box_reg_stage0: 0.2412  loss_cls_stage1: 0.2622  loss_box_reg_stage1: 0.3611  loss_cls_stage2: 0.1985  loss_box_reg_stage2: 0.2951  loss_mask: 0.5491  loss_rpn_cls: 0.06303  loss_rpn_loc: 0.03543  validation_loss: 2.135  time: 1.6612  data_time: 0.0240  lr: 1.1285e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:09:39 d2.utils.events]: \u001b[0m eta: 0:56:15  iter: 7839  total_loss: 2.428  loss_cls_stage0: 0.3256  loss_box_reg_stage0: 0.2507  loss_cls_stage1: 0.2846  loss_box_reg_stage1: 0.3729  loss_cls_stage2: 0.1936  loss_box_reg_stage2: 0.3128  loss_mask: 0.5722  loss_rpn_cls: 0.0556  loss_rpn_loc: 0.03489  validation_loss: 2.135  time: 1.6610  data_time: 0.0241  lr: 1.1087e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:10:10 d2.utils.events]: \u001b[0m eta: 0:55:46  iter: 7859  total_loss: 2.414  loss_cls_stage0: 0.3318  loss_box_reg_stage0: 0.2554  loss_cls_stage1: 0.2875  loss_box_reg_stage1: 0.413  loss_cls_stage2: 0.2204  loss_box_reg_stage2: 0.3213  loss_mask: 0.4974  loss_rpn_cls: 0.06645  loss_rpn_loc: 0.03657  validation_loss: 2.135  time: 1.6607  data_time: 0.0239  lr: 1.089e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:10:41 d2.utils.events]: \u001b[0m eta: 0:55:14  iter: 7879  total_loss: 2.348  loss_cls_stage0: 0.3052  loss_box_reg_stage0: 0.2538  loss_cls_stage1: 0.2543  loss_box_reg_stage1: 0.3667  loss_cls_stage2: 0.186  loss_box_reg_stage2: 0.314  loss_mask: 0.5549  loss_rpn_cls: 0.05663  loss_rpn_loc: 0.03391  validation_loss: 2.135  time: 1.6605  data_time: 0.0241  lr: 1.0695e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:11:13 d2.utils.events]: \u001b[0m eta: 0:54:43  iter: 7899  total_loss: 2.378  loss_cls_stage0: 0.3289  loss_box_reg_stage0: 0.2619  loss_cls_stage1: 0.2804  loss_box_reg_stage1: 0.3521  loss_cls_stage2: 0.2046  loss_box_reg_stage2: 0.3025  loss_mask: 0.4871  loss_rpn_cls: 0.06805  loss_rpn_loc: 0.03573  validation_loss: 2.135  time: 1.6603  data_time: 0.0221  lr: 1.0502e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:11:44 d2.utils.events]: \u001b[0m eta: 0:54:11  iter: 7919  total_loss: 2.369  loss_cls_stage0: 0.3139  loss_box_reg_stage0: 0.2467  loss_cls_stage1: 0.2684  loss_box_reg_stage1: 0.3595  loss_cls_stage2: 0.1932  loss_box_reg_stage2: 0.2979  loss_mask: 0.5841  loss_rpn_cls: 0.06552  loss_rpn_loc: 0.03397  validation_loss: 2.135  time: 1.6600  data_time: 0.0232  lr: 1.031e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:12:15 d2.utils.events]: \u001b[0m eta: 0:53:40  iter: 7939  total_loss: 2.398  loss_cls_stage0: 0.326  loss_box_reg_stage0: 0.2486  loss_cls_stage1: 0.2765  loss_box_reg_stage1: 0.3523  loss_cls_stage2: 0.2035  loss_box_reg_stage2: 0.2972  loss_mask: 0.5201  loss_rpn_cls: 0.06558  loss_rpn_loc: 0.03332  validation_loss: 2.135  time: 1.6598  data_time: 0.0234  lr: 1.012e-05  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:12:47 d2.utils.events]: \u001b[0m eta: 0:53:09  iter: 7959  total_loss: 2.475  loss_cls_stage0: 0.309  loss_box_reg_stage0: 0.2443  loss_cls_stage1: 0.2707  loss_box_reg_stage1: 0.3462  loss_cls_stage2: 0.1963  loss_box_reg_stage2: 0.2988  loss_mask: 0.5647  loss_rpn_cls: 0.06126  loss_rpn_loc: 0.03078  validation_loss: 2.135  time: 1.6596  data_time: 0.0222  lr: 9.931e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:13:18 d2.utils.events]: \u001b[0m eta: 0:52:38  iter: 7979  total_loss: 2.449  loss_cls_stage0: 0.3365  loss_box_reg_stage0: 0.2706  loss_cls_stage1: 0.2742  loss_box_reg_stage1: 0.3838  loss_cls_stage2: 0.2145  loss_box_reg_stage2: 0.3347  loss_mask: 0.5123  loss_rpn_cls: 0.07268  loss_rpn_loc: 0.03809  validation_loss: 2.135  time: 1.6593  data_time: 0.0237  lr: 9.7439e-06  max_mem: 11723M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/26 20:13:52 d2.data.common]: \u001b[0mSerializing 859 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/26 20:13:52 d2.data.common]: \u001b[0mSerialized dataset takes 0.90 MiB\n",
      "\u001b[32m[03/26 20:13:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 859 images\n",
      "\u001b[32m[03/26 20:13:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/859. 0.0808 s / img. ETA=0:01:38\n",
      "\u001b[32m[03/26 20:13:59 d2.evaluation.evaluator]: \u001b[0mInference done 53/859. 0.0810 s / img. ETA=0:01:36\n",
      "\u001b[32m[03/26 20:14:04 d2.evaluation.evaluator]: \u001b[0mInference done 94/859. 0.0812 s / img. ETA=0:01:32\n",
      "\u001b[32m[03/26 20:14:09 d2.evaluation.evaluator]: \u001b[0mInference done 136/859. 0.0811 s / img. ETA=0:01:27\n",
      "\u001b[32m[03/26 20:14:14 d2.evaluation.evaluator]: \u001b[0mInference done 179/859. 0.0810 s / img. ETA=0:01:21\n",
      "\u001b[32m[03/26 20:14:19 d2.evaluation.evaluator]: \u001b[0mInference done 218/859. 0.0812 s / img. ETA=0:01:18\n",
      "\u001b[32m[03/26 20:14:24 d2.evaluation.evaluator]: \u001b[0mInference done 260/859. 0.0812 s / img. ETA=0:01:12\n",
      "\u001b[32m[03/26 20:14:29 d2.evaluation.evaluator]: \u001b[0mInference done 298/859. 0.0813 s / img. ETA=0:01:09\n",
      "\u001b[32m[03/26 20:14:34 d2.evaluation.evaluator]: \u001b[0mInference done 341/859. 0.0812 s / img. ETA=0:01:03\n",
      "\u001b[32m[03/26 20:14:39 d2.evaluation.evaluator]: \u001b[0mInference done 386/859. 0.0811 s / img. ETA=0:00:57\n",
      "\u001b[32m[03/26 20:14:44 d2.evaluation.evaluator]: \u001b[0mInference done 427/859. 0.0811 s / img. ETA=0:00:52\n",
      "\u001b[32m[03/26 20:14:49 d2.evaluation.evaluator]: \u001b[0mInference done 468/859. 0.0811 s / img. ETA=0:00:47\n",
      "\u001b[32m[03/26 20:14:55 d2.evaluation.evaluator]: \u001b[0mInference done 510/859. 0.0811 s / img. ETA=0:00:42\n",
      "\u001b[32m[03/26 20:15:00 d2.evaluation.evaluator]: \u001b[0mInference done 551/859. 0.0812 s / img. ETA=0:00:37\n",
      "\u001b[32m[03/26 20:15:05 d2.evaluation.evaluator]: \u001b[0mInference done 593/859. 0.0811 s / img. ETA=0:00:32\n",
      "\u001b[32m[03/26 20:15:10 d2.evaluation.evaluator]: \u001b[0mInference done 636/859. 0.0811 s / img. ETA=0:00:27\n",
      "\u001b[32m[03/26 20:15:15 d2.evaluation.evaluator]: \u001b[0mInference done 678/859. 0.0811 s / img. ETA=0:00:21\n",
      "\u001b[32m[03/26 20:15:20 d2.evaluation.evaluator]: \u001b[0mInference done 719/859. 0.0811 s / img. ETA=0:00:16\n",
      "\u001b[32m[03/26 20:15:25 d2.evaluation.evaluator]: \u001b[0mInference done 757/859. 0.0812 s / img. ETA=0:00:12\n",
      "\u001b[32m[03/26 20:15:30 d2.evaluation.evaluator]: \u001b[0mInference done 799/859. 0.0812 s / img. ETA=0:00:07\n",
      "\u001b[32m[03/26 20:15:35 d2.evaluation.evaluator]: \u001b[0mInference done 840/859. 0.0812 s / img. ETA=0:00:02\n",
      "\u001b[32m[03/26 20:15:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:44.291236 (0.122121 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/26 20:15:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:09 (0.081170 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.53 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.089\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.147\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.166\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.041\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.094\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.129\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.174\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.175\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.055\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.193\n",
      "\u001b[32m[03/26 20:15:38 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold2 in csv format:\n",
      "\u001b[32m[03/26 20:15:38 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/26 20:15:38 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/26 20:15:38 d2.evaluation.testing]: \u001b[0mcopypaste: 8.9441,14.7279,16.6404,0.5668,4.1336,9.3603\n",
      "validation do loss eval 2.3980750658765393\n",
      "\u001b[32m[03/26 20:17:08 d2.utils.events]: \u001b[0m eta: 0:52:08  iter: 7999  total_loss: 2.487  loss_cls_stage0: 0.3508  loss_box_reg_stage0: 0.278  loss_cls_stage1: 0.2958  loss_box_reg_stage1: 0.398  loss_cls_stage2: 0.2091  loss_box_reg_stage2: 0.3169  loss_mask: 0.5241  loss_rpn_cls: 0.06449  loss_rpn_loc: 0.03712  validation_loss: 2.2  time: 1.6591  data_time: 0.0230  lr: 9.5584e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:17:39 d2.utils.events]: \u001b[0m eta: 0:51:37  iter: 8019  total_loss: 2.306  loss_cls_stage0: 0.3017  loss_box_reg_stage0: 0.251  loss_cls_stage1: 0.253  loss_box_reg_stage1: 0.3712  loss_cls_stage2: 0.1864  loss_box_reg_stage2: 0.3011  loss_mask: 0.5317  loss_rpn_cls: 0.05494  loss_rpn_loc: 0.03084  validation_loss: 2.2  time: 1.6589  data_time: 0.0251  lr: 9.3744e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:18:10 d2.utils.events]: \u001b[0m eta: 0:51:06  iter: 8039  total_loss: 2.364  loss_cls_stage0: 0.3178  loss_box_reg_stage0: 0.259  loss_cls_stage1: 0.2729  loss_box_reg_stage1: 0.3784  loss_cls_stage2: 0.1919  loss_box_reg_stage2: 0.3144  loss_mask: 0.5731  loss_rpn_cls: 0.05934  loss_rpn_loc: 0.0344  validation_loss: 2.2  time: 1.6586  data_time: 0.0223  lr: 9.1921e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:18:42 d2.utils.events]: \u001b[0m eta: 0:50:34  iter: 8059  total_loss: 2.319  loss_cls_stage0: 0.31  loss_box_reg_stage0: 0.2322  loss_cls_stage1: 0.2661  loss_box_reg_stage1: 0.3306  loss_cls_stage2: 0.208  loss_box_reg_stage2: 0.3058  loss_mask: 0.5383  loss_rpn_cls: 0.05724  loss_rpn_loc: 0.0312  validation_loss: 2.2  time: 1.6584  data_time: 0.0229  lr: 9.0114e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:19:13 d2.utils.events]: \u001b[0m eta: 0:50:02  iter: 8079  total_loss: 2.287  loss_cls_stage0: 0.3035  loss_box_reg_stage0: 0.2187  loss_cls_stage1: 0.228  loss_box_reg_stage1: 0.3414  loss_cls_stage2: 0.1812  loss_box_reg_stage2: 0.2971  loss_mask: 0.5269  loss_rpn_cls: 0.06616  loss_rpn_loc: 0.03493  validation_loss: 2.2  time: 1.6581  data_time: 0.0246  lr: 8.8323e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:19:44 d2.utils.events]: \u001b[0m eta: 0:49:31  iter: 8099  total_loss: 2.469  loss_cls_stage0: 0.3632  loss_box_reg_stage0: 0.2876  loss_cls_stage1: 0.2906  loss_box_reg_stage1: 0.3919  loss_cls_stage2: 0.203  loss_box_reg_stage2: 0.3124  loss_mask: 0.5526  loss_rpn_cls: 0.06592  loss_rpn_loc: 0.03922  validation_loss: 2.2  time: 1.6579  data_time: 0.0230  lr: 8.6548e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:20:16 d2.utils.events]: \u001b[0m eta: 0:49:01  iter: 8119  total_loss: 2.55  loss_cls_stage0: 0.3438  loss_box_reg_stage0: 0.2752  loss_cls_stage1: 0.3078  loss_box_reg_stage1: 0.3911  loss_cls_stage2: 0.2306  loss_box_reg_stage2: 0.2951  loss_mask: 0.5619  loss_rpn_cls: 0.06208  loss_rpn_loc: 0.04098  validation_loss: 2.2  time: 1.6577  data_time: 0.0245  lr: 8.479e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:20:47 d2.utils.events]: \u001b[0m eta: 0:48:29  iter: 8139  total_loss: 2.395  loss_cls_stage0: 0.3423  loss_box_reg_stage0: 0.2639  loss_cls_stage1: 0.2763  loss_box_reg_stage1: 0.3506  loss_cls_stage2: 0.1805  loss_box_reg_stage2: 0.301  loss_mask: 0.5443  loss_rpn_cls: 0.05807  loss_rpn_loc: 0.03717  validation_loss: 2.2  time: 1.6575  data_time: 0.0235  lr: 8.3047e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:21:18 d2.utils.events]: \u001b[0m eta: 0:47:58  iter: 8159  total_loss: 2.417  loss_cls_stage0: 0.3504  loss_box_reg_stage0: 0.2857  loss_cls_stage1: 0.2708  loss_box_reg_stage1: 0.3711  loss_cls_stage2: 0.1834  loss_box_reg_stage2: 0.3014  loss_mask: 0.4998  loss_rpn_cls: 0.06392  loss_rpn_loc: 0.0375  validation_loss: 2.2  time: 1.6573  data_time: 0.0230  lr: 8.1322e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:21:50 d2.utils.events]: \u001b[0m eta: 0:47:27  iter: 8179  total_loss: 2.477  loss_cls_stage0: 0.3452  loss_box_reg_stage0: 0.2791  loss_cls_stage1: 0.29  loss_box_reg_stage1: 0.3947  loss_cls_stage2: 0.2012  loss_box_reg_stage2: 0.3118  loss_mask: 0.5236  loss_rpn_cls: 0.07605  loss_rpn_loc: 0.04007  validation_loss: 2.2  time: 1.6571  data_time: 0.0240  lr: 7.9613e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:22:21 d2.utils.events]: \u001b[0m eta: 0:46:56  iter: 8199  total_loss: 2.453  loss_cls_stage0: 0.3277  loss_box_reg_stage0: 0.2695  loss_cls_stage1: 0.2684  loss_box_reg_stage1: 0.361  loss_cls_stage2: 0.1916  loss_box_reg_stage2: 0.2937  loss_mask: 0.5582  loss_rpn_cls: 0.06776  loss_rpn_loc: 0.03803  validation_loss: 2.2  time: 1.6569  data_time: 0.0225  lr: 7.792e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:22:52 d2.utils.events]: \u001b[0m eta: 0:46:25  iter: 8219  total_loss: 2.46  loss_cls_stage0: 0.3322  loss_box_reg_stage0: 0.2641  loss_cls_stage1: 0.2836  loss_box_reg_stage1: 0.3803  loss_cls_stage2: 0.2049  loss_box_reg_stage2: 0.3039  loss_mask: 0.543  loss_rpn_cls: 0.06107  loss_rpn_loc: 0.03604  validation_loss: 2.2  time: 1.6566  data_time: 0.0235  lr: 7.6244e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:23:24 d2.utils.events]: \u001b[0m eta: 0:45:54  iter: 8239  total_loss: 2.369  loss_cls_stage0: 0.3271  loss_box_reg_stage0: 0.2592  loss_cls_stage1: 0.2826  loss_box_reg_stage1: 0.3625  loss_cls_stage2: 0.1932  loss_box_reg_stage2: 0.2967  loss_mask: 0.5346  loss_rpn_cls: 0.06334  loss_rpn_loc: 0.04022  validation_loss: 2.2  time: 1.6564  data_time: 0.0238  lr: 7.4585e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:23:55 d2.utils.events]: \u001b[0m eta: 0:45:22  iter: 8259  total_loss: 2.324  loss_cls_stage0: 0.2977  loss_box_reg_stage0: 0.2363  loss_cls_stage1: 0.2562  loss_box_reg_stage1: 0.366  loss_cls_stage2: 0.1994  loss_box_reg_stage2: 0.317  loss_mask: 0.5369  loss_rpn_cls: 0.06143  loss_rpn_loc: 0.03343  validation_loss: 2.2  time: 1.6562  data_time: 0.0251  lr: 7.2943e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:24:27 d2.utils.events]: \u001b[0m eta: 0:44:51  iter: 8279  total_loss: 2.509  loss_cls_stage0: 0.3545  loss_box_reg_stage0: 0.2988  loss_cls_stage1: 0.2846  loss_box_reg_stage1: 0.3926  loss_cls_stage2: 0.195  loss_box_reg_stage2: 0.32  loss_mask: 0.5254  loss_rpn_cls: 0.06158  loss_rpn_loc: 0.03515  validation_loss: 2.2  time: 1.6560  data_time: 0.0228  lr: 7.1318e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:24:58 d2.utils.events]: \u001b[0m eta: 0:44:20  iter: 8299  total_loss: 2.525  loss_cls_stage0: 0.3406  loss_box_reg_stage0: 0.2552  loss_cls_stage1: 0.2879  loss_box_reg_stage1: 0.3492  loss_cls_stage2: 0.2039  loss_box_reg_stage2: 0.2996  loss_mask: 0.5443  loss_rpn_cls: 0.07238  loss_rpn_loc: 0.04123  validation_loss: 2.2  time: 1.6558  data_time: 0.0234  lr: 6.9709e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:25:29 d2.utils.events]: \u001b[0m eta: 0:43:48  iter: 8319  total_loss: 2.426  loss_cls_stage0: 0.3373  loss_box_reg_stage0: 0.2681  loss_cls_stage1: 0.2809  loss_box_reg_stage1: 0.3695  loss_cls_stage2: 0.2011  loss_box_reg_stage2: 0.3085  loss_mask: 0.537  loss_rpn_cls: 0.05899  loss_rpn_loc: 0.03252  validation_loss: 2.2  time: 1.6556  data_time: 0.0227  lr: 6.8117e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:26:01 d2.utils.events]: \u001b[0m eta: 0:43:17  iter: 8339  total_loss: 2.348  loss_cls_stage0: 0.309  loss_box_reg_stage0: 0.2449  loss_cls_stage1: 0.2607  loss_box_reg_stage1: 0.3782  loss_cls_stage2: 0.1881  loss_box_reg_stage2: 0.3063  loss_mask: 0.5325  loss_rpn_cls: 0.05433  loss_rpn_loc: 0.03097  validation_loss: 2.2  time: 1.6554  data_time: 0.0237  lr: 6.6543e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:26:32 d2.utils.events]: \u001b[0m eta: 0:42:45  iter: 8359  total_loss: 2.304  loss_cls_stage0: 0.312  loss_box_reg_stage0: 0.2578  loss_cls_stage1: 0.2657  loss_box_reg_stage1: 0.3607  loss_cls_stage2: 0.1955  loss_box_reg_stage2: 0.292  loss_mask: 0.5648  loss_rpn_cls: 0.06824  loss_rpn_loc: 0.0386  validation_loss: 2.2  time: 1.6551  data_time: 0.0235  lr: 6.4986e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:27:04 d2.utils.events]: \u001b[0m eta: 0:42:14  iter: 8379  total_loss: 2.497  loss_cls_stage0: 0.35  loss_box_reg_stage0: 0.2834  loss_cls_stage1: 0.3058  loss_box_reg_stage1: 0.3793  loss_cls_stage2: 0.2164  loss_box_reg_stage2: 0.308  loss_mask: 0.501  loss_rpn_cls: 0.06692  loss_rpn_loc: 0.03765  validation_loss: 2.2  time: 1.6550  data_time: 0.0228  lr: 6.3445e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:27:35 d2.utils.events]: \u001b[0m eta: 0:41:43  iter: 8399  total_loss: 2.563  loss_cls_stage0: 0.3819  loss_box_reg_stage0: 0.2909  loss_cls_stage1: 0.3128  loss_box_reg_stage1: 0.3945  loss_cls_stage2: 0.1954  loss_box_reg_stage2: 0.2954  loss_mask: 0.5361  loss_rpn_cls: 0.05677  loss_rpn_loc: 0.03687  validation_loss: 2.2  time: 1.6548  data_time: 0.0219  lr: 6.1922e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:28:06 d2.utils.events]: \u001b[0m eta: 0:41:11  iter: 8419  total_loss: 2.324  loss_cls_stage0: 0.3089  loss_box_reg_stage0: 0.2552  loss_cls_stage1: 0.2426  loss_box_reg_stage1: 0.3805  loss_cls_stage2: 0.1806  loss_box_reg_stage2: 0.3251  loss_mask: 0.5148  loss_rpn_cls: 0.05476  loss_rpn_loc: 0.03532  validation_loss: 2.2  time: 1.6546  data_time: 0.0240  lr: 6.0417e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:28:38 d2.utils.events]: \u001b[0m eta: 0:40:40  iter: 8439  total_loss: 2.335  loss_cls_stage0: 0.3402  loss_box_reg_stage0: 0.2667  loss_cls_stage1: 0.2804  loss_box_reg_stage1: 0.381  loss_cls_stage2: 0.1954  loss_box_reg_stage2: 0.2963  loss_mask: 0.4717  loss_rpn_cls: 0.05907  loss_rpn_loc: 0.03608  validation_loss: 2.2  time: 1.6544  data_time: 0.0239  lr: 5.8928e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:29:09 d2.utils.events]: \u001b[0m eta: 0:40:09  iter: 8459  total_loss: 2.42  loss_cls_stage0: 0.3406  loss_box_reg_stage0: 0.2649  loss_cls_stage1: 0.2742  loss_box_reg_stage1: 0.386  loss_cls_stage2: 0.211  loss_box_reg_stage2: 0.3198  loss_mask: 0.5267  loss_rpn_cls: 0.06212  loss_rpn_loc: 0.03593  validation_loss: 2.2  time: 1.6542  data_time: 0.0233  lr: 5.7457e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:29:41 d2.utils.events]: \u001b[0m eta: 0:39:38  iter: 8479  total_loss: 2.314  loss_cls_stage0: 0.3325  loss_box_reg_stage0: 0.2419  loss_cls_stage1: 0.2816  loss_box_reg_stage1: 0.365  loss_cls_stage2: 0.1969  loss_box_reg_stage2: 0.31  loss_mask: 0.4977  loss_rpn_cls: 0.06411  loss_rpn_loc: 0.0358  validation_loss: 2.2  time: 1.6540  data_time: 0.0236  lr: 5.6004e-06  max_mem: 11723M\n",
      "\u001b[32m[03/26 20:30:12 d2.utils.events]: \u001b[0m eta: 0:39:07  iter: 8499  total_loss: 2.378  loss_cls_stage0: 0.3317  loss_box_reg_stage0: 0.2793  loss_cls_stage1: 0.2638  loss_box_reg_stage1: 0.3741  loss_cls_stage2: 0.2032  loss_box_reg_stage2: 0.3174  loss_mask: 0.5155  loss_rpn_cls: 0.06014  loss_rpn_loc: 0.03343  validation_loss: 2.2  time: 1.6538  data_time: 0.0241  lr: 5.4568e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:30:44 d2.utils.events]: \u001b[0m eta: 0:38:35  iter: 8519  total_loss: 2.397  loss_cls_stage0: 0.3331  loss_box_reg_stage0: 0.2512  loss_cls_stage1: 0.2781  loss_box_reg_stage1: 0.3594  loss_cls_stage2: 0.2042  loss_box_reg_stage2: 0.3162  loss_mask: 0.5575  loss_rpn_cls: 0.06005  loss_rpn_loc: 0.03573  validation_loss: 2.2  time: 1.6536  data_time: 0.0238  lr: 5.315e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:31:15 d2.utils.events]: \u001b[0m eta: 0:38:04  iter: 8539  total_loss: 2.507  loss_cls_stage0: 0.3586  loss_box_reg_stage0: 0.2735  loss_cls_stage1: 0.3078  loss_box_reg_stage1: 0.3784  loss_cls_stage2: 0.2135  loss_box_reg_stage2: 0.3235  loss_mask: 0.524  loss_rpn_cls: 0.06222  loss_rpn_loc: 0.03568  validation_loss: 2.2  time: 1.6534  data_time: 0.0232  lr: 5.1749e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:31:47 d2.utils.events]: \u001b[0m eta: 0:37:33  iter: 8559  total_loss: 2.566  loss_cls_stage0: 0.3559  loss_box_reg_stage0: 0.2945  loss_cls_stage1: 0.2943  loss_box_reg_stage1: 0.3822  loss_cls_stage2: 0.2067  loss_box_reg_stage2: 0.3383  loss_mask: 0.5378  loss_rpn_cls: 0.05862  loss_rpn_loc: 0.03663  validation_loss: 2.2  time: 1.6532  data_time: 0.0238  lr: 5.0366e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:32:18 d2.utils.events]: \u001b[0m eta: 0:37:01  iter: 8579  total_loss: 2.308  loss_cls_stage0: 0.3286  loss_box_reg_stage0: 0.2689  loss_cls_stage1: 0.2702  loss_box_reg_stage1: 0.377  loss_cls_stage2: 0.1948  loss_box_reg_stage2: 0.2947  loss_mask: 0.5242  loss_rpn_cls: 0.06392  loss_rpn_loc: 0.03773  validation_loss: 2.2  time: 1.6530  data_time: 0.0240  lr: 4.9001e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:32:49 d2.utils.events]: \u001b[0m eta: 0:36:30  iter: 8599  total_loss: 2.502  loss_cls_stage0: 0.3555  loss_box_reg_stage0: 0.2892  loss_cls_stage1: 0.3086  loss_box_reg_stage1: 0.3814  loss_cls_stage2: 0.2214  loss_box_reg_stage2: 0.3096  loss_mask: 0.5638  loss_rpn_cls: 0.06582  loss_rpn_loc: 0.0362  validation_loss: 2.2  time: 1.6528  data_time: 0.0232  lr: 4.7653e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:33:21 d2.utils.events]: \u001b[0m eta: 0:35:59  iter: 8619  total_loss: 2.4  loss_cls_stage0: 0.3266  loss_box_reg_stage0: 0.2685  loss_cls_stage1: 0.2702  loss_box_reg_stage1: 0.3482  loss_cls_stage2: 0.1775  loss_box_reg_stage2: 0.2821  loss_mask: 0.5704  loss_rpn_cls: 0.0701  loss_rpn_loc: 0.03308  validation_loss: 2.2  time: 1.6526  data_time: 0.0242  lr: 4.6324e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:33:52 d2.utils.events]: \u001b[0m eta: 0:35:27  iter: 8639  total_loss: 2.265  loss_cls_stage0: 0.3177  loss_box_reg_stage0: 0.2568  loss_cls_stage1: 0.2587  loss_box_reg_stage1: 0.3449  loss_cls_stage2: 0.1897  loss_box_reg_stage2: 0.2764  loss_mask: 0.5018  loss_rpn_cls: 0.05719  loss_rpn_loc: 0.03483  validation_loss: 2.2  time: 1.6524  data_time: 0.0235  lr: 4.5012e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:34:23 d2.utils.events]: \u001b[0m eta: 0:34:56  iter: 8659  total_loss: 2.388  loss_cls_stage0: 0.3337  loss_box_reg_stage0: 0.2543  loss_cls_stage1: 0.2719  loss_box_reg_stage1: 0.3689  loss_cls_stage2: 0.1944  loss_box_reg_stage2: 0.3109  loss_mask: 0.5497  loss_rpn_cls: 0.06704  loss_rpn_loc: 0.03763  validation_loss: 2.2  time: 1.6522  data_time: 0.0235  lr: 4.3718e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:34:55 d2.utils.events]: \u001b[0m eta: 0:34:25  iter: 8679  total_loss: 2.302  loss_cls_stage0: 0.2922  loss_box_reg_stage0: 0.2376  loss_cls_stage1: 0.2491  loss_box_reg_stage1: 0.3588  loss_cls_stage2: 0.1921  loss_box_reg_stage2: 0.3148  loss_mask: 0.5397  loss_rpn_cls: 0.0642  loss_rpn_loc: 0.03628  validation_loss: 2.2  time: 1.6520  data_time: 0.0240  lr: 4.2443e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:35:26 d2.utils.events]: \u001b[0m eta: 0:33:53  iter: 8699  total_loss: 2.382  loss_cls_stage0: 0.3196  loss_box_reg_stage0: 0.266  loss_cls_stage1: 0.2624  loss_box_reg_stage1: 0.3836  loss_cls_stage2: 0.1852  loss_box_reg_stage2: 0.3117  loss_mask: 0.571  loss_rpn_cls: 0.04918  loss_rpn_loc: 0.03202  validation_loss: 2.2  time: 1.6518  data_time: 0.0249  lr: 4.1185e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:35:57 d2.utils.events]: \u001b[0m eta: 0:33:22  iter: 8719  total_loss: 2.272  loss_cls_stage0: 0.3051  loss_box_reg_stage0: 0.2573  loss_cls_stage1: 0.2472  loss_box_reg_stage1: 0.3464  loss_cls_stage2: 0.1786  loss_box_reg_stage2: 0.2944  loss_mask: 0.5552  loss_rpn_cls: 0.05912  loss_rpn_loc: 0.03101  validation_loss: 2.2  time: 1.6516  data_time: 0.0238  lr: 3.9946e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:36:29 d2.utils.events]: \u001b[0m eta: 0:32:50  iter: 8739  total_loss: 2.407  loss_cls_stage0: 0.3358  loss_box_reg_stage0: 0.2656  loss_cls_stage1: 0.2752  loss_box_reg_stage1: 0.3697  loss_cls_stage2: 0.203  loss_box_reg_stage2: 0.3207  loss_mask: 0.5173  loss_rpn_cls: 0.06269  loss_rpn_loc: 0.03634  validation_loss: 2.2  time: 1.6514  data_time: 0.0249  lr: 3.8724e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:37:00 d2.utils.events]: \u001b[0m eta: 0:32:19  iter: 8759  total_loss: 2.465  loss_cls_stage0: 0.3427  loss_box_reg_stage0: 0.2733  loss_cls_stage1: 0.2777  loss_box_reg_stage1: 0.3784  loss_cls_stage2: 0.1999  loss_box_reg_stage2: 0.3088  loss_mask: 0.5103  loss_rpn_cls: 0.07032  loss_rpn_loc: 0.03392  validation_loss: 2.2  time: 1.6512  data_time: 0.0232  lr: 3.7521e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:37:31 d2.utils.events]: \u001b[0m eta: 0:31:48  iter: 8779  total_loss: 2.328  loss_cls_stage0: 0.318  loss_box_reg_stage0: 0.251  loss_cls_stage1: 0.2647  loss_box_reg_stage1: 0.3586  loss_cls_stage2: 0.1938  loss_box_reg_stage2: 0.2852  loss_mask: 0.5022  loss_rpn_cls: 0.05175  loss_rpn_loc: 0.02985  validation_loss: 2.2  time: 1.6510  data_time: 0.0235  lr: 3.6336e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:38:03 d2.utils.events]: \u001b[0m eta: 0:31:16  iter: 8799  total_loss: 2.223  loss_cls_stage0: 0.3053  loss_box_reg_stage0: 0.2502  loss_cls_stage1: 0.2545  loss_box_reg_stage1: 0.3624  loss_cls_stage2: 0.1671  loss_box_reg_stage2: 0.2803  loss_mask: 0.5078  loss_rpn_cls: 0.0559  loss_rpn_loc: 0.0319  validation_loss: 2.2  time: 1.6508  data_time: 0.0246  lr: 3.517e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:38:34 d2.utils.events]: \u001b[0m eta: 0:30:45  iter: 8819  total_loss: 2.462  loss_cls_stage0: 0.3437  loss_box_reg_stage0: 0.2656  loss_cls_stage1: 0.2766  loss_box_reg_stage1: 0.38  loss_cls_stage2: 0.2052  loss_box_reg_stage2: 0.3155  loss_mask: 0.5355  loss_rpn_cls: 0.06412  loss_rpn_loc: 0.03563  validation_loss: 2.2  time: 1.6506  data_time: 0.0242  lr: 3.4021e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:39:05 d2.utils.events]: \u001b[0m eta: 0:30:14  iter: 8839  total_loss: 2.463  loss_cls_stage0: 0.3684  loss_box_reg_stage0: 0.2718  loss_cls_stage1: 0.3007  loss_box_reg_stage1: 0.352  loss_cls_stage2: 0.2085  loss_box_reg_stage2: 0.3183  loss_mask: 0.5425  loss_rpn_cls: 0.06564  loss_rpn_loc: 0.04097  validation_loss: 2.2  time: 1.6504  data_time: 0.0231  lr: 3.2892e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:39:37 d2.utils.events]: \u001b[0m eta: 0:29:42  iter: 8859  total_loss: 2.414  loss_cls_stage0: 0.3235  loss_box_reg_stage0: 0.2773  loss_cls_stage1: 0.2615  loss_box_reg_stage1: 0.3782  loss_cls_stage2: 0.1898  loss_box_reg_stage2: 0.3142  loss_mask: 0.5804  loss_rpn_cls: 0.06213  loss_rpn_loc: 0.04038  validation_loss: 2.2  time: 1.6503  data_time: 0.0240  lr: 3.178e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:40:08 d2.utils.events]: \u001b[0m eta: 0:29:11  iter: 8879  total_loss: 2.498  loss_cls_stage0: 0.3627  loss_box_reg_stage0: 0.3103  loss_cls_stage1: 0.3075  loss_box_reg_stage1: 0.391  loss_cls_stage2: 0.2117  loss_box_reg_stage2: 0.3047  loss_mask: 0.5105  loss_rpn_cls: 0.06163  loss_rpn_loc: 0.03891  validation_loss: 2.2  time: 1.6501  data_time: 0.0244  lr: 3.0687e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:40:40 d2.utils.events]: \u001b[0m eta: 0:28:40  iter: 8899  total_loss: 2.5  loss_cls_stage0: 0.3496  loss_box_reg_stage0: 0.2803  loss_cls_stage1: 0.288  loss_box_reg_stage1: 0.4027  loss_cls_stage2: 0.1986  loss_box_reg_stage2: 0.3142  loss_mask: 0.5745  loss_rpn_cls: 0.05684  loss_rpn_loc: 0.03422  validation_loss: 2.2  time: 1.6499  data_time: 0.0239  lr: 2.9613e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:41:11 d2.utils.events]: \u001b[0m eta: 0:28:09  iter: 8919  total_loss: 2.342  loss_cls_stage0: 0.3093  loss_box_reg_stage0: 0.2535  loss_cls_stage1: 0.2547  loss_box_reg_stage1: 0.3665  loss_cls_stage2: 0.1787  loss_box_reg_stage2: 0.2817  loss_mask: 0.5459  loss_rpn_cls: 0.05982  loss_rpn_loc: 0.03817  validation_loss: 2.2  time: 1.6497  data_time: 0.0241  lr: 2.8557e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:41:42 d2.utils.events]: \u001b[0m eta: 0:27:38  iter: 8939  total_loss: 2.143  loss_cls_stage0: 0.2773  loss_box_reg_stage0: 0.2071  loss_cls_stage1: 0.2298  loss_box_reg_stage1: 0.3061  loss_cls_stage2: 0.1794  loss_box_reg_stage2: 0.2775  loss_mask: 0.5237  loss_rpn_cls: 0.05994  loss_rpn_loc: 0.03149  validation_loss: 2.2  time: 1.6495  data_time: 0.0242  lr: 2.752e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:42:14 d2.utils.events]: \u001b[0m eta: 0:27:06  iter: 8959  total_loss: 2.385  loss_cls_stage0: 0.3196  loss_box_reg_stage0: 0.259  loss_cls_stage1: 0.2626  loss_box_reg_stage1: 0.3866  loss_cls_stage2: 0.1952  loss_box_reg_stage2: 0.3421  loss_mask: 0.5093  loss_rpn_cls: 0.06154  loss_rpn_loc: 0.03811  validation_loss: 2.2  time: 1.6493  data_time: 0.0247  lr: 2.6501e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:42:45 d2.utils.events]: \u001b[0m eta: 0:26:35  iter: 8979  total_loss: 2.427  loss_cls_stage0: 0.3322  loss_box_reg_stage0: 0.2745  loss_cls_stage1: 0.2694  loss_box_reg_stage1: 0.3769  loss_cls_stage2: 0.1898  loss_box_reg_stage2: 0.3074  loss_mask: 0.5356  loss_rpn_cls: 0.06031  loss_rpn_loc: 0.03557  validation_loss: 2.2  time: 1.6492  data_time: 0.0231  lr: 2.5501e-06  max_mem: 11758M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/26 20:43:19 d2.data.common]: \u001b[0mSerializing 859 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/26 20:43:19 d2.data.common]: \u001b[0mSerialized dataset takes 0.90 MiB\n",
      "\u001b[32m[03/26 20:43:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 859 images\n",
      "\u001b[32m[03/26 20:43:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/859. 0.0809 s / img. ETA=0:01:41\n",
      "\u001b[32m[03/26 20:43:26 d2.evaluation.evaluator]: \u001b[0mInference done 52/859. 0.0810 s / img. ETA=0:01:39\n",
      "\u001b[32m[03/26 20:43:31 d2.evaluation.evaluator]: \u001b[0mInference done 93/859. 0.0811 s / img. ETA=0:01:34\n",
      "\u001b[32m[03/26 20:43:36 d2.evaluation.evaluator]: \u001b[0mInference done 134/859. 0.0811 s / img. ETA=0:01:29\n",
      "\u001b[32m[03/26 20:43:41 d2.evaluation.evaluator]: \u001b[0mInference done 176/859. 0.0811 s / img. ETA=0:01:23\n",
      "\u001b[32m[03/26 20:43:46 d2.evaluation.evaluator]: \u001b[0mInference done 214/859. 0.0820 s / img. ETA=0:01:20\n",
      "\u001b[32m[03/26 20:43:51 d2.evaluation.evaluator]: \u001b[0mInference done 255/859. 0.0819 s / img. ETA=0:01:15\n",
      "\u001b[32m[03/26 20:43:56 d2.evaluation.evaluator]: \u001b[0mInference done 292/859. 0.0819 s / img. ETA=0:01:11\n",
      "\u001b[32m[03/26 20:44:01 d2.evaluation.evaluator]: \u001b[0mInference done 336/859. 0.0817 s / img. ETA=0:01:05\n",
      "\u001b[32m[03/26 20:44:06 d2.evaluation.evaluator]: \u001b[0mInference done 380/859. 0.0816 s / img. ETA=0:00:59\n",
      "\u001b[32m[03/26 20:44:12 d2.evaluation.evaluator]: \u001b[0mInference done 421/859. 0.0816 s / img. ETA=0:00:54\n",
      "\u001b[32m[03/26 20:44:17 d2.evaluation.evaluator]: \u001b[0mInference done 462/859. 0.0816 s / img. ETA=0:00:49\n",
      "\u001b[32m[03/26 20:44:22 d2.evaluation.evaluator]: \u001b[0mInference done 504/859. 0.0815 s / img. ETA=0:00:43\n",
      "\u001b[32m[03/26 20:44:27 d2.evaluation.evaluator]: \u001b[0mInference done 544/859. 0.0815 s / img. ETA=0:00:39\n",
      "\u001b[32m[03/26 20:44:32 d2.evaluation.evaluator]: \u001b[0mInference done 584/859. 0.0815 s / img. ETA=0:00:34\n",
      "\u001b[32m[03/26 20:44:37 d2.evaluation.evaluator]: \u001b[0mInference done 627/859. 0.0814 s / img. ETA=0:00:28\n",
      "\u001b[32m[03/26 20:44:42 d2.evaluation.evaluator]: \u001b[0mInference done 669/859. 0.0814 s / img. ETA=0:00:23\n",
      "\u001b[32m[03/26 20:44:47 d2.evaluation.evaluator]: \u001b[0mInference done 709/859. 0.0814 s / img. ETA=0:00:18\n",
      "\u001b[32m[03/26 20:44:52 d2.evaluation.evaluator]: \u001b[0mInference done 747/859. 0.0814 s / img. ETA=0:00:13\n",
      "\u001b[32m[03/26 20:44:57 d2.evaluation.evaluator]: \u001b[0mInference done 789/859. 0.0814 s / img. ETA=0:00:08\n",
      "\u001b[32m[03/26 20:45:02 d2.evaluation.evaluator]: \u001b[0mInference done 829/859. 0.0814 s / img. ETA=0:00:03\n",
      "\u001b[32m[03/26 20:45:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:46.116728 (0.124258 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/26 20:45:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:09 (0.081390 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.48 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.150\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.167\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.043\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.094\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.132\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.179\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.016\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.056\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.199\n",
      "\u001b[32m[03/26 20:45:07 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold2 in csv format:\n",
      "\u001b[32m[03/26 20:45:07 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/26 20:45:07 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/26 20:45:07 d2.evaluation.testing]: \u001b[0mcopypaste: 9.0068,14.9698,16.7166,0.6209,4.2999,9.4253\n",
      "validation do loss eval 2.4237087357045115\n",
      "\u001b[32m[03/26 20:46:36 d2.utils.events]: \u001b[0m eta: 0:26:04  iter: 8999  total_loss: 2.404  loss_cls_stage0: 0.3497  loss_box_reg_stage0: 0.2683  loss_cls_stage1: 0.2648  loss_box_reg_stage1: 0.3703  loss_cls_stage2: 0.1953  loss_box_reg_stage2: 0.3208  loss_mask: 0.5419  loss_rpn_cls: 0.06378  loss_rpn_loc: 0.03708  validation_loss: 2.265  time: 1.6490  data_time: 0.0237  lr: 2.452e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:47:07 d2.utils.events]: \u001b[0m eta: 0:25:32  iter: 9019  total_loss: 2.413  loss_cls_stage0: 0.3387  loss_box_reg_stage0: 0.2759  loss_cls_stage1: 0.2865  loss_box_reg_stage1: 0.387  loss_cls_stage2: 0.1956  loss_box_reg_stage2: 0.3057  loss_mask: 0.5374  loss_rpn_cls: 0.05634  loss_rpn_loc: 0.0359  validation_loss: 2.265  time: 1.6488  data_time: 0.0239  lr: 2.3558e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:47:39 d2.utils.events]: \u001b[0m eta: 0:25:01  iter: 9039  total_loss: 2.28  loss_cls_stage0: 0.3128  loss_box_reg_stage0: 0.2451  loss_cls_stage1: 0.2651  loss_box_reg_stage1: 0.3495  loss_cls_stage2: 0.1845  loss_box_reg_stage2: 0.3064  loss_mask: 0.5179  loss_rpn_cls: 0.05833  loss_rpn_loc: 0.03116  validation_loss: 2.265  time: 1.6486  data_time: 0.0245  lr: 2.2614e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:48:10 d2.utils.events]: \u001b[0m eta: 0:24:30  iter: 9059  total_loss: 2.386  loss_cls_stage0: 0.3301  loss_box_reg_stage0: 0.2635  loss_cls_stage1: 0.286  loss_box_reg_stage1: 0.4141  loss_cls_stage2: 0.2085  loss_box_reg_stage2: 0.3291  loss_mask: 0.5201  loss_rpn_cls: 0.05865  loss_rpn_loc: 0.03931  validation_loss: 2.265  time: 1.6484  data_time: 0.0236  lr: 2.169e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:48:42 d2.utils.events]: \u001b[0m eta: 0:23:59  iter: 9079  total_loss: 2.378  loss_cls_stage0: 0.3325  loss_box_reg_stage0: 0.2694  loss_cls_stage1: 0.2813  loss_box_reg_stage1: 0.3913  loss_cls_stage2: 0.1996  loss_box_reg_stage2: 0.3119  loss_mask: 0.4974  loss_rpn_cls: 0.06445  loss_rpn_loc: 0.0379  validation_loss: 2.265  time: 1.6483  data_time: 0.0226  lr: 2.0784e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:49:13 d2.utils.events]: \u001b[0m eta: 0:23:28  iter: 9099  total_loss: 2.314  loss_cls_stage0: 0.3303  loss_box_reg_stage0: 0.2414  loss_cls_stage1: 0.2739  loss_box_reg_stage1: 0.3726  loss_cls_stage2: 0.1956  loss_box_reg_stage2: 0.3042  loss_mask: 0.4753  loss_rpn_cls: 0.06606  loss_rpn_loc: 0.03593  validation_loss: 2.265  time: 1.6481  data_time: 0.0248  lr: 1.9897e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:49:45 d2.utils.events]: \u001b[0m eta: 0:22:56  iter: 9119  total_loss: 2.461  loss_cls_stage0: 0.3233  loss_box_reg_stage0: 0.2548  loss_cls_stage1: 0.2622  loss_box_reg_stage1: 0.3629  loss_cls_stage2: 0.1903  loss_box_reg_stage2: 0.3101  loss_mask: 0.5516  loss_rpn_cls: 0.05883  loss_rpn_loc: 0.03442  validation_loss: 2.265  time: 1.6479  data_time: 0.0247  lr: 1.9029e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:50:16 d2.utils.events]: \u001b[0m eta: 0:22:25  iter: 9139  total_loss: 2.441  loss_cls_stage0: 0.344  loss_box_reg_stage0: 0.2654  loss_cls_stage1: 0.2802  loss_box_reg_stage1: 0.3792  loss_cls_stage2: 0.2027  loss_box_reg_stage2: 0.3257  loss_mask: 0.5355  loss_rpn_cls: 0.06771  loss_rpn_loc: 0.03515  validation_loss: 2.265  time: 1.6478  data_time: 0.0231  lr: 1.818e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:50:48 d2.utils.events]: \u001b[0m eta: 0:21:54  iter: 9159  total_loss: 2.441  loss_cls_stage0: 0.3674  loss_box_reg_stage0: 0.2827  loss_cls_stage1: 0.2871  loss_box_reg_stage1: 0.3991  loss_cls_stage2: 0.2078  loss_box_reg_stage2: 0.3329  loss_mask: 0.5336  loss_rpn_cls: 0.05311  loss_rpn_loc: 0.03486  validation_loss: 2.265  time: 1.6476  data_time: 0.0240  lr: 1.735e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:51:19 d2.utils.events]: \u001b[0m eta: 0:21:22  iter: 9179  total_loss: 2.398  loss_cls_stage0: 0.3252  loss_box_reg_stage0: 0.2525  loss_cls_stage1: 0.2726  loss_box_reg_stage1: 0.3771  loss_cls_stage2: 0.2014  loss_box_reg_stage2: 0.2836  loss_mask: 0.4933  loss_rpn_cls: 0.06165  loss_rpn_loc: 0.03561  validation_loss: 2.265  time: 1.6474  data_time: 0.0232  lr: 1.6539e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:51:51 d2.utils.events]: \u001b[0m eta: 0:20:51  iter: 9199  total_loss: 2.444  loss_cls_stage0: 0.3236  loss_box_reg_stage0: 0.2688  loss_cls_stage1: 0.2722  loss_box_reg_stage1: 0.4154  loss_cls_stage2: 0.2037  loss_box_reg_stage2: 0.3522  loss_mask: 0.5128  loss_rpn_cls: 0.06925  loss_rpn_loc: 0.03827  validation_loss: 2.265  time: 1.6473  data_time: 0.0233  lr: 1.5748e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:52:22 d2.utils.events]: \u001b[0m eta: 0:20:20  iter: 9219  total_loss: 2.359  loss_cls_stage0: 0.3202  loss_box_reg_stage0: 0.2452  loss_cls_stage1: 0.2767  loss_box_reg_stage1: 0.3426  loss_cls_stage2: 0.1991  loss_box_reg_stage2: 0.2902  loss_mask: 0.5597  loss_rpn_cls: 0.0553  loss_rpn_loc: 0.03115  validation_loss: 2.265  time: 1.6471  data_time: 0.0246  lr: 1.4975e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:52:53 d2.utils.events]: \u001b[0m eta: 0:19:49  iter: 9239  total_loss: 2.377  loss_cls_stage0: 0.3383  loss_box_reg_stage0: 0.2711  loss_cls_stage1: 0.2822  loss_box_reg_stage1: 0.3736  loss_cls_stage2: 0.1984  loss_box_reg_stage2: 0.325  loss_mask: 0.5002  loss_rpn_cls: 0.068  loss_rpn_loc: 0.03878  validation_loss: 2.265  time: 1.6469  data_time: 0.0242  lr: 1.4221e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:53:25 d2.utils.events]: \u001b[0m eta: 0:19:17  iter: 9259  total_loss: 2.397  loss_cls_stage0: 0.3331  loss_box_reg_stage0: 0.2589  loss_cls_stage1: 0.2802  loss_box_reg_stage1: 0.3524  loss_cls_stage2: 0.2059  loss_box_reg_stage2: 0.3093  loss_mask: 0.5056  loss_rpn_cls: 0.0698  loss_rpn_loc: 0.03932  validation_loss: 2.265  time: 1.6468  data_time: 0.0235  lr: 1.3487e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:53:56 d2.utils.events]: \u001b[0m eta: 0:18:46  iter: 9279  total_loss: 2.476  loss_cls_stage0: 0.336  loss_box_reg_stage0: 0.2578  loss_cls_stage1: 0.2842  loss_box_reg_stage1: 0.3787  loss_cls_stage2: 0.2145  loss_box_reg_stage2: 0.3048  loss_mask: 0.5483  loss_rpn_cls: 0.05978  loss_rpn_loc: 0.03579  validation_loss: 2.265  time: 1.6466  data_time: 0.0237  lr: 1.2772e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:54:27 d2.utils.events]: \u001b[0m eta: 0:18:15  iter: 9299  total_loss: 2.413  loss_cls_stage0: 0.3302  loss_box_reg_stage0: 0.2454  loss_cls_stage1: 0.2735  loss_box_reg_stage1: 0.3547  loss_cls_stage2: 0.1964  loss_box_reg_stage2: 0.3131  loss_mask: 0.5683  loss_rpn_cls: 0.05774  loss_rpn_loc: 0.03569  validation_loss: 2.265  time: 1.6464  data_time: 0.0239  lr: 1.2076e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:54:59 d2.utils.events]: \u001b[0m eta: 0:17:43  iter: 9319  total_loss: 2.524  loss_cls_stage0: 0.3405  loss_box_reg_stage0: 0.2841  loss_cls_stage1: 0.27  loss_box_reg_stage1: 0.3965  loss_cls_stage2: 0.2053  loss_box_reg_stage2: 0.3079  loss_mask: 0.5215  loss_rpn_cls: 0.05877  loss_rpn_loc: 0.03602  validation_loss: 2.265  time: 1.6463  data_time: 0.0239  lr: 1.1399e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:55:30 d2.utils.events]: \u001b[0m eta: 0:17:12  iter: 9339  total_loss: 2.444  loss_cls_stage0: 0.3357  loss_box_reg_stage0: 0.259  loss_cls_stage1: 0.2726  loss_box_reg_stage1: 0.378  loss_cls_stage2: 0.1933  loss_box_reg_stage2: 0.3066  loss_mask: 0.5228  loss_rpn_cls: 0.05585  loss_rpn_loc: 0.03402  validation_loss: 2.265  time: 1.6461  data_time: 0.0243  lr: 1.0742e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:56:01 d2.utils.events]: \u001b[0m eta: 0:16:41  iter: 9359  total_loss: 2.097  loss_cls_stage0: 0.2746  loss_box_reg_stage0: 0.2122  loss_cls_stage1: 0.2271  loss_box_reg_stage1: 0.3117  loss_cls_stage2: 0.1676  loss_box_reg_stage2: 0.2888  loss_mask: 0.4815  loss_rpn_cls: 0.06169  loss_rpn_loc: 0.02972  validation_loss: 2.265  time: 1.6459  data_time: 0.0249  lr: 1.0104e-06  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:56:32 d2.utils.events]: \u001b[0m eta: 0:16:09  iter: 9379  total_loss: 2.428  loss_cls_stage0: 0.3248  loss_box_reg_stage0: 0.2606  loss_cls_stage1: 0.2686  loss_box_reg_stage1: 0.3659  loss_cls_stage2: 0.1892  loss_box_reg_stage2: 0.3026  loss_mask: 0.5404  loss_rpn_cls: 0.05832  loss_rpn_loc: 0.03511  validation_loss: 2.265  time: 1.6457  data_time: 0.0248  lr: 9.4852e-07  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:57:04 d2.utils.events]: \u001b[0m eta: 0:15:38  iter: 9399  total_loss: 2.49  loss_cls_stage0: 0.356  loss_box_reg_stage0: 0.2784  loss_cls_stage1: 0.2884  loss_box_reg_stage1: 0.3872  loss_cls_stage2: 0.2006  loss_box_reg_stage2: 0.3242  loss_mask: 0.5144  loss_rpn_cls: 0.06867  loss_rpn_loc: 0.03926  validation_loss: 2.265  time: 1.6456  data_time: 0.0230  lr: 8.8858e-07  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:57:35 d2.utils.events]: \u001b[0m eta: 0:15:07  iter: 9419  total_loss: 2.416  loss_cls_stage0: 0.3471  loss_box_reg_stage0: 0.2687  loss_cls_stage1: 0.271  loss_box_reg_stage1: 0.393  loss_cls_stage2: 0.2016  loss_box_reg_stage2: 0.3298  loss_mask: 0.5559  loss_rpn_cls: 0.05118  loss_rpn_loc: 0.03341  validation_loss: 2.265  time: 1.6454  data_time: 0.0240  lr: 8.3059e-07  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:58:07 d2.utils.events]: \u001b[0m eta: 0:14:36  iter: 9439  total_loss: 2.379  loss_cls_stage0: 0.3052  loss_box_reg_stage0: 0.2554  loss_cls_stage1: 0.2646  loss_box_reg_stage1: 0.3672  loss_cls_stage2: 0.1893  loss_box_reg_stage2: 0.3139  loss_mask: 0.5338  loss_rpn_cls: 0.06039  loss_rpn_loc: 0.03286  validation_loss: 2.265  time: 1.6452  data_time: 0.0241  lr: 7.7453e-07  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:58:38 d2.utils.events]: \u001b[0m eta: 0:14:04  iter: 9459  total_loss: 2.521  loss_cls_stage0: 0.3224  loss_box_reg_stage0: 0.27  loss_cls_stage1: 0.2824  loss_box_reg_stage1: 0.4103  loss_cls_stage2: 0.2106  loss_box_reg_stage2: 0.3419  loss_mask: 0.5325  loss_rpn_cls: 0.06624  loss_rpn_loc: 0.03697  validation_loss: 2.265  time: 1.6451  data_time: 0.0242  lr: 7.2042e-07  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:59:09 d2.utils.events]: \u001b[0m eta: 0:13:33  iter: 9479  total_loss: 2.341  loss_cls_stage0: 0.3334  loss_box_reg_stage0: 0.2578  loss_cls_stage1: 0.2727  loss_box_reg_stage1: 0.3535  loss_cls_stage2: 0.1901  loss_box_reg_stage2: 0.2764  loss_mask: 0.4927  loss_rpn_cls: 0.0645  loss_rpn_loc: 0.03122  validation_loss: 2.265  time: 1.6449  data_time: 0.0224  lr: 6.6826e-07  max_mem: 11758M\n",
      "\u001b[32m[03/26 20:59:41 d2.utils.events]: \u001b[0m eta: 0:13:02  iter: 9499  total_loss: 2.284  loss_cls_stage0: 0.3424  loss_box_reg_stage0: 0.2647  loss_cls_stage1: 0.2602  loss_box_reg_stage1: 0.357  loss_cls_stage2: 0.1803  loss_box_reg_stage2: 0.3037  loss_mask: 0.5273  loss_rpn_cls: 0.06564  loss_rpn_loc: 0.03648  validation_loss: 2.265  time: 1.6447  data_time: 0.0247  lr: 6.1804e-07  max_mem: 11758M\n",
      "\u001b[32m[03/26 21:00:12 d2.utils.events]: \u001b[0m eta: 0:12:30  iter: 9519  total_loss: 2.378  loss_cls_stage0: 0.3131  loss_box_reg_stage0: 0.2579  loss_cls_stage1: 0.2656  loss_box_reg_stage1: 0.362  loss_cls_stage2: 0.1889  loss_box_reg_stage2: 0.3299  loss_mask: 0.5244  loss_rpn_cls: 0.06667  loss_rpn_loc: 0.03909  validation_loss: 2.265  time: 1.6446  data_time: 0.0240  lr: 5.6977e-07  max_mem: 11758M\n",
      "\u001b[32m[03/26 21:00:44 d2.utils.events]: \u001b[0m eta: 0:11:59  iter: 9539  total_loss: 2.642  loss_cls_stage0: 0.3803  loss_box_reg_stage0: 0.3005  loss_cls_stage1: 0.3025  loss_box_reg_stage1: 0.4256  loss_cls_stage2: 0.235  loss_box_reg_stage2: 0.3473  loss_mask: 0.5084  loss_rpn_cls: 0.06714  loss_rpn_loc: 0.03938  validation_loss: 2.265  time: 1.6444  data_time: 0.0235  lr: 5.2346e-07  max_mem: 11758M\n",
      "\u001b[32m[03/26 21:01:15 d2.utils.events]: \u001b[0m eta: 0:11:28  iter: 9559  total_loss: 2.408  loss_cls_stage0: 0.3284  loss_box_reg_stage0: 0.263  loss_cls_stage1: 0.2767  loss_box_reg_stage1: 0.378  loss_cls_stage2: 0.1905  loss_box_reg_stage2: 0.3094  loss_mask: 0.5595  loss_rpn_cls: 0.05862  loss_rpn_loc: 0.0323  validation_loss: 2.265  time: 1.6443  data_time: 0.0236  lr: 4.791e-07  max_mem: 11758M\n",
      "\u001b[32m[03/26 21:01:47 d2.utils.events]: \u001b[0m eta: 0:10:57  iter: 9579  total_loss: 2.476  loss_cls_stage0: 0.3287  loss_box_reg_stage0: 0.2716  loss_cls_stage1: 0.2742  loss_box_reg_stage1: 0.3688  loss_cls_stage2: 0.2068  loss_box_reg_stage2: 0.3087  loss_mask: 0.5883  loss_rpn_cls: 0.06085  loss_rpn_loc: 0.035  validation_loss: 2.265  time: 1.6441  data_time: 0.0238  lr: 4.3669e-07  max_mem: 11758M\n",
      "\u001b[32m[03/26 21:02:18 d2.utils.events]: \u001b[0m eta: 0:10:25  iter: 9599  total_loss: 2.555  loss_cls_stage0: 0.3401  loss_box_reg_stage0: 0.3029  loss_cls_stage1: 0.2844  loss_box_reg_stage1: 0.4054  loss_cls_stage2: 0.2064  loss_box_reg_stage2: 0.3206  loss_mask: 0.597  loss_rpn_cls: 0.06656  loss_rpn_loc: 0.03734  validation_loss: 2.265  time: 1.6440  data_time: 0.0238  lr: 3.9624e-07  max_mem: 11758M\n",
      "\u001b[32m[03/26 21:02:50 d2.utils.events]: \u001b[0m eta: 0:09:54  iter: 9619  total_loss: 2.568  loss_cls_stage0: 0.3557  loss_box_reg_stage0: 0.2777  loss_cls_stage1: 0.3011  loss_box_reg_stage1: 0.4098  loss_cls_stage2: 0.2143  loss_box_reg_stage2: 0.3134  loss_mask: 0.5382  loss_rpn_cls: 0.05812  loss_rpn_loc: 0.0379  validation_loss: 2.265  time: 1.6439  data_time: 0.0237  lr: 3.5774e-07  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:03:21 d2.utils.events]: \u001b[0m eta: 0:09:23  iter: 9639  total_loss: 2.28  loss_cls_stage0: 0.3157  loss_box_reg_stage0: 0.2402  loss_cls_stage1: 0.2597  loss_box_reg_stage1: 0.3606  loss_cls_stage2: 0.1869  loss_box_reg_stage2: 0.2909  loss_mask: 0.529  loss_rpn_cls: 0.05957  loss_rpn_loc: 0.02987  validation_loss: 2.265  time: 1.6437  data_time: 0.0239  lr: 3.2121e-07  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:03:53 d2.utils.events]: \u001b[0m eta: 0:08:52  iter: 9659  total_loss: 2.39  loss_cls_stage0: 0.3165  loss_box_reg_stage0: 0.263  loss_cls_stage1: 0.266  loss_box_reg_stage1: 0.3826  loss_cls_stage2: 0.196  loss_box_reg_stage2: 0.3049  loss_mask: 0.5715  loss_rpn_cls: 0.06001  loss_rpn_loc: 0.03256  validation_loss: 2.265  time: 1.6436  data_time: 0.0233  lr: 2.8664e-07  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:04:24 d2.utils.events]: \u001b[0m eta: 0:08:20  iter: 9679  total_loss: 2.285  loss_cls_stage0: 0.3133  loss_box_reg_stage0: 0.2385  loss_cls_stage1: 0.2565  loss_box_reg_stage1: 0.3591  loss_cls_stage2: 0.1868  loss_box_reg_stage2: 0.3018  loss_mask: 0.5477  loss_rpn_cls: 0.05566  loss_rpn_loc: 0.03431  validation_loss: 2.265  time: 1.6434  data_time: 0.0235  lr: 2.5403e-07  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:04:55 d2.utils.events]: \u001b[0m eta: 0:07:49  iter: 9699  total_loss: 2.305  loss_cls_stage0: 0.3365  loss_box_reg_stage0: 0.2643  loss_cls_stage1: 0.2713  loss_box_reg_stage1: 0.3685  loss_cls_stage2: 0.1852  loss_box_reg_stage2: 0.2999  loss_mask: 0.5102  loss_rpn_cls: 0.05593  loss_rpn_loc: 0.03501  validation_loss: 2.265  time: 1.6432  data_time: 0.0233  lr: 2.2338e-07  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:05:27 d2.utils.events]: \u001b[0m eta: 0:07:18  iter: 9719  total_loss: 2.322  loss_cls_stage0: 0.321  loss_box_reg_stage0: 0.2478  loss_cls_stage1: 0.2665  loss_box_reg_stage1: 0.3592  loss_cls_stage2: 0.1954  loss_box_reg_stage2: 0.3026  loss_mask: 0.515  loss_rpn_cls: 0.05934  loss_rpn_loc: 0.03583  validation_loss: 2.265  time: 1.6431  data_time: 0.0234  lr: 1.947e-07  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:05:58 d2.utils.events]: \u001b[0m eta: 0:06:46  iter: 9739  total_loss: 2.338  loss_cls_stage0: 0.2827  loss_box_reg_stage0: 0.2544  loss_cls_stage1: 0.2527  loss_box_reg_stage1: 0.3606  loss_cls_stage2: 0.1909  loss_box_reg_stage2: 0.3133  loss_mask: 0.5088  loss_rpn_cls: 0.05797  loss_rpn_loc: 0.03835  validation_loss: 2.265  time: 1.6429  data_time: 0.0225  lr: 1.6799e-07  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:06:29 d2.utils.events]: \u001b[0m eta: 0:06:15  iter: 9759  total_loss: 2.343  loss_cls_stage0: 0.3245  loss_box_reg_stage0: 0.2713  loss_cls_stage1: 0.2649  loss_box_reg_stage1: 0.3748  loss_cls_stage2: 0.1855  loss_box_reg_stage2: 0.3109  loss_mask: 0.5164  loss_rpn_cls: 0.05523  loss_rpn_loc: 0.02882  validation_loss: 2.265  time: 1.6428  data_time: 0.0238  lr: 1.4324e-07  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:07:01 d2.utils.events]: \u001b[0m eta: 0:05:44  iter: 9779  total_loss: 2.476  loss_cls_stage0: 0.3364  loss_box_reg_stage0: 0.2666  loss_cls_stage1: 0.2887  loss_box_reg_stage1: 0.3865  loss_cls_stage2: 0.2151  loss_box_reg_stage2: 0.3289  loss_mask: 0.5331  loss_rpn_cls: 0.05654  loss_rpn_loc: 0.03809  validation_loss: 2.265  time: 1.6426  data_time: 0.0233  lr: 1.2046e-07  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:07:32 d2.utils.events]: \u001b[0m eta: 0:05:13  iter: 9799  total_loss: 2.345  loss_cls_stage0: 0.3117  loss_box_reg_stage0: 0.2569  loss_cls_stage1: 0.2368  loss_box_reg_stage1: 0.3651  loss_cls_stage2: 0.1693  loss_box_reg_stage2: 0.3185  loss_mask: 0.5825  loss_rpn_cls: 0.05801  loss_rpn_loc: 0.03669  validation_loss: 2.265  time: 1.6425  data_time: 0.0249  lr: 9.9652e-08  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:08:04 d2.utils.events]: \u001b[0m eta: 0:04:41  iter: 9819  total_loss: 2.425  loss_cls_stage0: 0.365  loss_box_reg_stage0: 0.279  loss_cls_stage1: 0.2878  loss_box_reg_stage1: 0.3666  loss_cls_stage2: 0.2026  loss_box_reg_stage2: 0.293  loss_mask: 0.5545  loss_rpn_cls: 0.05899  loss_rpn_loc: 0.03643  validation_loss: 2.265  time: 1.6423  data_time: 0.0233  lr: 8.0813e-08  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:08:35 d2.utils.events]: \u001b[0m eta: 0:04:10  iter: 9839  total_loss: 2.237  loss_cls_stage0: 0.3116  loss_box_reg_stage0: 0.2445  loss_cls_stage1: 0.2544  loss_box_reg_stage1: 0.3479  loss_cls_stage2: 0.1844  loss_box_reg_stage2: 0.3001  loss_mask: 0.4992  loss_rpn_cls: 0.06365  loss_rpn_loc: 0.03453  validation_loss: 2.265  time: 1.6422  data_time: 0.0230  lr: 6.3944e-08  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:09:07 d2.utils.events]: \u001b[0m eta: 0:03:39  iter: 9859  total_loss: 2.336  loss_cls_stage0: 0.3425  loss_box_reg_stage0: 0.2489  loss_cls_stage1: 0.2798  loss_box_reg_stage1: 0.352  loss_cls_stage2: 0.1965  loss_box_reg_stage2: 0.2923  loss_mask: 0.5188  loss_rpn_cls: 0.05974  loss_rpn_loc: 0.03609  validation_loss: 2.265  time: 1.6420  data_time: 0.0235  lr: 4.9046e-08  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:09:38 d2.utils.events]: \u001b[0m eta: 0:03:07  iter: 9879  total_loss: 2.503  loss_cls_stage0: 0.3514  loss_box_reg_stage0: 0.2774  loss_cls_stage1: 0.2932  loss_box_reg_stage1: 0.3895  loss_cls_stage2: 0.2112  loss_box_reg_stage2: 0.3408  loss_mask: 0.5511  loss_rpn_cls: 0.0543  loss_rpn_loc: 0.03398  validation_loss: 2.265  time: 1.6419  data_time: 0.0221  lr: 3.6121e-08  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:10:10 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 9899  total_loss: 2.51  loss_cls_stage0: 0.3679  loss_box_reg_stage0: 0.2846  loss_cls_stage1: 0.3117  loss_box_reg_stage1: 0.3871  loss_cls_stage2: 0.2115  loss_box_reg_stage2: 0.2925  loss_mask: 0.5401  loss_rpn_cls: 0.06457  loss_rpn_loc: 0.03601  validation_loss: 2.265  time: 1.6418  data_time: 0.0240  lr: 2.5168e-08  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:10:41 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 9919  total_loss: 2.535  loss_cls_stage0: 0.3383  loss_box_reg_stage0: 0.2638  loss_cls_stage1: 0.2887  loss_box_reg_stage1: 0.4084  loss_cls_stage2: 0.2246  loss_box_reg_stage2: 0.3255  loss_mask: 0.5313  loss_rpn_cls: 0.06465  loss_rpn_loc: 0.04354  validation_loss: 2.265  time: 1.6417  data_time: 0.0232  lr: 1.6188e-08  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:11:13 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 9939  total_loss: 2.429  loss_cls_stage0: 0.3286  loss_box_reg_stage0: 0.266  loss_cls_stage1: 0.2835  loss_box_reg_stage1: 0.3834  loss_cls_stage2: 0.2037  loss_box_reg_stage2: 0.3001  loss_mask: 0.4888  loss_rpn_cls: 0.06147  loss_rpn_loc: 0.03981  validation_loss: 2.265  time: 1.6415  data_time: 0.0239  lr: 9.1809e-09  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:11:44 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 9959  total_loss: 2.509  loss_cls_stage0: 0.3442  loss_box_reg_stage0: 0.2735  loss_cls_stage1: 0.2873  loss_box_reg_stage1: 0.3692  loss_cls_stage2: 0.2064  loss_box_reg_stage2: 0.3135  loss_mask: 0.5228  loss_rpn_cls: 0.05889  loss_rpn_loc: 0.03974  validation_loss: 2.265  time: 1.6414  data_time: 0.0227  lr: 4.1476e-09  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:12:16 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 9979  total_loss: 2.337  loss_cls_stage0: 0.3138  loss_box_reg_stage0: 0.2547  loss_cls_stage1: 0.2614  loss_box_reg_stage1: 0.3561  loss_cls_stage2: 0.1977  loss_box_reg_stage2: 0.3024  loss_mask: 0.5073  loss_rpn_cls: 0.06271  loss_rpn_loc: 0.03677  validation_loss: 2.265  time: 1.6412  data_time: 0.0234  lr: 1.0881e-09  max_mem: 11973M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/26 21:12:50 d2.data.common]: \u001b[0mSerializing 859 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/26 21:12:50 d2.data.common]: \u001b[0mSerialized dataset takes 0.90 MiB\n",
      "\u001b[32m[03/26 21:12:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 859 images\n",
      "\u001b[32m[03/26 21:12:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/859. 0.0812 s / img. ETA=0:01:45\n",
      "\u001b[32m[03/26 21:12:58 d2.evaluation.evaluator]: \u001b[0mInference done 51/859. 0.0811 s / img. ETA=0:01:42\n",
      "\u001b[32m[03/26 21:13:03 d2.evaluation.evaluator]: \u001b[0mInference done 90/859. 0.0814 s / img. ETA=0:01:39\n",
      "\u001b[32m[03/26 21:13:08 d2.evaluation.evaluator]: \u001b[0mInference done 131/859. 0.0814 s / img. ETA=0:01:32\n",
      "\u001b[32m[03/26 21:13:13 d2.evaluation.evaluator]: \u001b[0mInference done 172/859. 0.0813 s / img. ETA=0:01:26\n",
      "\u001b[32m[03/26 21:13:18 d2.evaluation.evaluator]: \u001b[0mInference done 211/859. 0.0814 s / img. ETA=0:01:22\n",
      "\u001b[32m[03/26 21:13:23 d2.evaluation.evaluator]: \u001b[0mInference done 251/859. 0.0814 s / img. ETA=0:01:16\n",
      "\u001b[32m[03/26 21:13:28 d2.evaluation.evaluator]: \u001b[0mInference done 288/859. 0.0815 s / img. ETA=0:01:13\n",
      "\u001b[32m[03/26 21:13:33 d2.evaluation.evaluator]: \u001b[0mInference done 330/859. 0.0814 s / img. ETA=0:01:07\n",
      "\u001b[32m[03/26 21:13:38 d2.evaluation.evaluator]: \u001b[0mInference done 375/859. 0.0812 s / img. ETA=0:01:00\n",
      "\u001b[32m[03/26 21:13:43 d2.evaluation.evaluator]: \u001b[0mInference done 414/859. 0.0813 s / img. ETA=0:00:55\n",
      "\u001b[32m[03/26 21:13:48 d2.evaluation.evaluator]: \u001b[0mInference done 452/859. 0.0814 s / img. ETA=0:00:51\n",
      "\u001b[32m[03/26 21:13:53 d2.evaluation.evaluator]: \u001b[0mInference done 494/859. 0.0814 s / img. ETA=0:00:45\n",
      "\u001b[32m[03/26 21:13:58 d2.evaluation.evaluator]: \u001b[0mInference done 535/859. 0.0814 s / img. ETA=0:00:40\n",
      "\u001b[32m[03/26 21:14:04 d2.evaluation.evaluator]: \u001b[0mInference done 572/859. 0.0814 s / img. ETA=0:00:36\n",
      "\u001b[32m[03/26 21:14:09 d2.evaluation.evaluator]: \u001b[0mInference done 613/859. 0.0814 s / img. ETA=0:00:31\n",
      "\u001b[32m[03/26 21:14:14 d2.evaluation.evaluator]: \u001b[0mInference done 655/859. 0.0814 s / img. ETA=0:00:25\n",
      "\u001b[32m[03/26 21:14:19 d2.evaluation.evaluator]: \u001b[0mInference done 694/859. 0.0814 s / img. ETA=0:00:20\n",
      "\u001b[32m[03/26 21:14:24 d2.evaluation.evaluator]: \u001b[0mInference done 732/859. 0.0815 s / img. ETA=0:00:16\n",
      "\u001b[32m[03/26 21:14:29 d2.evaluation.evaluator]: \u001b[0mInference done 772/859. 0.0815 s / img. ETA=0:00:10\n",
      "\u001b[32m[03/26 21:14:34 d2.evaluation.evaluator]: \u001b[0mInference done 812/859. 0.0814 s / img. ETA=0:00:05\n",
      "\u001b[32m[03/26 21:14:39 d2.evaluation.evaluator]: \u001b[0mInference done 853/859. 0.0814 s / img. ETA=0:00:00\n",
      "\u001b[32m[03/26 21:14:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:47.857851 (0.126297 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/26 21:14:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:09 (0.081441 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.49 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.149\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.168\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.042\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.094\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.132\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.179\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.055\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.199\n",
      "\u001b[32m[03/26 21:14:41 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold2 in csv format:\n",
      "\u001b[32m[03/26 21:14:41 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/26 21:14:41 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/26 21:14:41 d2.evaluation.testing]: \u001b[0mcopypaste: 9.0127,14.9066,16.8419,0.6163,4.1984,9.4268\n",
      "validation do loss eval 2.4312265820882435\n",
      "\u001b[32m[03/26 21:16:10 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 2.341  loss_cls_stage0: 0.3185  loss_box_reg_stage0: 0.2648  loss_cls_stage1: 0.2627  loss_box_reg_stage1: 0.374  loss_cls_stage2: 0.1942  loss_box_reg_stage2: 0.3237  loss_mask: 0.5152  loss_rpn_cls: 0.05553  loss_rpn_loc: 0.03356  validation_loss: 2.295  time: 1.6411  data_time: 0.0248  lr: 2.4674e-12  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:16:10 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 4:33:27 (1.6411 s / it)\n",
      "\u001b[32m[03/26 21:16:10 d2.engine.hooks]: \u001b[0mTotal training time: 5:05:56 (0:32:28 on hooks)\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/26 21:16:10 d2.data.common]: \u001b[0mSerializing 859 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/26 21:16:10 d2.data.common]: \u001b[0mSerialized dataset takes 0.90 MiB\n",
      "\u001b[32m[03/26 21:16:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 859 images\n",
      "\u001b[32m[03/26 21:16:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/859. 0.0806 s / img. ETA=0:01:56\n",
      "\u001b[32m[03/26 21:16:18 d2.evaluation.evaluator]: \u001b[0mInference done 47/859. 0.0811 s / img. ETA=0:01:52\n",
      "\u001b[32m[03/26 21:16:23 d2.evaluation.evaluator]: \u001b[0mInference done 82/859. 0.0811 s / img. ETA=0:01:49\n",
      "\u001b[32m[03/26 21:16:28 d2.evaluation.evaluator]: \u001b[0mInference done 122/859. 0.0812 s / img. ETA=0:01:40\n",
      "\u001b[32m[03/26 21:16:33 d2.evaluation.evaluator]: \u001b[0mInference done 160/859. 0.0812 s / img. ETA=0:01:34\n",
      "\u001b[32m[03/26 21:16:38 d2.evaluation.evaluator]: \u001b[0mInference done 199/859. 0.0813 s / img. ETA=0:01:28\n",
      "\u001b[32m[03/26 21:16:43 d2.evaluation.evaluator]: \u001b[0mInference done 238/859. 0.0813 s / img. ETA=0:01:22\n",
      "\u001b[32m[03/26 21:16:48 d2.evaluation.evaluator]: \u001b[0mInference done 276/859. 0.0813 s / img. ETA=0:01:17\n",
      "\u001b[32m[03/26 21:16:53 d2.evaluation.evaluator]: \u001b[0mInference done 314/859. 0.0814 s / img. ETA=0:01:12\n",
      "\u001b[32m[03/26 21:16:58 d2.evaluation.evaluator]: \u001b[0mInference done 357/859. 0.0813 s / img. ETA=0:01:06\n",
      "\u001b[32m[03/26 21:17:03 d2.evaluation.evaluator]: \u001b[0mInference done 397/859. 0.0813 s / img. ETA=0:01:00\n",
      "\u001b[32m[03/26 21:17:09 d2.evaluation.evaluator]: \u001b[0mInference done 437/859. 0.0813 s / img. ETA=0:00:55\n",
      "\u001b[32m[03/26 21:17:14 d2.evaluation.evaluator]: \u001b[0mInference done 477/859. 0.0813 s / img. ETA=0:00:49\n",
      "\u001b[32m[03/26 21:17:19 d2.evaluation.evaluator]: \u001b[0mInference done 516/859. 0.0813 s / img. ETA=0:00:44\n",
      "\u001b[32m[03/26 21:17:24 d2.evaluation.evaluator]: \u001b[0mInference done 552/859. 0.0813 s / img. ETA=0:00:40\n",
      "\u001b[32m[03/26 21:17:29 d2.evaluation.evaluator]: \u001b[0mInference done 592/859. 0.0813 s / img. ETA=0:00:34\n",
      "\u001b[32m[03/26 21:17:34 d2.evaluation.evaluator]: \u001b[0mInference done 633/859. 0.0813 s / img. ETA=0:00:29\n",
      "\u001b[32m[03/26 21:17:39 d2.evaluation.evaluator]: \u001b[0mInference done 673/859. 0.0813 s / img. ETA=0:00:24\n",
      "\u001b[32m[03/26 21:17:44 d2.evaluation.evaluator]: \u001b[0mInference done 712/859. 0.0813 s / img. ETA=0:00:19\n",
      "\u001b[32m[03/26 21:17:49 d2.evaluation.evaluator]: \u001b[0mInference done 749/859. 0.0813 s / img. ETA=0:00:14\n",
      "\u001b[32m[03/26 21:17:54 d2.evaluation.evaluator]: \u001b[0mInference done 790/859. 0.0813 s / img. ETA=0:00:09\n",
      "\u001b[32m[03/26 21:18:00 d2.evaluation.evaluator]: \u001b[0mInference done 829/859. 0.0813 s / img. ETA=0:00:03\n",
      "\u001b[32m[03/26 21:18:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:51.691783 (0.130787 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/26 21:18:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:09 (0.081311 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.31 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.10 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.149\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.168\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.042\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.094\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.132\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.179\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.055\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.199\n",
      "\u001b[32m[03/26 21:18:04 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold2 in csv format:\n",
      "\u001b[32m[03/26 21:18:04 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/26 21:18:04 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/26 21:18:04 d2.evaluation.testing]: \u001b[0mcopypaste: 9.0127,14.9066,16.8419,0.6163,4.1984,9.4268\n",
      "cfg.OUTPUT_DIR ./output -> /home/yamaguchi-milkcocholate/VinBigData/src/VinBigData-ObjectDetection/detectron2_results/results01/fold-3\n",
      "\u001b[32m[03/26 21:18:06 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): CascadeROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): ModuleList(\n",
      "      (0): FastRCNNConvFCHead(\n",
      "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "        (fc_relu1): ReLU()\n",
      "        (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (fc_relu2): ReLU()\n",
      "      )\n",
      "      (1): FastRCNNConvFCHead(\n",
      "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "        (fc_relu1): ReLU()\n",
      "        (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (fc_relu2): ReLU()\n",
      "      )\n",
      "      (2): FastRCNNConvFCHead(\n",
      "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "        (fc_relu1): ReLU()\n",
      "        (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (fc_relu2): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (box_predictor): ModuleList(\n",
      "      (0): FastRCNNOutputLayers(\n",
      "        (cls_score): Linear(in_features=1024, out_features=15, bias=True)\n",
      "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      )\n",
      "      (1): FastRCNNOutputLayers(\n",
      "        (cls_score): Linear(in_features=1024, out_features=15, bias=True)\n",
      "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      )\n",
      "      (2): FastRCNNOutputLayers(\n",
      "        (cls_score): Linear(in_features=1024, out_features=15, bias=True)\n",
      "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 14, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[AlbumentationsMapper] Augmentations used in training: Compose([\n",
      "  HorizontalFlip(always_apply=False, p=0.5),\n",
      "  ShiftScaleRotate(always_apply=False, p=0.5, shift_limit_x=(-0.0625, 0.0625), shift_limit_y=(-0.0625, 0.0625), scale_limit=(-0.15000000000000002, 0.1499999999999999), rotate_limit=(-10, 10), interpolation=1, border_mode=4, value=None, mask_value=None),\n",
      "  RandomBrightnessContrast(always_apply=False, p=0.5, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), brightness_by_max=True),\n",
      "  Blur(always_apply=False, p=0.4, blur_limit=(3, 10)),\n",
      "  IAAAffine(always_apply=False, p=0.5, scale=(1.0, 1.0), translate_percent=None, translate_px=None, rotate=(-0.0, 0.0), shear=(-0.0, 0.0), order=1, cval=0, mode='reflect'),\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/26 21:18:06 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 3499 images left.\n",
      "\u001b[32m[03/26 21:18:07 d2.data.build]: \u001b[0mDistribution of instances among all 14 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "| Aortic enla.. | 2707         |  Atelectasis  | 185          | Calcification | 595          |\n",
      "| Cardiomegaly  | 1903         | Consolidation | 338          |      ILD      | 571          |\n",
      "| Infiltration  | 755          | Lung Opacity  | 1585         |  Nodule/Mass  | 1498         |\n",
      "| Other lesion  | 1421         | Pleural eff.. | 1403         | Pleural thi.. | 3230         |\n",
      "| Pneumothorax  | 105          | Pulmonary f.. | 2672         |               |              |\n",
      "|     total     | 18968        |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/26 21:18:07 d2.data.common]: \u001b[0mSerializing 3499 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/26 21:18:07 d2.data.common]: \u001b[0mSerialized dataset takes 3.61 MiB\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/26 21:18:07 d2.data.build]: \u001b[0mDistribution of instances among all 14 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "| Aortic enla.. | 668          |  Atelectasis  | 47           | Calcification | 148          |\n",
      "| Cardiomegaly  | 480          | Consolidation | 85           |      ILD      | 150          |\n",
      "| Infiltration  | 188          | Lung Opacity  | 394          |  Nodule/Mass  | 354          |\n",
      "| Other lesion  | 386          | Pleural eff.. | 345          | Pleural thi.. | 795          |\n",
      "| Pneumothorax  | 24           | Pulmonary f.. | 682          |               |              |\n",
      "|     total     | 4746         |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/26 21:18:07 d2.data.common]: \u001b[0mSerializing 879 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/26 21:18:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.90 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'proposal_generator.anchor_generator.cell_anchors.0' to the model due to incompatible shapes: (3, 4) in the checkpoint but (5, 4) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.anchor_generator.cell_anchors.1' to the model due to incompatible shapes: (3, 4) in the checkpoint but (5, 4) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.anchor_generator.cell_anchors.2' to the model due to incompatible shapes: (3, 4) in the checkpoint but (5, 4) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.anchor_generator.cell_anchors.3' to the model due to incompatible shapes: (3, 4) in the checkpoint but (5, 4) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.anchor_generator.cell_anchors.4' to the model due to incompatible shapes: (3, 4) in the checkpoint but (5, 4) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.objectness_logits.weight' to the model due to incompatible shapes: (3, 256, 1, 1) in the checkpoint but (5, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.objectness_logits.bias' to the model due to incompatible shapes: (3,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.anchor_deltas.weight' to the model due to incompatible shapes: (12, 256, 1, 1) in the checkpoint but (20, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.anchor_deltas.bias' to the model due to incompatible shapes: (12,) in the checkpoint but (20,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.0.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (15, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.0.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (15,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.1.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (15, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.1.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (15,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.2.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (15, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.2.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (15,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (14, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (14,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/26 21:18:07 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/26 21:18:34 d2.utils.events]: \u001b[0m eta: 3:42:22  iter: 19  total_loss: 10.09  loss_cls_stage0: 2.795  loss_box_reg_stage0: 0.01763  loss_cls_stage1: 2.974  loss_box_reg_stage1: 0.04143  loss_cls_stage2: 2.674  loss_box_reg_stage2: 0.0327  loss_mask: 0.6927  loss_rpn_cls: 0.8011  loss_rpn_loc: 0.04592  time: 1.3384  data_time: 0.0457  lr: 1.9981e-06  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:19:01 d2.utils.events]: \u001b[0m eta: 3:42:41  iter: 39  total_loss: 9.473  loss_cls_stage0: 2.6  loss_box_reg_stage0: 0.02046  loss_cls_stage1: 2.772  loss_box_reg_stage1: 0.04552  loss_cls_stage2: 2.459  loss_box_reg_stage2: 0.03532  loss_mask: 0.693  loss_rpn_cls: 0.7908  loss_rpn_loc: 0.05738  time: 1.3445  data_time: 0.0235  lr: 3.996e-06  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:19:28 d2.utils.events]: \u001b[0m eta: 3:42:18  iter: 59  total_loss: 8.241  loss_cls_stage0: 2.223  loss_box_reg_stage0: 0.02053  loss_cls_stage1: 2.338  loss_box_reg_stage1: 0.04546  loss_cls_stage2: 2.078  loss_box_reg_stage2: 0.03662  loss_mask: 0.6927  loss_rpn_cls: 0.767  loss_rpn_loc: 0.04654  time: 1.3437  data_time: 0.0241  lr: 5.9936e-06  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:19:55 d2.utils.events]: \u001b[0m eta: 3:41:56  iter: 79  total_loss: 6.523  loss_cls_stage0: 1.651  loss_box_reg_stage0: 0.02427  loss_cls_stage1: 1.733  loss_box_reg_stage1: 0.05414  loss_cls_stage2: 1.506  loss_box_reg_stage2: 0.03813  loss_mask: 0.6928  loss_rpn_cls: 0.7385  loss_rpn_loc: 0.05334  time: 1.3441  data_time: 0.0244  lr: 7.9909e-06  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:20:22 d2.utils.events]: \u001b[0m eta: 3:41:32  iter: 99  total_loss: 4.623  loss_cls_stage0: 1.046  loss_box_reg_stage0: 0.02326  loss_cls_stage1: 1.058  loss_box_reg_stage1: 0.05141  loss_cls_stage2: 0.8969  loss_box_reg_stage2: 0.03767  loss_mask: 0.6923  loss_rpn_cls: 0.6991  loss_rpn_loc: 0.05935  time: 1.3465  data_time: 0.0226  lr: 9.9877e-06  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:20:49 d2.utils.events]: \u001b[0m eta: 3:41:26  iter: 119  total_loss: 3.175  loss_cls_stage0: 0.6032  loss_box_reg_stage0: 0.02352  loss_cls_stage1: 0.5872  loss_box_reg_stage1: 0.0468  loss_cls_stage2: 0.4697  loss_box_reg_stage2: 0.0345  loss_mask: 0.6925  loss_rpn_cls: 0.6526  loss_rpn_loc: 0.04907  time: 1.3477  data_time: 0.0243  lr: 1.1984e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:21:16 d2.utils.events]: \u001b[0m eta: 3:41:15  iter: 139  total_loss: 2.487  loss_cls_stage0: 0.3625  loss_box_reg_stage0: 0.02658  loss_cls_stage1: 0.3843  loss_box_reg_stage1: 0.05034  loss_cls_stage2: 0.3112  loss_box_reg_stage2: 0.03132  loss_mask: 0.6917  loss_rpn_cls: 0.5919  loss_rpn_loc: 0.04942  time: 1.3512  data_time: 0.0239  lr: 1.3979e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:21:44 d2.utils.events]: \u001b[0m eta: 3:41:17  iter: 159  total_loss: 2.416  loss_cls_stage0: 0.3212  loss_box_reg_stage0: 0.03724  loss_cls_stage1: 0.3728  loss_box_reg_stage1: 0.06355  loss_cls_stage2: 0.3161  loss_box_reg_stage2: 0.03988  loss_mask: 0.6912  loss_rpn_cls: 0.5253  loss_rpn_loc: 0.05896  time: 1.3584  data_time: 0.0312  lr: 1.5974e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:22:13 d2.utils.events]: \u001b[0m eta: 3:41:03  iter: 179  total_loss: 2.405  loss_cls_stage0: 0.3265  loss_box_reg_stage0: 0.05223  loss_cls_stage1: 0.3883  loss_box_reg_stage1: 0.05768  loss_cls_stage2: 0.3439  loss_box_reg_stage2: 0.03867  loss_mask: 0.6885  loss_rpn_cls: 0.4476  loss_rpn_loc: 0.04558  time: 1.3672  data_time: 0.0252  lr: 1.7968e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:22:43 d2.utils.events]: \u001b[0m eta: 3:41:09  iter: 199  total_loss: 2.415  loss_cls_stage0: 0.3408  loss_box_reg_stage0: 0.08863  loss_cls_stage1: 0.3694  loss_box_reg_stage1: 0.08739  loss_cls_stage2: 0.3417  loss_box_reg_stage2: 0.04988  loss_mask: 0.6877  loss_rpn_cls: 0.3903  loss_rpn_loc: 0.06089  time: 1.3772  data_time: 0.0231  lr: 1.9961e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:23:12 d2.utils.events]: \u001b[0m eta: 3:41:13  iter: 219  total_loss: 2.2  loss_cls_stage0: 0.3041  loss_box_reg_stage0: 0.0955  loss_cls_stage1: 0.2938  loss_box_reg_stage1: 0.0974  loss_cls_stage2: 0.2743  loss_box_reg_stage2: 0.05189  loss_mask: 0.6877  loss_rpn_cls: 0.3332  loss_rpn_loc: 0.05453  time: 1.3869  data_time: 0.0235  lr: 2.1952e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:23:42 d2.utils.events]: \u001b[0m eta: 3:42:07  iter: 239  total_loss: 2.078  loss_cls_stage0: 0.28  loss_box_reg_stage0: 0.1218  loss_cls_stage1: 0.2395  loss_box_reg_stage1: 0.1038  loss_cls_stage2: 0.22  loss_box_reg_stage2: 0.05197  loss_mask: 0.6855  loss_rpn_cls: 0.2924  loss_rpn_loc: 0.05405  time: 1.3953  data_time: 0.0241  lr: 2.3942e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:24:12 d2.utils.events]: \u001b[0m eta: 3:43:33  iter: 259  total_loss: 1.914  loss_cls_stage0: 0.2706  loss_box_reg_stage0: 0.115  loss_cls_stage1: 0.2066  loss_box_reg_stage1: 0.1118  loss_cls_stage2: 0.1677  loss_box_reg_stage2: 0.05522  loss_mask: 0.6856  loss_rpn_cls: 0.2594  loss_rpn_loc: 0.05602  time: 1.4027  data_time: 0.0238  lr: 2.5931e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:24:42 d2.utils.events]: \u001b[0m eta: 3:45:51  iter: 279  total_loss: 1.798  loss_cls_stage0: 0.2385  loss_box_reg_stage0: 0.1017  loss_cls_stage1: 0.1943  loss_box_reg_stage1: 0.09952  loss_cls_stage2: 0.1474  loss_box_reg_stage2: 0.06289  loss_mask: 0.6773  loss_rpn_cls: 0.2275  loss_rpn_loc: 0.04665  time: 1.4092  data_time: 0.0238  lr: 2.7918e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:25:11 d2.utils.events]: \u001b[0m eta: 3:48:06  iter: 299  total_loss: 1.854  loss_cls_stage0: 0.2542  loss_box_reg_stage0: 0.1092  loss_cls_stage1: 0.1973  loss_box_reg_stage1: 0.09811  loss_cls_stage2: 0.147  loss_box_reg_stage2: 0.05949  loss_mask: 0.681  loss_rpn_cls: 0.2283  loss_rpn_loc: 0.05686  time: 1.4144  data_time: 0.0241  lr: 2.9904e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:25:41 d2.utils.events]: \u001b[0m eta: 3:50:04  iter: 319  total_loss: 1.794  loss_cls_stage0: 0.2376  loss_box_reg_stage0: 0.1059  loss_cls_stage1: 0.1796  loss_box_reg_stage1: 0.1016  loss_cls_stage2: 0.1424  loss_box_reg_stage2: 0.0648  loss_mask: 0.6697  loss_rpn_cls: 0.2095  loss_rpn_loc: 0.05271  time: 1.4191  data_time: 0.0232  lr: 3.1888e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:26:11 d2.utils.events]: \u001b[0m eta: 3:52:44  iter: 339  total_loss: 1.786  loss_cls_stage0: 0.256  loss_box_reg_stage0: 0.1104  loss_cls_stage1: 0.1838  loss_box_reg_stage1: 0.09734  loss_cls_stage2: 0.1341  loss_box_reg_stage2: 0.06047  loss_mask: 0.673  loss_rpn_cls: 0.1903  loss_rpn_loc: 0.0474  time: 1.4238  data_time: 0.0243  lr: 3.387e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:26:41 d2.utils.events]: \u001b[0m eta: 3:53:43  iter: 359  total_loss: 1.69  loss_cls_stage0: 0.2325  loss_box_reg_stage0: 0.1032  loss_cls_stage1: 0.1762  loss_box_reg_stage1: 0.09422  loss_cls_stage2: 0.1277  loss_box_reg_stage2: 0.06114  loss_mask: 0.6786  loss_rpn_cls: 0.1797  loss_rpn_loc: 0.04567  time: 1.4275  data_time: 0.0245  lr: 3.585e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:27:11 d2.utils.events]: \u001b[0m eta: 3:54:28  iter: 379  total_loss: 1.729  loss_cls_stage0: 0.239  loss_box_reg_stage0: 0.1051  loss_cls_stage1: 0.1787  loss_box_reg_stage1: 0.08521  loss_cls_stage2: 0.1307  loss_box_reg_stage2: 0.0583  loss_mask: 0.6693  loss_rpn_cls: 0.1813  loss_rpn_loc: 0.05358  time: 1.4311  data_time: 0.0230  lr: 3.7828e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:27:41 d2.utils.events]: \u001b[0m eta: 3:54:52  iter: 399  total_loss: 1.702  loss_cls_stage0: 0.2498  loss_box_reg_stage0: 0.1073  loss_cls_stage1: 0.175  loss_box_reg_stage1: 0.08995  loss_cls_stage2: 0.1324  loss_box_reg_stage2: 0.06749  loss_mask: 0.6627  loss_rpn_cls: 0.1765  loss_rpn_loc: 0.04643  time: 1.4345  data_time: 0.0236  lr: 3.9803e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:28:11 d2.utils.events]: \u001b[0m eta: 3:54:56  iter: 419  total_loss: 1.654  loss_cls_stage0: 0.2462  loss_box_reg_stage0: 0.1134  loss_cls_stage1: 0.1717  loss_box_reg_stage1: 0.09769  loss_cls_stage2: 0.1211  loss_box_reg_stage2: 0.06067  loss_mask: 0.6561  loss_rpn_cls: 0.1571  loss_rpn_loc: 0.03548  time: 1.4373  data_time: 0.0251  lr: 4.1777e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:28:41 d2.utils.events]: \u001b[0m eta: 3:54:44  iter: 439  total_loss: 1.799  loss_cls_stage0: 0.2816  loss_box_reg_stage0: 0.1292  loss_cls_stage1: 0.187  loss_box_reg_stage1: 0.1138  loss_cls_stage2: 0.1352  loss_box_reg_stage2: 0.0673  loss_mask: 0.6683  loss_rpn_cls: 0.1769  loss_rpn_loc: 0.0503  time: 1.4404  data_time: 0.0307  lr: 4.3747e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:29:11 d2.utils.events]: \u001b[0m eta: 3:54:33  iter: 459  total_loss: 1.823  loss_cls_stage0: 0.2814  loss_box_reg_stage0: 0.1284  loss_cls_stage1: 0.1913  loss_box_reg_stage1: 0.1128  loss_cls_stage2: 0.135  loss_box_reg_stage2: 0.07317  loss_mask: 0.6551  loss_rpn_cls: 0.1701  loss_rpn_loc: 0.05122  time: 1.4431  data_time: 0.0236  lr: 4.5716e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:29:41 d2.utils.events]: \u001b[0m eta: 3:54:19  iter: 479  total_loss: 1.823  loss_cls_stage0: 0.2831  loss_box_reg_stage0: 0.1312  loss_cls_stage1: 0.1921  loss_box_reg_stage1: 0.1036  loss_cls_stage2: 0.1349  loss_box_reg_stage2: 0.06693  loss_mask: 0.6552  loss_rpn_cls: 0.1767  loss_rpn_loc: 0.0445  time: 1.4456  data_time: 0.0235  lr: 4.7681e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:30:11 d2.utils.events]: \u001b[0m eta: 3:53:56  iter: 499  total_loss: 1.741  loss_cls_stage0: 0.2732  loss_box_reg_stage0: 0.121  loss_cls_stage1: 0.1916  loss_box_reg_stage1: 0.09752  loss_cls_stage2: 0.1337  loss_box_reg_stage2: 0.06367  loss_mask: 0.6716  loss_rpn_cls: 0.1553  loss_rpn_loc: 0.04155  time: 1.4478  data_time: 0.0242  lr: 4.9644e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:30:41 d2.utils.events]: \u001b[0m eta: 3:53:45  iter: 519  total_loss: 1.754  loss_cls_stage0: 0.2902  loss_box_reg_stage0: 0.1421  loss_cls_stage1: 0.1869  loss_box_reg_stage1: 0.1191  loss_cls_stage2: 0.1261  loss_box_reg_stage2: 0.06996  loss_mask: 0.6459  loss_rpn_cls: 0.163  loss_rpn_loc: 0.0455  time: 1.4502  data_time: 0.0241  lr: 5.1604e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:31:11 d2.utils.events]: \u001b[0m eta: 3:53:28  iter: 539  total_loss: 1.764  loss_cls_stage0: 0.2845  loss_box_reg_stage0: 0.1328  loss_cls_stage1: 0.1877  loss_box_reg_stage1: 0.1104  loss_cls_stage2: 0.1305  loss_box_reg_stage2: 0.06864  loss_mask: 0.6669  loss_rpn_cls: 0.1525  loss_rpn_loc: 0.04222  time: 1.4519  data_time: 0.0249  lr: 5.356e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:31:41 d2.utils.events]: \u001b[0m eta: 3:53:03  iter: 559  total_loss: 1.707  loss_cls_stage0: 0.2791  loss_box_reg_stage0: 0.1336  loss_cls_stage1: 0.1789  loss_box_reg_stage1: 0.1001  loss_cls_stage2: 0.1209  loss_box_reg_stage2: 0.05945  loss_mask: 0.6556  loss_rpn_cls: 0.1456  loss_rpn_loc: 0.04074  time: 1.4536  data_time: 0.0323  lr: 5.5514e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:32:11 d2.utils.events]: \u001b[0m eta: 3:52:47  iter: 579  total_loss: 1.797  loss_cls_stage0: 0.2933  loss_box_reg_stage0: 0.1416  loss_cls_stage1: 0.2017  loss_box_reg_stage1: 0.1181  loss_cls_stage2: 0.1296  loss_box_reg_stage2: 0.06818  loss_mask: 0.6443  loss_rpn_cls: 0.1603  loss_rpn_loc: 0.04581  time: 1.4552  data_time: 0.0240  lr: 5.7464e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:32:41 d2.utils.events]: \u001b[0m eta: 3:52:32  iter: 599  total_loss: 1.775  loss_cls_stage0: 0.2903  loss_box_reg_stage0: 0.1455  loss_cls_stage1: 0.1878  loss_box_reg_stage1: 0.113  loss_cls_stage2: 0.1213  loss_box_reg_stage2: 0.06803  loss_mask: 0.6651  loss_rpn_cls: 0.1391  loss_rpn_loc: 0.04049  time: 1.4566  data_time: 0.0238  lr: 5.9411e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:33:11 d2.utils.events]: \u001b[0m eta: 3:52:10  iter: 619  total_loss: 1.906  loss_cls_stage0: 0.3027  loss_box_reg_stage0: 0.1495  loss_cls_stage1: 0.2009  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.1345  loss_box_reg_stage2: 0.07547  loss_mask: 0.6761  loss_rpn_cls: 0.146  loss_rpn_loc: 0.04382  time: 1.4580  data_time: 0.0246  lr: 6.1354e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:33:41 d2.utils.events]: \u001b[0m eta: 3:51:46  iter: 639  total_loss: 1.917  loss_cls_stage0: 0.3242  loss_box_reg_stage0: 0.157  loss_cls_stage1: 0.2178  loss_box_reg_stage1: 0.1321  loss_cls_stage2: 0.1401  loss_box_reg_stage2: 0.07468  loss_mask: 0.6457  loss_rpn_cls: 0.1468  loss_rpn_loc: 0.04346  time: 1.4596  data_time: 0.0253  lr: 6.3294e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:34:11 d2.utils.events]: \u001b[0m eta: 3:51:18  iter: 659  total_loss: 1.758  loss_cls_stage0: 0.2881  loss_box_reg_stage0: 0.1413  loss_cls_stage1: 0.186  loss_box_reg_stage1: 0.1056  loss_cls_stage2: 0.1224  loss_box_reg_stage2: 0.06734  loss_mask: 0.6855  loss_rpn_cls: 0.1333  loss_rpn_loc: 0.03839  time: 1.4607  data_time: 0.0234  lr: 6.523e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:34:42 d2.utils.events]: \u001b[0m eta: 3:50:56  iter: 679  total_loss: 1.917  loss_cls_stage0: 0.318  loss_box_reg_stage0: 0.1601  loss_cls_stage1: 0.212  loss_box_reg_stage1: 0.1423  loss_cls_stage2: 0.1326  loss_box_reg_stage2: 0.07967  loss_mask: 0.6622  loss_rpn_cls: 0.1499  loss_rpn_loc: 0.04189  time: 1.4621  data_time: 0.0239  lr: 6.7162e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:35:11 d2.utils.events]: \u001b[0m eta: 3:50:29  iter: 699  total_loss: 1.87  loss_cls_stage0: 0.3079  loss_box_reg_stage0: 0.1513  loss_cls_stage1: 0.2102  loss_box_reg_stage1: 0.1264  loss_cls_stage2: 0.1405  loss_box_reg_stage2: 0.07582  loss_mask: 0.6786  loss_rpn_cls: 0.1343  loss_rpn_loc: 0.04163  time: 1.4631  data_time: 0.0231  lr: 6.909e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:35:42 d2.utils.events]: \u001b[0m eta: 3:50:04  iter: 719  total_loss: 1.828  loss_cls_stage0: 0.2939  loss_box_reg_stage0: 0.1462  loss_cls_stage1: 0.1999  loss_box_reg_stage1: 0.1266  loss_cls_stage2: 0.1365  loss_box_reg_stage2: 0.07486  loss_mask: 0.6393  loss_rpn_cls: 0.1365  loss_rpn_loc: 0.04096  time: 1.4642  data_time: 0.0250  lr: 7.1015e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:36:12 d2.utils.events]: \u001b[0m eta: 3:49:39  iter: 739  total_loss: 1.971  loss_cls_stage0: 0.3479  loss_box_reg_stage0: 0.1737  loss_cls_stage1: 0.2228  loss_box_reg_stage1: 0.1436  loss_cls_stage2: 0.1338  loss_box_reg_stage2: 0.08137  loss_mask: 0.6555  loss_rpn_cls: 0.1446  loss_rpn_loc: 0.04312  time: 1.4653  data_time: 0.0251  lr: 7.2934e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:36:42 d2.utils.events]: \u001b[0m eta: 3:49:09  iter: 759  total_loss: 1.757  loss_cls_stage0: 0.2906  loss_box_reg_stage0: 0.1409  loss_cls_stage1: 0.1971  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.1337  loss_box_reg_stage2: 0.07455  loss_mask: 0.6421  loss_rpn_cls: 0.139  loss_rpn_loc: 0.04196  time: 1.4660  data_time: 0.0240  lr: 7.485e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:37:12 d2.utils.events]: \u001b[0m eta: 3:48:41  iter: 779  total_loss: 1.865  loss_cls_stage0: 0.2964  loss_box_reg_stage0: 0.16  loss_cls_stage1: 0.1985  loss_box_reg_stage1: 0.1281  loss_cls_stage2: 0.1293  loss_box_reg_stage2: 0.07547  loss_mask: 0.6681  loss_rpn_cls: 0.135  loss_rpn_loc: 0.04155  time: 1.4669  data_time: 0.0256  lr: 7.6761e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:37:41 d2.utils.events]: \u001b[0m eta: 3:48:11  iter: 799  total_loss: 1.887  loss_cls_stage0: 0.3059  loss_box_reg_stage0: 0.1512  loss_cls_stage1: 0.2247  loss_box_reg_stage1: 0.1419  loss_cls_stage2: 0.1418  loss_box_reg_stage2: 0.08077  loss_mask: 0.6556  loss_rpn_cls: 0.1428  loss_rpn_loc: 0.03992  time: 1.4676  data_time: 0.0256  lr: 7.8668e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:38:12 d2.utils.events]: \u001b[0m eta: 3:47:48  iter: 819  total_loss: 1.873  loss_cls_stage0: 0.3202  loss_box_reg_stage0: 0.162  loss_cls_stage1: 0.2246  loss_box_reg_stage1: 0.1345  loss_cls_stage2: 0.1479  loss_box_reg_stage2: 0.08535  loss_mask: 0.6496  loss_rpn_cls: 0.1399  loss_rpn_loc: 0.04392  time: 1.4685  data_time: 0.0262  lr: 8.057e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:38:42 d2.utils.events]: \u001b[0m eta: 3:47:20  iter: 839  total_loss: 1.904  loss_cls_stage0: 0.3266  loss_box_reg_stage0: 0.1676  loss_cls_stage1: 0.2229  loss_box_reg_stage1: 0.1462  loss_cls_stage2: 0.1392  loss_box_reg_stage2: 0.08951  loss_mask: 0.6351  loss_rpn_cls: 0.1372  loss_rpn_loc: 0.0436  time: 1.4692  data_time: 0.0241  lr: 8.2467e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:39:12 d2.utils.events]: \u001b[0m eta: 3:46:53  iter: 859  total_loss: 1.994  loss_cls_stage0: 0.3487  loss_box_reg_stage0: 0.177  loss_cls_stage1: 0.2434  loss_box_reg_stage1: 0.1624  loss_cls_stage2: 0.1491  loss_box_reg_stage2: 0.09217  loss_mask: 0.6461  loss_rpn_cls: 0.1291  loss_rpn_loc: 0.04176  time: 1.4700  data_time: 0.0241  lr: 8.4359e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:39:42 d2.utils.events]: \u001b[0m eta: 3:46:24  iter: 879  total_loss: 1.976  loss_cls_stage0: 0.3174  loss_box_reg_stage0: 0.163  loss_cls_stage1: 0.2228  loss_box_reg_stage1: 0.1471  loss_cls_stage2: 0.1469  loss_box_reg_stage2: 0.08339  loss_mask: 0.6627  loss_rpn_cls: 0.1409  loss_rpn_loc: 0.04218  time: 1.4707  data_time: 0.0255  lr: 8.6247e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:40:11 d2.utils.events]: \u001b[0m eta: 3:45:54  iter: 899  total_loss: 1.823  loss_cls_stage0: 0.2803  loss_box_reg_stage0: 0.1326  loss_cls_stage1: 0.2014  loss_box_reg_stage1: 0.1214  loss_cls_stage2: 0.1314  loss_box_reg_stage2: 0.07555  loss_mask: 0.6906  loss_rpn_cls: 0.1289  loss_rpn_loc: 0.03835  time: 1.4712  data_time: 0.0251  lr: 8.8129e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:40:42 d2.utils.events]: \u001b[0m eta: 3:45:25  iter: 919  total_loss: 1.837  loss_cls_stage0: 0.3177  loss_box_reg_stage0: 0.1594  loss_cls_stage1: 0.2037  loss_box_reg_stage1: 0.1374  loss_cls_stage2: 0.1364  loss_box_reg_stage2: 0.0806  loss_mask: 0.6679  loss_rpn_cls: 0.1256  loss_rpn_loc: 0.04254  time: 1.4719  data_time: 0.0237  lr: 9.0006e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:41:12 d2.utils.events]: \u001b[0m eta: 3:44:56  iter: 939  total_loss: 1.869  loss_cls_stage0: 0.2973  loss_box_reg_stage0: 0.1587  loss_cls_stage1: 0.2174  loss_box_reg_stage1: 0.1426  loss_cls_stage2: 0.1426  loss_box_reg_stage2: 0.0813  loss_mask: 0.6443  loss_rpn_cls: 0.1317  loss_rpn_loc: 0.04037  time: 1.4725  data_time: 0.0262  lr: 9.1878e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:41:41 d2.utils.events]: \u001b[0m eta: 3:44:26  iter: 959  total_loss: 1.859  loss_cls_stage0: 0.3004  loss_box_reg_stage0: 0.1444  loss_cls_stage1: 0.212  loss_box_reg_stage1: 0.1366  loss_cls_stage2: 0.1417  loss_box_reg_stage2: 0.08268  loss_mask: 0.6615  loss_rpn_cls: 0.1271  loss_rpn_loc: 0.03804  time: 1.4729  data_time: 0.0234  lr: 9.3744e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:42:12 d2.utils.events]: \u001b[0m eta: 3:43:58  iter: 979  total_loss: 1.984  loss_cls_stage0: 0.3395  loss_box_reg_stage0: 0.159  loss_cls_stage1: 0.2412  loss_box_reg_stage1: 0.1555  loss_cls_stage2: 0.1561  loss_box_reg_stage2: 0.09748  loss_mask: 0.6447  loss_rpn_cls: 0.1364  loss_rpn_loc: 0.0441  time: 1.4735  data_time: 0.0240  lr: 9.5605e-05  max_mem: 11973M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/26 21:42:43 d2.data.common]: \u001b[0mSerializing 879 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/26 21:42:43 d2.data.common]: \u001b[0mSerialized dataset takes 0.90 MiB\n",
      "\u001b[32m[03/26 21:42:43 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'vinbigdata_valid_fold3' to COCO format ...)\n",
      "\u001b[32m[03/26 21:42:43 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
      "\u001b[32m[03/26 21:42:44 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 879, #annotations: 4746\n",
      "\u001b[32m[03/26 21:42:44 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at '/home/yamaguchi-milkcocholate/VinBigData/src/VinBigData-ObjectDetection/detectron2_results/results01/fold-3/inference/vinbigdata_valid_fold3_coco_format.json' ...\n",
      "\u001b[32m[03/26 21:42:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 879 images\n",
      "\u001b[32m[03/26 21:42:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/879. 0.0761 s / img. ETA=0:01:08\n",
      "\u001b[32m[03/26 21:42:51 d2.evaluation.evaluator]: \u001b[0mInference done 74/879. 0.0774 s / img. ETA=0:01:04\n",
      "\u001b[32m[03/26 21:42:56 d2.evaluation.evaluator]: \u001b[0mInference done 137/879. 0.0772 s / img. ETA=0:00:59\n",
      "\u001b[32m[03/26 21:43:01 d2.evaluation.evaluator]: \u001b[0mInference done 200/879. 0.0770 s / img. ETA=0:00:54\n",
      "\u001b[32m[03/26 21:43:06 d2.evaluation.evaluator]: \u001b[0mInference done 263/879. 0.0769 s / img. ETA=0:00:49\n",
      "\u001b[32m[03/26 21:43:11 d2.evaluation.evaluator]: \u001b[0mInference done 327/879. 0.0768 s / img. ETA=0:00:44\n",
      "\u001b[32m[03/26 21:43:16 d2.evaluation.evaluator]: \u001b[0mInference done 391/879. 0.0767 s / img. ETA=0:00:38\n",
      "\u001b[32m[03/26 21:43:21 d2.evaluation.evaluator]: \u001b[0mInference done 455/879. 0.0767 s / img. ETA=0:00:33\n",
      "\u001b[32m[03/26 21:43:26 d2.evaluation.evaluator]: \u001b[0mInference done 519/879. 0.0766 s / img. ETA=0:00:28\n",
      "\u001b[32m[03/26 21:43:31 d2.evaluation.evaluator]: \u001b[0mInference done 583/879. 0.0766 s / img. ETA=0:00:23\n",
      "\u001b[32m[03/26 21:43:36 d2.evaluation.evaluator]: \u001b[0mInference done 647/879. 0.0765 s / img. ETA=0:00:18\n",
      "\u001b[32m[03/26 21:43:41 d2.evaluation.evaluator]: \u001b[0mInference done 711/879. 0.0765 s / img. ETA=0:00:13\n",
      "\u001b[32m[03/26 21:43:46 d2.evaluation.evaluator]: \u001b[0mInference done 775/879. 0.0765 s / img. ETA=0:00:08\n",
      "\u001b[32m[03/26 21:43:51 d2.evaluation.evaluator]: \u001b[0mInference done 839/879. 0.0765 s / img. ETA=0:00:03\n",
      "\u001b[32m[03/26 21:43:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:09.496677 (0.079516 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/26 21:43:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:06 (0.076473 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.33 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "\u001b[32m[03/26 21:43:55 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold3 in csv format:\n",
      "\u001b[32m[03/26 21:43:55 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/26 21:43:55 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/26 21:43:55 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n",
      "validation do loss eval 1.948306142968834\n",
      "\u001b[32m[03/26 21:45:24 d2.utils.events]: \u001b[0m eta: 3:43:30  iter: 999  total_loss: 1.866  loss_cls_stage0: 0.3145  loss_box_reg_stage0: 0.155  loss_cls_stage1: 0.2162  loss_box_reg_stage1: 0.1371  loss_cls_stage2: 0.135  loss_box_reg_stage2: 0.07784  loss_mask: 0.6492  loss_rpn_cls: 0.1239  loss_rpn_loc: 0.0395  validation_loss: 1.948  time: 1.4739  data_time: 0.0238  lr: 9.746e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:45:53 d2.utils.events]: \u001b[0m eta: 3:43:04  iter: 1019  total_loss: 1.931  loss_cls_stage0: 0.308  loss_box_reg_stage0: 0.1579  loss_cls_stage1: 0.2362  loss_box_reg_stage1: 0.16  loss_cls_stage2: 0.1605  loss_box_reg_stage2: 0.09256  loss_mask: 0.6346  loss_rpn_cls: 0.1214  loss_rpn_loc: 0.03999  validation_loss: 1.948  time: 1.4737  data_time: 0.0245  lr: 9.746e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:46:24 d2.utils.events]: \u001b[0m eta: 3:42:42  iter: 1039  total_loss: 1.996  loss_cls_stage0: 0.3337  loss_box_reg_stage0: 0.1719  loss_cls_stage1: 0.2426  loss_box_reg_stage1: 0.1501  loss_cls_stage2: 0.1567  loss_box_reg_stage2: 0.09536  loss_mask: 0.6317  loss_rpn_cls: 0.14  loss_rpn_loc: 0.0407  validation_loss: 1.948  time: 1.4744  data_time: 0.0250  lr: 9.736e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:46:54 d2.utils.events]: \u001b[0m eta: 3:42:16  iter: 1059  total_loss: 1.794  loss_cls_stage0: 0.279  loss_box_reg_stage0: 0.1366  loss_cls_stage1: 0.2125  loss_box_reg_stage1: 0.1397  loss_cls_stage2: 0.1486  loss_box_reg_stage2: 0.08942  loss_mask: 0.642  loss_rpn_cls: 0.1145  loss_rpn_loc: 0.03553  validation_loss: 1.948  time: 1.4748  data_time: 0.0258  lr: 9.7258e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:47:23 d2.utils.events]: \u001b[0m eta: 3:41:50  iter: 1079  total_loss: 1.882  loss_cls_stage0: 0.284  loss_box_reg_stage0: 0.1449  loss_cls_stage1: 0.2206  loss_box_reg_stage1: 0.1464  loss_cls_stage2: 0.1468  loss_box_reg_stage2: 0.08873  loss_mask: 0.6365  loss_rpn_cls: 0.117  loss_rpn_loc: 0.0406  validation_loss: 1.948  time: 1.4752  data_time: 0.0241  lr: 9.7155e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:47:53 d2.utils.events]: \u001b[0m eta: 3:41:24  iter: 1099  total_loss: 1.889  loss_cls_stage0: 0.3055  loss_box_reg_stage0: 0.1509  loss_cls_stage1: 0.2256  loss_box_reg_stage1: 0.1488  loss_cls_stage2: 0.1469  loss_box_reg_stage2: 0.09388  loss_mask: 0.6451  loss_rpn_cls: 0.1268  loss_rpn_loc: 0.03751  validation_loss: 1.948  time: 1.4756  data_time: 0.0249  lr: 9.7049e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:48:23 d2.utils.events]: \u001b[0m eta: 3:40:57  iter: 1119  total_loss: 1.835  loss_cls_stage0: 0.2767  loss_box_reg_stage0: 0.1454  loss_cls_stage1: 0.2097  loss_box_reg_stage1: 0.1447  loss_cls_stage2: 0.1437  loss_box_reg_stage2: 0.0851  loss_mask: 0.6461  loss_rpn_cls: 0.1167  loss_rpn_loc: 0.03943  validation_loss: 1.948  time: 1.4759  data_time: 0.0242  lr: 9.6942e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:48:53 d2.utils.events]: \u001b[0m eta: 3:40:34  iter: 1139  total_loss: 1.849  loss_cls_stage0: 0.3149  loss_box_reg_stage0: 0.1524  loss_cls_stage1: 0.2327  loss_box_reg_stage1: 0.1533  loss_cls_stage2: 0.1507  loss_box_reg_stage2: 0.08991  loss_mask: 0.6331  loss_rpn_cls: 0.1157  loss_rpn_loc: 0.03825  validation_loss: 1.948  time: 1.4764  data_time: 0.0233  lr: 9.6833e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:49:23 d2.utils.events]: \u001b[0m eta: 3:40:08  iter: 1159  total_loss: 1.862  loss_cls_stage0: 0.3088  loss_box_reg_stage0: 0.1536  loss_cls_stage1: 0.2284  loss_box_reg_stage1: 0.1508  loss_cls_stage2: 0.149  loss_box_reg_stage2: 0.09345  loss_mask: 0.6435  loss_rpn_cls: 0.1122  loss_rpn_loc: 0.03795  validation_loss: 1.948  time: 1.4767  data_time: 0.0234  lr: 9.6722e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:49:53 d2.utils.events]: \u001b[0m eta: 3:39:43  iter: 1179  total_loss: 1.845  loss_cls_stage0: 0.3048  loss_box_reg_stage0: 0.1525  loss_cls_stage1: 0.2315  loss_box_reg_stage1: 0.1626  loss_cls_stage2: 0.1563  loss_box_reg_stage2: 0.09586  loss_mask: 0.6083  loss_rpn_cls: 0.1244  loss_rpn_loc: 0.04168  validation_loss: 1.948  time: 1.4770  data_time: 0.0252  lr: 9.6609e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:50:23 d2.utils.events]: \u001b[0m eta: 3:39:17  iter: 1199  total_loss: 1.862  loss_cls_stage0: 0.3131  loss_box_reg_stage0: 0.1558  loss_cls_stage1: 0.2234  loss_box_reg_stage1: 0.1445  loss_cls_stage2: 0.1485  loss_box_reg_stage2: 0.08952  loss_mask: 0.6367  loss_rpn_cls: 0.1215  loss_rpn_loc: 0.038  validation_loss: 1.948  time: 1.4774  data_time: 0.0249  lr: 9.6495e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:50:53 d2.utils.events]: \u001b[0m eta: 3:38:49  iter: 1219  total_loss: 1.843  loss_cls_stage0: 0.2869  loss_box_reg_stage0: 0.143  loss_cls_stage1: 0.2215  loss_box_reg_stage1: 0.1476  loss_cls_stage2: 0.1444  loss_box_reg_stage2: 0.09421  loss_mask: 0.6472  loss_rpn_cls: 0.1219  loss_rpn_loc: 0.0374  validation_loss: 1.948  time: 1.4777  data_time: 0.0252  lr: 9.6378e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:51:23 d2.utils.events]: \u001b[0m eta: 3:38:24  iter: 1239  total_loss: 2.097  loss_cls_stage0: 0.3426  loss_box_reg_stage0: 0.1717  loss_cls_stage1: 0.2489  loss_box_reg_stage1: 0.1819  loss_cls_stage2: 0.166  loss_box_reg_stage2: 0.1025  loss_mask: 0.6431  loss_rpn_cls: 0.1348  loss_rpn_loc: 0.04659  validation_loss: 1.948  time: 1.4781  data_time: 0.0241  lr: 9.626e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:51:53 d2.utils.events]: \u001b[0m eta: 3:37:55  iter: 1259  total_loss: 1.86  loss_cls_stage0: 0.2914  loss_box_reg_stage0: 0.1468  loss_cls_stage1: 0.2179  loss_box_reg_stage1: 0.1493  loss_cls_stage2: 0.1448  loss_box_reg_stage2: 0.09204  loss_mask: 0.6054  loss_rpn_cls: 0.1128  loss_rpn_loc: 0.03951  validation_loss: 1.948  time: 1.4786  data_time: 0.0249  lr: 9.614e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:52:23 d2.utils.events]: \u001b[0m eta: 3:37:26  iter: 1279  total_loss: 1.793  loss_cls_stage0: 0.2941  loss_box_reg_stage0: 0.147  loss_cls_stage1: 0.2136  loss_box_reg_stage1: 0.1405  loss_cls_stage2: 0.1428  loss_box_reg_stage2: 0.08952  loss_mask: 0.618  loss_rpn_cls: 0.113  loss_rpn_loc: 0.03698  validation_loss: 1.948  time: 1.4789  data_time: 0.0244  lr: 9.6018e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:52:54 d2.utils.events]: \u001b[0m eta: 3:37:00  iter: 1299  total_loss: 2.015  loss_cls_stage0: 0.3274  loss_box_reg_stage0: 0.1703  loss_cls_stage1: 0.2424  loss_box_reg_stage1: 0.1747  loss_cls_stage2: 0.1604  loss_box_reg_stage2: 0.1015  loss_mask: 0.6299  loss_rpn_cls: 0.1062  loss_rpn_loc: 0.04074  validation_loss: 1.948  time: 1.4793  data_time: 0.0247  lr: 9.5894e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:53:23 d2.utils.events]: \u001b[0m eta: 3:36:33  iter: 1319  total_loss: 1.932  loss_cls_stage0: 0.3097  loss_box_reg_stage0: 0.1521  loss_cls_stage1: 0.2324  loss_box_reg_stage1: 0.1592  loss_cls_stage2: 0.16  loss_box_reg_stage2: 0.0955  loss_mask: 0.6764  loss_rpn_cls: 0.1187  loss_rpn_loc: 0.0416  validation_loss: 1.948  time: 1.4796  data_time: 0.0249  lr: 9.5768e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:53:54 d2.utils.events]: \u001b[0m eta: 3:36:05  iter: 1339  total_loss: 1.852  loss_cls_stage0: 0.3048  loss_box_reg_stage0: 0.1689  loss_cls_stage1: 0.2226  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.1479  loss_box_reg_stage2: 0.09253  loss_mask: 0.6691  loss_rpn_cls: 0.1117  loss_rpn_loc: 0.03738  validation_loss: 1.948  time: 1.4799  data_time: 0.0249  lr: 9.5641e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:54:24 d2.utils.events]: \u001b[0m eta: 3:35:36  iter: 1359  total_loss: 1.864  loss_cls_stage0: 0.2973  loss_box_reg_stage0: 0.1501  loss_cls_stage1: 0.2253  loss_box_reg_stage1: 0.1594  loss_cls_stage2: 0.1508  loss_box_reg_stage2: 0.1018  loss_mask: 0.6138  loss_rpn_cls: 0.1203  loss_rpn_loc: 0.03989  validation_loss: 1.948  time: 1.4802  data_time: 0.0321  lr: 9.5512e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:54:53 d2.utils.events]: \u001b[0m eta: 3:35:08  iter: 1379  total_loss: 1.931  loss_cls_stage0: 0.3057  loss_box_reg_stage0: 0.1551  loss_cls_stage1: 0.2416  loss_box_reg_stage1: 0.1769  loss_cls_stage2: 0.1623  loss_box_reg_stage2: 0.09826  loss_mask: 0.6171  loss_rpn_cls: 0.1156  loss_rpn_loc: 0.03814  validation_loss: 1.948  time: 1.4804  data_time: 0.0240  lr: 9.5381e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:55:23 d2.utils.events]: \u001b[0m eta: 3:34:39  iter: 1399  total_loss: 1.811  loss_cls_stage0: 0.3082  loss_box_reg_stage0: 0.1526  loss_cls_stage1: 0.2174  loss_box_reg_stage1: 0.1559  loss_cls_stage2: 0.1539  loss_box_reg_stage2: 0.1004  loss_mask: 0.5968  loss_rpn_cls: 0.0993  loss_rpn_loc: 0.03656  validation_loss: 1.948  time: 1.4807  data_time: 0.0234  lr: 9.5248e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:55:53 d2.utils.events]: \u001b[0m eta: 3:34:11  iter: 1419  total_loss: 1.851  loss_cls_stage0: 0.2937  loss_box_reg_stage0: 0.1481  loss_cls_stage1: 0.2228  loss_box_reg_stage1: 0.1498  loss_cls_stage2: 0.1468  loss_box_reg_stage2: 0.09683  loss_mask: 0.6333  loss_rpn_cls: 0.1161  loss_rpn_loc: 0.03972  validation_loss: 1.948  time: 1.4809  data_time: 0.0249  lr: 9.5113e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:56:23 d2.utils.events]: \u001b[0m eta: 3:33:39  iter: 1439  total_loss: 1.866  loss_cls_stage0: 0.2859  loss_box_reg_stage0: 0.1481  loss_cls_stage1: 0.2195  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.1431  loss_box_reg_stage2: 0.09638  loss_mask: 0.6001  loss_rpn_cls: 0.107  loss_rpn_loc: 0.03642  validation_loss: 1.948  time: 1.4811  data_time: 0.0237  lr: 9.4977e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:56:53 d2.utils.events]: \u001b[0m eta: 3:33:09  iter: 1459  total_loss: 2.001  loss_cls_stage0: 0.3229  loss_box_reg_stage0: 0.1662  loss_cls_stage1: 0.248  loss_box_reg_stage1: 0.1916  loss_cls_stage2: 0.1543  loss_box_reg_stage2: 0.1111  loss_mask: 0.6403  loss_rpn_cls: 0.1073  loss_rpn_loc: 0.03715  validation_loss: 1.948  time: 1.4814  data_time: 0.0291  lr: 9.4839e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:57:23 d2.utils.events]: \u001b[0m eta: 3:32:38  iter: 1479  total_loss: 1.913  loss_cls_stage0: 0.3288  loss_box_reg_stage0: 0.1686  loss_cls_stage1: 0.2507  loss_box_reg_stage1: 0.1858  loss_cls_stage2: 0.1696  loss_box_reg_stage2: 0.1198  loss_mask: 0.5785  loss_rpn_cls: 0.1095  loss_rpn_loc: 0.03983  validation_loss: 1.948  time: 1.4817  data_time: 0.0240  lr: 9.4699e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:57:53 d2.utils.events]: \u001b[0m eta: 3:32:08  iter: 1499  total_loss: 1.791  loss_cls_stage0: 0.2822  loss_box_reg_stage0: 0.1473  loss_cls_stage1: 0.222  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.1456  loss_box_reg_stage2: 0.1078  loss_mask: 0.5872  loss_rpn_cls: 0.1045  loss_rpn_loc: 0.03884  validation_loss: 1.948  time: 1.4820  data_time: 0.0253  lr: 9.4557e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:58:24 d2.utils.events]: \u001b[0m eta: 3:31:36  iter: 1519  total_loss: 1.943  loss_cls_stage0: 0.316  loss_box_reg_stage0: 0.1722  loss_cls_stage1: 0.227  loss_box_reg_stage1: 0.1618  loss_cls_stage2: 0.1508  loss_box_reg_stage2: 0.1038  loss_mask: 0.6551  loss_rpn_cls: 0.1064  loss_rpn_loc: 0.0353  validation_loss: 1.948  time: 1.4823  data_time: 0.0256  lr: 9.4414e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:58:54 d2.utils.events]: \u001b[0m eta: 3:31:05  iter: 1539  total_loss: 1.898  loss_cls_stage0: 0.3101  loss_box_reg_stage0: 0.1596  loss_cls_stage1: 0.217  loss_box_reg_stage1: 0.1556  loss_cls_stage2: 0.1564  loss_box_reg_stage2: 0.1099  loss_mask: 0.6179  loss_rpn_cls: 0.1187  loss_rpn_loc: 0.03868  validation_loss: 1.948  time: 1.4825  data_time: 0.0237  lr: 9.4269e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:59:24 d2.utils.events]: \u001b[0m eta: 3:30:39  iter: 1559  total_loss: 2.065  loss_cls_stage0: 0.3365  loss_box_reg_stage0: 0.1718  loss_cls_stage1: 0.2543  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.1684  loss_box_reg_stage2: 0.1268  loss_mask: 0.6189  loss_rpn_cls: 0.1301  loss_rpn_loc: 0.04425  validation_loss: 1.948  time: 1.4829  data_time: 0.0245  lr: 9.4122e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 21:59:54 d2.utils.events]: \u001b[0m eta: 3:30:05  iter: 1579  total_loss: 1.848  loss_cls_stage0: 0.2703  loss_box_reg_stage0: 0.1341  loss_cls_stage1: 0.2181  loss_box_reg_stage1: 0.1556  loss_cls_stage2: 0.1474  loss_box_reg_stage2: 0.1037  loss_mask: 0.633  loss_rpn_cls: 0.1103  loss_rpn_loc: 0.03655  validation_loss: 1.948  time: 1.4831  data_time: 0.0243  lr: 9.3973e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:00:24 d2.utils.events]: \u001b[0m eta: 3:29:36  iter: 1599  total_loss: 1.963  loss_cls_stage0: 0.3146  loss_box_reg_stage0: 0.1614  loss_cls_stage1: 0.2432  loss_box_reg_stage1: 0.1779  loss_cls_stage2: 0.1593  loss_box_reg_stage2: 0.1089  loss_mask: 0.6008  loss_rpn_cls: 0.1151  loss_rpn_loc: 0.04416  validation_loss: 1.948  time: 1.4833  data_time: 0.0249  lr: 9.3823e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:00:54 d2.utils.events]: \u001b[0m eta: 3:29:04  iter: 1619  total_loss: 1.807  loss_cls_stage0: 0.2912  loss_box_reg_stage0: 0.1465  loss_cls_stage1: 0.2301  loss_box_reg_stage1: 0.1664  loss_cls_stage2: 0.1527  loss_box_reg_stage2: 0.1054  loss_mask: 0.6236  loss_rpn_cls: 0.09946  loss_rpn_loc: 0.03828  validation_loss: 1.948  time: 1.4836  data_time: 0.0258  lr: 9.3671e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:01:24 d2.utils.events]: \u001b[0m eta: 3:28:31  iter: 1639  total_loss: 1.824  loss_cls_stage0: 0.2816  loss_box_reg_stage0: 0.1452  loss_cls_stage1: 0.2237  loss_box_reg_stage1: 0.1639  loss_cls_stage2: 0.152  loss_box_reg_stage2: 0.1093  loss_mask: 0.6289  loss_rpn_cls: 0.1008  loss_rpn_loc: 0.03536  validation_loss: 1.948  time: 1.4838  data_time: 0.0257  lr: 9.3517e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:01:54 d2.utils.events]: \u001b[0m eta: 3:28:06  iter: 1659  total_loss: 1.879  loss_cls_stage0: 0.2845  loss_box_reg_stage0: 0.1489  loss_cls_stage1: 0.2207  loss_box_reg_stage1: 0.1605  loss_cls_stage2: 0.1454  loss_box_reg_stage2: 0.09967  loss_mask: 0.6042  loss_rpn_cls: 0.1056  loss_rpn_loc: 0.03558  validation_loss: 1.948  time: 1.4841  data_time: 0.0238  lr: 9.3361e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:02:24 d2.utils.events]: \u001b[0m eta: 3:27:34  iter: 1679  total_loss: 2.012  loss_cls_stage0: 0.3062  loss_box_reg_stage0: 0.1647  loss_cls_stage1: 0.237  loss_box_reg_stage1: 0.1855  loss_cls_stage2: 0.1692  loss_box_reg_stage2: 0.1275  loss_mask: 0.6343  loss_rpn_cls: 0.1098  loss_rpn_loc: 0.03759  validation_loss: 1.948  time: 1.4844  data_time: 0.0248  lr: 9.3204e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:02:54 d2.utils.events]: \u001b[0m eta: 3:27:04  iter: 1699  total_loss: 1.875  loss_cls_stage0: 0.2771  loss_box_reg_stage0: 0.1466  loss_cls_stage1: 0.2216  loss_box_reg_stage1: 0.1631  loss_cls_stage2: 0.151  loss_box_reg_stage2: 0.1038  loss_mask: 0.6126  loss_rpn_cls: 0.1055  loss_rpn_loc: 0.03611  validation_loss: 1.948  time: 1.4846  data_time: 0.0237  lr: 9.3045e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:03:24 d2.utils.events]: \u001b[0m eta: 3:26:34  iter: 1719  total_loss: 1.82  loss_cls_stage0: 0.2828  loss_box_reg_stage0: 0.1445  loss_cls_stage1: 0.2205  loss_box_reg_stage1: 0.1674  loss_cls_stage2: 0.1524  loss_box_reg_stage2: 0.1033  loss_mask: 0.5832  loss_rpn_cls: 0.103  loss_rpn_loc: 0.03787  validation_loss: 1.948  time: 1.4847  data_time: 0.0318  lr: 9.2884e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:03:54 d2.utils.events]: \u001b[0m eta: 3:26:02  iter: 1739  total_loss: 1.945  loss_cls_stage0: 0.2987  loss_box_reg_stage0: 0.1574  loss_cls_stage1: 0.2219  loss_box_reg_stage1: 0.1647  loss_cls_stage2: 0.1525  loss_box_reg_stage2: 0.1054  loss_mask: 0.6142  loss_rpn_cls: 0.103  loss_rpn_loc: 0.03709  validation_loss: 1.948  time: 1.4849  data_time: 0.0230  lr: 9.2722e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:04:24 d2.utils.events]: \u001b[0m eta: 3:25:32  iter: 1759  total_loss: 1.905  loss_cls_stage0: 0.2922  loss_box_reg_stage0: 0.1509  loss_cls_stage1: 0.2347  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.1594  loss_box_reg_stage2: 0.1161  loss_mask: 0.5792  loss_rpn_cls: 0.09736  loss_rpn_loc: 0.03426  validation_loss: 1.948  time: 1.4851  data_time: 0.0239  lr: 9.2558e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:04:54 d2.utils.events]: \u001b[0m eta: 3:25:02  iter: 1779  total_loss: 1.737  loss_cls_stage0: 0.2653  loss_box_reg_stage0: 0.1344  loss_cls_stage1: 0.2003  loss_box_reg_stage1: 0.1491  loss_cls_stage2: 0.1426  loss_box_reg_stage2: 0.1024  loss_mask: 0.5913  loss_rpn_cls: 0.103  loss_rpn_loc: 0.03525  validation_loss: 1.948  time: 1.4852  data_time: 0.0242  lr: 9.2392e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:05:24 d2.utils.events]: \u001b[0m eta: 3:24:33  iter: 1799  total_loss: 1.903  loss_cls_stage0: 0.2954  loss_box_reg_stage0: 0.1507  loss_cls_stage1: 0.2379  loss_box_reg_stage1: 0.18  loss_cls_stage2: 0.1645  loss_box_reg_stage2: 0.1146  loss_mask: 0.5889  loss_rpn_cls: 0.1036  loss_rpn_loc: 0.03514  validation_loss: 1.948  time: 1.4853  data_time: 0.0244  lr: 9.2225e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:05:54 d2.utils.events]: \u001b[0m eta: 3:24:04  iter: 1819  total_loss: 2.02  loss_cls_stage0: 0.3125  loss_box_reg_stage0: 0.1639  loss_cls_stage1: 0.2453  loss_box_reg_stage1: 0.1766  loss_cls_stage2: 0.1667  loss_box_reg_stage2: 0.122  loss_mask: 0.5963  loss_rpn_cls: 0.1079  loss_rpn_loc: 0.03908  validation_loss: 1.948  time: 1.4855  data_time: 0.0263  lr: 9.2056e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:06:25 d2.utils.events]: \u001b[0m eta: 3:23:35  iter: 1839  total_loss: 1.833  loss_cls_stage0: 0.2826  loss_box_reg_stage0: 0.1528  loss_cls_stage1: 0.213  loss_box_reg_stage1: 0.1707  loss_cls_stage2: 0.1452  loss_box_reg_stage2: 0.1068  loss_mask: 0.554  loss_rpn_cls: 0.1133  loss_rpn_loc: 0.0393  validation_loss: 1.948  time: 1.4858  data_time: 0.0245  lr: 9.1885e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:06:55 d2.utils.events]: \u001b[0m eta: 3:23:06  iter: 1859  total_loss: 1.937  loss_cls_stage0: 0.319  loss_box_reg_stage0: 0.1665  loss_cls_stage1: 0.2359  loss_box_reg_stage1: 0.1673  loss_cls_stage2: 0.1628  loss_box_reg_stage2: 0.1132  loss_mask: 0.6076  loss_rpn_cls: 0.102  loss_rpn_loc: 0.04002  validation_loss: 1.948  time: 1.4860  data_time: 0.0243  lr: 9.1713e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:07:25 d2.utils.events]: \u001b[0m eta: 3:22:37  iter: 1879  total_loss: 1.9  loss_cls_stage0: 0.2766  loss_box_reg_stage0: 0.1429  loss_cls_stage1: 0.2249  loss_box_reg_stage1: 0.1751  loss_cls_stage2: 0.163  loss_box_reg_stage2: 0.1269  loss_mask: 0.5801  loss_rpn_cls: 0.1077  loss_rpn_loc: 0.04391  validation_loss: 1.948  time: 1.4862  data_time: 0.0235  lr: 9.1539e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:07:55 d2.utils.events]: \u001b[0m eta: 3:22:11  iter: 1899  total_loss: 1.837  loss_cls_stage0: 0.3005  loss_box_reg_stage0: 0.1584  loss_cls_stage1: 0.2333  loss_box_reg_stage1: 0.1828  loss_cls_stage2: 0.1701  loss_box_reg_stage2: 0.1219  loss_mask: 0.6164  loss_rpn_cls: 0.116  loss_rpn_loc: 0.04152  validation_loss: 1.948  time: 1.4864  data_time: 0.0246  lr: 9.1363e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:08:25 d2.utils.events]: \u001b[0m eta: 3:21:48  iter: 1919  total_loss: 1.909  loss_cls_stage0: 0.3083  loss_box_reg_stage0: 0.1644  loss_cls_stage1: 0.2403  loss_box_reg_stage1: 0.1845  loss_cls_stage2: 0.174  loss_box_reg_stage2: 0.126  loss_mask: 0.5944  loss_rpn_cls: 0.1086  loss_rpn_loc: 0.04622  validation_loss: 1.948  time: 1.4867  data_time: 0.0239  lr: 9.1186e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:08:55 d2.utils.events]: \u001b[0m eta: 3:21:20  iter: 1939  total_loss: 1.923  loss_cls_stage0: 0.3186  loss_box_reg_stage0: 0.163  loss_cls_stage1: 0.2422  loss_box_reg_stage1: 0.1881  loss_cls_stage2: 0.1683  loss_box_reg_stage2: 0.121  loss_mask: 0.6113  loss_rpn_cls: 0.1093  loss_rpn_loc: 0.03939  validation_loss: 1.948  time: 1.4868  data_time: 0.0240  lr: 9.1007e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:09:25 d2.utils.events]: \u001b[0m eta: 3:20:51  iter: 1959  total_loss: 1.875  loss_cls_stage0: 0.2854  loss_box_reg_stage0: 0.154  loss_cls_stage1: 0.2168  loss_box_reg_stage1: 0.1712  loss_cls_stage2: 0.1621  loss_box_reg_stage2: 0.1181  loss_mask: 0.6242  loss_rpn_cls: 0.09479  loss_rpn_loc: 0.04216  validation_loss: 1.948  time: 1.4870  data_time: 0.0236  lr: 9.0826e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:09:56 d2.utils.events]: \u001b[0m eta: 3:20:23  iter: 1979  total_loss: 2.105  loss_cls_stage0: 0.3419  loss_box_reg_stage0: 0.186  loss_cls_stage1: 0.2632  loss_box_reg_stage1: 0.2132  loss_cls_stage2: 0.1764  loss_box_reg_stage2: 0.1381  loss_mask: 0.6003  loss_rpn_cls: 0.111  loss_rpn_loc: 0.04035  validation_loss: 1.948  time: 1.4873  data_time: 0.0240  lr: 9.0644e-05  max_mem: 11973M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/26 22:10:28 d2.data.common]: \u001b[0mSerializing 879 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/26 22:10:28 d2.data.common]: \u001b[0mSerialized dataset takes 0.90 MiB\n",
      "\u001b[32m[03/26 22:10:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 879 images\n",
      "\u001b[32m[03/26 22:10:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/879. 0.0782 s / img. ETA=0:01:15\n",
      "\u001b[32m[03/26 22:10:34 d2.evaluation.evaluator]: \u001b[0mInference done 69/879. 0.0781 s / img. ETA=0:01:10\n",
      "\u001b[32m[03/26 22:10:39 d2.evaluation.evaluator]: \u001b[0mInference done 128/879. 0.0780 s / img. ETA=0:01:04\n",
      "\u001b[32m[03/26 22:10:45 d2.evaluation.evaluator]: \u001b[0mInference done 187/879. 0.0780 s / img. ETA=0:00:59\n",
      "\u001b[32m[03/26 22:10:50 d2.evaluation.evaluator]: \u001b[0mInference done 246/879. 0.0780 s / img. ETA=0:00:54\n",
      "\u001b[32m[03/26 22:10:55 d2.evaluation.evaluator]: \u001b[0mInference done 303/879. 0.0781 s / img. ETA=0:00:49\n",
      "\u001b[32m[03/26 22:11:00 d2.evaluation.evaluator]: \u001b[0mInference done 362/879. 0.0781 s / img. ETA=0:00:44\n",
      "\u001b[32m[03/26 22:11:05 d2.evaluation.evaluator]: \u001b[0mInference done 420/879. 0.0781 s / img. ETA=0:00:39\n",
      "\u001b[32m[03/26 22:11:10 d2.evaluation.evaluator]: \u001b[0mInference done 478/879. 0.0782 s / img. ETA=0:00:34\n",
      "\u001b[32m[03/26 22:11:15 d2.evaluation.evaluator]: \u001b[0mInference done 536/879. 0.0782 s / img. ETA=0:00:29\n",
      "\u001b[32m[03/26 22:11:20 d2.evaluation.evaluator]: \u001b[0mInference done 594/879. 0.0782 s / img. ETA=0:00:24\n",
      "\u001b[32m[03/26 22:11:25 d2.evaluation.evaluator]: \u001b[0mInference done 653/879. 0.0782 s / img. ETA=0:00:19\n",
      "\u001b[32m[03/26 22:11:30 d2.evaluation.evaluator]: \u001b[0mInference done 711/879. 0.0782 s / img. ETA=0:00:14\n",
      "\u001b[32m[03/26 22:11:35 d2.evaluation.evaluator]: \u001b[0mInference done 769/879. 0.0782 s / img. ETA=0:00:09\n",
      "\u001b[32m[03/26 22:11:40 d2.evaluation.evaluator]: \u001b[0mInference done 827/879. 0.0782 s / img. ETA=0:00:04\n",
      "\u001b[32m[03/26 22:11:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:15.819478 (0.086750 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/26 22:11:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:08 (0.078203 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.37 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.030\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.057\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.061\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.018\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.031\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.048\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.048\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.029\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.049\n",
      "\u001b[32m[03/26 22:11:45 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold3 in csv format:\n",
      "\u001b[32m[03/26 22:11:45 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/26 22:11:45 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/26 22:11:45 d2.evaluation.testing]: \u001b[0mcopypaste: 2.9662,5.7482,6.0933,0.0000,1.7635,3.1114\n",
      "validation do loss eval 1.9782228005668032\n",
      "\u001b[32m[03/26 22:13:14 d2.utils.events]: \u001b[0m eta: 3:19:54  iter: 1999  total_loss: 1.942  loss_cls_stage0: 0.3063  loss_box_reg_stage0: 0.1615  loss_cls_stage1: 0.2574  loss_box_reg_stage1: 0.1933  loss_cls_stage2: 0.1822  loss_box_reg_stage2: 0.1422  loss_mask: 0.5679  loss_rpn_cls: 0.1083  loss_rpn_loc: 0.04032  validation_loss: 1.963  time: 1.4875  data_time: 0.0238  lr: 9.046e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:13:44 d2.utils.events]: \u001b[0m eta: 3:19:24  iter: 2019  total_loss: 1.955  loss_cls_stage0: 0.3099  loss_box_reg_stage0: 0.1674  loss_cls_stage1: 0.2468  loss_box_reg_stage1: 0.1988  loss_cls_stage2: 0.1753  loss_box_reg_stage2: 0.1328  loss_mask: 0.6166  loss_rpn_cls: 0.09349  loss_rpn_loc: 0.03679  validation_loss: 1.963  time: 1.4874  data_time: 0.0245  lr: 9.0275e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:14:14 d2.utils.events]: \u001b[0m eta: 3:18:54  iter: 2039  total_loss: 1.801  loss_cls_stage0: 0.2724  loss_box_reg_stage0: 0.137  loss_cls_stage1: 0.2322  loss_box_reg_stage1: 0.1718  loss_cls_stage2: 0.1679  loss_box_reg_stage2: 0.1266  loss_mask: 0.5901  loss_rpn_cls: 0.09402  loss_rpn_loc: 0.03666  validation_loss: 1.963  time: 1.4876  data_time: 0.0232  lr: 9.0088e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:14:44 d2.utils.events]: \u001b[0m eta: 3:18:25  iter: 2059  total_loss: 1.853  loss_cls_stage0: 0.3204  loss_box_reg_stage0: 0.1708  loss_cls_stage1: 0.2289  loss_box_reg_stage1: 0.1818  loss_cls_stage2: 0.1546  loss_box_reg_stage2: 0.127  loss_mask: 0.5458  loss_rpn_cls: 0.1035  loss_rpn_loc: 0.03606  validation_loss: 1.963  time: 1.4878  data_time: 0.0241  lr: 8.9899e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:15:14 d2.utils.events]: \u001b[0m eta: 3:17:55  iter: 2079  total_loss: 1.749  loss_cls_stage0: 0.2547  loss_box_reg_stage0: 0.1365  loss_cls_stage1: 0.2127  loss_box_reg_stage1: 0.1685  loss_cls_stage2: 0.1564  loss_box_reg_stage2: 0.1168  loss_mask: 0.6059  loss_rpn_cls: 0.09279  loss_rpn_loc: 0.03331  validation_loss: 1.963  time: 1.4880  data_time: 0.0239  lr: 8.9709e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:15:45 d2.utils.events]: \u001b[0m eta: 3:17:26  iter: 2099  total_loss: 2.007  loss_cls_stage0: 0.3135  loss_box_reg_stage0: 0.1623  loss_cls_stage1: 0.2479  loss_box_reg_stage1: 0.1997  loss_cls_stage2: 0.1904  loss_box_reg_stage2: 0.1471  loss_mask: 0.6125  loss_rpn_cls: 0.1174  loss_rpn_loc: 0.04218  validation_loss: 1.963  time: 1.4882  data_time: 0.0231  lr: 8.9517e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:16:15 d2.utils.events]: \u001b[0m eta: 3:16:57  iter: 2119  total_loss: 1.848  loss_cls_stage0: 0.2912  loss_box_reg_stage0: 0.1569  loss_cls_stage1: 0.2319  loss_box_reg_stage1: 0.1868  loss_cls_stage2: 0.1657  loss_box_reg_stage2: 0.1331  loss_mask: 0.5274  loss_rpn_cls: 0.1047  loss_rpn_loc: 0.03994  validation_loss: 1.963  time: 1.4884  data_time: 0.0229  lr: 8.9324e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:16:45 d2.utils.events]: \u001b[0m eta: 3:16:29  iter: 2139  total_loss: 1.902  loss_cls_stage0: 0.2898  loss_box_reg_stage0: 0.1606  loss_cls_stage1: 0.2296  loss_box_reg_stage1: 0.184  loss_cls_stage2: 0.1715  loss_box_reg_stage2: 0.1323  loss_mask: 0.5809  loss_rpn_cls: 0.09459  loss_rpn_loc: 0.03633  validation_loss: 1.963  time: 1.4886  data_time: 0.0237  lr: 8.9129e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:17:15 d2.utils.events]: \u001b[0m eta: 3:16:01  iter: 2159  total_loss: 1.918  loss_cls_stage0: 0.2961  loss_box_reg_stage0: 0.1508  loss_cls_stage1: 0.2448  loss_box_reg_stage1: 0.1977  loss_cls_stage2: 0.1768  loss_box_reg_stage2: 0.1297  loss_mask: 0.5513  loss_rpn_cls: 0.1148  loss_rpn_loc: 0.04035  validation_loss: 1.963  time: 1.4888  data_time: 0.0229  lr: 8.8933e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:17:45 d2.utils.events]: \u001b[0m eta: 3:15:32  iter: 2179  total_loss: 1.872  loss_cls_stage0: 0.2777  loss_box_reg_stage0: 0.1548  loss_cls_stage1: 0.2154  loss_box_reg_stage1: 0.1773  loss_cls_stage2: 0.153  loss_box_reg_stage2: 0.1268  loss_mask: 0.5648  loss_rpn_cls: 0.09757  loss_rpn_loc: 0.03659  validation_loss: 1.963  time: 1.4889  data_time: 0.0242  lr: 8.8735e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:18:16 d2.utils.events]: \u001b[0m eta: 3:15:03  iter: 2199  total_loss: 1.988  loss_cls_stage0: 0.3045  loss_box_reg_stage0: 0.1708  loss_cls_stage1: 0.2501  loss_box_reg_stage1: 0.2109  loss_cls_stage2: 0.1778  loss_box_reg_stage2: 0.1349  loss_mask: 0.5745  loss_rpn_cls: 0.1054  loss_rpn_loc: 0.04163  validation_loss: 1.963  time: 1.4891  data_time: 0.0245  lr: 8.8536e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:18:46 d2.utils.events]: \u001b[0m eta: 3:14:38  iter: 2219  total_loss: 2.004  loss_cls_stage0: 0.3072  loss_box_reg_stage0: 0.1747  loss_cls_stage1: 0.2442  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.1686  loss_box_reg_stage2: 0.131  loss_mask: 0.6401  loss_rpn_cls: 0.101  loss_rpn_loc: 0.04187  validation_loss: 1.963  time: 1.4893  data_time: 0.0245  lr: 8.8335e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:19:16 d2.utils.events]: \u001b[0m eta: 3:14:08  iter: 2239  total_loss: 1.911  loss_cls_stage0: 0.2831  loss_box_reg_stage0: 0.1542  loss_cls_stage1: 0.2352  loss_box_reg_stage1: 0.1903  loss_cls_stage2: 0.1732  loss_box_reg_stage2: 0.1337  loss_mask: 0.5992  loss_rpn_cls: 0.08938  loss_rpn_loc: 0.03104  validation_loss: 1.963  time: 1.4894  data_time: 0.0247  lr: 8.8132e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:19:46 d2.utils.events]: \u001b[0m eta: 3:13:37  iter: 2259  total_loss: 1.806  loss_cls_stage0: 0.2475  loss_box_reg_stage0: 0.139  loss_cls_stage1: 0.2084  loss_box_reg_stage1: 0.1763  loss_cls_stage2: 0.1592  loss_box_reg_stage2: 0.1257  loss_mask: 0.6109  loss_rpn_cls: 0.1051  loss_rpn_loc: 0.03547  validation_loss: 1.963  time: 1.4896  data_time: 0.0244  lr: 8.7928e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:20:16 d2.utils.events]: \u001b[0m eta: 3:13:09  iter: 2279  total_loss: 2.007  loss_cls_stage0: 0.3148  loss_box_reg_stage0: 0.1805  loss_cls_stage1: 0.245  loss_box_reg_stage1: 0.1899  loss_cls_stage2: 0.1722  loss_box_reg_stage2: 0.129  loss_mask: 0.6097  loss_rpn_cls: 0.105  loss_rpn_loc: 0.04179  validation_loss: 1.963  time: 1.4897  data_time: 0.0233  lr: 8.7723e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:20:46 d2.utils.events]: \u001b[0m eta: 3:12:39  iter: 2299  total_loss: 1.931  loss_cls_stage0: 0.292  loss_box_reg_stage0: 0.1667  loss_cls_stage1: 0.2327  loss_box_reg_stage1: 0.1856  loss_cls_stage2: 0.1729  loss_box_reg_stage2: 0.1411  loss_mask: 0.5836  loss_rpn_cls: 0.09459  loss_rpn_loc: 0.0375  validation_loss: 1.963  time: 1.4899  data_time: 0.0235  lr: 8.7516e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:21:16 d2.utils.events]: \u001b[0m eta: 3:12:10  iter: 2319  total_loss: 1.898  loss_cls_stage0: 0.2781  loss_box_reg_stage0: 0.1536  loss_cls_stage1: 0.2189  loss_box_reg_stage1: 0.1847  loss_cls_stage2: 0.1633  loss_box_reg_stage2: 0.1274  loss_mask: 0.5798  loss_rpn_cls: 0.1055  loss_rpn_loc: 0.04122  validation_loss: 1.963  time: 1.4901  data_time: 0.0237  lr: 8.7308e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:21:47 d2.utils.events]: \u001b[0m eta: 3:11:41  iter: 2339  total_loss: 1.918  loss_cls_stage0: 0.2845  loss_box_reg_stage0: 0.1531  loss_cls_stage1: 0.2318  loss_box_reg_stage1: 0.1902  loss_cls_stage2: 0.1655  loss_box_reg_stage2: 0.1309  loss_mask: 0.5839  loss_rpn_cls: 0.1092  loss_rpn_loc: 0.041  validation_loss: 1.963  time: 1.4903  data_time: 0.0244  lr: 8.7098e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:22:17 d2.utils.events]: \u001b[0m eta: 3:11:12  iter: 2359  total_loss: 1.99  loss_cls_stage0: 0.3036  loss_box_reg_stage0: 0.1735  loss_cls_stage1: 0.2473  loss_box_reg_stage1: 0.2005  loss_cls_stage2: 0.1705  loss_box_reg_stage2: 0.1395  loss_mask: 0.5931  loss_rpn_cls: 0.0963  loss_rpn_loc: 0.03626  validation_loss: 1.963  time: 1.4904  data_time: 0.0231  lr: 8.6886e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:22:47 d2.utils.events]: \u001b[0m eta: 3:10:48  iter: 2379  total_loss: 1.984  loss_cls_stage0: 0.3226  loss_box_reg_stage0: 0.185  loss_cls_stage1: 0.2509  loss_box_reg_stage1: 0.1956  loss_cls_stage2: 0.1752  loss_box_reg_stage2: 0.1433  loss_mask: 0.6031  loss_rpn_cls: 0.0963  loss_rpn_loc: 0.03864  validation_loss: 1.963  time: 1.4907  data_time: 0.0250  lr: 8.6673e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:23:18 d2.utils.events]: \u001b[0m eta: 3:10:19  iter: 2399  total_loss: 1.951  loss_cls_stage0: 0.3039  loss_box_reg_stage0: 0.1705  loss_cls_stage1: 0.2567  loss_box_reg_stage1: 0.2143  loss_cls_stage2: 0.1781  loss_box_reg_stage2: 0.1505  loss_mask: 0.5562  loss_rpn_cls: 0.1003  loss_rpn_loc: 0.03801  validation_loss: 1.963  time: 1.4909  data_time: 0.0254  lr: 8.6459e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:23:48 d2.utils.events]: \u001b[0m eta: 3:09:52  iter: 2419  total_loss: 2.067  loss_cls_stage0: 0.3265  loss_box_reg_stage0: 0.2005  loss_cls_stage1: 0.2542  loss_box_reg_stage1: 0.2146  loss_cls_stage2: 0.177  loss_box_reg_stage2: 0.1437  loss_mask: 0.556  loss_rpn_cls: 0.1017  loss_rpn_loc: 0.04494  validation_loss: 1.963  time: 1.4911  data_time: 0.0240  lr: 8.6243e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:24:18 d2.utils.events]: \u001b[0m eta: 3:09:23  iter: 2439  total_loss: 1.772  loss_cls_stage0: 0.2658  loss_box_reg_stage0: 0.1556  loss_cls_stage1: 0.2128  loss_box_reg_stage1: 0.1842  loss_cls_stage2: 0.1494  loss_box_reg_stage2: 0.1289  loss_mask: 0.6185  loss_rpn_cls: 0.08417  loss_rpn_loc: 0.0305  validation_loss: 1.963  time: 1.4912  data_time: 0.0237  lr: 8.6026e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:24:48 d2.utils.events]: \u001b[0m eta: 3:08:53  iter: 2459  total_loss: 1.901  loss_cls_stage0: 0.2829  loss_box_reg_stage0: 0.1655  loss_cls_stage1: 0.229  loss_box_reg_stage1: 0.1959  loss_cls_stage2: 0.1686  loss_box_reg_stage2: 0.1403  loss_mask: 0.5544  loss_rpn_cls: 0.1073  loss_rpn_loc: 0.04063  validation_loss: 1.963  time: 1.4914  data_time: 0.0237  lr: 8.5808e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:25:19 d2.utils.events]: \u001b[0m eta: 3:08:24  iter: 2479  total_loss: 1.934  loss_cls_stage0: 0.2767  loss_box_reg_stage0: 0.1634  loss_cls_stage1: 0.2271  loss_box_reg_stage1: 0.1973  loss_cls_stage2: 0.1672  loss_box_reg_stage2: 0.1555  loss_mask: 0.6095  loss_rpn_cls: 0.0907  loss_rpn_loc: 0.03667  validation_loss: 1.963  time: 1.4915  data_time: 0.0224  lr: 8.5588e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:25:49 d2.utils.events]: \u001b[0m eta: 3:07:57  iter: 2499  total_loss: 1.837  loss_cls_stage0: 0.2939  loss_box_reg_stage0: 0.1766  loss_cls_stage1: 0.2261  loss_box_reg_stage1: 0.1899  loss_cls_stage2: 0.1602  loss_box_reg_stage2: 0.1403  loss_mask: 0.5886  loss_rpn_cls: 0.08496  loss_rpn_loc: 0.0343  validation_loss: 1.963  time: 1.4917  data_time: 0.0227  lr: 8.5366e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:26:19 d2.utils.events]: \u001b[0m eta: 3:07:27  iter: 2519  total_loss: 1.975  loss_cls_stage0: 0.3015  loss_box_reg_stage0: 0.1779  loss_cls_stage1: 0.2266  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.1607  loss_box_reg_stage2: 0.1341  loss_mask: 0.5876  loss_rpn_cls: 0.1133  loss_rpn_loc: 0.04148  validation_loss: 1.963  time: 1.4919  data_time: 0.0242  lr: 8.5144e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:26:49 d2.utils.events]: \u001b[0m eta: 3:06:57  iter: 2539  total_loss: 1.804  loss_cls_stage0: 0.2818  loss_box_reg_stage0: 0.1658  loss_cls_stage1: 0.2114  loss_box_reg_stage1: 0.1794  loss_cls_stage2: 0.1526  loss_box_reg_stage2: 0.1268  loss_mask: 0.5571  loss_rpn_cls: 0.09988  loss_rpn_loc: 0.04001  validation_loss: 1.963  time: 1.4920  data_time: 0.0237  lr: 8.492e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:27:20 d2.utils.events]: \u001b[0m eta: 3:06:27  iter: 2559  total_loss: 1.886  loss_cls_stage0: 0.2698  loss_box_reg_stage0: 0.1614  loss_cls_stage1: 0.2204  loss_box_reg_stage1: 0.212  loss_cls_stage2: 0.1664  loss_box_reg_stage2: 0.1555  loss_mask: 0.5793  loss_rpn_cls: 0.09299  loss_rpn_loc: 0.03743  validation_loss: 1.963  time: 1.4922  data_time: 0.0245  lr: 8.4694e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:27:50 d2.utils.events]: \u001b[0m eta: 3:05:59  iter: 2579  total_loss: 1.877  loss_cls_stage0: 0.2815  loss_box_reg_stage0: 0.1676  loss_cls_stage1: 0.214  loss_box_reg_stage1: 0.2047  loss_cls_stage2: 0.1559  loss_box_reg_stage2: 0.1438  loss_mask: 0.5669  loss_rpn_cls: 0.08931  loss_rpn_loc: 0.03742  validation_loss: 1.963  time: 1.4924  data_time: 0.0241  lr: 8.4467e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:28:20 d2.utils.events]: \u001b[0m eta: 3:05:30  iter: 2599  total_loss: 1.922  loss_cls_stage0: 0.2982  loss_box_reg_stage0: 0.173  loss_cls_stage1: 0.2293  loss_box_reg_stage1: 0.2107  loss_cls_stage2: 0.1616  loss_box_reg_stage2: 0.1391  loss_mask: 0.5483  loss_rpn_cls: 0.08978  loss_rpn_loc: 0.03521  validation_loss: 1.963  time: 1.4925  data_time: 0.0250  lr: 8.4239e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:28:51 d2.utils.events]: \u001b[0m eta: 3:05:02  iter: 2619  total_loss: 1.83  loss_cls_stage0: 0.2747  loss_box_reg_stage0: 0.1553  loss_cls_stage1: 0.2018  loss_box_reg_stage1: 0.1744  loss_cls_stage2: 0.1619  loss_box_reg_stage2: 0.1421  loss_mask: 0.5809  loss_rpn_cls: 0.09483  loss_rpn_loc: 0.03628  validation_loss: 1.963  time: 1.4927  data_time: 0.0239  lr: 8.4009e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:29:21 d2.utils.events]: \u001b[0m eta: 3:04:32  iter: 2639  total_loss: 1.786  loss_cls_stage0: 0.2615  loss_box_reg_stage0: 0.1488  loss_cls_stage1: 0.2045  loss_box_reg_stage1: 0.1841  loss_cls_stage2: 0.1488  loss_box_reg_stage2: 0.1391  loss_mask: 0.5783  loss_rpn_cls: 0.08819  loss_rpn_loc: 0.0337  validation_loss: 1.963  time: 1.4927  data_time: 0.0233  lr: 8.3778e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:29:51 d2.utils.events]: \u001b[0m eta: 3:04:03  iter: 2659  total_loss: 1.833  loss_cls_stage0: 0.2822  loss_box_reg_stage0: 0.1717  loss_cls_stage1: 0.2185  loss_box_reg_stage1: 0.2074  loss_cls_stage2: 0.1568  loss_box_reg_stage2: 0.142  loss_mask: 0.5721  loss_rpn_cls: 0.09716  loss_rpn_loc: 0.04058  validation_loss: 1.963  time: 1.4929  data_time: 0.0221  lr: 8.3546e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:30:21 d2.utils.events]: \u001b[0m eta: 3:03:34  iter: 2679  total_loss: 1.933  loss_cls_stage0: 0.2829  loss_box_reg_stage0: 0.1648  loss_cls_stage1: 0.2363  loss_box_reg_stage1: 0.2004  loss_cls_stage2: 0.1698  loss_box_reg_stage2: 0.1391  loss_mask: 0.604  loss_rpn_cls: 0.09487  loss_rpn_loc: 0.04229  validation_loss: 1.963  time: 1.4930  data_time: 0.0230  lr: 8.3312e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:30:52 d2.utils.events]: \u001b[0m eta: 3:03:05  iter: 2699  total_loss: 2.097  loss_cls_stage0: 0.3114  loss_box_reg_stage0: 0.1763  loss_cls_stage1: 0.2539  loss_box_reg_stage1: 0.2351  loss_cls_stage2: 0.1871  loss_box_reg_stage2: 0.1664  loss_mask: 0.587  loss_rpn_cls: 0.08925  loss_rpn_loc: 0.03728  validation_loss: 1.963  time: 1.4933  data_time: 0.0243  lr: 8.3077e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:31:22 d2.utils.events]: \u001b[0m eta: 3:02:36  iter: 2719  total_loss: 1.824  loss_cls_stage0: 0.2767  loss_box_reg_stage0: 0.1676  loss_cls_stage1: 0.2098  loss_box_reg_stage1: 0.2035  loss_cls_stage2: 0.1498  loss_box_reg_stage2: 0.1493  loss_mask: 0.5656  loss_rpn_cls: 0.09404  loss_rpn_loc: 0.03961  validation_loss: 1.963  time: 1.4934  data_time: 0.0249  lr: 8.2841e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:31:52 d2.utils.events]: \u001b[0m eta: 3:02:09  iter: 2739  total_loss: 2.021  loss_cls_stage0: 0.2885  loss_box_reg_stage0: 0.1714  loss_cls_stage1: 0.2342  loss_box_reg_stage1: 0.2077  loss_cls_stage2: 0.1775  loss_box_reg_stage2: 0.1666  loss_mask: 0.5428  loss_rpn_cls: 0.1097  loss_rpn_loc: 0.04012  validation_loss: 1.963  time: 1.4935  data_time: 0.0232  lr: 8.2604e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:32:22 d2.utils.events]: \u001b[0m eta: 3:01:40  iter: 2759  total_loss: 1.864  loss_cls_stage0: 0.2664  loss_box_reg_stage0: 0.171  loss_cls_stage1: 0.2167  loss_box_reg_stage1: 0.2055  loss_cls_stage2: 0.1571  loss_box_reg_stage2: 0.138  loss_mask: 0.595  loss_rpn_cls: 0.09196  loss_rpn_loc: 0.03317  validation_loss: 1.963  time: 1.4937  data_time: 0.0239  lr: 8.2365e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:32:53 d2.utils.events]: \u001b[0m eta: 3:01:13  iter: 2779  total_loss: 2.031  loss_cls_stage0: 0.2991  loss_box_reg_stage0: 0.1788  loss_cls_stage1: 0.2375  loss_box_reg_stage1: 0.2204  loss_cls_stage2: 0.1708  loss_box_reg_stage2: 0.1455  loss_mask: 0.5273  loss_rpn_cls: 0.09149  loss_rpn_loc: 0.03783  validation_loss: 1.963  time: 1.4939  data_time: 0.0238  lr: 8.2125e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:33:23 d2.utils.events]: \u001b[0m eta: 3:00:43  iter: 2799  total_loss: 1.946  loss_cls_stage0: 0.3007  loss_box_reg_stage0: 0.1761  loss_cls_stage1: 0.2289  loss_box_reg_stage1: 0.2089  loss_cls_stage2: 0.161  loss_box_reg_stage2: 0.1456  loss_mask: 0.5905  loss_rpn_cls: 0.09006  loss_rpn_loc: 0.04161  validation_loss: 1.963  time: 1.4940  data_time: 0.0235  lr: 8.1883e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:33:53 d2.utils.events]: \u001b[0m eta: 3:00:13  iter: 2819  total_loss: 1.849  loss_cls_stage0: 0.2724  loss_box_reg_stage0: 0.1664  loss_cls_stage1: 0.218  loss_box_reg_stage1: 0.1897  loss_cls_stage2: 0.1502  loss_box_reg_stage2: 0.1455  loss_mask: 0.5372  loss_rpn_cls: 0.08774  loss_rpn_loc: 0.03553  validation_loss: 1.963  time: 1.4942  data_time: 0.0242  lr: 8.1641e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:34:24 d2.utils.events]: \u001b[0m eta: 2:59:45  iter: 2839  total_loss: 2.099  loss_cls_stage0: 0.3237  loss_box_reg_stage0: 0.2016  loss_cls_stage1: 0.2604  loss_box_reg_stage1: 0.2358  loss_cls_stage2: 0.1701  loss_box_reg_stage2: 0.1731  loss_mask: 0.577  loss_rpn_cls: 0.07971  loss_rpn_loc: 0.04096  validation_loss: 1.963  time: 1.4944  data_time: 0.0243  lr: 8.1397e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:34:54 d2.utils.events]: \u001b[0m eta: 2:59:17  iter: 2859  total_loss: 1.805  loss_cls_stage0: 0.2734  loss_box_reg_stage0: 0.1552  loss_cls_stage1: 0.2155  loss_box_reg_stage1: 0.2007  loss_cls_stage2: 0.1524  loss_box_reg_stage2: 0.1526  loss_mask: 0.5815  loss_rpn_cls: 0.08911  loss_rpn_loc: 0.03395  validation_loss: 1.963  time: 1.4946  data_time: 0.0235  lr: 8.1152e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:35:24 d2.utils.events]: \u001b[0m eta: 2:58:49  iter: 2879  total_loss: 1.856  loss_cls_stage0: 0.2588  loss_box_reg_stage0: 0.1702  loss_cls_stage1: 0.1956  loss_box_reg_stage1: 0.1994  loss_cls_stage2: 0.1424  loss_box_reg_stage2: 0.1359  loss_mask: 0.5381  loss_rpn_cls: 0.08392  loss_rpn_loc: 0.03411  validation_loss: 1.963  time: 1.4946  data_time: 0.0247  lr: 8.0905e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:35:55 d2.utils.events]: \u001b[0m eta: 2:58:22  iter: 2899  total_loss: 2.067  loss_cls_stage0: 0.3214  loss_box_reg_stage0: 0.1955  loss_cls_stage1: 0.2547  loss_box_reg_stage1: 0.2311  loss_cls_stage2: 0.1753  loss_box_reg_stage2: 0.1747  loss_mask: 0.5927  loss_rpn_cls: 0.09622  loss_rpn_loc: 0.03793  validation_loss: 1.963  time: 1.4949  data_time: 0.0241  lr: 8.0658e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:36:25 d2.utils.events]: \u001b[0m eta: 2:57:54  iter: 2919  total_loss: 2.016  loss_cls_stage0: 0.3076  loss_box_reg_stage0: 0.1804  loss_cls_stage1: 0.2416  loss_box_reg_stage1: 0.2241  loss_cls_stage2: 0.1688  loss_box_reg_stage2: 0.1672  loss_mask: 0.5393  loss_rpn_cls: 0.1106  loss_rpn_loc: 0.04224  validation_loss: 1.963  time: 1.4950  data_time: 0.0229  lr: 8.0409e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:36:56 d2.utils.events]: \u001b[0m eta: 2:57:27  iter: 2939  total_loss: 1.974  loss_cls_stage0: 0.3113  loss_box_reg_stage0: 0.1931  loss_cls_stage1: 0.2465  loss_box_reg_stage1: 0.2181  loss_cls_stage2: 0.1819  loss_box_reg_stage2: 0.1687  loss_mask: 0.5734  loss_rpn_cls: 0.09489  loss_rpn_loc: 0.03845  validation_loss: 1.963  time: 1.4952  data_time: 0.0235  lr: 8.0159e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:37:26 d2.utils.events]: \u001b[0m eta: 2:56:59  iter: 2959  total_loss: 1.873  loss_cls_stage0: 0.2744  loss_box_reg_stage0: 0.1734  loss_cls_stage1: 0.2235  loss_box_reg_stage1: 0.2174  loss_cls_stage2: 0.1655  loss_box_reg_stage2: 0.1697  loss_mask: 0.5642  loss_rpn_cls: 0.08989  loss_rpn_loc: 0.03629  validation_loss: 1.963  time: 1.4954  data_time: 0.0214  lr: 7.9908e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:37:57 d2.utils.events]: \u001b[0m eta: 2:56:29  iter: 2979  total_loss: 1.956  loss_cls_stage0: 0.2868  loss_box_reg_stage0: 0.1798  loss_cls_stage1: 0.2241  loss_box_reg_stage1: 0.2184  loss_cls_stage2: 0.1775  loss_box_reg_stage2: 0.1836  loss_mask: 0.538  loss_rpn_cls: 0.08968  loss_rpn_loc: 0.04142  validation_loss: 1.963  time: 1.4955  data_time: 0.0241  lr: 7.9655e-05  max_mem: 11973M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/26 22:38:29 d2.data.common]: \u001b[0mSerializing 879 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/26 22:38:29 d2.data.common]: \u001b[0mSerialized dataset takes 0.90 MiB\n",
      "\u001b[32m[03/26 22:38:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 879 images\n",
      "\u001b[32m[03/26 22:38:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/879. 0.0809 s / img. ETA=0:01:40\n",
      "\u001b[32m[03/26 22:38:36 d2.evaluation.evaluator]: \u001b[0mInference done 57/879. 0.0803 s / img. ETA=0:01:31\n",
      "\u001b[32m[03/26 22:38:41 d2.evaluation.evaluator]: \u001b[0mInference done 102/879. 0.0803 s / img. ETA=0:01:26\n",
      "\u001b[32m[03/26 22:38:46 d2.evaluation.evaluator]: \u001b[0mInference done 146/879. 0.0804 s / img. ETA=0:01:22\n",
      "\u001b[32m[03/26 22:38:51 d2.evaluation.evaluator]: \u001b[0mInference done 193/879. 0.0802 s / img. ETA=0:01:16\n",
      "\u001b[32m[03/26 22:38:56 d2.evaluation.evaluator]: \u001b[0mInference done 238/879. 0.0802 s / img. ETA=0:01:11\n",
      "\u001b[32m[03/26 22:39:01 d2.evaluation.evaluator]: \u001b[0mInference done 284/879. 0.0801 s / img. ETA=0:01:06\n",
      "\u001b[32m[03/26 22:39:06 d2.evaluation.evaluator]: \u001b[0mInference done 329/879. 0.0801 s / img. ETA=0:01:01\n",
      "\u001b[32m[03/26 22:39:11 d2.evaluation.evaluator]: \u001b[0mInference done 375/879. 0.0801 s / img. ETA=0:00:56\n",
      "\u001b[32m[03/26 22:39:16 d2.evaluation.evaluator]: \u001b[0mInference done 422/879. 0.0801 s / img. ETA=0:00:50\n",
      "\u001b[32m[03/26 22:39:22 d2.evaluation.evaluator]: \u001b[0mInference done 468/879. 0.0801 s / img. ETA=0:00:45\n",
      "\u001b[32m[03/26 22:39:27 d2.evaluation.evaluator]: \u001b[0mInference done 514/879. 0.0800 s / img. ETA=0:00:40\n",
      "\u001b[32m[03/26 22:39:32 d2.evaluation.evaluator]: \u001b[0mInference done 559/879. 0.0800 s / img. ETA=0:00:35\n",
      "\u001b[32m[03/26 22:39:37 d2.evaluation.evaluator]: \u001b[0mInference done 606/879. 0.0800 s / img. ETA=0:00:30\n",
      "\u001b[32m[03/26 22:39:42 d2.evaluation.evaluator]: \u001b[0mInference done 652/879. 0.0800 s / img. ETA=0:00:25\n",
      "\u001b[32m[03/26 22:39:47 d2.evaluation.evaluator]: \u001b[0mInference done 697/879. 0.0800 s / img. ETA=0:00:20\n",
      "\u001b[32m[03/26 22:39:52 d2.evaluation.evaluator]: \u001b[0mInference done 741/879. 0.0800 s / img. ETA=0:00:15\n",
      "\u001b[32m[03/26 22:39:57 d2.evaluation.evaluator]: \u001b[0mInference done 787/879. 0.0800 s / img. ETA=0:00:10\n",
      "\u001b[32m[03/26 22:40:02 d2.evaluation.evaluator]: \u001b[0mInference done 833/879. 0.0800 s / img. ETA=0:00:05\n",
      "\u001b[32m[03/26 22:40:07 d2.evaluation.evaluator]: \u001b[0mInference done 879/879. 0.0800 s / img. ETA=0:00:00\n",
      "\u001b[32m[03/26 22:40:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:36.885434 (0.110853 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/26 22:40:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:09 (0.080020 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.42 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.054\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.094\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.097\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.029\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.055\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.079\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.088\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.088\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.037\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.090\n",
      "\u001b[32m[03/26 22:40:08 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold3 in csv format:\n",
      "\u001b[32m[03/26 22:40:08 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/26 22:40:08 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/26 22:40:08 d2.evaluation.testing]: \u001b[0mcopypaste: 5.4308,9.3551,9.6654,0.0774,2.8780,5.4734\n",
      "validation do loss eval 2.059828476339713\n",
      "\u001b[32m[03/26 22:41:37 d2.utils.events]: \u001b[0m eta: 2:56:00  iter: 2999  total_loss: 1.944  loss_cls_stage0: 0.2889  loss_box_reg_stage0: 0.1695  loss_cls_stage1: 0.2295  loss_box_reg_stage1: 0.2172  loss_cls_stage2: 0.1693  loss_box_reg_stage2: 0.1691  loss_mask: 0.5814  loss_rpn_cls: 0.07965  loss_rpn_loc: 0.03714  validation_loss: 1.978  time: 1.4957  data_time: 0.0223  lr: 7.9402e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:42:07 d2.utils.events]: \u001b[0m eta: 2:55:31  iter: 3019  total_loss: 2.026  loss_cls_stage0: 0.3107  loss_box_reg_stage0: 0.196  loss_cls_stage1: 0.2466  loss_box_reg_stage1: 0.2378  loss_cls_stage2: 0.1611  loss_box_reg_stage2: 0.1709  loss_mask: 0.5807  loss_rpn_cls: 0.08191  loss_rpn_loc: 0.03608  validation_loss: 1.978  time: 1.4957  data_time: 0.0243  lr: 7.9147e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:42:38 d2.utils.events]: \u001b[0m eta: 2:55:03  iter: 3039  total_loss: 1.971  loss_cls_stage0: 0.2924  loss_box_reg_stage0: 0.179  loss_cls_stage1: 0.2392  loss_box_reg_stage1: 0.2226  loss_cls_stage2: 0.1699  loss_box_reg_stage2: 0.1809  loss_mask: 0.5703  loss_rpn_cls: 0.09137  loss_rpn_loc: 0.03812  validation_loss: 1.978  time: 1.4959  data_time: 0.0232  lr: 7.8891e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:43:08 d2.utils.events]: \u001b[0m eta: 2:54:34  iter: 3059  total_loss: 1.88  loss_cls_stage0: 0.2759  loss_box_reg_stage0: 0.1783  loss_cls_stage1: 0.2178  loss_box_reg_stage1: 0.2188  loss_cls_stage2: 0.1428  loss_box_reg_stage2: 0.1625  loss_mask: 0.5785  loss_rpn_cls: 0.07052  loss_rpn_loc: 0.03161  validation_loss: 1.978  time: 1.4960  data_time: 0.0236  lr: 7.8634e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:43:39 d2.utils.events]: \u001b[0m eta: 2:54:10  iter: 3079  total_loss: 2.033  loss_cls_stage0: 0.2992  loss_box_reg_stage0: 0.1911  loss_cls_stage1: 0.2453  loss_box_reg_stage1: 0.2521  loss_cls_stage2: 0.185  loss_box_reg_stage2: 0.1819  loss_mask: 0.5492  loss_rpn_cls: 0.08828  loss_rpn_loc: 0.03871  validation_loss: 1.978  time: 1.4962  data_time: 0.0224  lr: 7.8376e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:44:09 d2.utils.events]: \u001b[0m eta: 2:53:41  iter: 3099  total_loss: 2.069  loss_cls_stage0: 0.2902  loss_box_reg_stage0: 0.185  loss_cls_stage1: 0.2412  loss_box_reg_stage1: 0.2481  loss_cls_stage2: 0.1777  loss_box_reg_stage2: 0.1854  loss_mask: 0.6193  loss_rpn_cls: 0.08878  loss_rpn_loc: 0.04001  validation_loss: 1.978  time: 1.4964  data_time: 0.0246  lr: 7.8117e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:44:40 d2.utils.events]: \u001b[0m eta: 2:53:17  iter: 3119  total_loss: 2.153  loss_cls_stage0: 0.3519  loss_box_reg_stage0: 0.2202  loss_cls_stage1: 0.2683  loss_box_reg_stage1: 0.259  loss_cls_stage2: 0.1932  loss_box_reg_stage2: 0.2015  loss_mask: 0.5659  loss_rpn_cls: 0.08626  loss_rpn_loc: 0.04018  validation_loss: 1.978  time: 1.4967  data_time: 0.0238  lr: 7.7857e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:45:10 d2.utils.events]: \u001b[0m eta: 2:52:47  iter: 3139  total_loss: 1.936  loss_cls_stage0: 0.2939  loss_box_reg_stage0: 0.1686  loss_cls_stage1: 0.2346  loss_box_reg_stage1: 0.2136  loss_cls_stage2: 0.1576  loss_box_reg_stage2: 0.155  loss_mask: 0.5665  loss_rpn_cls: 0.08526  loss_rpn_loc: 0.03752  validation_loss: 1.978  time: 1.4968  data_time: 0.0242  lr: 7.7595e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:45:41 d2.utils.events]: \u001b[0m eta: 2:52:19  iter: 3159  total_loss: 1.873  loss_cls_stage0: 0.2692  loss_box_reg_stage0: 0.1681  loss_cls_stage1: 0.2121  loss_box_reg_stage1: 0.2141  loss_cls_stage2: 0.1511  loss_box_reg_stage2: 0.1668  loss_mask: 0.5735  loss_rpn_cls: 0.0826  loss_rpn_loc: 0.03621  validation_loss: 1.978  time: 1.4970  data_time: 0.0237  lr: 7.7333e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:46:11 d2.utils.events]: \u001b[0m eta: 2:51:50  iter: 3179  total_loss: 2.028  loss_cls_stage0: 0.291  loss_box_reg_stage0: 0.1849  loss_cls_stage1: 0.2414  loss_box_reg_stage1: 0.2473  loss_cls_stage2: 0.1756  loss_box_reg_stage2: 0.1889  loss_mask: 0.5325  loss_rpn_cls: 0.08588  loss_rpn_loc: 0.03916  validation_loss: 1.978  time: 1.4972  data_time: 0.0234  lr: 7.7069e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:46:42 d2.utils.events]: \u001b[0m eta: 2:51:21  iter: 3199  total_loss: 1.997  loss_cls_stage0: 0.2915  loss_box_reg_stage0: 0.1787  loss_cls_stage1: 0.2361  loss_box_reg_stage1: 0.2414  loss_cls_stage2: 0.1662  loss_box_reg_stage2: 0.1699  loss_mask: 0.5428  loss_rpn_cls: 0.08211  loss_rpn_loc: 0.0357  validation_loss: 1.978  time: 1.4973  data_time: 0.0233  lr: 7.6805e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:47:12 d2.utils.events]: \u001b[0m eta: 2:50:52  iter: 3219  total_loss: 1.956  loss_cls_stage0: 0.2826  loss_box_reg_stage0: 0.1749  loss_cls_stage1: 0.2297  loss_box_reg_stage1: 0.2267  loss_cls_stage2: 0.1652  loss_box_reg_stage2: 0.1649  loss_mask: 0.5742  loss_rpn_cls: 0.07689  loss_rpn_loc: 0.03667  validation_loss: 1.978  time: 1.4975  data_time: 0.0241  lr: 7.6539e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:47:43 d2.utils.events]: \u001b[0m eta: 2:50:25  iter: 3239  total_loss: 2.15  loss_cls_stage0: 0.2958  loss_box_reg_stage0: 0.2062  loss_cls_stage1: 0.2498  loss_box_reg_stage1: 0.2644  loss_cls_stage2: 0.1747  loss_box_reg_stage2: 0.1989  loss_mask: 0.5712  loss_rpn_cls: 0.0816  loss_rpn_loc: 0.04206  validation_loss: 1.978  time: 1.4978  data_time: 0.0240  lr: 7.6272e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:48:14 d2.utils.events]: \u001b[0m eta: 2:49:59  iter: 3259  total_loss: 2.058  loss_cls_stage0: 0.317  loss_box_reg_stage0: 0.1893  loss_cls_stage1: 0.2461  loss_box_reg_stage1: 0.2464  loss_cls_stage2: 0.1813  loss_box_reg_stage2: 0.1926  loss_mask: 0.5788  loss_rpn_cls: 0.08449  loss_rpn_loc: 0.03725  validation_loss: 1.978  time: 1.4980  data_time: 0.0226  lr: 7.6004e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:48:44 d2.utils.events]: \u001b[0m eta: 2:49:30  iter: 3279  total_loss: 2.024  loss_cls_stage0: 0.2904  loss_box_reg_stage0: 0.1836  loss_cls_stage1: 0.2427  loss_box_reg_stage1: 0.2448  loss_cls_stage2: 0.1657  loss_box_reg_stage2: 0.1879  loss_mask: 0.5864  loss_rpn_cls: 0.07805  loss_rpn_loc: 0.03632  validation_loss: 1.978  time: 1.4981  data_time: 0.0237  lr: 7.5735e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:49:15 d2.utils.events]: \u001b[0m eta: 2:49:01  iter: 3299  total_loss: 1.857  loss_cls_stage0: 0.2903  loss_box_reg_stage0: 0.1792  loss_cls_stage1: 0.2344  loss_box_reg_stage1: 0.231  loss_cls_stage2: 0.153  loss_box_reg_stage2: 0.1798  loss_mask: 0.5583  loss_rpn_cls: 0.07709  loss_rpn_loc: 0.03905  validation_loss: 1.978  time: 1.4983  data_time: 0.0243  lr: 7.5466e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:49:45 d2.utils.events]: \u001b[0m eta: 2:48:33  iter: 3319  total_loss: 2.094  loss_cls_stage0: 0.3001  loss_box_reg_stage0: 0.1952  loss_cls_stage1: 0.2429  loss_box_reg_stage1: 0.2547  loss_cls_stage2: 0.1925  loss_box_reg_stage2: 0.1934  loss_mask: 0.5426  loss_rpn_cls: 0.092  loss_rpn_loc: 0.03975  validation_loss: 1.978  time: 1.4985  data_time: 0.0245  lr: 7.5195e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:50:16 d2.utils.events]: \u001b[0m eta: 2:48:04  iter: 3339  total_loss: 2.098  loss_cls_stage0: 0.3044  loss_box_reg_stage0: 0.1967  loss_cls_stage1: 0.235  loss_box_reg_stage1: 0.2561  loss_cls_stage2: 0.1775  loss_box_reg_stage2: 0.1786  loss_mask: 0.552  loss_rpn_cls: 0.0938  loss_rpn_loc: 0.04126  validation_loss: 1.978  time: 1.4987  data_time: 0.0232  lr: 7.4923e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:50:46 d2.utils.events]: \u001b[0m eta: 2:47:35  iter: 3359  total_loss: 1.95  loss_cls_stage0: 0.2878  loss_box_reg_stage0: 0.1887  loss_cls_stage1: 0.2387  loss_box_reg_stage1: 0.2208  loss_cls_stage2: 0.168  loss_box_reg_stage2: 0.1759  loss_mask: 0.5929  loss_rpn_cls: 0.07568  loss_rpn_loc: 0.03276  validation_loss: 1.978  time: 1.4988  data_time: 0.0235  lr: 7.465e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:51:17 d2.utils.events]: \u001b[0m eta: 2:47:05  iter: 3379  total_loss: 2.055  loss_cls_stage0: 0.2992  loss_box_reg_stage0: 0.2029  loss_cls_stage1: 0.2286  loss_box_reg_stage1: 0.2533  loss_cls_stage2: 0.165  loss_box_reg_stage2: 0.1762  loss_mask: 0.5723  loss_rpn_cls: 0.0905  loss_rpn_loc: 0.04124  validation_loss: 1.978  time: 1.4989  data_time: 0.0312  lr: 7.4376e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:51:47 d2.utils.events]: \u001b[0m eta: 2:46:35  iter: 3399  total_loss: 2.015  loss_cls_stage0: 0.288  loss_box_reg_stage0: 0.2032  loss_cls_stage1: 0.2256  loss_box_reg_stage1: 0.2414  loss_cls_stage2: 0.1583  loss_box_reg_stage2: 0.1708  loss_mask: 0.5321  loss_rpn_cls: 0.07415  loss_rpn_loc: 0.03372  validation_loss: 1.978  time: 1.4991  data_time: 0.0241  lr: 7.4101e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:52:18 d2.utils.events]: \u001b[0m eta: 2:46:06  iter: 3419  total_loss: 2.132  loss_cls_stage0: 0.3137  loss_box_reg_stage0: 0.2053  loss_cls_stage1: 0.2736  loss_box_reg_stage1: 0.2677  loss_cls_stage2: 0.1926  loss_box_reg_stage2: 0.2001  loss_mask: 0.5599  loss_rpn_cls: 0.07769  loss_rpn_loc: 0.03946  validation_loss: 1.978  time: 1.4993  data_time: 0.0241  lr: 7.3826e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:52:49 d2.utils.events]: \u001b[0m eta: 2:45:39  iter: 3439  total_loss: 2.04  loss_cls_stage0: 0.3114  loss_box_reg_stage0: 0.1936  loss_cls_stage1: 0.2403  loss_box_reg_stage1: 0.245  loss_cls_stage2: 0.1639  loss_box_reg_stage2: 0.1818  loss_mask: 0.5611  loss_rpn_cls: 0.07913  loss_rpn_loc: 0.03589  validation_loss: 1.978  time: 1.4994  data_time: 0.0239  lr: 7.3549e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:53:19 d2.utils.events]: \u001b[0m eta: 2:45:10  iter: 3459  total_loss: 1.901  loss_cls_stage0: 0.2704  loss_box_reg_stage0: 0.1708  loss_cls_stage1: 0.2208  loss_box_reg_stage1: 0.2226  loss_cls_stage2: 0.1561  loss_box_reg_stage2: 0.1805  loss_mask: 0.5926  loss_rpn_cls: 0.08433  loss_rpn_loc: 0.03748  validation_loss: 1.978  time: 1.4995  data_time: 0.0232  lr: 7.3271e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:53:50 d2.utils.events]: \u001b[0m eta: 2:44:43  iter: 3479  total_loss: 2.183  loss_cls_stage0: 0.3417  loss_box_reg_stage0: 0.2319  loss_cls_stage1: 0.2599  loss_box_reg_stage1: 0.2806  loss_cls_stage2: 0.1843  loss_box_reg_stage2: 0.2058  loss_mask: 0.597  loss_rpn_cls: 0.07871  loss_rpn_loc: 0.03893  validation_loss: 1.978  time: 1.4997  data_time: 0.0290  lr: 7.2993e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:54:20 d2.utils.events]: \u001b[0m eta: 2:44:15  iter: 3499  total_loss: 2.074  loss_cls_stage0: 0.3122  loss_box_reg_stage0: 0.2084  loss_cls_stage1: 0.2413  loss_box_reg_stage1: 0.252  loss_cls_stage2: 0.1768  loss_box_reg_stage2: 0.1846  loss_mask: 0.5799  loss_rpn_cls: 0.07646  loss_rpn_loc: 0.03942  validation_loss: 1.978  time: 1.4999  data_time: 0.0233  lr: 7.2714e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:54:51 d2.utils.events]: \u001b[0m eta: 2:43:45  iter: 3519  total_loss: 1.916  loss_cls_stage0: 0.2672  loss_box_reg_stage0: 0.1727  loss_cls_stage1: 0.2129  loss_box_reg_stage1: 0.2136  loss_cls_stage2: 0.1593  loss_box_reg_stage2: 0.1822  loss_mask: 0.6262  loss_rpn_cls: 0.07287  loss_rpn_loc: 0.03167  validation_loss: 1.978  time: 1.5000  data_time: 0.0231  lr: 7.2433e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:55:21 d2.utils.events]: \u001b[0m eta: 2:43:17  iter: 3539  total_loss: 1.832  loss_cls_stage0: 0.2781  loss_box_reg_stage0: 0.1792  loss_cls_stage1: 0.2105  loss_box_reg_stage1: 0.2368  loss_cls_stage2: 0.1599  loss_box_reg_stage2: 0.1913  loss_mask: 0.5605  loss_rpn_cls: 0.07391  loss_rpn_loc: 0.03237  validation_loss: 1.978  time: 1.5001  data_time: 0.0229  lr: 7.2152e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:55:52 d2.utils.events]: \u001b[0m eta: 2:42:48  iter: 3559  total_loss: 2.13  loss_cls_stage0: 0.3037  loss_box_reg_stage0: 0.2  loss_cls_stage1: 0.2551  loss_box_reg_stage1: 0.2861  loss_cls_stage2: 0.1908  loss_box_reg_stage2: 0.2087  loss_mask: 0.5455  loss_rpn_cls: 0.08348  loss_rpn_loc: 0.0409  validation_loss: 1.978  time: 1.5003  data_time: 0.0224  lr: 7.187e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:56:23 d2.utils.events]: \u001b[0m eta: 2:42:22  iter: 3579  total_loss: 2.062  loss_cls_stage0: 0.2946  loss_box_reg_stage0: 0.2045  loss_cls_stage1: 0.2353  loss_box_reg_stage1: 0.2662  loss_cls_stage2: 0.177  loss_box_reg_stage2: 0.2073  loss_mask: 0.569  loss_rpn_cls: 0.08193  loss_rpn_loc: 0.03977  validation_loss: 1.978  time: 1.5005  data_time: 0.0235  lr: 7.1587e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:56:53 d2.utils.events]: \u001b[0m eta: 2:41:54  iter: 3599  total_loss: 2.199  loss_cls_stage0: 0.3086  loss_box_reg_stage0: 0.2089  loss_cls_stage1: 0.2488  loss_box_reg_stage1: 0.2625  loss_cls_stage2: 0.181  loss_box_reg_stage2: 0.205  loss_mask: 0.6167  loss_rpn_cls: 0.07836  loss_rpn_loc: 0.03858  validation_loss: 1.978  time: 1.5007  data_time: 0.0243  lr: 7.1303e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:57:24 d2.utils.events]: \u001b[0m eta: 2:41:28  iter: 3619  total_loss: 1.991  loss_cls_stage0: 0.2935  loss_box_reg_stage0: 0.1837  loss_cls_stage1: 0.2294  loss_box_reg_stage1: 0.2505  loss_cls_stage2: 0.1665  loss_box_reg_stage2: 0.1964  loss_mask: 0.5427  loss_rpn_cls: 0.07634  loss_rpn_loc: 0.03505  validation_loss: 1.978  time: 1.5009  data_time: 0.0244  lr: 7.1019e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:57:54 d2.utils.events]: \u001b[0m eta: 2:41:01  iter: 3639  total_loss: 2.018  loss_cls_stage0: 0.3111  loss_box_reg_stage0: 0.2121  loss_cls_stage1: 0.2474  loss_box_reg_stage1: 0.2581  loss_cls_stage2: 0.1679  loss_box_reg_stage2: 0.2024  loss_mask: 0.529  loss_rpn_cls: 0.07077  loss_rpn_loc: 0.0375  validation_loss: 1.978  time: 1.5010  data_time: 0.0236  lr: 7.0733e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:58:25 d2.utils.events]: \u001b[0m eta: 2:40:35  iter: 3659  total_loss: 2.124  loss_cls_stage0: 0.324  loss_box_reg_stage0: 0.2263  loss_cls_stage1: 0.2544  loss_box_reg_stage1: 0.2676  loss_cls_stage2: 0.1793  loss_box_reg_stage2: 0.2093  loss_mask: 0.5511  loss_rpn_cls: 0.07601  loss_rpn_loc: 0.03756  validation_loss: 1.978  time: 1.5012  data_time: 0.0225  lr: 7.0447e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:58:56 d2.utils.events]: \u001b[0m eta: 2:40:09  iter: 3679  total_loss: 2.106  loss_cls_stage0: 0.3284  loss_box_reg_stage0: 0.2097  loss_cls_stage1: 0.2524  loss_box_reg_stage1: 0.2679  loss_cls_stage2: 0.1777  loss_box_reg_stage2: 0.2017  loss_mask: 0.5907  loss_rpn_cls: 0.08037  loss_rpn_loc: 0.03831  validation_loss: 1.978  time: 1.5014  data_time: 0.0235  lr: 7.016e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:59:26 d2.utils.events]: \u001b[0m eta: 2:39:42  iter: 3699  total_loss: 2.073  loss_cls_stage0: 0.3047  loss_box_reg_stage0: 0.2116  loss_cls_stage1: 0.2341  loss_box_reg_stage1: 0.2595  loss_cls_stage2: 0.1648  loss_box_reg_stage2: 0.1869  loss_mask: 0.5465  loss_rpn_cls: 0.07763  loss_rpn_loc: 0.03896  validation_loss: 1.978  time: 1.5015  data_time: 0.0237  lr: 6.9872e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 22:59:57 d2.utils.events]: \u001b[0m eta: 2:39:14  iter: 3719  total_loss: 2.207  loss_cls_stage0: 0.3498  loss_box_reg_stage0: 0.2334  loss_cls_stage1: 0.2794  loss_box_reg_stage1: 0.2965  loss_cls_stage2: 0.1834  loss_box_reg_stage2: 0.1994  loss_mask: 0.5552  loss_rpn_cls: 0.0792  loss_rpn_loc: 0.03948  validation_loss: 1.978  time: 1.5017  data_time: 0.0308  lr: 6.9583e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:00:28 d2.utils.events]: \u001b[0m eta: 2:38:44  iter: 3739  total_loss: 2.101  loss_cls_stage0: 0.2922  loss_box_reg_stage0: 0.2157  loss_cls_stage1: 0.2262  loss_box_reg_stage1: 0.2821  loss_cls_stage2: 0.1646  loss_box_reg_stage2: 0.2151  loss_mask: 0.5611  loss_rpn_cls: 0.07945  loss_rpn_loc: 0.03754  validation_loss: 1.978  time: 1.5019  data_time: 0.0229  lr: 6.9294e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:00:58 d2.utils.events]: \u001b[0m eta: 2:38:14  iter: 3759  total_loss: 2  loss_cls_stage0: 0.283  loss_box_reg_stage0: 0.1777  loss_cls_stage1: 0.2343  loss_box_reg_stage1: 0.2497  loss_cls_stage2: 0.1693  loss_box_reg_stage2: 0.1841  loss_mask: 0.5736  loss_rpn_cls: 0.07059  loss_rpn_loc: 0.03243  validation_loss: 1.978  time: 1.5020  data_time: 0.0231  lr: 6.9003e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:01:29 d2.utils.events]: \u001b[0m eta: 2:37:47  iter: 3779  total_loss: 2.138  loss_cls_stage0: 0.3203  loss_box_reg_stage0: 0.2186  loss_cls_stage1: 0.257  loss_box_reg_stage1: 0.2651  loss_cls_stage2: 0.18  loss_box_reg_stage2: 0.2144  loss_mask: 0.5273  loss_rpn_cls: 0.07418  loss_rpn_loc: 0.03818  validation_loss: 1.978  time: 1.5022  data_time: 0.0232  lr: 6.8713e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:02:00 d2.utils.events]: \u001b[0m eta: 2:37:22  iter: 3799  total_loss: 2.239  loss_cls_stage0: 0.3281  loss_box_reg_stage0: 0.2272  loss_cls_stage1: 0.2597  loss_box_reg_stage1: 0.2993  loss_cls_stage2: 0.1816  loss_box_reg_stage2: 0.2096  loss_mask: 0.5487  loss_rpn_cls: 0.08381  loss_rpn_loc: 0.03807  validation_loss: 1.978  time: 1.5024  data_time: 0.0231  lr: 6.8421e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:02:31 d2.utils.events]: \u001b[0m eta: 2:36:56  iter: 3819  total_loss: 2.293  loss_cls_stage0: 0.3272  loss_box_reg_stage0: 0.229  loss_cls_stage1: 0.2657  loss_box_reg_stage1: 0.2827  loss_cls_stage2: 0.1818  loss_box_reg_stage2: 0.1946  loss_mask: 0.5899  loss_rpn_cls: 0.08698  loss_rpn_loc: 0.04015  validation_loss: 1.978  time: 1.5026  data_time: 0.0231  lr: 6.8128e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:03:01 d2.utils.events]: \u001b[0m eta: 2:36:25  iter: 3839  total_loss: 2.002  loss_cls_stage0: 0.2972  loss_box_reg_stage0: 0.1907  loss_cls_stage1: 0.2385  loss_box_reg_stage1: 0.2621  loss_cls_stage2: 0.1737  loss_box_reg_stage2: 0.1936  loss_mask: 0.5611  loss_rpn_cls: 0.07949  loss_rpn_loc: 0.03603  validation_loss: 1.978  time: 1.5028  data_time: 0.0232  lr: 6.7835e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:03:32 d2.utils.events]: \u001b[0m eta: 2:35:59  iter: 3859  total_loss: 2.145  loss_cls_stage0: 0.3056  loss_box_reg_stage0: 0.2461  loss_cls_stage1: 0.2428  loss_box_reg_stage1: 0.279  loss_cls_stage2: 0.1649  loss_box_reg_stage2: 0.2188  loss_mask: 0.5717  loss_rpn_cls: 0.0758  loss_rpn_loc: 0.03797  validation_loss: 1.978  time: 1.5030  data_time: 0.0249  lr: 6.7541e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:04:03 d2.utils.events]: \u001b[0m eta: 2:35:34  iter: 3879  total_loss: 2.229  loss_cls_stage0: 0.3203  loss_box_reg_stage0: 0.2347  loss_cls_stage1: 0.262  loss_box_reg_stage1: 0.3112  loss_cls_stage2: 0.1743  loss_box_reg_stage2: 0.2238  loss_mask: 0.566  loss_rpn_cls: 0.06873  loss_rpn_loc: 0.03441  validation_loss: 1.978  time: 1.5031  data_time: 0.0246  lr: 6.7247e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:04:34 d2.utils.events]: \u001b[0m eta: 2:35:05  iter: 3899  total_loss: 2.148  loss_cls_stage0: 0.288  loss_box_reg_stage0: 0.2067  loss_cls_stage1: 0.2319  loss_box_reg_stage1: 0.2662  loss_cls_stage2: 0.1733  loss_box_reg_stage2: 0.2211  loss_mask: 0.5823  loss_rpn_cls: 0.06647  loss_rpn_loc: 0.03616  validation_loss: 1.978  time: 1.5033  data_time: 0.0254  lr: 6.6952e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:05:05 d2.utils.events]: \u001b[0m eta: 2:34:36  iter: 3919  total_loss: 2.079  loss_cls_stage0: 0.2979  loss_box_reg_stage0: 0.2056  loss_cls_stage1: 0.2486  loss_box_reg_stage1: 0.2899  loss_cls_stage2: 0.1734  loss_box_reg_stage2: 0.2301  loss_mask: 0.5337  loss_rpn_cls: 0.0733  loss_rpn_loc: 0.03958  validation_loss: 1.978  time: 1.5035  data_time: 0.0244  lr: 6.6656e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:05:36 d2.utils.events]: \u001b[0m eta: 2:34:08  iter: 3939  total_loss: 2.277  loss_cls_stage0: 0.3253  loss_box_reg_stage0: 0.2339  loss_cls_stage1: 0.2712  loss_box_reg_stage1: 0.3062  loss_cls_stage2: 0.1927  loss_box_reg_stage2: 0.2326  loss_mask: 0.5681  loss_rpn_cls: 0.07552  loss_rpn_loc: 0.03848  validation_loss: 1.978  time: 1.5038  data_time: 0.0239  lr: 6.6359e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:06:06 d2.utils.events]: \u001b[0m eta: 2:33:40  iter: 3959  total_loss: 2.067  loss_cls_stage0: 0.3396  loss_box_reg_stage0: 0.2206  loss_cls_stage1: 0.2555  loss_box_reg_stage1: 0.2605  loss_cls_stage2: 0.1662  loss_box_reg_stage2: 0.2116  loss_mask: 0.5456  loss_rpn_cls: 0.0884  loss_rpn_loc: 0.03813  validation_loss: 1.978  time: 1.5039  data_time: 0.0314  lr: 6.6062e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:06:37 d2.utils.events]: \u001b[0m eta: 2:33:13  iter: 3979  total_loss: 2.271  loss_cls_stage0: 0.3224  loss_box_reg_stage0: 0.2263  loss_cls_stage1: 0.2773  loss_box_reg_stage1: 0.3073  loss_cls_stage2: 0.1915  loss_box_reg_stage2: 0.2444  loss_mask: 0.5882  loss_rpn_cls: 0.08428  loss_rpn_loc: 0.04005  validation_loss: 1.978  time: 1.5041  data_time: 0.0232  lr: 6.5764e-05  max_mem: 11973M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/26 23:07:10 d2.data.common]: \u001b[0mSerializing 879 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/26 23:07:10 d2.data.common]: \u001b[0mSerialized dataset takes 0.90 MiB\n",
      "\u001b[32m[03/26 23:07:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 879 images\n",
      "\u001b[32m[03/26 23:07:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/879. 0.0795 s / img. ETA=0:01:29\n",
      "\u001b[32m[03/26 23:07:17 d2.evaluation.evaluator]: \u001b[0mInference done 61/879. 0.0793 s / img. ETA=0:01:23\n",
      "\u001b[32m[03/26 23:07:22 d2.evaluation.evaluator]: \u001b[0mInference done 110/879. 0.0793 s / img. ETA=0:01:18\n",
      "\u001b[32m[03/26 23:07:27 d2.evaluation.evaluator]: \u001b[0mInference done 159/879. 0.0793 s / img. ETA=0:01:13\n",
      "\u001b[32m[03/26 23:07:32 d2.evaluation.evaluator]: \u001b[0mInference done 209/879. 0.0793 s / img. ETA=0:01:08\n",
      "\u001b[32m[03/26 23:07:37 d2.evaluation.evaluator]: \u001b[0mInference done 259/879. 0.0792 s / img. ETA=0:01:02\n",
      "\u001b[32m[03/26 23:07:42 d2.evaluation.evaluator]: \u001b[0mInference done 308/879. 0.0792 s / img. ETA=0:00:58\n",
      "\u001b[32m[03/26 23:07:47 d2.evaluation.evaluator]: \u001b[0mInference done 358/879. 0.0792 s / img. ETA=0:00:52\n",
      "\u001b[32m[03/26 23:07:52 d2.evaluation.evaluator]: \u001b[0mInference done 409/879. 0.0792 s / img. ETA=0:00:47\n",
      "\u001b[32m[03/26 23:07:57 d2.evaluation.evaluator]: \u001b[0mInference done 458/879. 0.0792 s / img. ETA=0:00:42\n",
      "\u001b[32m[03/26 23:08:02 d2.evaluation.evaluator]: \u001b[0mInference done 508/879. 0.0793 s / img. ETA=0:00:37\n",
      "\u001b[32m[03/26 23:08:07 d2.evaluation.evaluator]: \u001b[0mInference done 557/879. 0.0793 s / img. ETA=0:00:32\n",
      "\u001b[32m[03/26 23:08:12 d2.evaluation.evaluator]: \u001b[0mInference done 607/879. 0.0793 s / img. ETA=0:00:27\n",
      "\u001b[32m[03/26 23:08:17 d2.evaluation.evaluator]: \u001b[0mInference done 657/879. 0.0793 s / img. ETA=0:00:22\n",
      "\u001b[32m[03/26 23:08:22 d2.evaluation.evaluator]: \u001b[0mInference done 708/879. 0.0793 s / img. ETA=0:00:17\n",
      "\u001b[32m[03/26 23:08:27 d2.evaluation.evaluator]: \u001b[0mInference done 758/879. 0.0793 s / img. ETA=0:00:12\n",
      "\u001b[32m[03/26 23:08:32 d2.evaluation.evaluator]: \u001b[0mInference done 808/879. 0.0793 s / img. ETA=0:00:07\n",
      "\u001b[32m[03/26 23:08:37 d2.evaluation.evaluator]: \u001b[0mInference done 859/879. 0.0793 s / img. ETA=0:00:02\n",
      "\u001b[32m[03/26 23:08:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:28.394202 (0.101138 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/26 23:08:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:09 (0.079357 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.40 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.064\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.107\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.111\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.031\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.065\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.095\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.107\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.107\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.111\n",
      "\u001b[32m[03/26 23:08:40 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold3 in csv format:\n",
      "\u001b[32m[03/26 23:08:40 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/26 23:08:40 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/26 23:08:40 d2.evaluation.testing]: \u001b[0mcopypaste: 6.3602,10.6762,11.1433,0.2802,3.0998,6.5098\n",
      "validation do loss eval 2.1096770915200675\n",
      "\u001b[32m[03/26 23:10:10 d2.utils.events]: \u001b[0m eta: 2:32:43  iter: 3999  total_loss: 2.086  loss_cls_stage0: 0.2887  loss_box_reg_stage0: 0.1957  loss_cls_stage1: 0.2306  loss_box_reg_stage1: 0.2709  loss_cls_stage2: 0.1693  loss_box_reg_stage2: 0.2372  loss_mask: 0.6006  loss_rpn_cls: 0.08157  loss_rpn_loc: 0.03609  validation_loss: 2.019  time: 1.5042  data_time: 0.0223  lr: 6.5466e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:10:40 d2.utils.events]: \u001b[0m eta: 2:32:14  iter: 4019  total_loss: 2.189  loss_cls_stage0: 0.3139  loss_box_reg_stage0: 0.2092  loss_cls_stage1: 0.2615  loss_box_reg_stage1: 0.2884  loss_cls_stage2: 0.1785  loss_box_reg_stage2: 0.2314  loss_mask: 0.565  loss_rpn_cls: 0.07419  loss_rpn_loc: 0.03898  validation_loss: 2.019  time: 1.5043  data_time: 0.0244  lr: 6.5167e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:11:11 d2.utils.events]: \u001b[0m eta: 2:31:47  iter: 4039  total_loss: 2.203  loss_cls_stage0: 0.3117  loss_box_reg_stage0: 0.2161  loss_cls_stage1: 0.2409  loss_box_reg_stage1: 0.2858  loss_cls_stage2: 0.1732  loss_box_reg_stage2: 0.2321  loss_mask: 0.5857  loss_rpn_cls: 0.07627  loss_rpn_loc: 0.03436  validation_loss: 2.019  time: 1.5045  data_time: 0.0257  lr: 6.4867e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:11:42 d2.utils.events]: \u001b[0m eta: 2:31:21  iter: 4059  total_loss: 2.357  loss_cls_stage0: 0.359  loss_box_reg_stage0: 0.2386  loss_cls_stage1: 0.2844  loss_box_reg_stage1: 0.3054  loss_cls_stage2: 0.1908  loss_box_reg_stage2: 0.2382  loss_mask: 0.5876  loss_rpn_cls: 0.08129  loss_rpn_loc: 0.04511  validation_loss: 2.019  time: 1.5047  data_time: 0.0244  lr: 6.4567e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:12:13 d2.utils.events]: \u001b[0m eta: 2:30:51  iter: 4079  total_loss: 2.025  loss_cls_stage0: 0.2948  loss_box_reg_stage0: 0.1927  loss_cls_stage1: 0.2356  loss_box_reg_stage1: 0.242  loss_cls_stage2: 0.1699  loss_box_reg_stage2: 0.1941  loss_mask: 0.5494  loss_rpn_cls: 0.06847  loss_rpn_loc: 0.03392  validation_loss: 2.019  time: 1.5048  data_time: 0.0241  lr: 6.4266e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:12:44 d2.utils.events]: \u001b[0m eta: 2:30:23  iter: 4099  total_loss: 2.188  loss_cls_stage0: 0.3297  loss_box_reg_stage0: 0.2362  loss_cls_stage1: 0.2462  loss_box_reg_stage1: 0.2919  loss_cls_stage2: 0.1905  loss_box_reg_stage2: 0.2334  loss_mask: 0.5712  loss_rpn_cls: 0.07316  loss_rpn_loc: 0.03701  validation_loss: 2.019  time: 1.5051  data_time: 0.0245  lr: 6.3965e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:13:14 d2.utils.events]: \u001b[0m eta: 2:29:52  iter: 4119  total_loss: 2.203  loss_cls_stage0: 0.3363  loss_box_reg_stage0: 0.2378  loss_cls_stage1: 0.2656  loss_box_reg_stage1: 0.2959  loss_cls_stage2: 0.1854  loss_box_reg_stage2: 0.2413  loss_mask: 0.5017  loss_rpn_cls: 0.06908  loss_rpn_loc: 0.0361  validation_loss: 2.019  time: 1.5052  data_time: 0.0238  lr: 6.3663e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:13:45 d2.utils.events]: \u001b[0m eta: 2:29:24  iter: 4139  total_loss: 2.231  loss_cls_stage0: 0.3227  loss_box_reg_stage0: 0.2455  loss_cls_stage1: 0.244  loss_box_reg_stage1: 0.3123  loss_cls_stage2: 0.1789  loss_box_reg_stage2: 0.2403  loss_mask: 0.5953  loss_rpn_cls: 0.06412  loss_rpn_loc: 0.0355  validation_loss: 2.019  time: 1.5054  data_time: 0.0235  lr: 6.336e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:14:16 d2.utils.events]: \u001b[0m eta: 2:28:56  iter: 4159  total_loss: 2.217  loss_cls_stage0: 0.3375  loss_box_reg_stage0: 0.2259  loss_cls_stage1: 0.2695  loss_box_reg_stage1: 0.2907  loss_cls_stage2: 0.1853  loss_box_reg_stage2: 0.2253  loss_mask: 0.5755  loss_rpn_cls: 0.0637  loss_rpn_loc: 0.03746  validation_loss: 2.019  time: 1.5056  data_time: 0.0234  lr: 6.3057e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:14:47 d2.utils.events]: \u001b[0m eta: 2:28:26  iter: 4179  total_loss: 2.229  loss_cls_stage0: 0.3051  loss_box_reg_stage0: 0.2224  loss_cls_stage1: 0.2572  loss_box_reg_stage1: 0.321  loss_cls_stage2: 0.1756  loss_box_reg_stage2: 0.2402  loss_mask: 0.56  loss_rpn_cls: 0.07226  loss_rpn_loc: 0.0361  validation_loss: 2.019  time: 1.5058  data_time: 0.0252  lr: 6.2754e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:15:18 d2.utils.events]: \u001b[0m eta: 2:27:56  iter: 4199  total_loss: 2.211  loss_cls_stage0: 0.3137  loss_box_reg_stage0: 0.2192  loss_cls_stage1: 0.2498  loss_box_reg_stage1: 0.2968  loss_cls_stage2: 0.1889  loss_box_reg_stage2: 0.2263  loss_mask: 0.5637  loss_rpn_cls: 0.07325  loss_rpn_loc: 0.03321  validation_loss: 2.019  time: 1.5060  data_time: 0.0243  lr: 6.245e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:15:49 d2.utils.events]: \u001b[0m eta: 2:27:26  iter: 4219  total_loss: 1.972  loss_cls_stage0: 0.2618  loss_box_reg_stage0: 0.1924  loss_cls_stage1: 0.2174  loss_box_reg_stage1: 0.269  loss_cls_stage2: 0.17  loss_box_reg_stage2: 0.2231  loss_mask: 0.5616  loss_rpn_cls: 0.06231  loss_rpn_loc: 0.03397  validation_loss: 2.019  time: 1.5061  data_time: 0.0254  lr: 6.2145e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:16:20 d2.utils.events]: \u001b[0m eta: 2:26:55  iter: 4239  total_loss: 1.961  loss_cls_stage0: 0.2897  loss_box_reg_stage0: 0.1995  loss_cls_stage1: 0.2291  loss_box_reg_stage1: 0.2572  loss_cls_stage2: 0.1747  loss_box_reg_stage2: 0.2166  loss_mask: 0.5261  loss_rpn_cls: 0.07811  loss_rpn_loc: 0.03656  validation_loss: 2.019  time: 1.5063  data_time: 0.0245  lr: 6.184e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:16:51 d2.utils.events]: \u001b[0m eta: 2:26:27  iter: 4259  total_loss: 2.258  loss_cls_stage0: 0.3226  loss_box_reg_stage0: 0.2252  loss_cls_stage1: 0.2671  loss_box_reg_stage1: 0.3087  loss_cls_stage2: 0.1906  loss_box_reg_stage2: 0.2382  loss_mask: 0.5623  loss_rpn_cls: 0.0697  loss_rpn_loc: 0.03576  validation_loss: 2.019  time: 1.5064  data_time: 0.0245  lr: 6.1535e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:17:21 d2.utils.events]: \u001b[0m eta: 2:25:58  iter: 4279  total_loss: 2.135  loss_cls_stage0: 0.3419  loss_box_reg_stage0: 0.2377  loss_cls_stage1: 0.2591  loss_box_reg_stage1: 0.2881  loss_cls_stage2: 0.1873  loss_box_reg_stage2: 0.22  loss_mask: 0.5076  loss_rpn_cls: 0.06762  loss_rpn_loc: 0.03549  validation_loss: 2.019  time: 1.5066  data_time: 0.0235  lr: 6.1229e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:17:52 d2.utils.events]: \u001b[0m eta: 2:25:30  iter: 4299  total_loss: 2.12  loss_cls_stage0: 0.3054  loss_box_reg_stage0: 0.2257  loss_cls_stage1: 0.2367  loss_box_reg_stage1: 0.305  loss_cls_stage2: 0.1757  loss_box_reg_stage2: 0.2502  loss_mask: 0.5227  loss_rpn_cls: 0.06845  loss_rpn_loc: 0.03398  validation_loss: 2.019  time: 1.5068  data_time: 0.0246  lr: 6.0922e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:18:23 d2.utils.events]: \u001b[0m eta: 2:25:01  iter: 4319  total_loss: 2.103  loss_cls_stage0: 0.3087  loss_box_reg_stage0: 0.2178  loss_cls_stage1: 0.2521  loss_box_reg_stage1: 0.2745  loss_cls_stage2: 0.1669  loss_box_reg_stage2: 0.2211  loss_mask: 0.54  loss_rpn_cls: 0.06681  loss_rpn_loc: 0.0322  validation_loss: 2.019  time: 1.5069  data_time: 0.0238  lr: 6.0616e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:18:54 d2.utils.events]: \u001b[0m eta: 2:24:33  iter: 4339  total_loss: 2.148  loss_cls_stage0: 0.3095  loss_box_reg_stage0: 0.2184  loss_cls_stage1: 0.2378  loss_box_reg_stage1: 0.2799  loss_cls_stage2: 0.1787  loss_box_reg_stage2: 0.2399  loss_mask: 0.5717  loss_rpn_cls: 0.0728  loss_rpn_loc: 0.03819  validation_loss: 2.019  time: 1.5072  data_time: 0.0230  lr: 6.0309e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:19:25 d2.utils.events]: \u001b[0m eta: 2:24:03  iter: 4359  total_loss: 2.082  loss_cls_stage0: 0.3094  loss_box_reg_stage0: 0.2142  loss_cls_stage1: 0.2399  loss_box_reg_stage1: 0.2663  loss_cls_stage2: 0.1719  loss_box_reg_stage2: 0.2088  loss_mask: 0.5759  loss_rpn_cls: 0.07867  loss_rpn_loc: 0.033  validation_loss: 2.019  time: 1.5073  data_time: 0.0242  lr: 6.0001e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:19:56 d2.utils.events]: \u001b[0m eta: 2:23:34  iter: 4379  total_loss: 2.022  loss_cls_stage0: 0.3212  loss_box_reg_stage0: 0.2104  loss_cls_stage1: 0.2487  loss_box_reg_stage1: 0.2698  loss_cls_stage2: 0.1794  loss_box_reg_stage2: 0.2068  loss_mask: 0.5137  loss_rpn_cls: 0.0714  loss_rpn_loc: 0.03878  validation_loss: 2.019  time: 1.5075  data_time: 0.0261  lr: 5.9693e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:20:27 d2.utils.events]: \u001b[0m eta: 2:23:06  iter: 4399  total_loss: 2.219  loss_cls_stage0: 0.3102  loss_box_reg_stage0: 0.2239  loss_cls_stage1: 0.2612  loss_box_reg_stage1: 0.2994  loss_cls_stage2: 0.1946  loss_box_reg_stage2: 0.2511  loss_mask: 0.5817  loss_rpn_cls: 0.06913  loss_rpn_loc: 0.03762  validation_loss: 2.019  time: 1.5076  data_time: 0.0244  lr: 5.9384e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:20:58 d2.utils.events]: \u001b[0m eta: 2:22:38  iter: 4419  total_loss: 2.424  loss_cls_stage0: 0.3543  loss_box_reg_stage0: 0.2598  loss_cls_stage1: 0.2912  loss_box_reg_stage1: 0.3381  loss_cls_stage2: 0.2005  loss_box_reg_stage2: 0.26  loss_mask: 0.5815  loss_rpn_cls: 0.07727  loss_rpn_loc: 0.03941  validation_loss: 2.019  time: 1.5078  data_time: 0.0243  lr: 5.9076e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:21:29 d2.utils.events]: \u001b[0m eta: 2:22:09  iter: 4439  total_loss: 2.141  loss_cls_stage0: 0.3099  loss_box_reg_stage0: 0.2199  loss_cls_stage1: 0.242  loss_box_reg_stage1: 0.2922  loss_cls_stage2: 0.1686  loss_box_reg_stage2: 0.2362  loss_mask: 0.5374  loss_rpn_cls: 0.07471  loss_rpn_loc: 0.0344  validation_loss: 2.019  time: 1.5080  data_time: 0.0241  lr: 5.8767e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:22:00 d2.utils.events]: \u001b[0m eta: 2:21:41  iter: 4459  total_loss: 2.251  loss_cls_stage0: 0.3319  loss_box_reg_stage0: 0.2412  loss_cls_stage1: 0.2576  loss_box_reg_stage1: 0.2975  loss_cls_stage2: 0.1718  loss_box_reg_stage2: 0.2351  loss_mask: 0.5769  loss_rpn_cls: 0.07249  loss_rpn_loc: 0.0382  validation_loss: 2.019  time: 1.5082  data_time: 0.0235  lr: 5.8457e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:22:30 d2.utils.events]: \u001b[0m eta: 2:21:10  iter: 4479  total_loss: 1.956  loss_cls_stage0: 0.2538  loss_box_reg_stage0: 0.192  loss_cls_stage1: 0.2103  loss_box_reg_stage1: 0.2547  loss_cls_stage2: 0.1566  loss_box_reg_stage2: 0.2175  loss_mask: 0.5738  loss_rpn_cls: 0.05781  loss_rpn_loc: 0.02997  validation_loss: 2.019  time: 1.5083  data_time: 0.0259  lr: 5.8147e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:23:01 d2.utils.events]: \u001b[0m eta: 2:20:41  iter: 4499  total_loss: 2.244  loss_cls_stage0: 0.3502  loss_box_reg_stage0: 0.2381  loss_cls_stage1: 0.2754  loss_box_reg_stage1: 0.3125  loss_cls_stage2: 0.1996  loss_box_reg_stage2: 0.2491  loss_mask: 0.5388  loss_rpn_cls: 0.06894  loss_rpn_loc: 0.03538  validation_loss: 2.019  time: 1.5085  data_time: 0.0234  lr: 5.7837e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:23:32 d2.utils.events]: \u001b[0m eta: 2:20:13  iter: 4519  total_loss: 2.096  loss_cls_stage0: 0.2611  loss_box_reg_stage0: 0.205  loss_cls_stage1: 0.2319  loss_box_reg_stage1: 0.2864  loss_cls_stage2: 0.1813  loss_box_reg_stage2: 0.236  loss_mask: 0.5721  loss_rpn_cls: 0.07187  loss_rpn_loc: 0.03682  validation_loss: 2.019  time: 1.5086  data_time: 0.0235  lr: 5.7527e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:24:03 d2.utils.events]: \u001b[0m eta: 2:19:44  iter: 4539  total_loss: 2.165  loss_cls_stage0: 0.2973  loss_box_reg_stage0: 0.208  loss_cls_stage1: 0.2542  loss_box_reg_stage1: 0.3098  loss_cls_stage2: 0.1921  loss_box_reg_stage2: 0.2527  loss_mask: 0.5545  loss_rpn_cls: 0.06662  loss_rpn_loc: 0.03325  validation_loss: 2.019  time: 1.5087  data_time: 0.0299  lr: 5.7216e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:24:34 d2.utils.events]: \u001b[0m eta: 2:19:16  iter: 4559  total_loss: 2.203  loss_cls_stage0: 0.3166  loss_box_reg_stage0: 0.2269  loss_cls_stage1: 0.2571  loss_box_reg_stage1: 0.3231  loss_cls_stage2: 0.1885  loss_box_reg_stage2: 0.2467  loss_mask: 0.5435  loss_rpn_cls: 0.07568  loss_rpn_loc: 0.04178  validation_loss: 2.019  time: 1.5089  data_time: 0.0237  lr: 5.6905e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:25:05 d2.utils.events]: \u001b[0m eta: 2:18:46  iter: 4579  total_loss: 1.962  loss_cls_stage0: 0.2333  loss_box_reg_stage0: 0.1844  loss_cls_stage1: 0.196  loss_box_reg_stage1: 0.2778  loss_cls_stage2: 0.1506  loss_box_reg_stage2: 0.2516  loss_mask: 0.5352  loss_rpn_cls: 0.06729  loss_rpn_loc: 0.03142  validation_loss: 2.019  time: 1.5090  data_time: 0.0233  lr: 5.6594e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:25:36 d2.utils.events]: \u001b[0m eta: 2:18:17  iter: 4599  total_loss: 2.068  loss_cls_stage0: 0.2983  loss_box_reg_stage0: 0.2142  loss_cls_stage1: 0.2399  loss_box_reg_stage1: 0.2835  loss_cls_stage2: 0.1737  loss_box_reg_stage2: 0.2438  loss_mask: 0.5885  loss_rpn_cls: 0.07457  loss_rpn_loc: 0.03239  validation_loss: 2.019  time: 1.5092  data_time: 0.0229  lr: 5.6282e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:26:06 d2.utils.events]: \u001b[0m eta: 2:17:49  iter: 4619  total_loss: 2.25  loss_cls_stage0: 0.32  loss_box_reg_stage0: 0.2365  loss_cls_stage1: 0.2489  loss_box_reg_stage1: 0.3128  loss_cls_stage2: 0.1826  loss_box_reg_stage2: 0.2439  loss_mask: 0.5604  loss_rpn_cls: 0.0789  loss_rpn_loc: 0.03856  validation_loss: 2.019  time: 1.5093  data_time: 0.0217  lr: 5.597e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:26:38 d2.utils.events]: \u001b[0m eta: 2:17:22  iter: 4639  total_loss: 2.304  loss_cls_stage0: 0.3307  loss_box_reg_stage0: 0.2394  loss_cls_stage1: 0.2734  loss_box_reg_stage1: 0.3317  loss_cls_stage2: 0.194  loss_box_reg_stage2: 0.2757  loss_mask: 0.55  loss_rpn_cls: 0.07577  loss_rpn_loc: 0.03862  validation_loss: 2.019  time: 1.5096  data_time: 0.0226  lr: 5.5658e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:27:08 d2.utils.events]: \u001b[0m eta: 2:16:52  iter: 4659  total_loss: 2.161  loss_cls_stage0: 0.3271  loss_box_reg_stage0: 0.2252  loss_cls_stage1: 0.2636  loss_box_reg_stage1: 0.2806  loss_cls_stage2: 0.1819  loss_box_reg_stage2: 0.2272  loss_mask: 0.5333  loss_rpn_cls: 0.07489  loss_rpn_loc: 0.03689  validation_loss: 2.019  time: 1.5097  data_time: 0.0240  lr: 5.5346e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:27:39 d2.utils.events]: \u001b[0m eta: 2:16:22  iter: 4679  total_loss: 2.14  loss_cls_stage0: 0.3054  loss_box_reg_stage0: 0.2256  loss_cls_stage1: 0.2335  loss_box_reg_stage1: 0.2939  loss_cls_stage2: 0.1667  loss_box_reg_stage2: 0.2226  loss_mask: 0.565  loss_rpn_cls: 0.07327  loss_rpn_loc: 0.03414  validation_loss: 2.019  time: 1.5099  data_time: 0.0232  lr: 5.5034e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:28:10 d2.utils.events]: \u001b[0m eta: 2:15:53  iter: 4699  total_loss: 2.231  loss_cls_stage0: 0.3196  loss_box_reg_stage0: 0.2377  loss_cls_stage1: 0.2661  loss_box_reg_stage1: 0.3182  loss_cls_stage2: 0.1798  loss_box_reg_stage2: 0.2339  loss_mask: 0.5705  loss_rpn_cls: 0.06709  loss_rpn_loc: 0.03552  validation_loss: 2.019  time: 1.5100  data_time: 0.0235  lr: 5.4721e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:28:41 d2.utils.events]: \u001b[0m eta: 2:15:23  iter: 4719  total_loss: 2.163  loss_cls_stage0: 0.3052  loss_box_reg_stage0: 0.2259  loss_cls_stage1: 0.2418  loss_box_reg_stage1: 0.2984  loss_cls_stage2: 0.1829  loss_box_reg_stage2: 0.2388  loss_mask: 0.5361  loss_rpn_cls: 0.07185  loss_rpn_loc: 0.04056  validation_loss: 2.019  time: 1.5102  data_time: 0.0248  lr: 5.4408e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:29:12 d2.utils.events]: \u001b[0m eta: 2:14:55  iter: 4739  total_loss: 2.217  loss_cls_stage0: 0.3067  loss_box_reg_stage0: 0.2234  loss_cls_stage1: 0.2475  loss_box_reg_stage1: 0.3066  loss_cls_stage2: 0.1851  loss_box_reg_stage2: 0.2415  loss_mask: 0.5412  loss_rpn_cls: 0.06261  loss_rpn_loc: 0.03327  validation_loss: 2.019  time: 1.5104  data_time: 0.0245  lr: 5.4095e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:29:43 d2.utils.events]: \u001b[0m eta: 2:14:26  iter: 4759  total_loss: 2.216  loss_cls_stage0: 0.3204  loss_box_reg_stage0: 0.2307  loss_cls_stage1: 0.2563  loss_box_reg_stage1: 0.3108  loss_cls_stage2: 0.1844  loss_box_reg_stage2: 0.2354  loss_mask: 0.574  loss_rpn_cls: 0.07522  loss_rpn_loc: 0.03954  validation_loss: 2.019  time: 1.5105  data_time: 0.0241  lr: 5.3782e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:30:14 d2.utils.events]: \u001b[0m eta: 2:13:56  iter: 4779  total_loss: 2.063  loss_cls_stage0: 0.2782  loss_box_reg_stage0: 0.2057  loss_cls_stage1: 0.2307  loss_box_reg_stage1: 0.31  loss_cls_stage2: 0.1756  loss_box_reg_stage2: 0.2422  loss_mask: 0.4945  loss_rpn_cls: 0.07198  loss_rpn_loc: 0.03353  validation_loss: 2.019  time: 1.5107  data_time: 0.0236  lr: 5.3469e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:30:45 d2.utils.events]: \u001b[0m eta: 2:13:26  iter: 4799  total_loss: 2.223  loss_cls_stage0: 0.302  loss_box_reg_stage0: 0.2392  loss_cls_stage1: 0.2415  loss_box_reg_stage1: 0.3015  loss_cls_stage2: 0.1817  loss_box_reg_stage2: 0.2558  loss_mask: 0.5551  loss_rpn_cls: 0.06968  loss_rpn_loc: 0.03935  validation_loss: 2.019  time: 1.5108  data_time: 0.0242  lr: 5.3155e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:31:16 d2.utils.events]: \u001b[0m eta: 2:12:56  iter: 4819  total_loss: 2.23  loss_cls_stage0: 0.334  loss_box_reg_stage0: 0.2283  loss_cls_stage1: 0.2766  loss_box_reg_stage1: 0.3161  loss_cls_stage2: 0.2005  loss_box_reg_stage2: 0.2575  loss_mask: 0.5377  loss_rpn_cls: 0.07204  loss_rpn_loc: 0.03646  validation_loss: 2.019  time: 1.5110  data_time: 0.0302  lr: 5.2842e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:31:47 d2.utils.events]: \u001b[0m eta: 2:12:28  iter: 4839  total_loss: 2.169  loss_cls_stage0: 0.284  loss_box_reg_stage0: 0.2173  loss_cls_stage1: 0.2204  loss_box_reg_stage1: 0.304  loss_cls_stage2: 0.1664  loss_box_reg_stage2: 0.2393  loss_mask: 0.5758  loss_rpn_cls: 0.07327  loss_rpn_loc: 0.03713  validation_loss: 2.019  time: 1.5111  data_time: 0.0241  lr: 5.2528e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:32:18 d2.utils.events]: \u001b[0m eta: 2:11:57  iter: 4859  total_loss: 2.143  loss_cls_stage0: 0.3159  loss_box_reg_stage0: 0.2127  loss_cls_stage1: 0.2561  loss_box_reg_stage1: 0.2999  loss_cls_stage2: 0.1788  loss_box_reg_stage2: 0.2468  loss_mask: 0.5557  loss_rpn_cls: 0.07633  loss_rpn_loc: 0.03754  validation_loss: 2.019  time: 1.5113  data_time: 0.0243  lr: 5.2214e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:32:49 d2.utils.events]: \u001b[0m eta: 2:11:26  iter: 4879  total_loss: 2.075  loss_cls_stage0: 0.277  loss_box_reg_stage0: 0.2181  loss_cls_stage1: 0.2238  loss_box_reg_stage1: 0.2924  loss_cls_stage2: 0.1616  loss_box_reg_stage2: 0.2513  loss_mask: 0.5585  loss_rpn_cls: 0.06088  loss_rpn_loc: 0.02794  validation_loss: 2.019  time: 1.5114  data_time: 0.0237  lr: 5.19e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:33:20 d2.utils.events]: \u001b[0m eta: 2:10:55  iter: 4899  total_loss: 2.161  loss_cls_stage0: 0.3066  loss_box_reg_stage0: 0.2258  loss_cls_stage1: 0.2572  loss_box_reg_stage1: 0.3088  loss_cls_stage2: 0.1701  loss_box_reg_stage2: 0.2405  loss_mask: 0.5671  loss_rpn_cls: 0.07132  loss_rpn_loc: 0.03521  validation_loss: 2.019  time: 1.5115  data_time: 0.0234  lr: 5.1586e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:33:51 d2.utils.events]: \u001b[0m eta: 2:10:24  iter: 4919  total_loss: 2.134  loss_cls_stage0: 0.3019  loss_box_reg_stage0: 0.2187  loss_cls_stage1: 0.2392  loss_box_reg_stage1: 0.2736  loss_cls_stage2: 0.1711  loss_box_reg_stage2: 0.2218  loss_mask: 0.5709  loss_rpn_cls: 0.07112  loss_rpn_loc: 0.03751  validation_loss: 2.019  time: 1.5117  data_time: 0.0246  lr: 5.1272e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:34:22 d2.utils.events]: \u001b[0m eta: 2:09:54  iter: 4939  total_loss: 2.234  loss_cls_stage0: 0.32  loss_box_reg_stage0: 0.2265  loss_cls_stage1: 0.2616  loss_box_reg_stage1: 0.3088  loss_cls_stage2: 0.1873  loss_box_reg_stage2: 0.2659  loss_mask: 0.5457  loss_rpn_cls: 0.07062  loss_rpn_loc: 0.03521  validation_loss: 2.019  time: 1.5118  data_time: 0.0232  lr: 5.0958e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:34:53 d2.utils.events]: \u001b[0m eta: 2:09:24  iter: 4959  total_loss: 2.248  loss_cls_stage0: 0.3211  loss_box_reg_stage0: 0.2231  loss_cls_stage1: 0.2688  loss_box_reg_stage1: 0.3305  loss_cls_stage2: 0.201  loss_box_reg_stage2: 0.2668  loss_mask: 0.5362  loss_rpn_cls: 0.05795  loss_rpn_loc: 0.03587  validation_loss: 2.019  time: 1.5120  data_time: 0.0237  lr: 5.0644e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:35:24 d2.utils.events]: \u001b[0m eta: 2:08:53  iter: 4979  total_loss: 2.254  loss_cls_stage0: 0.3226  loss_box_reg_stage0: 0.2186  loss_cls_stage1: 0.2592  loss_box_reg_stage1: 0.3158  loss_cls_stage2: 0.1759  loss_box_reg_stage2: 0.2386  loss_mask: 0.5651  loss_rpn_cls: 0.06028  loss_rpn_loc: 0.03524  validation_loss: 2.019  time: 1.5121  data_time: 0.0227  lr: 5.033e-05  max_mem: 11973M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/26 23:35:57 d2.data.common]: \u001b[0mSerializing 879 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/26 23:35:57 d2.data.common]: \u001b[0mSerialized dataset takes 0.90 MiB\n",
      "\u001b[32m[03/26 23:35:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 879 images\n",
      "\u001b[32m[03/26 23:35:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/879. 0.0802 s / img. ETA=0:01:43\n",
      "\u001b[32m[03/26 23:36:04 d2.evaluation.evaluator]: \u001b[0mInference done 58/879. 0.0798 s / img. ETA=0:01:29\n",
      "\u001b[32m[03/26 23:36:09 d2.evaluation.evaluator]: \u001b[0mInference done 103/879. 0.0799 s / img. ETA=0:01:25\n",
      "\u001b[32m[03/26 23:36:14 d2.evaluation.evaluator]: \u001b[0mInference done 147/879. 0.0800 s / img. ETA=0:01:21\n",
      "\u001b[32m[03/26 23:36:19 d2.evaluation.evaluator]: \u001b[0mInference done 194/879. 0.0799 s / img. ETA=0:01:15\n",
      "\u001b[32m[03/26 23:36:24 d2.evaluation.evaluator]: \u001b[0mInference done 238/879. 0.0799 s / img. ETA=0:01:11\n",
      "\u001b[32m[03/26 23:36:29 d2.evaluation.evaluator]: \u001b[0mInference done 284/879. 0.0799 s / img. ETA=0:01:06\n",
      "\u001b[32m[03/26 23:36:34 d2.evaluation.evaluator]: \u001b[0mInference done 330/879. 0.0799 s / img. ETA=0:01:00\n",
      "\u001b[32m[03/26 23:36:39 d2.evaluation.evaluator]: \u001b[0mInference done 377/879. 0.0799 s / img. ETA=0:00:55\n",
      "\u001b[32m[03/26 23:36:44 d2.evaluation.evaluator]: \u001b[0mInference done 424/879. 0.0799 s / img. ETA=0:00:50\n",
      "\u001b[32m[03/26 23:36:49 d2.evaluation.evaluator]: \u001b[0mInference done 470/879. 0.0799 s / img. ETA=0:00:45\n",
      "\u001b[32m[03/26 23:36:54 d2.evaluation.evaluator]: \u001b[0mInference done 517/879. 0.0799 s / img. ETA=0:00:39\n",
      "\u001b[32m[03/26 23:36:59 d2.evaluation.evaluator]: \u001b[0mInference done 561/879. 0.0799 s / img. ETA=0:00:35\n",
      "\u001b[32m[03/26 23:37:04 d2.evaluation.evaluator]: \u001b[0mInference done 607/879. 0.0799 s / img. ETA=0:00:29\n",
      "\u001b[32m[03/26 23:37:09 d2.evaluation.evaluator]: \u001b[0mInference done 655/879. 0.0799 s / img. ETA=0:00:24\n",
      "\u001b[32m[03/26 23:37:14 d2.evaluation.evaluator]: \u001b[0mInference done 701/879. 0.0799 s / img. ETA=0:00:19\n",
      "\u001b[32m[03/26 23:37:19 d2.evaluation.evaluator]: \u001b[0mInference done 747/879. 0.0799 s / img. ETA=0:00:14\n",
      "\u001b[32m[03/26 23:37:24 d2.evaluation.evaluator]: \u001b[0mInference done 792/879. 0.0799 s / img. ETA=0:00:09\n",
      "\u001b[32m[03/26 23:37:29 d2.evaluation.evaluator]: \u001b[0mInference done 838/879. 0.0799 s / img. ETA=0:00:04\n",
      "\u001b[32m[03/26 23:37:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:36.106245 (0.109961 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/26 23:37:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:09 (0.079887 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.46 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.076\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.125\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.134\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.035\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.079\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.113\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.140\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.140\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.042\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.151\n",
      "\u001b[32m[03/26 23:37:35 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold3 in csv format:\n",
      "\u001b[32m[03/26 23:37:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/26 23:37:35 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/26 23:37:35 d2.evaluation.testing]: \u001b[0mcopypaste: 7.6198,12.4644,13.4472,0.5126,3.5404,7.8797\n",
      "validation do loss eval 2.2441875830414415\n",
      "\u001b[32m[03/26 23:39:05 d2.utils.events]: \u001b[0m eta: 2:08:23  iter: 4999  total_loss: 1.976  loss_cls_stage0: 0.2665  loss_box_reg_stage0: 0.2044  loss_cls_stage1: 0.2191  loss_box_reg_stage1: 0.2863  loss_cls_stage2: 0.1606  loss_box_reg_stage2: 0.2301  loss_mask: 0.5335  loss_rpn_cls: 0.07047  loss_rpn_loc: 0.03042  validation_loss: 2.06  time: 1.5122  data_time: 0.0242  lr: 5.0016e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:39:36 d2.utils.events]: \u001b[0m eta: 2:07:53  iter: 5019  total_loss: 2.201  loss_cls_stage0: 0.3011  loss_box_reg_stage0: 0.2231  loss_cls_stage1: 0.2427  loss_box_reg_stage1: 0.2914  loss_cls_stage2: 0.1767  loss_box_reg_stage2: 0.2399  loss_mask: 0.5207  loss_rpn_cls: 0.07365  loss_rpn_loc: 0.03558  validation_loss: 2.06  time: 1.5123  data_time: 0.0249  lr: 4.9702e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:40:07 d2.utils.events]: \u001b[0m eta: 2:07:22  iter: 5039  total_loss: 2.288  loss_cls_stage0: 0.3141  loss_box_reg_stage0: 0.24  loss_cls_stage1: 0.2503  loss_box_reg_stage1: 0.3181  loss_cls_stage2: 0.1738  loss_box_reg_stage2: 0.2553  loss_mask: 0.5685  loss_rpn_cls: 0.06781  loss_rpn_loc: 0.03705  validation_loss: 2.06  time: 1.5124  data_time: 0.0239  lr: 4.9387e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:40:38 d2.utils.events]: \u001b[0m eta: 2:06:52  iter: 5059  total_loss: 2.072  loss_cls_stage0: 0.3056  loss_box_reg_stage0: 0.2255  loss_cls_stage1: 0.2376  loss_box_reg_stage1: 0.2924  loss_cls_stage2: 0.1691  loss_box_reg_stage2: 0.2245  loss_mask: 0.5685  loss_rpn_cls: 0.06486  loss_rpn_loc: 0.03724  validation_loss: 2.06  time: 1.5126  data_time: 0.0234  lr: 4.9073e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:41:09 d2.utils.events]: \u001b[0m eta: 2:06:23  iter: 5079  total_loss: 2.224  loss_cls_stage0: 0.3032  loss_box_reg_stage0: 0.2397  loss_cls_stage1: 0.2374  loss_box_reg_stage1: 0.3196  loss_cls_stage2: 0.1708  loss_box_reg_stage2: 0.2547  loss_mask: 0.5931  loss_rpn_cls: 0.07302  loss_rpn_loc: 0.03667  validation_loss: 2.06  time: 1.5127  data_time: 0.0238  lr: 4.8759e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:41:40 d2.utils.events]: \u001b[0m eta: 2:05:52  iter: 5099  total_loss: 2.128  loss_cls_stage0: 0.2915  loss_box_reg_stage0: 0.2142  loss_cls_stage1: 0.2204  loss_box_reg_stage1: 0.2976  loss_cls_stage2: 0.1676  loss_box_reg_stage2: 0.2502  loss_mask: 0.5401  loss_rpn_cls: 0.07182  loss_rpn_loc: 0.03735  validation_loss: 2.06  time: 1.5129  data_time: 0.0260  lr: 4.8445e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:42:11 d2.utils.events]: \u001b[0m eta: 2:05:21  iter: 5119  total_loss: 2.221  loss_cls_stage0: 0.3129  loss_box_reg_stage0: 0.2459  loss_cls_stage1: 0.2488  loss_box_reg_stage1: 0.3276  loss_cls_stage2: 0.1805  loss_box_reg_stage2: 0.2663  loss_mask: 0.5205  loss_rpn_cls: 0.08224  loss_rpn_loc: 0.03453  validation_loss: 2.06  time: 1.5130  data_time: 0.0242  lr: 4.8131e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:42:42 d2.utils.events]: \u001b[0m eta: 2:04:50  iter: 5139  total_loss: 2.232  loss_cls_stage0: 0.3408  loss_box_reg_stage0: 0.239  loss_cls_stage1: 0.2659  loss_box_reg_stage1: 0.295  loss_cls_stage2: 0.1766  loss_box_reg_stage2: 0.2214  loss_mask: 0.574  loss_rpn_cls: 0.06528  loss_rpn_loc: 0.04008  validation_loss: 2.06  time: 1.5132  data_time: 0.0236  lr: 4.7817e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:43:13 d2.utils.events]: \u001b[0m eta: 2:04:19  iter: 5159  total_loss: 2.064  loss_cls_stage0: 0.2787  loss_box_reg_stage0: 0.1916  loss_cls_stage1: 0.2325  loss_box_reg_stage1: 0.2814  loss_cls_stage2: 0.1652  loss_box_reg_stage2: 0.2612  loss_mask: 0.5351  loss_rpn_cls: 0.07077  loss_rpn_loc: 0.03251  validation_loss: 2.06  time: 1.5133  data_time: 0.0230  lr: 4.7503e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:43:44 d2.utils.events]: \u001b[0m eta: 2:03:50  iter: 5179  total_loss: 2.319  loss_cls_stage0: 0.3318  loss_box_reg_stage0: 0.248  loss_cls_stage1: 0.2655  loss_box_reg_stage1: 0.3135  loss_cls_stage2: 0.1875  loss_box_reg_stage2: 0.2651  loss_mask: 0.5399  loss_rpn_cls: 0.07803  loss_rpn_loc: 0.03868  validation_loss: 2.06  time: 1.5135  data_time: 0.0235  lr: 4.719e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:44:15 d2.utils.events]: \u001b[0m eta: 2:03:18  iter: 5199  total_loss: 2.123  loss_cls_stage0: 0.3147  loss_box_reg_stage0: 0.2096  loss_cls_stage1: 0.2481  loss_box_reg_stage1: 0.3202  loss_cls_stage2: 0.1818  loss_box_reg_stage2: 0.2647  loss_mask: 0.5324  loss_rpn_cls: 0.07435  loss_rpn_loc: 0.03694  validation_loss: 2.06  time: 1.5136  data_time: 0.0238  lr: 4.6876e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:44:46 d2.utils.events]: \u001b[0m eta: 2:02:52  iter: 5219  total_loss: 2.316  loss_cls_stage0: 0.3402  loss_box_reg_stage0: 0.2461  loss_cls_stage1: 0.2787  loss_box_reg_stage1: 0.3456  loss_cls_stage2: 0.1909  loss_box_reg_stage2: 0.2821  loss_mask: 0.5337  loss_rpn_cls: 0.07279  loss_rpn_loc: 0.03675  validation_loss: 2.06  time: 1.5138  data_time: 0.0256  lr: 4.6563e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:45:17 d2.utils.events]: \u001b[0m eta: 2:02:23  iter: 5239  total_loss: 2.252  loss_cls_stage0: 0.325  loss_box_reg_stage0: 0.2498  loss_cls_stage1: 0.2405  loss_box_reg_stage1: 0.3355  loss_cls_stage2: 0.1648  loss_box_reg_stage2: 0.2547  loss_mask: 0.5349  loss_rpn_cls: 0.06834  loss_rpn_loc: 0.0378  validation_loss: 2.06  time: 1.5140  data_time: 0.0237  lr: 4.6249e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:45:48 d2.utils.events]: \u001b[0m eta: 2:01:52  iter: 5259  total_loss: 2.218  loss_cls_stage0: 0.3077  loss_box_reg_stage0: 0.214  loss_cls_stage1: 0.2536  loss_box_reg_stage1: 0.3008  loss_cls_stage2: 0.1803  loss_box_reg_stage2: 0.2651  loss_mask: 0.5408  loss_rpn_cls: 0.05703  loss_rpn_loc: 0.0356  validation_loss: 2.06  time: 1.5141  data_time: 0.0239  lr: 4.5936e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:46:19 d2.utils.events]: \u001b[0m eta: 2:01:22  iter: 5279  total_loss: 2.341  loss_cls_stage0: 0.3213  loss_box_reg_stage0: 0.2504  loss_cls_stage1: 0.2679  loss_box_reg_stage1: 0.3412  loss_cls_stage2: 0.1918  loss_box_reg_stage2: 0.2646  loss_mask: 0.5266  loss_rpn_cls: 0.0618  loss_rpn_loc: 0.03815  validation_loss: 2.06  time: 1.5142  data_time: 0.0260  lr: 4.5623e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:46:50 d2.utils.events]: \u001b[0m eta: 2:00:52  iter: 5299  total_loss: 2.336  loss_cls_stage0: 0.318  loss_box_reg_stage0: 0.2393  loss_cls_stage1: 0.273  loss_box_reg_stage1: 0.343  loss_cls_stage2: 0.1989  loss_box_reg_stage2: 0.2855  loss_mask: 0.5576  loss_rpn_cls: 0.0693  loss_rpn_loc: 0.03515  validation_loss: 2.06  time: 1.5144  data_time: 0.0255  lr: 4.531e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:47:22 d2.utils.events]: \u001b[0m eta: 2:00:23  iter: 5319  total_loss: 2.134  loss_cls_stage0: 0.2813  loss_box_reg_stage0: 0.2246  loss_cls_stage1: 0.2353  loss_box_reg_stage1: 0.3278  loss_cls_stage2: 0.1712  loss_box_reg_stage2: 0.2636  loss_mask: 0.5511  loss_rpn_cls: 0.06011  loss_rpn_loc: 0.03343  validation_loss: 2.06  time: 1.5145  data_time: 0.0238  lr: 4.4998e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:47:53 d2.utils.events]: \u001b[0m eta: 1:59:52  iter: 5339  total_loss: 2.208  loss_cls_stage0: 0.3224  loss_box_reg_stage0: 0.2371  loss_cls_stage1: 0.2677  loss_box_reg_stage1: 0.3183  loss_cls_stage2: 0.1804  loss_box_reg_stage2: 0.252  loss_mask: 0.5604  loss_rpn_cls: 0.06377  loss_rpn_loc: 0.03514  validation_loss: 2.06  time: 1.5147  data_time: 0.0229  lr: 4.4685e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:48:24 d2.utils.events]: \u001b[0m eta: 1:59:22  iter: 5359  total_loss: 2.282  loss_cls_stage0: 0.3289  loss_box_reg_stage0: 0.2436  loss_cls_stage1: 0.2751  loss_box_reg_stage1: 0.3293  loss_cls_stage2: 0.1919  loss_box_reg_stage2: 0.2524  loss_mask: 0.5265  loss_rpn_cls: 0.07303  loss_rpn_loc: 0.038  validation_loss: 2.06  time: 1.5148  data_time: 0.0245  lr: 4.4373e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:48:55 d2.utils.events]: \u001b[0m eta: 1:58:53  iter: 5379  total_loss: 2.313  loss_cls_stage0: 0.3285  loss_box_reg_stage0: 0.2396  loss_cls_stage1: 0.2699  loss_box_reg_stage1: 0.3255  loss_cls_stage2: 0.188  loss_box_reg_stage2: 0.2604  loss_mask: 0.5618  loss_rpn_cls: 0.06904  loss_rpn_loc: 0.03916  validation_loss: 2.06  time: 1.5149  data_time: 0.0226  lr: 4.4061e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:49:26 d2.utils.events]: \u001b[0m eta: 1:58:22  iter: 5399  total_loss: 1.997  loss_cls_stage0: 0.3055  loss_box_reg_stage0: 0.2187  loss_cls_stage1: 0.2497  loss_box_reg_stage1: 0.2925  loss_cls_stage2: 0.1805  loss_box_reg_stage2: 0.2368  loss_mask: 0.4765  loss_rpn_cls: 0.06407  loss_rpn_loc: 0.03437  validation_loss: 2.06  time: 1.5150  data_time: 0.0229  lr: 4.3749e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:49:57 d2.utils.events]: \u001b[0m eta: 1:57:50  iter: 5419  total_loss: 2.362  loss_cls_stage0: 0.3255  loss_box_reg_stage0: 0.242  loss_cls_stage1: 0.2646  loss_box_reg_stage1: 0.3316  loss_cls_stage2: 0.1931  loss_box_reg_stage2: 0.2598  loss_mask: 0.5523  loss_rpn_cls: 0.07586  loss_rpn_loc: 0.03829  validation_loss: 2.06  time: 1.5152  data_time: 0.0235  lr: 4.3437e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:50:28 d2.utils.events]: \u001b[0m eta: 1:57:19  iter: 5439  total_loss: 2.16  loss_cls_stage0: 0.2876  loss_box_reg_stage0: 0.228  loss_cls_stage1: 0.246  loss_box_reg_stage1: 0.3215  loss_cls_stage2: 0.1839  loss_box_reg_stage2: 0.2705  loss_mask: 0.5468  loss_rpn_cls: 0.06074  loss_rpn_loc: 0.03064  validation_loss: 2.06  time: 1.5153  data_time: 0.0256  lr: 4.3126e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:50:58 d2.utils.events]: \u001b[0m eta: 1:56:47  iter: 5459  total_loss: 2.096  loss_cls_stage0: 0.3088  loss_box_reg_stage0: 0.2293  loss_cls_stage1: 0.2347  loss_box_reg_stage1: 0.2952  loss_cls_stage2: 0.162  loss_box_reg_stage2: 0.2402  loss_mask: 0.5269  loss_rpn_cls: 0.06489  loss_rpn_loc: 0.03431  validation_loss: 2.06  time: 1.5154  data_time: 0.0241  lr: 4.2815e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:51:29 d2.utils.events]: \u001b[0m eta: 1:56:17  iter: 5479  total_loss: 2.105  loss_cls_stage0: 0.29  loss_box_reg_stage0: 0.2275  loss_cls_stage1: 0.2289  loss_box_reg_stage1: 0.3015  loss_cls_stage2: 0.1623  loss_box_reg_stage2: 0.2521  loss_mask: 0.5356  loss_rpn_cls: 0.06666  loss_rpn_loc: 0.03312  validation_loss: 2.06  time: 1.5155  data_time: 0.0238  lr: 4.2504e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:52:00 d2.utils.events]: \u001b[0m eta: 1:55:46  iter: 5499  total_loss: 2.125  loss_cls_stage0: 0.3076  loss_box_reg_stage0: 0.2306  loss_cls_stage1: 0.2467  loss_box_reg_stage1: 0.3113  loss_cls_stage2: 0.1654  loss_box_reg_stage2: 0.2475  loss_mask: 0.5681  loss_rpn_cls: 0.05862  loss_rpn_loc: 0.03337  validation_loss: 2.06  time: 1.5156  data_time: 0.0250  lr: 4.2194e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:52:31 d2.utils.events]: \u001b[0m eta: 1:55:15  iter: 5519  total_loss: 2.112  loss_cls_stage0: 0.302  loss_box_reg_stage0: 0.2197  loss_cls_stage1: 0.2399  loss_box_reg_stage1: 0.3052  loss_cls_stage2: 0.1715  loss_box_reg_stage2: 0.2471  loss_mask: 0.5384  loss_rpn_cls: 0.06332  loss_rpn_loc: 0.03148  validation_loss: 2.06  time: 1.5157  data_time: 0.0236  lr: 4.1884e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:53:02 d2.utils.events]: \u001b[0m eta: 1:54:46  iter: 5539  total_loss: 2.339  loss_cls_stage0: 0.3089  loss_box_reg_stage0: 0.2583  loss_cls_stage1: 0.2622  loss_box_reg_stage1: 0.3511  loss_cls_stage2: 0.1937  loss_box_reg_stage2: 0.2835  loss_mask: 0.5546  loss_rpn_cls: 0.06955  loss_rpn_loc: 0.0402  validation_loss: 2.06  time: 1.5159  data_time: 0.0233  lr: 4.1574e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:53:33 d2.utils.events]: \u001b[0m eta: 1:54:14  iter: 5559  total_loss: 2.302  loss_cls_stage0: 0.296  loss_box_reg_stage0: 0.2182  loss_cls_stage1: 0.2429  loss_box_reg_stage1: 0.3273  loss_cls_stage2: 0.1847  loss_box_reg_stage2: 0.2681  loss_mask: 0.5613  loss_rpn_cls: 0.06579  loss_rpn_loc: 0.03398  validation_loss: 2.06  time: 1.5160  data_time: 0.0234  lr: 4.1264e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:54:04 d2.utils.events]: \u001b[0m eta: 1:53:45  iter: 5579  total_loss: 2.358  loss_cls_stage0: 0.3525  loss_box_reg_stage0: 0.2634  loss_cls_stage1: 0.2874  loss_box_reg_stage1: 0.3525  loss_cls_stage2: 0.2034  loss_box_reg_stage2: 0.2515  loss_mask: 0.5426  loss_rpn_cls: 0.06607  loss_rpn_loc: 0.03621  validation_loss: 2.06  time: 1.5161  data_time: 0.0238  lr: 4.0955e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:54:36 d2.utils.events]: \u001b[0m eta: 1:53:17  iter: 5599  total_loss: 2.371  loss_cls_stage0: 0.334  loss_box_reg_stage0: 0.259  loss_cls_stage1: 0.2797  loss_box_reg_stage1: 0.3601  loss_cls_stage2: 0.2007  loss_box_reg_stage2: 0.2943  loss_mask: 0.5395  loss_rpn_cls: 0.07049  loss_rpn_loc: 0.04087  validation_loss: 2.06  time: 1.5163  data_time: 0.0237  lr: 4.0646e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:55:07 d2.utils.events]: \u001b[0m eta: 1:52:46  iter: 5619  total_loss: 2.176  loss_cls_stage0: 0.3045  loss_box_reg_stage0: 0.2281  loss_cls_stage1: 0.2495  loss_box_reg_stage1: 0.3072  loss_cls_stage2: 0.19  loss_box_reg_stage2: 0.2539  loss_mask: 0.5575  loss_rpn_cls: 0.07091  loss_rpn_loc: 0.03661  validation_loss: 2.06  time: 1.5164  data_time: 0.0240  lr: 4.0338e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:55:38 d2.utils.events]: \u001b[0m eta: 1:52:15  iter: 5639  total_loss: 2.283  loss_cls_stage0: 0.3153  loss_box_reg_stage0: 0.2548  loss_cls_stage1: 0.2537  loss_box_reg_stage1: 0.3468  loss_cls_stage2: 0.1922  loss_box_reg_stage2: 0.2663  loss_mask: 0.5495  loss_rpn_cls: 0.0553  loss_rpn_loc: 0.03319  validation_loss: 2.06  time: 1.5165  data_time: 0.0238  lr: 4.003e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:56:09 d2.utils.events]: \u001b[0m eta: 1:51:45  iter: 5659  total_loss: 2.418  loss_cls_stage0: 0.3402  loss_box_reg_stage0: 0.2614  loss_cls_stage1: 0.278  loss_box_reg_stage1: 0.356  loss_cls_stage2: 0.2018  loss_box_reg_stage2: 0.2901  loss_mask: 0.5541  loss_rpn_cls: 0.0658  loss_rpn_loc: 0.03545  validation_loss: 2.06  time: 1.5167  data_time: 0.0234  lr: 3.9722e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:56:40 d2.utils.events]: \u001b[0m eta: 1:51:15  iter: 5679  total_loss: 2.232  loss_cls_stage0: 0.3385  loss_box_reg_stage0: 0.2415  loss_cls_stage1: 0.2716  loss_box_reg_stage1: 0.3174  loss_cls_stage2: 0.1912  loss_box_reg_stage2: 0.2402  loss_mask: 0.5128  loss_rpn_cls: 0.07205  loss_rpn_loc: 0.03901  validation_loss: 2.06  time: 1.5168  data_time: 0.0241  lr: 3.9415e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:57:11 d2.utils.events]: \u001b[0m eta: 1:50:45  iter: 5699  total_loss: 2.41  loss_cls_stage0: 0.3352  loss_box_reg_stage0: 0.2512  loss_cls_stage1: 0.2697  loss_box_reg_stage1: 0.3646  loss_cls_stage2: 0.1898  loss_box_reg_stage2: 0.2935  loss_mask: 0.5357  loss_rpn_cls: 0.0723  loss_rpn_loc: 0.03536  validation_loss: 2.06  time: 1.5170  data_time: 0.0244  lr: 3.9108e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:57:42 d2.utils.events]: \u001b[0m eta: 1:50:14  iter: 5719  total_loss: 2.268  loss_cls_stage0: 0.3229  loss_box_reg_stage0: 0.2362  loss_cls_stage1: 0.2599  loss_box_reg_stage1: 0.3377  loss_cls_stage2: 0.1866  loss_box_reg_stage2: 0.2699  loss_mask: 0.5526  loss_rpn_cls: 0.06405  loss_rpn_loc: 0.04105  validation_loss: 2.06  time: 1.5171  data_time: 0.0240  lr: 3.8802e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:58:14 d2.utils.events]: \u001b[0m eta: 1:49:44  iter: 5739  total_loss: 2.418  loss_cls_stage0: 0.3596  loss_box_reg_stage0: 0.269  loss_cls_stage1: 0.2979  loss_box_reg_stage1: 0.383  loss_cls_stage2: 0.2072  loss_box_reg_stage2: 0.2815  loss_mask: 0.5873  loss_rpn_cls: 0.05748  loss_rpn_loc: 0.03567  validation_loss: 2.06  time: 1.5173  data_time: 0.0245  lr: 3.8496e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:58:45 d2.utils.events]: \u001b[0m eta: 1:49:13  iter: 5759  total_loss: 2.128  loss_cls_stage0: 0.302  loss_box_reg_stage0: 0.2242  loss_cls_stage1: 0.2472  loss_box_reg_stage1: 0.3102  loss_cls_stage2: 0.1882  loss_box_reg_stage2: 0.2618  loss_mask: 0.5041  loss_rpn_cls: 0.06857  loss_rpn_loc: 0.03825  validation_loss: 2.06  time: 1.5174  data_time: 0.0246  lr: 3.819e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:59:16 d2.utils.events]: \u001b[0m eta: 1:48:42  iter: 5779  total_loss: 2.156  loss_cls_stage0: 0.2878  loss_box_reg_stage0: 0.2204  loss_cls_stage1: 0.2428  loss_box_reg_stage1: 0.3163  loss_cls_stage2: 0.1813  loss_box_reg_stage2: 0.2417  loss_mask: 0.5168  loss_rpn_cls: 0.06593  loss_rpn_loc: 0.03868  validation_loss: 2.06  time: 1.5175  data_time: 0.0226  lr: 3.7885e-05  max_mem: 11973M\n",
      "\u001b[32m[03/26 23:59:47 d2.utils.events]: \u001b[0m eta: 1:48:11  iter: 5799  total_loss: 2.414  loss_cls_stage0: 0.339  loss_box_reg_stage0: 0.2508  loss_cls_stage1: 0.2908  loss_box_reg_stage1: 0.3539  loss_cls_stage2: 0.2109  loss_box_reg_stage2: 0.3036  loss_mask: 0.5586  loss_rpn_cls: 0.07666  loss_rpn_loc: 0.03706  validation_loss: 2.06  time: 1.5177  data_time: 0.0232  lr: 3.7581e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:00:18 d2.utils.events]: \u001b[0m eta: 1:47:40  iter: 5819  total_loss: 2.212  loss_cls_stage0: 0.2943  loss_box_reg_stage0: 0.2278  loss_cls_stage1: 0.2462  loss_box_reg_stage1: 0.324  loss_cls_stage2: 0.1748  loss_box_reg_stage2: 0.2727  loss_mask: 0.5574  loss_rpn_cls: 0.06297  loss_rpn_loc: 0.03474  validation_loss: 2.06  time: 1.5178  data_time: 0.0254  lr: 3.7277e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:00:49 d2.utils.events]: \u001b[0m eta: 1:47:11  iter: 5839  total_loss: 2.258  loss_cls_stage0: 0.3139  loss_box_reg_stage0: 0.2421  loss_cls_stage1: 0.258  loss_box_reg_stage1: 0.3478  loss_cls_stage2: 0.1944  loss_box_reg_stage2: 0.3193  loss_mask: 0.5455  loss_rpn_cls: 0.06068  loss_rpn_loc: 0.03432  validation_loss: 2.06  time: 1.5179  data_time: 0.0265  lr: 3.6973e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:01:21 d2.utils.events]: \u001b[0m eta: 1:46:41  iter: 5859  total_loss: 2.16  loss_cls_stage0: 0.3134  loss_box_reg_stage0: 0.2247  loss_cls_stage1: 0.268  loss_box_reg_stage1: 0.3273  loss_cls_stage2: 0.1922  loss_box_reg_stage2: 0.2705  loss_mask: 0.5203  loss_rpn_cls: 0.06737  loss_rpn_loc: 0.0364  validation_loss: 2.06  time: 1.5181  data_time: 0.0253  lr: 3.667e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:01:52 d2.utils.events]: \u001b[0m eta: 1:46:11  iter: 5879  total_loss: 2.248  loss_cls_stage0: 0.2973  loss_box_reg_stage0: 0.2268  loss_cls_stage1: 0.2546  loss_box_reg_stage1: 0.3433  loss_cls_stage2: 0.187  loss_box_reg_stage2: 0.2641  loss_mask: 0.5398  loss_rpn_cls: 0.05458  loss_rpn_loc: 0.03388  validation_loss: 2.06  time: 1.5182  data_time: 0.0249  lr: 3.6368e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:02:23 d2.utils.events]: \u001b[0m eta: 1:45:41  iter: 5899  total_loss: 2.342  loss_cls_stage0: 0.3496  loss_box_reg_stage0: 0.2495  loss_cls_stage1: 0.268  loss_box_reg_stage1: 0.3405  loss_cls_stage2: 0.1877  loss_box_reg_stage2: 0.2707  loss_mask: 0.5545  loss_rpn_cls: 0.06854  loss_rpn_loc: 0.0393  validation_loss: 2.06  time: 1.5184  data_time: 0.0244  lr: 3.6066e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:02:54 d2.utils.events]: \u001b[0m eta: 1:45:13  iter: 5919  total_loss: 2.41  loss_cls_stage0: 0.3679  loss_box_reg_stage0: 0.2593  loss_cls_stage1: 0.3055  loss_box_reg_stage1: 0.3851  loss_cls_stage2: 0.2158  loss_box_reg_stage2: 0.2981  loss_mask: 0.5248  loss_rpn_cls: 0.06607  loss_rpn_loc: 0.04089  validation_loss: 2.06  time: 1.5185  data_time: 0.0235  lr: 3.5764e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:03:25 d2.utils.events]: \u001b[0m eta: 1:44:43  iter: 5939  total_loss: 2.243  loss_cls_stage0: 0.2976  loss_box_reg_stage0: 0.2403  loss_cls_stage1: 0.2527  loss_box_reg_stage1: 0.358  loss_cls_stage2: 0.1717  loss_box_reg_stage2: 0.281  loss_mask: 0.5497  loss_rpn_cls: 0.05651  loss_rpn_loc: 0.03518  validation_loss: 2.06  time: 1.5187  data_time: 0.0249  lr: 3.5463e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:03:57 d2.utils.events]: \u001b[0m eta: 1:44:14  iter: 5959  total_loss: 2.255  loss_cls_stage0: 0.3487  loss_box_reg_stage0: 0.2692  loss_cls_stage1: 0.2795  loss_box_reg_stage1: 0.3513  loss_cls_stage2: 0.1873  loss_box_reg_stage2: 0.2661  loss_mask: 0.5142  loss_rpn_cls: 0.06951  loss_rpn_loc: 0.03773  validation_loss: 2.06  time: 1.5188  data_time: 0.0237  lr: 3.5163e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:04:28 d2.utils.events]: \u001b[0m eta: 1:43:44  iter: 5979  total_loss: 2.283  loss_cls_stage0: 0.3234  loss_box_reg_stage0: 0.2434  loss_cls_stage1: 0.2716  loss_box_reg_stage1: 0.3372  loss_cls_stage2: 0.1902  loss_box_reg_stage2: 0.2818  loss_mask: 0.5137  loss_rpn_cls: 0.06965  loss_rpn_loc: 0.03183  validation_loss: 2.06  time: 1.5189  data_time: 0.0234  lr: 3.4863e-05  max_mem: 11973M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/27 00:05:01 d2.data.common]: \u001b[0mSerializing 879 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/27 00:05:01 d2.data.common]: \u001b[0mSerialized dataset takes 0.90 MiB\n",
      "\u001b[32m[03/27 00:05:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 879 images\n",
      "\u001b[32m[03/27 00:05:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/879. 0.0801 s / img. ETA=0:01:37\n",
      "\u001b[32m[03/27 00:05:08 d2.evaluation.evaluator]: \u001b[0mInference done 57/879. 0.0800 s / img. ETA=0:01:31\n",
      "\u001b[32m[03/27 00:05:13 d2.evaluation.evaluator]: \u001b[0mInference done 100/879. 0.0804 s / img. ETA=0:01:29\n",
      "\u001b[32m[03/27 00:05:18 d2.evaluation.evaluator]: \u001b[0mInference done 142/879. 0.0806 s / img. ETA=0:01:25\n",
      "\u001b[32m[03/27 00:05:23 d2.evaluation.evaluator]: \u001b[0mInference done 186/879. 0.0805 s / img. ETA=0:01:20\n",
      "\u001b[32m[03/27 00:05:28 d2.evaluation.evaluator]: \u001b[0mInference done 226/879. 0.0807 s / img. ETA=0:01:16\n",
      "\u001b[32m[03/27 00:05:33 d2.evaluation.evaluator]: \u001b[0mInference done 271/879. 0.0806 s / img. ETA=0:01:10\n",
      "\u001b[32m[03/27 00:05:38 d2.evaluation.evaluator]: \u001b[0mInference done 316/879. 0.0806 s / img. ETA=0:01:05\n",
      "\u001b[32m[03/27 00:05:43 d2.evaluation.evaluator]: \u001b[0mInference done 361/879. 0.0805 s / img. ETA=0:00:59\n",
      "\u001b[32m[03/27 00:05:48 d2.evaluation.evaluator]: \u001b[0mInference done 407/879. 0.0805 s / img. ETA=0:00:54\n",
      "\u001b[32m[03/27 00:05:54 d2.evaluation.evaluator]: \u001b[0mInference done 454/879. 0.0804 s / img. ETA=0:00:48\n",
      "\u001b[32m[03/27 00:05:59 d2.evaluation.evaluator]: \u001b[0mInference done 499/879. 0.0804 s / img. ETA=0:00:43\n",
      "\u001b[32m[03/27 00:06:04 d2.evaluation.evaluator]: \u001b[0mInference done 544/879. 0.0804 s / img. ETA=0:00:38\n",
      "\u001b[32m[03/27 00:06:09 d2.evaluation.evaluator]: \u001b[0mInference done 586/879. 0.0804 s / img. ETA=0:00:33\n",
      "\u001b[32m[03/27 00:06:14 d2.evaluation.evaluator]: \u001b[0mInference done 631/879. 0.0804 s / img. ETA=0:00:28\n",
      "\u001b[32m[03/27 00:06:19 d2.evaluation.evaluator]: \u001b[0mInference done 676/879. 0.0804 s / img. ETA=0:00:23\n",
      "\u001b[32m[03/27 00:06:24 d2.evaluation.evaluator]: \u001b[0mInference done 722/879. 0.0804 s / img. ETA=0:00:17\n",
      "\u001b[32m[03/27 00:06:29 d2.evaluation.evaluator]: \u001b[0mInference done 765/879. 0.0804 s / img. ETA=0:00:12\n",
      "\u001b[32m[03/27 00:06:34 d2.evaluation.evaluator]: \u001b[0mInference done 807/879. 0.0805 s / img. ETA=0:00:08\n",
      "\u001b[32m[03/27 00:06:39 d2.evaluation.evaluator]: \u001b[0mInference done 855/879. 0.0804 s / img. ETA=0:00:02\n",
      "\u001b[32m[03/27 00:06:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:39.490769 (0.113834 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/27 00:06:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:10 (0.080435 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.45 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.082\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.133\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.146\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.039\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.085\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.128\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.164\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.165\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.052\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.181\n",
      "\u001b[32m[03/27 00:06:43 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold3 in csv format:\n",
      "\u001b[32m[03/27 00:06:43 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/27 00:06:43 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/27 00:06:43 d2.evaluation.testing]: \u001b[0mcopypaste: 8.1506,13.3472,14.5978,0.5857,3.9257,8.4865\n",
      "validation do loss eval 2.265264979606167\n",
      "\u001b[32m[03/27 00:08:13 d2.utils.events]: \u001b[0m eta: 1:43:16  iter: 5999  total_loss: 2.471  loss_cls_stage0: 0.3498  loss_box_reg_stage0: 0.2608  loss_cls_stage1: 0.2872  loss_box_reg_stage1: 0.3611  loss_cls_stage2: 0.2043  loss_box_reg_stage2: 0.291  loss_mask: 0.5655  loss_rpn_cls: 0.06403  loss_rpn_loc: 0.03599  validation_loss: 2.085  time: 1.5191  data_time: 0.0312  lr: 3.4564e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:08:44 d2.utils.events]: \u001b[0m eta: 1:42:46  iter: 6019  total_loss: 2.28  loss_cls_stage0: 0.3267  loss_box_reg_stage0: 0.244  loss_cls_stage1: 0.2621  loss_box_reg_stage1: 0.3418  loss_cls_stage2: 0.1874  loss_box_reg_stage2: 0.2839  loss_mask: 0.5825  loss_rpn_cls: 0.06611  loss_rpn_loc: 0.03774  validation_loss: 2.085  time: 1.5192  data_time: 0.0253  lr: 3.4266e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:09:16 d2.utils.events]: \u001b[0m eta: 1:42:16  iter: 6039  total_loss: 2.402  loss_cls_stage0: 0.3211  loss_box_reg_stage0: 0.2566  loss_cls_stage1: 0.2677  loss_box_reg_stage1: 0.3573  loss_cls_stage2: 0.1954  loss_box_reg_stage2: 0.2959  loss_mask: 0.5734  loss_rpn_cls: 0.0694  loss_rpn_loc: 0.03781  validation_loss: 2.085  time: 1.5193  data_time: 0.0235  lr: 3.3968e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:09:47 d2.utils.events]: \u001b[0m eta: 1:41:46  iter: 6059  total_loss: 2.373  loss_cls_stage0: 0.3542  loss_box_reg_stage0: 0.2588  loss_cls_stage1: 0.2859  loss_box_reg_stage1: 0.3485  loss_cls_stage2: 0.1992  loss_box_reg_stage2: 0.2962  loss_mask: 0.5388  loss_rpn_cls: 0.06535  loss_rpn_loc: 0.03972  validation_loss: 2.085  time: 1.5194  data_time: 0.0244  lr: 3.367e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:10:18 d2.utils.events]: \u001b[0m eta: 1:41:15  iter: 6079  total_loss: 2.207  loss_cls_stage0: 0.3175  loss_box_reg_stage0: 0.2564  loss_cls_stage1: 0.255  loss_box_reg_stage1: 0.3271  loss_cls_stage2: 0.1748  loss_box_reg_stage2: 0.2747  loss_mask: 0.5292  loss_rpn_cls: 0.06003  loss_rpn_loc: 0.03457  validation_loss: 2.085  time: 1.5196  data_time: 0.0231  lr: 3.3374e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:10:49 d2.utils.events]: \u001b[0m eta: 1:40:44  iter: 6099  total_loss: 2.183  loss_cls_stage0: 0.2994  loss_box_reg_stage0: 0.229  loss_cls_stage1: 0.2542  loss_box_reg_stage1: 0.3399  loss_cls_stage2: 0.183  loss_box_reg_stage2: 0.2705  loss_mask: 0.5305  loss_rpn_cls: 0.0716  loss_rpn_loc: 0.03297  validation_loss: 2.085  time: 1.5197  data_time: 0.0228  lr: 3.3078e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:11:20 d2.utils.events]: \u001b[0m eta: 1:40:13  iter: 6119  total_loss: 2.213  loss_cls_stage0: 0.3167  loss_box_reg_stage0: 0.2425  loss_cls_stage1: 0.2515  loss_box_reg_stage1: 0.3365  loss_cls_stage2: 0.1823  loss_box_reg_stage2: 0.2651  loss_mask: 0.5538  loss_rpn_cls: 0.06291  loss_rpn_loc: 0.03319  validation_loss: 2.085  time: 1.5198  data_time: 0.0242  lr: 3.2783e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:11:51 d2.utils.events]: \u001b[0m eta: 1:39:43  iter: 6139  total_loss: 2.286  loss_cls_stage0: 0.3238  loss_box_reg_stage0: 0.2524  loss_cls_stage1: 0.2636  loss_box_reg_stage1: 0.3407  loss_cls_stage2: 0.1998  loss_box_reg_stage2: 0.2793  loss_mask: 0.5191  loss_rpn_cls: 0.06442  loss_rpn_loc: 0.03419  validation_loss: 2.085  time: 1.5199  data_time: 0.0246  lr: 3.2488e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:12:23 d2.utils.events]: \u001b[0m eta: 1:39:14  iter: 6159  total_loss: 2.116  loss_cls_stage0: 0.3159  loss_box_reg_stage0: 0.234  loss_cls_stage1: 0.2478  loss_box_reg_stage1: 0.3167  loss_cls_stage2: 0.172  loss_box_reg_stage2: 0.2546  loss_mask: 0.4981  loss_rpn_cls: 0.06902  loss_rpn_loc: 0.03483  validation_loss: 2.085  time: 1.5200  data_time: 0.0238  lr: 3.2194e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:12:54 d2.utils.events]: \u001b[0m eta: 1:38:41  iter: 6179  total_loss: 2.305  loss_cls_stage0: 0.2963  loss_box_reg_stage0: 0.2389  loss_cls_stage1: 0.2506  loss_box_reg_stage1: 0.3334  loss_cls_stage2: 0.1719  loss_box_reg_stage2: 0.2745  loss_mask: 0.563  loss_rpn_cls: 0.06004  loss_rpn_loc: 0.03308  validation_loss: 2.085  time: 1.5201  data_time: 0.0244  lr: 3.1901e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:13:25 d2.utils.events]: \u001b[0m eta: 1:38:10  iter: 6199  total_loss: 2.097  loss_cls_stage0: 0.2883  loss_box_reg_stage0: 0.2212  loss_cls_stage1: 0.2244  loss_box_reg_stage1: 0.3146  loss_cls_stage2: 0.17  loss_box_reg_stage2: 0.2753  loss_mask: 0.5226  loss_rpn_cls: 0.05991  loss_rpn_loc: 0.03281  validation_loss: 2.085  time: 1.5202  data_time: 0.0237  lr: 3.1608e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:13:56 d2.utils.events]: \u001b[0m eta: 1:37:39  iter: 6219  total_loss: 2.302  loss_cls_stage0: 0.3094  loss_box_reg_stage0: 0.2418  loss_cls_stage1: 0.2465  loss_box_reg_stage1: 0.3416  loss_cls_stage2: 0.1846  loss_box_reg_stage2: 0.2771  loss_mask: 0.5372  loss_rpn_cls: 0.07285  loss_rpn_loc: 0.03887  validation_loss: 2.085  time: 1.5204  data_time: 0.0224  lr: 3.1317e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:14:27 d2.utils.events]: \u001b[0m eta: 1:37:10  iter: 6239  total_loss: 2.121  loss_cls_stage0: 0.2911  loss_box_reg_stage0: 0.2389  loss_cls_stage1: 0.236  loss_box_reg_stage1: 0.3388  loss_cls_stage2: 0.1653  loss_box_reg_stage2: 0.2718  loss_mask: 0.5055  loss_rpn_cls: 0.05805  loss_rpn_loc: 0.03079  validation_loss: 2.085  time: 1.5205  data_time: 0.0226  lr: 3.1026e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:14:58 d2.utils.events]: \u001b[0m eta: 1:36:42  iter: 6259  total_loss: 2.393  loss_cls_stage0: 0.346  loss_box_reg_stage0: 0.2819  loss_cls_stage1: 0.2811  loss_box_reg_stage1: 0.3827  loss_cls_stage2: 0.2042  loss_box_reg_stage2: 0.298  loss_mask: 0.5365  loss_rpn_cls: 0.06592  loss_rpn_loc: 0.03971  validation_loss: 2.085  time: 1.5207  data_time: 0.0235  lr: 3.0735e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:15:30 d2.utils.events]: \u001b[0m eta: 1:36:11  iter: 6279  total_loss: 2.274  loss_cls_stage0: 0.3064  loss_box_reg_stage0: 0.2447  loss_cls_stage1: 0.2778  loss_box_reg_stage1: 0.3557  loss_cls_stage2: 0.2046  loss_box_reg_stage2: 0.2951  loss_mask: 0.5379  loss_rpn_cls: 0.06489  loss_rpn_loc: 0.03382  validation_loss: 2.085  time: 1.5208  data_time: 0.0242  lr: 3.0446e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:16:01 d2.utils.events]: \u001b[0m eta: 1:35:42  iter: 6299  total_loss: 2.582  loss_cls_stage0: 0.3846  loss_box_reg_stage0: 0.2921  loss_cls_stage1: 0.3135  loss_box_reg_stage1: 0.3827  loss_cls_stage2: 0.2041  loss_box_reg_stage2: 0.2865  loss_mask: 0.5276  loss_rpn_cls: 0.06853  loss_rpn_loc: 0.04101  validation_loss: 2.085  time: 1.5209  data_time: 0.0232  lr: 3.0157e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:16:32 d2.utils.events]: \u001b[0m eta: 1:35:11  iter: 6319  total_loss: 2.379  loss_cls_stage0: 0.3191  loss_box_reg_stage0: 0.2385  loss_cls_stage1: 0.2783  loss_box_reg_stage1: 0.3325  loss_cls_stage2: 0.1861  loss_box_reg_stage2: 0.2571  loss_mask: 0.5401  loss_rpn_cls: 0.06208  loss_rpn_loc: 0.03642  validation_loss: 2.085  time: 1.5211  data_time: 0.0249  lr: 2.9869e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:17:03 d2.utils.events]: \u001b[0m eta: 1:34:40  iter: 6339  total_loss: 2.079  loss_cls_stage0: 0.2805  loss_box_reg_stage0: 0.212  loss_cls_stage1: 0.2251  loss_box_reg_stage1: 0.3235  loss_cls_stage2: 0.1667  loss_box_reg_stage2: 0.258  loss_mask: 0.5598  loss_rpn_cls: 0.07096  loss_rpn_loc: 0.03537  validation_loss: 2.085  time: 1.5211  data_time: 0.0220  lr: 2.9582e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:17:35 d2.utils.events]: \u001b[0m eta: 1:34:09  iter: 6359  total_loss: 2.334  loss_cls_stage0: 0.3449  loss_box_reg_stage0: 0.2601  loss_cls_stage1: 0.2842  loss_box_reg_stage1: 0.3602  loss_cls_stage2: 0.1995  loss_box_reg_stage2: 0.3017  loss_mask: 0.5568  loss_rpn_cls: 0.06371  loss_rpn_loc: 0.03832  validation_loss: 2.085  time: 1.5213  data_time: 0.0243  lr: 2.9296e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:18:06 d2.utils.events]: \u001b[0m eta: 1:33:39  iter: 6379  total_loss: 2.348  loss_cls_stage0: 0.3121  loss_box_reg_stage0: 0.2628  loss_cls_stage1: 0.256  loss_box_reg_stage1: 0.3502  loss_cls_stage2: 0.188  loss_box_reg_stage2: 0.2797  loss_mask: 0.5802  loss_rpn_cls: 0.05615  loss_rpn_loc: 0.03542  validation_loss: 2.085  time: 1.5214  data_time: 0.0234  lr: 2.901e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:18:37 d2.utils.events]: \u001b[0m eta: 1:33:08  iter: 6399  total_loss: 2.307  loss_cls_stage0: 0.3332  loss_box_reg_stage0: 0.2629  loss_cls_stage1: 0.2794  loss_box_reg_stage1: 0.3529  loss_cls_stage2: 0.1814  loss_box_reg_stage2: 0.3045  loss_mask: 0.4876  loss_rpn_cls: 0.06449  loss_rpn_loc: 0.03796  validation_loss: 2.085  time: 1.5216  data_time: 0.0233  lr: 2.8725e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:19:08 d2.utils.events]: \u001b[0m eta: 1:32:39  iter: 6419  total_loss: 2.397  loss_cls_stage0: 0.3568  loss_box_reg_stage0: 0.2801  loss_cls_stage1: 0.2807  loss_box_reg_stage1: 0.3536  loss_cls_stage2: 0.2  loss_box_reg_stage2: 0.2748  loss_mask: 0.5396  loss_rpn_cls: 0.05897  loss_rpn_loc: 0.03341  validation_loss: 2.085  time: 1.5217  data_time: 0.0243  lr: 2.8441e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:19:40 d2.utils.events]: \u001b[0m eta: 1:32:09  iter: 6439  total_loss: 2.243  loss_cls_stage0: 0.3193  loss_box_reg_stage0: 0.2605  loss_cls_stage1: 0.2616  loss_box_reg_stage1: 0.3517  loss_cls_stage2: 0.1915  loss_box_reg_stage2: 0.272  loss_mask: 0.5255  loss_rpn_cls: 0.06168  loss_rpn_loc: 0.03456  validation_loss: 2.085  time: 1.5218  data_time: 0.0228  lr: 2.8158e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:20:11 d2.utils.events]: \u001b[0m eta: 1:31:39  iter: 6459  total_loss: 2.259  loss_cls_stage0: 0.3199  loss_box_reg_stage0: 0.2546  loss_cls_stage1: 0.2593  loss_box_reg_stage1: 0.3583  loss_cls_stage2: 0.1851  loss_box_reg_stage2: 0.2986  loss_mask: 0.564  loss_rpn_cls: 0.06117  loss_rpn_loc: 0.0367  validation_loss: 2.085  time: 1.5219  data_time: 0.0243  lr: 2.7876e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:20:42 d2.utils.events]: \u001b[0m eta: 1:31:09  iter: 6479  total_loss: 2.385  loss_cls_stage0: 0.3115  loss_box_reg_stage0: 0.2513  loss_cls_stage1: 0.2798  loss_box_reg_stage1: 0.3557  loss_cls_stage2: 0.1943  loss_box_reg_stage2: 0.2928  loss_mask: 0.5237  loss_rpn_cls: 0.06638  loss_rpn_loc: 0.03634  validation_loss: 2.085  time: 1.5220  data_time: 0.0229  lr: 2.7595e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:21:13 d2.utils.events]: \u001b[0m eta: 1:30:40  iter: 6499  total_loss: 2.339  loss_cls_stage0: 0.3364  loss_box_reg_stage0: 0.2761  loss_cls_stage1: 0.2799  loss_box_reg_stage1: 0.3669  loss_cls_stage2: 0.1955  loss_box_reg_stage2: 0.3017  loss_mask: 0.4959  loss_rpn_cls: 0.06483  loss_rpn_loc: 0.03717  validation_loss: 2.085  time: 1.5222  data_time: 0.0230  lr: 2.7314e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:21:45 d2.utils.events]: \u001b[0m eta: 1:30:10  iter: 6519  total_loss: 2.433  loss_cls_stage0: 0.3408  loss_box_reg_stage0: 0.2663  loss_cls_stage1: 0.2869  loss_box_reg_stage1: 0.3807  loss_cls_stage2: 0.2068  loss_box_reg_stage2: 0.2936  loss_mask: 0.5226  loss_rpn_cls: 0.06306  loss_rpn_loc: 0.03622  validation_loss: 2.085  time: 1.5223  data_time: 0.0241  lr: 2.7035e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:22:16 d2.utils.events]: \u001b[0m eta: 1:29:39  iter: 6539  total_loss: 2.276  loss_cls_stage0: 0.3052  loss_box_reg_stage0: 0.2245  loss_cls_stage1: 0.2541  loss_box_reg_stage1: 0.3264  loss_cls_stage2: 0.1828  loss_box_reg_stage2: 0.3003  loss_mask: 0.5607  loss_rpn_cls: 0.06079  loss_rpn_loc: 0.03452  validation_loss: 2.085  time: 1.5224  data_time: 0.0221  lr: 2.6756e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:22:47 d2.utils.events]: \u001b[0m eta: 1:29:08  iter: 6559  total_loss: 2.179  loss_cls_stage0: 0.3172  loss_box_reg_stage0: 0.2449  loss_cls_stage1: 0.2555  loss_box_reg_stage1: 0.3164  loss_cls_stage2: 0.1828  loss_box_reg_stage2: 0.2537  loss_mask: 0.5392  loss_rpn_cls: 0.05834  loss_rpn_loc: 0.0342  validation_loss: 2.085  time: 1.5225  data_time: 0.0238  lr: 2.6479e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:23:18 d2.utils.events]: \u001b[0m eta: 1:28:37  iter: 6579  total_loss: 2.262  loss_cls_stage0: 0.3188  loss_box_reg_stage0: 0.2508  loss_cls_stage1: 0.2741  loss_box_reg_stage1: 0.3552  loss_cls_stage2: 0.1948  loss_box_reg_stage2: 0.3005  loss_mask: 0.5563  loss_rpn_cls: 0.07283  loss_rpn_loc: 0.04213  validation_loss: 2.085  time: 1.5227  data_time: 0.0238  lr: 2.6202e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:23:50 d2.utils.events]: \u001b[0m eta: 1:28:06  iter: 6599  total_loss: 2.179  loss_cls_stage0: 0.3154  loss_box_reg_stage0: 0.2312  loss_cls_stage1: 0.2543  loss_box_reg_stage1: 0.3153  loss_cls_stage2: 0.1739  loss_box_reg_stage2: 0.2658  loss_mask: 0.5721  loss_rpn_cls: 0.05817  loss_rpn_loc: 0.03395  validation_loss: 2.085  time: 1.5228  data_time: 0.0238  lr: 2.5926e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:24:21 d2.utils.events]: \u001b[0m eta: 1:27:35  iter: 6619  total_loss: 2.235  loss_cls_stage0: 0.3113  loss_box_reg_stage0: 0.2306  loss_cls_stage1: 0.2565  loss_box_reg_stage1: 0.3183  loss_cls_stage2: 0.1879  loss_box_reg_stage2: 0.2872  loss_mask: 0.5762  loss_rpn_cls: 0.06355  loss_rpn_loc: 0.03859  validation_loss: 2.085  time: 1.5229  data_time: 0.0233  lr: 2.5651e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:24:52 d2.utils.events]: \u001b[0m eta: 1:27:05  iter: 6639  total_loss: 2.331  loss_cls_stage0: 0.3233  loss_box_reg_stage0: 0.2527  loss_cls_stage1: 0.2767  loss_box_reg_stage1: 0.3469  loss_cls_stage2: 0.1947  loss_box_reg_stage2: 0.2825  loss_mask: 0.5225  loss_rpn_cls: 0.05671  loss_rpn_loc: 0.03456  validation_loss: 2.085  time: 1.5230  data_time: 0.0233  lr: 2.5377e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:25:23 d2.utils.events]: \u001b[0m eta: 1:26:34  iter: 6659  total_loss: 2.338  loss_cls_stage0: 0.3358  loss_box_reg_stage0: 0.2487  loss_cls_stage1: 0.2822  loss_box_reg_stage1: 0.3668  loss_cls_stage2: 0.2028  loss_box_reg_stage2: 0.2949  loss_mask: 0.529  loss_rpn_cls: 0.05619  loss_rpn_loc: 0.03725  validation_loss: 2.085  time: 1.5231  data_time: 0.0228  lr: 2.5104e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:25:55 d2.utils.events]: \u001b[0m eta: 1:26:03  iter: 6679  total_loss: 2.467  loss_cls_stage0: 0.3479  loss_box_reg_stage0: 0.2696  loss_cls_stage1: 0.2789  loss_box_reg_stage1: 0.3897  loss_cls_stage2: 0.2091  loss_box_reg_stage2: 0.3133  loss_mask: 0.5202  loss_rpn_cls: 0.06393  loss_rpn_loc: 0.03699  validation_loss: 2.085  time: 1.5232  data_time: 0.0291  lr: 2.4832e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:26:26 d2.utils.events]: \u001b[0m eta: 1:25:32  iter: 6699  total_loss: 2.381  loss_cls_stage0: 0.3288  loss_box_reg_stage0: 0.27  loss_cls_stage1: 0.2663  loss_box_reg_stage1: 0.3877  loss_cls_stage2: 0.1931  loss_box_reg_stage2: 0.2927  loss_mask: 0.5327  loss_rpn_cls: 0.06126  loss_rpn_loc: 0.03421  validation_loss: 2.085  time: 1.5233  data_time: 0.0238  lr: 2.4561e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:26:57 d2.utils.events]: \u001b[0m eta: 1:25:02  iter: 6719  total_loss: 2.468  loss_cls_stage0: 0.3457  loss_box_reg_stage0: 0.2704  loss_cls_stage1: 0.2885  loss_box_reg_stage1: 0.3944  loss_cls_stage2: 0.21  loss_box_reg_stage2: 0.3223  loss_mask: 0.5384  loss_rpn_cls: 0.0708  loss_rpn_loc: 0.0393  validation_loss: 2.085  time: 1.5235  data_time: 0.0230  lr: 2.4291e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:27:29 d2.utils.events]: \u001b[0m eta: 1:24:31  iter: 6739  total_loss: 2.568  loss_cls_stage0: 0.3662  loss_box_reg_stage0: 0.2888  loss_cls_stage1: 0.316  loss_box_reg_stage1: 0.4027  loss_cls_stage2: 0.2266  loss_box_reg_stage2: 0.3183  loss_mask: 0.5397  loss_rpn_cls: 0.06598  loss_rpn_loc: 0.03923  validation_loss: 2.085  time: 1.5236  data_time: 0.0237  lr: 2.4023e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:28:00 d2.utils.events]: \u001b[0m eta: 1:24:02  iter: 6759  total_loss: 2.593  loss_cls_stage0: 0.3476  loss_box_reg_stage0: 0.273  loss_cls_stage1: 0.2881  loss_box_reg_stage1: 0.3963  loss_cls_stage2: 0.2118  loss_box_reg_stage2: 0.3063  loss_mask: 0.5604  loss_rpn_cls: 0.06244  loss_rpn_loc: 0.03793  validation_loss: 2.085  time: 1.5238  data_time: 0.0245  lr: 2.3755e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:28:31 d2.utils.events]: \u001b[0m eta: 1:23:32  iter: 6779  total_loss: 2.345  loss_cls_stage0: 0.3205  loss_box_reg_stage0: 0.2423  loss_cls_stage1: 0.2726  loss_box_reg_stage1: 0.3497  loss_cls_stage2: 0.1901  loss_box_reg_stage2: 0.2541  loss_mask: 0.5724  loss_rpn_cls: 0.06698  loss_rpn_loc: 0.03604  validation_loss: 2.085  time: 1.5239  data_time: 0.0239  lr: 2.3488e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:29:02 d2.utils.events]: \u001b[0m eta: 1:23:00  iter: 6799  total_loss: 2.197  loss_cls_stage0: 0.2993  loss_box_reg_stage0: 0.2175  loss_cls_stage1: 0.2535  loss_box_reg_stage1: 0.3306  loss_cls_stage2: 0.1875  loss_box_reg_stage2: 0.2992  loss_mask: 0.5258  loss_rpn_cls: 0.06872  loss_rpn_loc: 0.03533  validation_loss: 2.085  time: 1.5240  data_time: 0.0249  lr: 2.3222e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:29:34 d2.utils.events]: \u001b[0m eta: 1:22:30  iter: 6819  total_loss: 2.406  loss_cls_stage0: 0.33  loss_box_reg_stage0: 0.2575  loss_cls_stage1: 0.2796  loss_box_reg_stage1: 0.3786  loss_cls_stage2: 0.1963  loss_box_reg_stage2: 0.3058  loss_mask: 0.5177  loss_rpn_cls: 0.06245  loss_rpn_loc: 0.03759  validation_loss: 2.085  time: 1.5241  data_time: 0.0246  lr: 2.2957e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:30:05 d2.utils.events]: \u001b[0m eta: 1:21:58  iter: 6839  total_loss: 2.277  loss_cls_stage0: 0.3082  loss_box_reg_stage0: 0.2426  loss_cls_stage1: 0.2595  loss_box_reg_stage1: 0.3531  loss_cls_stage2: 0.1924  loss_box_reg_stage2: 0.301  loss_mask: 0.5476  loss_rpn_cls: 0.05618  loss_rpn_loc: 0.03294  validation_loss: 2.085  time: 1.5242  data_time: 0.0239  lr: 2.2693e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:30:36 d2.utils.events]: \u001b[0m eta: 1:21:28  iter: 6859  total_loss: 2.37  loss_cls_stage0: 0.338  loss_box_reg_stage0: 0.27  loss_cls_stage1: 0.2824  loss_box_reg_stage1: 0.3561  loss_cls_stage2: 0.1983  loss_box_reg_stage2: 0.2866  loss_mask: 0.5532  loss_rpn_cls: 0.06633  loss_rpn_loc: 0.03904  validation_loss: 2.085  time: 1.5243  data_time: 0.0246  lr: 2.2431e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:31:07 d2.utils.events]: \u001b[0m eta: 1:20:58  iter: 6879  total_loss: 2.402  loss_cls_stage0: 0.3533  loss_box_reg_stage0: 0.27  loss_cls_stage1: 0.2906  loss_box_reg_stage1: 0.3599  loss_cls_stage2: 0.1997  loss_box_reg_stage2: 0.2825  loss_mask: 0.5659  loss_rpn_cls: 0.06144  loss_rpn_loc: 0.03805  validation_loss: 2.085  time: 1.5244  data_time: 0.0230  lr: 2.2169e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:31:38 d2.utils.events]: \u001b[0m eta: 1:20:26  iter: 6899  total_loss: 2.147  loss_cls_stage0: 0.2979  loss_box_reg_stage0: 0.2343  loss_cls_stage1: 0.2501  loss_box_reg_stage1: 0.3366  loss_cls_stage2: 0.1746  loss_box_reg_stage2: 0.2722  loss_mask: 0.4989  loss_rpn_cls: 0.05953  loss_rpn_loc: 0.03533  validation_loss: 2.085  time: 1.5245  data_time: 0.0229  lr: 2.1909e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:32:10 d2.utils.events]: \u001b[0m eta: 1:19:54  iter: 6919  total_loss: 2.339  loss_cls_stage0: 0.3075  loss_box_reg_stage0: 0.2516  loss_cls_stage1: 0.2793  loss_box_reg_stage1: 0.3533  loss_cls_stage2: 0.1953  loss_box_reg_stage2: 0.2975  loss_mask: 0.4827  loss_rpn_cls: 0.06827  loss_rpn_loc: 0.03732  validation_loss: 2.085  time: 1.5246  data_time: 0.0239  lr: 2.1649e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:32:41 d2.utils.events]: \u001b[0m eta: 1:19:23  iter: 6939  total_loss: 2.34  loss_cls_stage0: 0.309  loss_box_reg_stage0: 0.2465  loss_cls_stage1: 0.2633  loss_box_reg_stage1: 0.3344  loss_cls_stage2: 0.1804  loss_box_reg_stage2: 0.2733  loss_mask: 0.5727  loss_rpn_cls: 0.06134  loss_rpn_loc: 0.03464  validation_loss: 2.085  time: 1.5247  data_time: 0.0237  lr: 2.1391e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:33:12 d2.utils.events]: \u001b[0m eta: 1:18:51  iter: 6959  total_loss: 2.131  loss_cls_stage0: 0.3003  loss_box_reg_stage0: 0.2376  loss_cls_stage1: 0.2348  loss_box_reg_stage1: 0.3397  loss_cls_stage2: 0.1637  loss_box_reg_stage2: 0.2599  loss_mask: 0.5075  loss_rpn_cls: 0.04757  loss_rpn_loc: 0.02826  validation_loss: 2.085  time: 1.5248  data_time: 0.0239  lr: 2.1134e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:33:43 d2.utils.events]: \u001b[0m eta: 1:18:21  iter: 6979  total_loss: 2.224  loss_cls_stage0: 0.2974  loss_box_reg_stage0: 0.2486  loss_cls_stage1: 0.2591  loss_box_reg_stage1: 0.3302  loss_cls_stage2: 0.183  loss_box_reg_stage2: 0.2724  loss_mask: 0.5225  loss_rpn_cls: 0.05032  loss_rpn_loc: 0.0313  validation_loss: 2.085  time: 1.5249  data_time: 0.0224  lr: 2.0878e-05  max_mem: 11973M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/27 00:34:17 d2.data.common]: \u001b[0mSerializing 879 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/27 00:34:17 d2.data.common]: \u001b[0mSerialized dataset takes 0.90 MiB\n",
      "\u001b[32m[03/27 00:34:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 879 images\n",
      "\u001b[32m[03/27 00:34:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/879. 0.0809 s / img. ETA=0:01:46\n",
      "\u001b[32m[03/27 00:34:24 d2.evaluation.evaluator]: \u001b[0mInference done 54/879. 0.0804 s / img. ETA=0:01:36\n",
      "\u001b[32m[03/27 00:34:29 d2.evaluation.evaluator]: \u001b[0mInference done 94/879. 0.0807 s / img. ETA=0:01:34\n",
      "\u001b[32m[03/27 00:34:34 d2.evaluation.evaluator]: \u001b[0mInference done 134/879. 0.0808 s / img. ETA=0:01:31\n",
      "\u001b[32m[03/27 00:34:39 d2.evaluation.evaluator]: \u001b[0mInference done 177/879. 0.0808 s / img. ETA=0:01:25\n",
      "\u001b[32m[03/27 00:34:44 d2.evaluation.evaluator]: \u001b[0mInference done 218/879. 0.0808 s / img. ETA=0:01:20\n",
      "\u001b[32m[03/27 00:34:49 d2.evaluation.evaluator]: \u001b[0mInference done 260/879. 0.0808 s / img. ETA=0:01:15\n",
      "\u001b[32m[03/27 00:34:54 d2.evaluation.evaluator]: \u001b[0mInference done 303/879. 0.0808 s / img. ETA=0:01:09\n",
      "\u001b[32m[03/27 00:34:59 d2.evaluation.evaluator]: \u001b[0mInference done 347/879. 0.0807 s / img. ETA=0:01:04\n",
      "\u001b[32m[03/27 00:35:04 d2.evaluation.evaluator]: \u001b[0mInference done 389/879. 0.0807 s / img. ETA=0:00:59\n",
      "\u001b[32m[03/27 00:35:09 d2.evaluation.evaluator]: \u001b[0mInference done 432/879. 0.0807 s / img. ETA=0:00:53\n",
      "\u001b[32m[03/27 00:35:14 d2.evaluation.evaluator]: \u001b[0mInference done 475/879. 0.0807 s / img. ETA=0:00:48\n",
      "\u001b[32m[03/27 00:35:19 d2.evaluation.evaluator]: \u001b[0mInference done 518/879. 0.0807 s / img. ETA=0:00:43\n",
      "\u001b[32m[03/27 00:35:24 d2.evaluation.evaluator]: \u001b[0mInference done 559/879. 0.0807 s / img. ETA=0:00:38\n",
      "\u001b[32m[03/27 00:35:29 d2.evaluation.evaluator]: \u001b[0mInference done 600/879. 0.0807 s / img. ETA=0:00:33\n",
      "\u001b[32m[03/27 00:35:34 d2.evaluation.evaluator]: \u001b[0mInference done 645/879. 0.0807 s / img. ETA=0:00:27\n",
      "\u001b[32m[03/27 00:35:40 d2.evaluation.evaluator]: \u001b[0mInference done 688/879. 0.0807 s / img. ETA=0:00:22\n",
      "\u001b[32m[03/27 00:35:45 d2.evaluation.evaluator]: \u001b[0mInference done 731/879. 0.0807 s / img. ETA=0:00:17\n",
      "\u001b[32m[03/27 00:35:50 d2.evaluation.evaluator]: \u001b[0mInference done 773/879. 0.0807 s / img. ETA=0:00:12\n",
      "\u001b[32m[03/27 00:35:55 d2.evaluation.evaluator]: \u001b[0mInference done 814/879. 0.0807 s / img. ETA=0:00:07\n",
      "\u001b[32m[03/27 00:36:00 d2.evaluation.evaluator]: \u001b[0mInference done 858/879. 0.0807 s / img. ETA=0:00:02\n",
      "\u001b[32m[03/27 00:36:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:44.317066 (0.119356 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/27 00:36:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:10 (0.080670 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.48 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.085\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.137\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.153\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.042\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.089\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.133\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.172\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.173\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.058\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.192\n",
      "\u001b[32m[03/27 00:36:03 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold3 in csv format:\n",
      "\u001b[32m[03/27 00:36:03 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/27 00:36:03 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/27 00:36:03 d2.evaluation.testing]: \u001b[0mcopypaste: 8.5350,13.7208,15.2699,0.6807,4.2171,8.9013\n",
      "validation do loss eval 2.368979764326165\n",
      "\u001b[32m[03/27 00:37:34 d2.utils.events]: \u001b[0m eta: 1:17:49  iter: 6999  total_loss: 2.492  loss_cls_stage0: 0.3487  loss_box_reg_stage0: 0.2651  loss_cls_stage1: 0.2983  loss_box_reg_stage1: 0.3951  loss_cls_stage2: 0.2123  loss_box_reg_stage2: 0.3043  loss_mask: 0.5425  loss_rpn_cls: 0.06629  loss_rpn_loc: 0.04176  validation_loss: 2.11  time: 1.5250  data_time: 0.0230  lr: 2.0623e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:38:05 d2.utils.events]: \u001b[0m eta: 1:17:18  iter: 7019  total_loss: 2.401  loss_cls_stage0: 0.3471  loss_box_reg_stage0: 0.275  loss_cls_stage1: 0.2847  loss_box_reg_stage1: 0.3648  loss_cls_stage2: 0.2076  loss_box_reg_stage2: 0.3024  loss_mask: 0.5438  loss_rpn_cls: 0.06533  loss_rpn_loc: 0.03861  validation_loss: 2.11  time: 1.5250  data_time: 0.0226  lr: 2.037e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:38:36 d2.utils.events]: \u001b[0m eta: 1:16:48  iter: 7039  total_loss: 2.479  loss_cls_stage0: 0.3515  loss_box_reg_stage0: 0.2627  loss_cls_stage1: 0.2891  loss_box_reg_stage1: 0.3797  loss_cls_stage2: 0.1982  loss_box_reg_stage2: 0.2934  loss_mask: 0.5657  loss_rpn_cls: 0.06883  loss_rpn_loc: 0.03852  validation_loss: 2.11  time: 1.5252  data_time: 0.0239  lr: 2.0117e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:39:08 d2.utils.events]: \u001b[0m eta: 1:16:17  iter: 7059  total_loss: 2.37  loss_cls_stage0: 0.3348  loss_box_reg_stage0: 0.2612  loss_cls_stage1: 0.2725  loss_box_reg_stage1: 0.3765  loss_cls_stage2: 0.1961  loss_box_reg_stage2: 0.3157  loss_mask: 0.5374  loss_rpn_cls: 0.0619  loss_rpn_loc: 0.03579  validation_loss: 2.11  time: 1.5253  data_time: 0.0227  lr: 1.9866e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:39:39 d2.utils.events]: \u001b[0m eta: 1:15:46  iter: 7079  total_loss: 2.321  loss_cls_stage0: 0.3343  loss_box_reg_stage0: 0.2631  loss_cls_stage1: 0.282  loss_box_reg_stage1: 0.3659  loss_cls_stage2: 0.1987  loss_box_reg_stage2: 0.2904  loss_mask: 0.5091  loss_rpn_cls: 0.05679  loss_rpn_loc: 0.03453  validation_loss: 2.11  time: 1.5254  data_time: 0.0225  lr: 1.9616e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:40:10 d2.utils.events]: \u001b[0m eta: 1:15:15  iter: 7099  total_loss: 2.381  loss_cls_stage0: 0.3321  loss_box_reg_stage0: 0.263  loss_cls_stage1: 0.2887  loss_box_reg_stage1: 0.3571  loss_cls_stage2: 0.2093  loss_box_reg_stage2: 0.2808  loss_mask: 0.5043  loss_rpn_cls: 0.06891  loss_rpn_loc: 0.03943  validation_loss: 2.11  time: 1.5255  data_time: 0.0233  lr: 1.9367e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:40:41 d2.utils.events]: \u001b[0m eta: 1:14:45  iter: 7119  total_loss: 2.358  loss_cls_stage0: 0.3202  loss_box_reg_stage0: 0.2511  loss_cls_stage1: 0.2763  loss_box_reg_stage1: 0.3493  loss_cls_stage2: 0.1842  loss_box_reg_stage2: 0.2783  loss_mask: 0.5277  loss_rpn_cls: 0.06143  loss_rpn_loc: 0.03643  validation_loss: 2.11  time: 1.5256  data_time: 0.0238  lr: 1.9119e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:41:13 d2.utils.events]: \u001b[0m eta: 1:14:14  iter: 7139  total_loss: 2.52  loss_cls_stage0: 0.3431  loss_box_reg_stage0: 0.2644  loss_cls_stage1: 0.2831  loss_box_reg_stage1: 0.3794  loss_cls_stage2: 0.1968  loss_box_reg_stage2: 0.292  loss_mask: 0.5483  loss_rpn_cls: 0.0718  loss_rpn_loc: 0.04291  validation_loss: 2.11  time: 1.5257  data_time: 0.0243  lr: 1.8873e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:41:44 d2.utils.events]: \u001b[0m eta: 1:13:43  iter: 7159  total_loss: 2.389  loss_cls_stage0: 0.3452  loss_box_reg_stage0: 0.248  loss_cls_stage1: 0.2893  loss_box_reg_stage1: 0.3647  loss_cls_stage2: 0.2086  loss_box_reg_stage2: 0.2963  loss_mask: 0.5341  loss_rpn_cls: 0.06253  loss_rpn_loc: 0.03519  validation_loss: 2.11  time: 1.5258  data_time: 0.0238  lr: 1.8628e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:42:15 d2.utils.events]: \u001b[0m eta: 1:13:14  iter: 7179  total_loss: 2.459  loss_cls_stage0: 0.3467  loss_box_reg_stage0: 0.2661  loss_cls_stage1: 0.2939  loss_box_reg_stage1: 0.3744  loss_cls_stage2: 0.2164  loss_box_reg_stage2: 0.3123  loss_mask: 0.4995  loss_rpn_cls: 0.07269  loss_rpn_loc: 0.04587  validation_loss: 2.11  time: 1.5259  data_time: 0.0235  lr: 1.8384e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:42:47 d2.utils.events]: \u001b[0m eta: 1:12:43  iter: 7199  total_loss: 2.361  loss_cls_stage0: 0.3442  loss_box_reg_stage0: 0.2672  loss_cls_stage1: 0.2829  loss_box_reg_stage1: 0.3727  loss_cls_stage2: 0.2032  loss_box_reg_stage2: 0.3019  loss_mask: 0.526  loss_rpn_cls: 0.06057  loss_rpn_loc: 0.03654  validation_loss: 2.11  time: 1.5260  data_time: 0.0239  lr: 1.8141e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:43:18 d2.utils.events]: \u001b[0m eta: 1:12:12  iter: 7219  total_loss: 2.302  loss_cls_stage0: 0.3246  loss_box_reg_stage0: 0.2541  loss_cls_stage1: 0.2597  loss_box_reg_stage1: 0.3408  loss_cls_stage2: 0.1953  loss_box_reg_stage2: 0.2961  loss_mask: 0.5122  loss_rpn_cls: 0.06854  loss_rpn_loc: 0.03755  validation_loss: 2.11  time: 1.5261  data_time: 0.0245  lr: 1.7899e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:43:49 d2.utils.events]: \u001b[0m eta: 1:11:42  iter: 7239  total_loss: 2.225  loss_cls_stage0: 0.3284  loss_box_reg_stage0: 0.2585  loss_cls_stage1: 0.2746  loss_box_reg_stage1: 0.3299  loss_cls_stage2: 0.193  loss_box_reg_stage2: 0.2783  loss_mask: 0.5806  loss_rpn_cls: 0.06827  loss_rpn_loc: 0.03867  validation_loss: 2.11  time: 1.5262  data_time: 0.0238  lr: 1.7659e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:44:21 d2.utils.events]: \u001b[0m eta: 1:11:10  iter: 7259  total_loss: 2.362  loss_cls_stage0: 0.3386  loss_box_reg_stage0: 0.2694  loss_cls_stage1: 0.264  loss_box_reg_stage1: 0.3491  loss_cls_stage2: 0.1827  loss_box_reg_stage2: 0.2908  loss_mask: 0.5384  loss_rpn_cls: 0.06471  loss_rpn_loc: 0.03304  validation_loss: 2.11  time: 1.5263  data_time: 0.0230  lr: 1.742e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:44:52 d2.utils.events]: \u001b[0m eta: 1:10:39  iter: 7279  total_loss: 2.41  loss_cls_stage0: 0.3254  loss_box_reg_stage0: 0.2546  loss_cls_stage1: 0.257  loss_box_reg_stage1: 0.3617  loss_cls_stage2: 0.1813  loss_box_reg_stage2: 0.2925  loss_mask: 0.5873  loss_rpn_cls: 0.06458  loss_rpn_loc: 0.03456  validation_loss: 2.11  time: 1.5264  data_time: 0.0246  lr: 1.7183e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:45:23 d2.utils.events]: \u001b[0m eta: 1:10:07  iter: 7299  total_loss: 2.277  loss_cls_stage0: 0.3509  loss_box_reg_stage0: 0.2671  loss_cls_stage1: 0.2902  loss_box_reg_stage1: 0.3811  loss_cls_stage2: 0.2073  loss_box_reg_stage2: 0.3288  loss_mask: 0.4959  loss_rpn_cls: 0.05964  loss_rpn_loc: 0.03564  validation_loss: 2.11  time: 1.5266  data_time: 0.0230  lr: 1.6946e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:45:54 d2.utils.events]: \u001b[0m eta: 1:09:36  iter: 7319  total_loss: 2.17  loss_cls_stage0: 0.3018  loss_box_reg_stage0: 0.2415  loss_cls_stage1: 0.2397  loss_box_reg_stage1: 0.3241  loss_cls_stage2: 0.1736  loss_box_reg_stage2: 0.2578  loss_mask: 0.5079  loss_rpn_cls: 0.05982  loss_rpn_loc: 0.03312  validation_loss: 2.11  time: 1.5266  data_time: 0.0237  lr: 1.6711e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:46:26 d2.utils.events]: \u001b[0m eta: 1:09:07  iter: 7339  total_loss: 2.437  loss_cls_stage0: 0.369  loss_box_reg_stage0: 0.3047  loss_cls_stage1: 0.2918  loss_box_reg_stage1: 0.3974  loss_cls_stage2: 0.1954  loss_box_reg_stage2: 0.303  loss_mask: 0.4887  loss_rpn_cls: 0.06087  loss_rpn_loc: 0.03611  validation_loss: 2.11  time: 1.5267  data_time: 0.0236  lr: 1.6477e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:46:57 d2.utils.events]: \u001b[0m eta: 1:08:36  iter: 7359  total_loss: 2.41  loss_cls_stage0: 0.3302  loss_box_reg_stage0: 0.259  loss_cls_stage1: 0.2809  loss_box_reg_stage1: 0.3786  loss_cls_stage2: 0.1954  loss_box_reg_stage2: 0.3024  loss_mask: 0.5724  loss_rpn_cls: 0.06043  loss_rpn_loc: 0.0375  validation_loss: 2.11  time: 1.5269  data_time: 0.0227  lr: 1.6245e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:47:28 d2.utils.events]: \u001b[0m eta: 1:08:04  iter: 7379  total_loss: 2.199  loss_cls_stage0: 0.3095  loss_box_reg_stage0: 0.2525  loss_cls_stage1: 0.2477  loss_box_reg_stage1: 0.3312  loss_cls_stage2: 0.1771  loss_box_reg_stage2: 0.2731  loss_mask: 0.5155  loss_rpn_cls: 0.05514  loss_rpn_loc: 0.03606  validation_loss: 2.11  time: 1.5269  data_time: 0.0235  lr: 1.6014e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:47:59 d2.utils.events]: \u001b[0m eta: 1:07:32  iter: 7399  total_loss: 2.24  loss_cls_stage0: 0.3067  loss_box_reg_stage0: 0.2405  loss_cls_stage1: 0.2556  loss_box_reg_stage1: 0.3384  loss_cls_stage2: 0.1964  loss_box_reg_stage2: 0.2904  loss_mask: 0.4654  loss_rpn_cls: 0.05842  loss_rpn_loc: 0.03528  validation_loss: 2.11  time: 1.5270  data_time: 0.0237  lr: 1.5784e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:48:30 d2.utils.events]: \u001b[0m eta: 1:07:00  iter: 7419  total_loss: 2.013  loss_cls_stage0: 0.2476  loss_box_reg_stage0: 0.2161  loss_cls_stage1: 0.2073  loss_box_reg_stage1: 0.3037  loss_cls_stage2: 0.1668  loss_box_reg_stage2: 0.2765  loss_mask: 0.5494  loss_rpn_cls: 0.05265  loss_rpn_loc: 0.03436  validation_loss: 2.11  time: 1.5271  data_time: 0.0238  lr: 1.5556e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:49:02 d2.utils.events]: \u001b[0m eta: 1:06:29  iter: 7439  total_loss: 2.492  loss_cls_stage0: 0.3553  loss_box_reg_stage0: 0.2523  loss_cls_stage1: 0.295  loss_box_reg_stage1: 0.3737  loss_cls_stage2: 0.2002  loss_box_reg_stage2: 0.3279  loss_mask: 0.5822  loss_rpn_cls: 0.06369  loss_rpn_loc: 0.03945  validation_loss: 2.11  time: 1.5272  data_time: 0.0233  lr: 1.5329e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:49:33 d2.utils.events]: \u001b[0m eta: 1:05:58  iter: 7459  total_loss: 2.364  loss_cls_stage0: 0.3387  loss_box_reg_stage0: 0.2609  loss_cls_stage1: 0.2951  loss_box_reg_stage1: 0.362  loss_cls_stage2: 0.2053  loss_box_reg_stage2: 0.2774  loss_mask: 0.4972  loss_rpn_cls: 0.05946  loss_rpn_loc: 0.03534  validation_loss: 2.11  time: 1.5273  data_time: 0.0225  lr: 1.5103e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:50:04 d2.utils.events]: \u001b[0m eta: 1:05:27  iter: 7479  total_loss: 2.441  loss_cls_stage0: 0.3489  loss_box_reg_stage0: 0.2867  loss_cls_stage1: 0.2923  loss_box_reg_stage1: 0.3699  loss_cls_stage2: 0.1975  loss_box_reg_stage2: 0.3228  loss_mask: 0.5594  loss_rpn_cls: 0.05422  loss_rpn_loc: 0.03738  validation_loss: 2.11  time: 1.5274  data_time: 0.0239  lr: 1.4879e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:50:36 d2.utils.events]: \u001b[0m eta: 1:04:55  iter: 7499  total_loss: 2.362  loss_cls_stage0: 0.3408  loss_box_reg_stage0: 0.2593  loss_cls_stage1: 0.288  loss_box_reg_stage1: 0.3656  loss_cls_stage2: 0.1938  loss_box_reg_stage2: 0.2734  loss_mask: 0.5231  loss_rpn_cls: 0.06536  loss_rpn_loc: 0.03614  validation_loss: 2.11  time: 1.5275  data_time: 0.0238  lr: 1.4656e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:51:07 d2.utils.events]: \u001b[0m eta: 1:04:24  iter: 7519  total_loss: 2.125  loss_cls_stage0: 0.296  loss_box_reg_stage0: 0.2184  loss_cls_stage1: 0.2368  loss_box_reg_stage1: 0.3134  loss_cls_stage2: 0.1695  loss_box_reg_stage2: 0.266  loss_mask: 0.5073  loss_rpn_cls: 0.07152  loss_rpn_loc: 0.03512  validation_loss: 2.11  time: 1.5276  data_time: 0.0228  lr: 1.4434e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:51:38 d2.utils.events]: \u001b[0m eta: 1:03:53  iter: 7539  total_loss: 2.448  loss_cls_stage0: 0.3391  loss_box_reg_stage0: 0.274  loss_cls_stage1: 0.2967  loss_box_reg_stage1: 0.3747  loss_cls_stage2: 0.2108  loss_box_reg_stage2: 0.3165  loss_mask: 0.5336  loss_rpn_cls: 0.05941  loss_rpn_loc: 0.03526  validation_loss: 2.11  time: 1.5277  data_time: 0.0221  lr: 1.4214e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:52:10 d2.utils.events]: \u001b[0m eta: 1:03:22  iter: 7559  total_loss: 2.37  loss_cls_stage0: 0.3425  loss_box_reg_stage0: 0.26  loss_cls_stage1: 0.2718  loss_box_reg_stage1: 0.3482  loss_cls_stage2: 0.1898  loss_box_reg_stage2: 0.2706  loss_mask: 0.5561  loss_rpn_cls: 0.07108  loss_rpn_loc: 0.04029  validation_loss: 2.11  time: 1.5278  data_time: 0.0251  lr: 1.3995e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:52:41 d2.utils.events]: \u001b[0m eta: 1:02:51  iter: 7579  total_loss: 2.443  loss_cls_stage0: 0.3395  loss_box_reg_stage0: 0.282  loss_cls_stage1: 0.2866  loss_box_reg_stage1: 0.3751  loss_cls_stage2: 0.1992  loss_box_reg_stage2: 0.2965  loss_mask: 0.5339  loss_rpn_cls: 0.05833  loss_rpn_loc: 0.0351  validation_loss: 2.11  time: 1.5279  data_time: 0.0314  lr: 1.3778e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:53:12 d2.utils.events]: \u001b[0m eta: 1:02:20  iter: 7599  total_loss: 2.204  loss_cls_stage0: 0.3034  loss_box_reg_stage0: 0.2286  loss_cls_stage1: 0.2641  loss_box_reg_stage1: 0.3207  loss_cls_stage2: 0.1739  loss_box_reg_stage2: 0.2729  loss_mask: 0.5101  loss_rpn_cls: 0.05799  loss_rpn_loc: 0.03169  validation_loss: 2.11  time: 1.5279  data_time: 0.0228  lr: 1.3562e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:53:43 d2.utils.events]: \u001b[0m eta: 1:01:50  iter: 7619  total_loss: 2.326  loss_cls_stage0: 0.3326  loss_box_reg_stage0: 0.2668  loss_cls_stage1: 0.2895  loss_box_reg_stage1: 0.3707  loss_cls_stage2: 0.2068  loss_box_reg_stage2: 0.3047  loss_mask: 0.4823  loss_rpn_cls: 0.05267  loss_rpn_loc: 0.03387  validation_loss: 2.11  time: 1.5280  data_time: 0.0221  lr: 1.3348e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:54:15 d2.utils.events]: \u001b[0m eta: 1:01:19  iter: 7639  total_loss: 2.302  loss_cls_stage0: 0.2984  loss_box_reg_stage0: 0.2398  loss_cls_stage1: 0.2585  loss_box_reg_stage1: 0.3521  loss_cls_stage2: 0.1945  loss_box_reg_stage2: 0.2887  loss_mask: 0.5163  loss_rpn_cls: 0.0553  loss_rpn_loc: 0.03431  validation_loss: 2.11  time: 1.5281  data_time: 0.0229  lr: 1.3135e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:54:46 d2.utils.events]: \u001b[0m eta: 1:00:48  iter: 7659  total_loss: 2.369  loss_cls_stage0: 0.3567  loss_box_reg_stage0: 0.2662  loss_cls_stage1: 0.2867  loss_box_reg_stage1: 0.3622  loss_cls_stage2: 0.2099  loss_box_reg_stage2: 0.2988  loss_mask: 0.4673  loss_rpn_cls: 0.06296  loss_rpn_loc: 0.03299  validation_loss: 2.11  time: 1.5282  data_time: 0.0240  lr: 1.2923e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:55:17 d2.utils.events]: \u001b[0m eta: 1:00:17  iter: 7679  total_loss: 2.432  loss_cls_stage0: 0.3359  loss_box_reg_stage0: 0.2665  loss_cls_stage1: 0.2769  loss_box_reg_stage1: 0.3625  loss_cls_stage2: 0.2042  loss_box_reg_stage2: 0.3002  loss_mask: 0.5261  loss_rpn_cls: 0.07082  loss_rpn_loc: 0.04354  validation_loss: 2.11  time: 1.5283  data_time: 0.0243  lr: 1.2713e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:55:48 d2.utils.events]: \u001b[0m eta: 0:59:44  iter: 7699  total_loss: 2.142  loss_cls_stage0: 0.2894  loss_box_reg_stage0: 0.2247  loss_cls_stage1: 0.2543  loss_box_reg_stage1: 0.3337  loss_cls_stage2: 0.1675  loss_box_reg_stage2: 0.2853  loss_mask: 0.4598  loss_rpn_cls: 0.05884  loss_rpn_loc: 0.02935  validation_loss: 2.11  time: 1.5284  data_time: 0.0242  lr: 1.2505e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:56:20 d2.utils.events]: \u001b[0m eta: 0:59:12  iter: 7719  total_loss: 2.349  loss_cls_stage0: 0.3025  loss_box_reg_stage0: 0.2445  loss_cls_stage1: 0.2633  loss_box_reg_stage1: 0.3585  loss_cls_stage2: 0.1856  loss_box_reg_stage2: 0.2996  loss_mask: 0.5391  loss_rpn_cls: 0.06577  loss_rpn_loc: 0.04083  validation_loss: 2.11  time: 1.5284  data_time: 0.0241  lr: 1.2298e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:56:51 d2.utils.events]: \u001b[0m eta: 0:58:41  iter: 7739  total_loss: 2.076  loss_cls_stage0: 0.3094  loss_box_reg_stage0: 0.2462  loss_cls_stage1: 0.2465  loss_box_reg_stage1: 0.3275  loss_cls_stage2: 0.1773  loss_box_reg_stage2: 0.2956  loss_mask: 0.4328  loss_rpn_cls: 0.05564  loss_rpn_loc: 0.03578  validation_loss: 2.11  time: 1.5285  data_time: 0.0241  lr: 1.2092e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:57:22 d2.utils.events]: \u001b[0m eta: 0:58:09  iter: 7759  total_loss: 2.429  loss_cls_stage0: 0.3178  loss_box_reg_stage0: 0.254  loss_cls_stage1: 0.2716  loss_box_reg_stage1: 0.3829  loss_cls_stage2: 0.2077  loss_box_reg_stage2: 0.313  loss_mask: 0.5314  loss_rpn_cls: 0.06054  loss_rpn_loc: 0.03432  validation_loss: 2.11  time: 1.5286  data_time: 0.0239  lr: 1.1888e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:57:54 d2.utils.events]: \u001b[0m eta: 0:57:38  iter: 7779  total_loss: 2.378  loss_cls_stage0: 0.3283  loss_box_reg_stage0: 0.2603  loss_cls_stage1: 0.2778  loss_box_reg_stage1: 0.3882  loss_cls_stage2: 0.194  loss_box_reg_stage2: 0.2985  loss_mask: 0.5718  loss_rpn_cls: 0.05869  loss_rpn_loc: 0.03792  validation_loss: 2.11  time: 1.5287  data_time: 0.0242  lr: 1.1685e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:58:25 d2.utils.events]: \u001b[0m eta: 0:57:07  iter: 7799  total_loss: 2.251  loss_cls_stage0: 0.3128  loss_box_reg_stage0: 0.239  loss_cls_stage1: 0.2566  loss_box_reg_stage1: 0.3287  loss_cls_stage2: 0.1911  loss_box_reg_stage2: 0.306  loss_mask: 0.4919  loss_rpn_cls: 0.06047  loss_rpn_loc: 0.03381  validation_loss: 2.11  time: 1.5288  data_time: 0.0243  lr: 1.1484e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:58:56 d2.utils.events]: \u001b[0m eta: 0:56:36  iter: 7819  total_loss: 2.374  loss_cls_stage0: 0.3416  loss_box_reg_stage0: 0.2568  loss_cls_stage1: 0.2813  loss_box_reg_stage1: 0.3564  loss_cls_stage2: 0.2054  loss_box_reg_stage2: 0.2895  loss_mask: 0.5113  loss_rpn_cls: 0.05644  loss_rpn_loc: 0.03447  validation_loss: 2.11  time: 1.5289  data_time: 0.0230  lr: 1.1285e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:59:27 d2.utils.events]: \u001b[0m eta: 0:56:05  iter: 7839  total_loss: 2.219  loss_cls_stage0: 0.2953  loss_box_reg_stage0: 0.217  loss_cls_stage1: 0.2474  loss_box_reg_stage1: 0.3464  loss_cls_stage2: 0.1726  loss_box_reg_stage2: 0.2813  loss_mask: 0.5456  loss_rpn_cls: 0.06475  loss_rpn_loc: 0.03329  validation_loss: 2.11  time: 1.5290  data_time: 0.0236  lr: 1.1087e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 00:59:58 d2.utils.events]: \u001b[0m eta: 0:55:34  iter: 7859  total_loss: 2.272  loss_cls_stage0: 0.3304  loss_box_reg_stage0: 0.2465  loss_cls_stage1: 0.2789  loss_box_reg_stage1: 0.3498  loss_cls_stage2: 0.1967  loss_box_reg_stage2: 0.286  loss_mask: 0.5267  loss_rpn_cls: 0.06549  loss_rpn_loc: 0.03644  validation_loss: 2.11  time: 1.5290  data_time: 0.0243  lr: 1.089e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 01:00:29 d2.utils.events]: \u001b[0m eta: 0:55:02  iter: 7879  total_loss: 2.138  loss_cls_stage0: 0.2883  loss_box_reg_stage0: 0.2364  loss_cls_stage1: 0.2429  loss_box_reg_stage1: 0.3197  loss_cls_stage2: 0.1782  loss_box_reg_stage2: 0.2786  loss_mask: 0.4944  loss_rpn_cls: 0.05431  loss_rpn_loc: 0.03576  validation_loss: 2.11  time: 1.5291  data_time: 0.0241  lr: 1.0695e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 01:01:01 d2.utils.events]: \u001b[0m eta: 0:54:31  iter: 7899  total_loss: 2.271  loss_cls_stage0: 0.3177  loss_box_reg_stage0: 0.2706  loss_cls_stage1: 0.2522  loss_box_reg_stage1: 0.353  loss_cls_stage2: 0.1773  loss_box_reg_stage2: 0.2957  loss_mask: 0.4919  loss_rpn_cls: 0.0569  loss_rpn_loc: 0.03735  validation_loss: 2.11  time: 1.5292  data_time: 0.0245  lr: 1.0502e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 01:01:32 d2.utils.events]: \u001b[0m eta: 0:54:00  iter: 7919  total_loss: 2.451  loss_cls_stage0: 0.3394  loss_box_reg_stage0: 0.275  loss_cls_stage1: 0.2692  loss_box_reg_stage1: 0.3796  loss_cls_stage2: 0.1938  loss_box_reg_stage2: 0.3115  loss_mask: 0.569  loss_rpn_cls: 0.06089  loss_rpn_loc: 0.03442  validation_loss: 2.11  time: 1.5293  data_time: 0.0237  lr: 1.031e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 01:02:03 d2.utils.events]: \u001b[0m eta: 0:53:29  iter: 7939  total_loss: 2.203  loss_cls_stage0: 0.2882  loss_box_reg_stage0: 0.2341  loss_cls_stage1: 0.2663  loss_box_reg_stage1: 0.3372  loss_cls_stage2: 0.1873  loss_box_reg_stage2: 0.2988  loss_mask: 0.5101  loss_rpn_cls: 0.05661  loss_rpn_loc: 0.03581  validation_loss: 2.11  time: 1.5293  data_time: 0.0231  lr: 1.012e-05  max_mem: 11973M\n",
      "\u001b[32m[03/27 01:02:34 d2.utils.events]: \u001b[0m eta: 0:52:58  iter: 7959  total_loss: 2.463  loss_cls_stage0: 0.3726  loss_box_reg_stage0: 0.2742  loss_cls_stage1: 0.3105  loss_box_reg_stage1: 0.3702  loss_cls_stage2: 0.2179  loss_box_reg_stage2: 0.2935  loss_mask: 0.593  loss_rpn_cls: 0.06409  loss_rpn_loc: 0.03723  validation_loss: 2.11  time: 1.5294  data_time: 0.0226  lr: 9.931e-06  max_mem: 11973M\n",
      "\u001b[32m[03/27 01:03:06 d2.utils.events]: \u001b[0m eta: 0:52:27  iter: 7979  total_loss: 2.361  loss_cls_stage0: 0.3318  loss_box_reg_stage0: 0.2674  loss_cls_stage1: 0.2741  loss_box_reg_stage1: 0.3719  loss_cls_stage2: 0.1986  loss_box_reg_stage2: 0.2876  loss_mask: 0.5161  loss_rpn_cls: 0.06  loss_rpn_loc: 0.03595  validation_loss: 2.11  time: 1.5295  data_time: 0.0234  lr: 9.7439e-06  max_mem: 11973M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/27 01:03:39 d2.data.common]: \u001b[0mSerializing 879 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/27 01:03:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.90 MiB\n",
      "\u001b[32m[03/27 01:03:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 879 images\n",
      "\u001b[32m[03/27 01:03:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/879. 0.0810 s / img. ETA=0:01:48\n",
      "\u001b[32m[03/27 01:03:46 d2.evaluation.evaluator]: \u001b[0mInference done 54/879. 0.0808 s / img. ETA=0:01:37\n",
      "\u001b[32m[03/27 01:03:51 d2.evaluation.evaluator]: \u001b[0mInference done 94/879. 0.0811 s / img. ETA=0:01:36\n",
      "\u001b[32m[03/27 01:03:56 d2.evaluation.evaluator]: \u001b[0mInference done 134/879. 0.0812 s / img. ETA=0:01:32\n",
      "\u001b[32m[03/27 01:04:01 d2.evaluation.evaluator]: \u001b[0mInference done 176/879. 0.0811 s / img. ETA=0:01:26\n",
      "\u001b[32m[03/27 01:04:06 d2.evaluation.evaluator]: \u001b[0mInference done 216/879. 0.0812 s / img. ETA=0:01:21\n",
      "\u001b[32m[03/27 01:04:11 d2.evaluation.evaluator]: \u001b[0mInference done 257/879. 0.0812 s / img. ETA=0:01:17\n",
      "\u001b[32m[03/27 01:04:16 d2.evaluation.evaluator]: \u001b[0mInference done 298/879. 0.0812 s / img. ETA=0:01:11\n",
      "\u001b[32m[03/27 01:04:22 d2.evaluation.evaluator]: \u001b[0mInference done 340/879. 0.0812 s / img. ETA=0:01:06\n",
      "\u001b[32m[03/27 01:04:27 d2.evaluation.evaluator]: \u001b[0mInference done 382/879. 0.0812 s / img. ETA=0:01:01\n",
      "\u001b[32m[03/27 01:04:32 d2.evaluation.evaluator]: \u001b[0mInference done 424/879. 0.0811 s / img. ETA=0:00:55\n",
      "\u001b[32m[03/27 01:04:37 d2.evaluation.evaluator]: \u001b[0mInference done 465/879. 0.0811 s / img. ETA=0:00:50\n",
      "\u001b[32m[03/27 01:04:42 d2.evaluation.evaluator]: \u001b[0mInference done 510/879. 0.0811 s / img. ETA=0:00:44\n",
      "\u001b[32m[03/27 01:04:47 d2.evaluation.evaluator]: \u001b[0mInference done 550/879. 0.0811 s / img. ETA=0:00:40\n",
      "\u001b[32m[03/27 01:04:52 d2.evaluation.evaluator]: \u001b[0mInference done 590/879. 0.0811 s / img. ETA=0:00:35\n",
      "\u001b[32m[03/27 01:04:57 d2.evaluation.evaluator]: \u001b[0mInference done 633/879. 0.0811 s / img. ETA=0:00:30\n",
      "\u001b[32m[03/27 01:05:02 d2.evaluation.evaluator]: \u001b[0mInference done 674/879. 0.0811 s / img. ETA=0:00:25\n",
      "\u001b[32m[03/27 01:05:07 d2.evaluation.evaluator]: \u001b[0mInference done 717/879. 0.0811 s / img. ETA=0:00:19\n",
      "\u001b[32m[03/27 01:05:12 d2.evaluation.evaluator]: \u001b[0mInference done 758/879. 0.0813 s / img. ETA=0:00:14\n",
      "\u001b[32m[03/27 01:05:17 d2.evaluation.evaluator]: \u001b[0mInference done 797/879. 0.0813 s / img. ETA=0:00:10\n",
      "\u001b[32m[03/27 01:05:22 d2.evaluation.evaluator]: \u001b[0mInference done 840/879. 0.0812 s / img. ETA=0:00:04\n",
      "\u001b[32m[03/27 01:05:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:46.682131 (0.122062 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/27 01:05:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:10 (0.081214 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.31 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.088\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.142\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.159\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.044\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.093\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.138\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.183\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.184\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.059\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.206\n",
      "\u001b[32m[03/27 01:05:28 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold3 in csv format:\n",
      "\u001b[32m[03/27 01:05:28 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/27 01:05:28 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/27 01:05:28 d2.evaluation.testing]: \u001b[0mcopypaste: 8.8154,14.2402,15.9176,0.8868,4.3522,9.2608\n",
      "validation do loss eval 2.360127322662442\n",
      "\u001b[32m[03/27 01:06:59 d2.utils.events]: \u001b[0m eta: 0:51:56  iter: 7999  total_loss: 2.411  loss_cls_stage0: 0.3298  loss_box_reg_stage0: 0.2824  loss_cls_stage1: 0.2763  loss_box_reg_stage1: 0.3867  loss_cls_stage2: 0.189  loss_box_reg_stage2: 0.2961  loss_mask: 0.5171  loss_rpn_cls: 0.06611  loss_rpn_loc: 0.03736  validation_loss: 2.177  time: 1.5296  data_time: 0.0238  lr: 9.5584e-06  max_mem: 11973M\n",
      "\u001b[32m[03/27 01:07:30 d2.utils.events]: \u001b[0m eta: 0:51:25  iter: 8019  total_loss: 2.377  loss_cls_stage0: 0.3623  loss_box_reg_stage0: 0.2807  loss_cls_stage1: 0.2984  loss_box_reg_stage1: 0.3833  loss_cls_stage2: 0.1976  loss_box_reg_stage2: 0.3057  loss_mask: 0.5502  loss_rpn_cls: 0.05987  loss_rpn_loc: 0.0345  validation_loss: 2.177  time: 1.5297  data_time: 0.0249  lr: 9.3744e-06  max_mem: 11973M\n",
      "\u001b[32m[03/27 01:08:01 d2.utils.events]: \u001b[0m eta: 0:50:53  iter: 8039  total_loss: 2.284  loss_cls_stage0: 0.3276  loss_box_reg_stage0: 0.2357  loss_cls_stage1: 0.2673  loss_box_reg_stage1: 0.3164  loss_cls_stage2: 0.1784  loss_box_reg_stage2: 0.2634  loss_mask: 0.5441  loss_rpn_cls: 0.06213  loss_rpn_loc: 0.03437  validation_loss: 2.177  time: 1.5297  data_time: 0.0240  lr: 9.1921e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:08:32 d2.utils.events]: \u001b[0m eta: 0:50:22  iter: 8059  total_loss: 2.346  loss_cls_stage0: 0.3186  loss_box_reg_stage0: 0.2579  loss_cls_stage1: 0.2616  loss_box_reg_stage1: 0.3484  loss_cls_stage2: 0.1877  loss_box_reg_stage2: 0.2966  loss_mask: 0.5423  loss_rpn_cls: 0.05955  loss_rpn_loc: 0.03363  validation_loss: 2.177  time: 1.5298  data_time: 0.0233  lr: 9.0114e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:09:03 d2.utils.events]: \u001b[0m eta: 0:49:50  iter: 8079  total_loss: 2.335  loss_cls_stage0: 0.3225  loss_box_reg_stage0: 0.2616  loss_cls_stage1: 0.2635  loss_box_reg_stage1: 0.3481  loss_cls_stage2: 0.1962  loss_box_reg_stage2: 0.2834  loss_mask: 0.507  loss_rpn_cls: 0.0603  loss_rpn_loc: 0.0349  validation_loss: 2.177  time: 1.5299  data_time: 0.0233  lr: 8.8323e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:09:35 d2.utils.events]: \u001b[0m eta: 0:49:20  iter: 8099  total_loss: 2.456  loss_cls_stage0: 0.361  loss_box_reg_stage0: 0.2794  loss_cls_stage1: 0.2914  loss_box_reg_stage1: 0.3892  loss_cls_stage2: 0.2064  loss_box_reg_stage2: 0.3051  loss_mask: 0.5369  loss_rpn_cls: 0.05938  loss_rpn_loc: 0.03312  validation_loss: 2.177  time: 1.5300  data_time: 0.0234  lr: 8.6548e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:10:06 d2.utils.events]: \u001b[0m eta: 0:48:49  iter: 8119  total_loss: 2.513  loss_cls_stage0: 0.3672  loss_box_reg_stage0: 0.2658  loss_cls_stage1: 0.2955  loss_box_reg_stage1: 0.3624  loss_cls_stage2: 0.1952  loss_box_reg_stage2: 0.2812  loss_mask: 0.5635  loss_rpn_cls: 0.06225  loss_rpn_loc: 0.03455  validation_loss: 2.177  time: 1.5301  data_time: 0.0241  lr: 8.479e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:10:38 d2.utils.events]: \u001b[0m eta: 0:48:17  iter: 8139  total_loss: 2.331  loss_cls_stage0: 0.3333  loss_box_reg_stage0: 0.2613  loss_cls_stage1: 0.2818  loss_box_reg_stage1: 0.3625  loss_cls_stage2: 0.1983  loss_box_reg_stage2: 0.2897  loss_mask: 0.5134  loss_rpn_cls: 0.06389  loss_rpn_loc: 0.03587  validation_loss: 2.177  time: 1.5302  data_time: 0.0250  lr: 8.3047e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:11:09 d2.utils.events]: \u001b[0m eta: 0:47:47  iter: 8159  total_loss: 2.418  loss_cls_stage0: 0.3502  loss_box_reg_stage0: 0.2748  loss_cls_stage1: 0.2908  loss_box_reg_stage1: 0.3795  loss_cls_stage2: 0.2042  loss_box_reg_stage2: 0.3093  loss_mask: 0.5069  loss_rpn_cls: 0.05945  loss_rpn_loc: 0.03469  validation_loss: 2.177  time: 1.5303  data_time: 0.0241  lr: 8.1322e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:11:40 d2.utils.events]: \u001b[0m eta: 0:47:15  iter: 8179  total_loss: 2.352  loss_cls_stage0: 0.318  loss_box_reg_stage0: 0.2487  loss_cls_stage1: 0.2774  loss_box_reg_stage1: 0.3436  loss_cls_stage2: 0.2046  loss_box_reg_stage2: 0.2941  loss_mask: 0.5408  loss_rpn_cls: 0.07073  loss_rpn_loc: 0.03697  validation_loss: 2.177  time: 1.5304  data_time: 0.0245  lr: 7.9613e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:12:12 d2.utils.events]: \u001b[0m eta: 0:46:44  iter: 8199  total_loss: 2.234  loss_cls_stage0: 0.3043  loss_box_reg_stage0: 0.2537  loss_cls_stage1: 0.2403  loss_box_reg_stage1: 0.3458  loss_cls_stage2: 0.182  loss_box_reg_stage2: 0.2917  loss_mask: 0.5404  loss_rpn_cls: 0.0601  loss_rpn_loc: 0.03674  validation_loss: 2.177  time: 1.5304  data_time: 0.0239  lr: 7.792e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:12:43 d2.utils.events]: \u001b[0m eta: 0:46:13  iter: 8219  total_loss: 2.346  loss_cls_stage0: 0.3298  loss_box_reg_stage0: 0.2681  loss_cls_stage1: 0.2731  loss_box_reg_stage1: 0.3854  loss_cls_stage2: 0.1878  loss_box_reg_stage2: 0.3127  loss_mask: 0.5304  loss_rpn_cls: 0.05933  loss_rpn_loc: 0.03707  validation_loss: 2.177  time: 1.5305  data_time: 0.0227  lr: 7.6244e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:13:14 d2.utils.events]: \u001b[0m eta: 0:45:42  iter: 8239  total_loss: 2.298  loss_cls_stage0: 0.3399  loss_box_reg_stage0: 0.2627  loss_cls_stage1: 0.2488  loss_box_reg_stage1: 0.3612  loss_cls_stage2: 0.1766  loss_box_reg_stage2: 0.2775  loss_mask: 0.5133  loss_rpn_cls: 0.053  loss_rpn_loc: 0.03383  validation_loss: 2.177  time: 1.5306  data_time: 0.0236  lr: 7.4585e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:13:45 d2.utils.events]: \u001b[0m eta: 0:45:10  iter: 8259  total_loss: 2.398  loss_cls_stage0: 0.3397  loss_box_reg_stage0: 0.2559  loss_cls_stage1: 0.2812  loss_box_reg_stage1: 0.3626  loss_cls_stage2: 0.1927  loss_box_reg_stage2: 0.2891  loss_mask: 0.5274  loss_rpn_cls: 0.06695  loss_rpn_loc: 0.03729  validation_loss: 2.177  time: 1.5307  data_time: 0.0241  lr: 7.2943e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:14:17 d2.utils.events]: \u001b[0m eta: 0:44:40  iter: 8279  total_loss: 2.363  loss_cls_stage0: 0.3439  loss_box_reg_stage0: 0.2819  loss_cls_stage1: 0.2735  loss_box_reg_stage1: 0.3791  loss_cls_stage2: 0.2002  loss_box_reg_stage2: 0.3228  loss_mask: 0.5207  loss_rpn_cls: 0.06226  loss_rpn_loc: 0.03666  validation_loss: 2.177  time: 1.5308  data_time: 0.0243  lr: 7.1318e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:14:48 d2.utils.events]: \u001b[0m eta: 0:44:08  iter: 8299  total_loss: 2.344  loss_cls_stage0: 0.3395  loss_box_reg_stage0: 0.2583  loss_cls_stage1: 0.288  loss_box_reg_stage1: 0.3675  loss_cls_stage2: 0.2058  loss_box_reg_stage2: 0.2963  loss_mask: 0.5472  loss_rpn_cls: 0.05903  loss_rpn_loc: 0.0359  validation_loss: 2.177  time: 1.5309  data_time: 0.0239  lr: 6.9709e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:15:19 d2.utils.events]: \u001b[0m eta: 0:43:37  iter: 8319  total_loss: 2.226  loss_cls_stage0: 0.3026  loss_box_reg_stage0: 0.2365  loss_cls_stage1: 0.2587  loss_box_reg_stage1: 0.3343  loss_cls_stage2: 0.1915  loss_box_reg_stage2: 0.2969  loss_mask: 0.4878  loss_rpn_cls: 0.06729  loss_rpn_loc: 0.03713  validation_loss: 2.177  time: 1.5309  data_time: 0.0229  lr: 6.8117e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:15:51 d2.utils.events]: \u001b[0m eta: 0:43:06  iter: 8339  total_loss: 2.434  loss_cls_stage0: 0.3541  loss_box_reg_stage0: 0.2809  loss_cls_stage1: 0.2869  loss_box_reg_stage1: 0.3749  loss_cls_stage2: 0.2013  loss_box_reg_stage2: 0.2852  loss_mask: 0.5595  loss_rpn_cls: 0.05833  loss_rpn_loc: 0.04281  validation_loss: 2.177  time: 1.5310  data_time: 0.0223  lr: 6.6543e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:16:22 d2.utils.events]: \u001b[0m eta: 0:42:35  iter: 8359  total_loss: 2.354  loss_cls_stage0: 0.3492  loss_box_reg_stage0: 0.2519  loss_cls_stage1: 0.2948  loss_box_reg_stage1: 0.3476  loss_cls_stage2: 0.1964  loss_box_reg_stage2: 0.2935  loss_mask: 0.5307  loss_rpn_cls: 0.05969  loss_rpn_loc: 0.03665  validation_loss: 2.177  time: 1.5311  data_time: 0.0230  lr: 6.4986e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:16:53 d2.utils.events]: \u001b[0m eta: 0:42:04  iter: 8379  total_loss: 2.377  loss_cls_stage0: 0.3129  loss_box_reg_stage0: 0.2372  loss_cls_stage1: 0.2714  loss_box_reg_stage1: 0.3682  loss_cls_stage2: 0.2022  loss_box_reg_stage2: 0.3182  loss_mask: 0.5058  loss_rpn_cls: 0.06095  loss_rpn_loc: 0.03429  validation_loss: 2.177  time: 1.5312  data_time: 0.0232  lr: 6.3445e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:17:25 d2.utils.events]: \u001b[0m eta: 0:41:34  iter: 8399  total_loss: 2.306  loss_cls_stage0: 0.3324  loss_box_reg_stage0: 0.2533  loss_cls_stage1: 0.2802  loss_box_reg_stage1: 0.3545  loss_cls_stage2: 0.2001  loss_box_reg_stage2: 0.2912  loss_mask: 0.5436  loss_rpn_cls: 0.062  loss_rpn_loc: 0.03777  validation_loss: 2.177  time: 1.5312  data_time: 0.0235  lr: 6.1922e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:17:56 d2.utils.events]: \u001b[0m eta: 0:41:04  iter: 8419  total_loss: 2.434  loss_cls_stage0: 0.3416  loss_box_reg_stage0: 0.2725  loss_cls_stage1: 0.2819  loss_box_reg_stage1: 0.3748  loss_cls_stage2: 0.1977  loss_box_reg_stage2: 0.298  loss_mask: 0.5464  loss_rpn_cls: 0.06103  loss_rpn_loc: 0.03735  validation_loss: 2.177  time: 1.5313  data_time: 0.0235  lr: 6.0417e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:18:28 d2.utils.events]: \u001b[0m eta: 0:40:33  iter: 8439  total_loss: 2.455  loss_cls_stage0: 0.3566  loss_box_reg_stage0: 0.2849  loss_cls_stage1: 0.3102  loss_box_reg_stage1: 0.3798  loss_cls_stage2: 0.2082  loss_box_reg_stage2: 0.3028  loss_mask: 0.4846  loss_rpn_cls: 0.05682  loss_rpn_loc: 0.03948  validation_loss: 2.177  time: 1.5314  data_time: 0.0235  lr: 5.8928e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:18:59 d2.utils.events]: \u001b[0m eta: 0:40:02  iter: 8459  total_loss: 2.478  loss_cls_stage0: 0.3619  loss_box_reg_stage0: 0.2972  loss_cls_stage1: 0.3004  loss_box_reg_stage1: 0.4215  loss_cls_stage2: 0.2162  loss_box_reg_stage2: 0.3188  loss_mask: 0.547  loss_rpn_cls: 0.06469  loss_rpn_loc: 0.04111  validation_loss: 2.177  time: 1.5315  data_time: 0.0237  lr: 5.7457e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:19:31 d2.utils.events]: \u001b[0m eta: 0:39:31  iter: 8479  total_loss: 2.567  loss_cls_stage0: 0.3574  loss_box_reg_stage0: 0.2904  loss_cls_stage1: 0.2978  loss_box_reg_stage1: 0.4033  loss_cls_stage2: 0.2131  loss_box_reg_stage2: 0.3214  loss_mask: 0.5489  loss_rpn_cls: 0.06025  loss_rpn_loc: 0.04162  validation_loss: 2.177  time: 1.5317  data_time: 0.0225  lr: 5.6004e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:20:02 d2.utils.events]: \u001b[0m eta: 0:38:59  iter: 8499  total_loss: 2.267  loss_cls_stage0: 0.2981  loss_box_reg_stage0: 0.2365  loss_cls_stage1: 0.2561  loss_box_reg_stage1: 0.3555  loss_cls_stage2: 0.183  loss_box_reg_stage2: 0.3003  loss_mask: 0.5421  loss_rpn_cls: 0.06819  loss_rpn_loc: 0.03443  validation_loss: 2.177  time: 1.5317  data_time: 0.0236  lr: 5.4568e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:20:33 d2.utils.events]: \u001b[0m eta: 0:38:28  iter: 8519  total_loss: 2.444  loss_cls_stage0: 0.3317  loss_box_reg_stage0: 0.2598  loss_cls_stage1: 0.261  loss_box_reg_stage1: 0.3619  loss_cls_stage2: 0.1964  loss_box_reg_stage2: 0.3049  loss_mask: 0.5524  loss_rpn_cls: 0.06055  loss_rpn_loc: 0.03534  validation_loss: 2.177  time: 1.5318  data_time: 0.0234  lr: 5.315e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:21:04 d2.utils.events]: \u001b[0m eta: 0:37:57  iter: 8539  total_loss: 2.206  loss_cls_stage0: 0.2991  loss_box_reg_stage0: 0.2375  loss_cls_stage1: 0.2462  loss_box_reg_stage1: 0.352  loss_cls_stage2: 0.1827  loss_box_reg_stage2: 0.2821  loss_mask: 0.507  loss_rpn_cls: 0.05381  loss_rpn_loc: 0.03133  validation_loss: 2.177  time: 1.5319  data_time: 0.0228  lr: 5.1749e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:21:36 d2.utils.events]: \u001b[0m eta: 0:37:26  iter: 8559  total_loss: 2.324  loss_cls_stage0: 0.3317  loss_box_reg_stage0: 0.2684  loss_cls_stage1: 0.2743  loss_box_reg_stage1: 0.3682  loss_cls_stage2: 0.2032  loss_box_reg_stage2: 0.2902  loss_mask: 0.5059  loss_rpn_cls: 0.06024  loss_rpn_loc: 0.03423  validation_loss: 2.177  time: 1.5319  data_time: 0.0249  lr: 5.0366e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:22:07 d2.utils.events]: \u001b[0m eta: 0:36:55  iter: 8579  total_loss: 2.549  loss_cls_stage0: 0.3739  loss_box_reg_stage0: 0.2941  loss_cls_stage1: 0.2981  loss_box_reg_stage1: 0.3992  loss_cls_stage2: 0.2085  loss_box_reg_stage2: 0.3425  loss_mask: 0.5085  loss_rpn_cls: 0.05712  loss_rpn_loc: 0.03554  validation_loss: 2.177  time: 1.5321  data_time: 0.0239  lr: 4.9001e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:22:39 d2.utils.events]: \u001b[0m eta: 0:36:24  iter: 8599  total_loss: 2.366  loss_cls_stage0: 0.3323  loss_box_reg_stage0: 0.2692  loss_cls_stage1: 0.2815  loss_box_reg_stage1: 0.4008  loss_cls_stage2: 0.2065  loss_box_reg_stage2: 0.3026  loss_mask: 0.5319  loss_rpn_cls: 0.06592  loss_rpn_loc: 0.03804  validation_loss: 2.177  time: 1.5321  data_time: 0.0217  lr: 4.7653e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:23:10 d2.utils.events]: \u001b[0m eta: 0:35:53  iter: 8619  total_loss: 2.323  loss_cls_stage0: 0.3021  loss_box_reg_stage0: 0.2332  loss_cls_stage1: 0.2645  loss_box_reg_stage1: 0.3296  loss_cls_stage2: 0.1922  loss_box_reg_stage2: 0.2839  loss_mask: 0.5207  loss_rpn_cls: 0.05239  loss_rpn_loc: 0.03132  validation_loss: 2.177  time: 1.5322  data_time: 0.0231  lr: 4.6324e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:23:41 d2.utils.events]: \u001b[0m eta: 0:35:22  iter: 8639  total_loss: 2.312  loss_cls_stage0: 0.3331  loss_box_reg_stage0: 0.2598  loss_cls_stage1: 0.283  loss_box_reg_stage1: 0.3704  loss_cls_stage2: 0.2017  loss_box_reg_stage2: 0.3151  loss_mask: 0.525  loss_rpn_cls: 0.06419  loss_rpn_loc: 0.03471  validation_loss: 2.177  time: 1.5323  data_time: 0.0223  lr: 4.5012e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:24:12 d2.utils.events]: \u001b[0m eta: 0:34:51  iter: 8659  total_loss: 2.35  loss_cls_stage0: 0.3299  loss_box_reg_stage0: 0.2628  loss_cls_stage1: 0.2598  loss_box_reg_stage1: 0.3598  loss_cls_stage2: 0.1799  loss_box_reg_stage2: 0.3022  loss_mask: 0.5392  loss_rpn_cls: 0.06404  loss_rpn_loc: 0.03681  validation_loss: 2.177  time: 1.5323  data_time: 0.0224  lr: 4.3718e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:24:44 d2.utils.events]: \u001b[0m eta: 0:34:19  iter: 8679  total_loss: 2.357  loss_cls_stage0: 0.3384  loss_box_reg_stage0: 0.2626  loss_cls_stage1: 0.2812  loss_box_reg_stage1: 0.3653  loss_cls_stage2: 0.2054  loss_box_reg_stage2: 0.2999  loss_mask: 0.5291  loss_rpn_cls: 0.06272  loss_rpn_loc: 0.03651  validation_loss: 2.177  time: 1.5324  data_time: 0.0231  lr: 4.2443e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:25:15 d2.utils.events]: \u001b[0m eta: 0:33:48  iter: 8699  total_loss: 2.348  loss_cls_stage0: 0.3351  loss_box_reg_stage0: 0.2576  loss_cls_stage1: 0.2649  loss_box_reg_stage1: 0.365  loss_cls_stage2: 0.1868  loss_box_reg_stage2: 0.2948  loss_mask: 0.5324  loss_rpn_cls: 0.0698  loss_rpn_loc: 0.03666  validation_loss: 2.177  time: 1.5325  data_time: 0.0220  lr: 4.1185e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:25:46 d2.utils.events]: \u001b[0m eta: 0:33:17  iter: 8719  total_loss: 2.426  loss_cls_stage0: 0.3344  loss_box_reg_stage0: 0.2608  loss_cls_stage1: 0.2728  loss_box_reg_stage1: 0.3642  loss_cls_stage2: 0.1942  loss_box_reg_stage2: 0.3148  loss_mask: 0.5267  loss_rpn_cls: 0.05844  loss_rpn_loc: 0.03592  validation_loss: 2.177  time: 1.5326  data_time: 0.0238  lr: 3.9946e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:26:18 d2.utils.events]: \u001b[0m eta: 0:32:46  iter: 8739  total_loss: 2.353  loss_cls_stage0: 0.3273  loss_box_reg_stage0: 0.2807  loss_cls_stage1: 0.2676  loss_box_reg_stage1: 0.3696  loss_cls_stage2: 0.1904  loss_box_reg_stage2: 0.2929  loss_mask: 0.5264  loss_rpn_cls: 0.05774  loss_rpn_loc: 0.03579  validation_loss: 2.177  time: 1.5326  data_time: 0.0238  lr: 3.8724e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:26:49 d2.utils.events]: \u001b[0m eta: 0:32:15  iter: 8759  total_loss: 2.343  loss_cls_stage0: 0.3406  loss_box_reg_stage0: 0.279  loss_cls_stage1: 0.2712  loss_box_reg_stage1: 0.3821  loss_cls_stage2: 0.1956  loss_box_reg_stage2: 0.2987  loss_mask: 0.464  loss_rpn_cls: 0.05121  loss_rpn_loc: 0.03639  validation_loss: 2.177  time: 1.5327  data_time: 0.0225  lr: 3.7521e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:27:20 d2.utils.events]: \u001b[0m eta: 0:31:44  iter: 8779  total_loss: 2.311  loss_cls_stage0: 0.3189  loss_box_reg_stage0: 0.2611  loss_cls_stage1: 0.2779  loss_box_reg_stage1: 0.378  loss_cls_stage2: 0.199  loss_box_reg_stage2: 0.3067  loss_mask: 0.4965  loss_rpn_cls: 0.05943  loss_rpn_loc: 0.03474  validation_loss: 2.177  time: 1.5328  data_time: 0.0245  lr: 3.6336e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:27:52 d2.utils.events]: \u001b[0m eta: 0:31:13  iter: 8799  total_loss: 2.317  loss_cls_stage0: 0.3133  loss_box_reg_stage0: 0.2606  loss_cls_stage1: 0.2619  loss_box_reg_stage1: 0.3821  loss_cls_stage2: 0.1981  loss_box_reg_stage2: 0.3243  loss_mask: 0.497  loss_rpn_cls: 0.05758  loss_rpn_loc: 0.0342  validation_loss: 2.177  time: 1.5329  data_time: 0.0242  lr: 3.517e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:28:23 d2.utils.events]: \u001b[0m eta: 0:30:42  iter: 8819  total_loss: 2.535  loss_cls_stage0: 0.3496  loss_box_reg_stage0: 0.257  loss_cls_stage1: 0.3208  loss_box_reg_stage1: 0.3859  loss_cls_stage2: 0.2245  loss_box_reg_stage2: 0.3102  loss_mask: 0.5267  loss_rpn_cls: 0.05973  loss_rpn_loc: 0.03328  validation_loss: 2.177  time: 1.5330  data_time: 0.0238  lr: 3.4021e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:28:54 d2.utils.events]: \u001b[0m eta: 0:30:11  iter: 8839  total_loss: 2.339  loss_cls_stage0: 0.3294  loss_box_reg_stage0: 0.2585  loss_cls_stage1: 0.2738  loss_box_reg_stage1: 0.364  loss_cls_stage2: 0.2  loss_box_reg_stage2: 0.3026  loss_mask: 0.5419  loss_rpn_cls: 0.05763  loss_rpn_loc: 0.03259  validation_loss: 2.177  time: 1.5330  data_time: 0.0227  lr: 3.2892e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:29:26 d2.utils.events]: \u001b[0m eta: 0:29:39  iter: 8859  total_loss: 2.336  loss_cls_stage0: 0.3118  loss_box_reg_stage0: 0.2606  loss_cls_stage1: 0.2635  loss_box_reg_stage1: 0.3713  loss_cls_stage2: 0.1894  loss_box_reg_stage2: 0.3127  loss_mask: 0.5641  loss_rpn_cls: 0.05167  loss_rpn_loc: 0.03057  validation_loss: 2.177  time: 1.5331  data_time: 0.0251  lr: 3.178e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:29:57 d2.utils.events]: \u001b[0m eta: 0:29:09  iter: 8879  total_loss: 2.643  loss_cls_stage0: 0.3652  loss_box_reg_stage0: 0.3008  loss_cls_stage1: 0.3144  loss_box_reg_stage1: 0.3969  loss_cls_stage2: 0.2103  loss_box_reg_stage2: 0.3193  loss_mask: 0.5721  loss_rpn_cls: 0.05772  loss_rpn_loc: 0.03901  validation_loss: 2.177  time: 1.5332  data_time: 0.0232  lr: 3.0687e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:30:29 d2.utils.events]: \u001b[0m eta: 0:28:38  iter: 8899  total_loss: 2.476  loss_cls_stage0: 0.3338  loss_box_reg_stage0: 0.2727  loss_cls_stage1: 0.2724  loss_box_reg_stage1: 0.3775  loss_cls_stage2: 0.1959  loss_box_reg_stage2: 0.3143  loss_mask: 0.5501  loss_rpn_cls: 0.07205  loss_rpn_loc: 0.04109  validation_loss: 2.177  time: 1.5333  data_time: 0.0241  lr: 2.9613e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:31:00 d2.utils.events]: \u001b[0m eta: 0:28:06  iter: 8919  total_loss: 2.601  loss_cls_stage0: 0.365  loss_box_reg_stage0: 0.2899  loss_cls_stage1: 0.3047  loss_box_reg_stage1: 0.4139  loss_cls_stage2: 0.2114  loss_box_reg_stage2: 0.3192  loss_mask: 0.5237  loss_rpn_cls: 0.06943  loss_rpn_loc: 0.04222  validation_loss: 2.177  time: 1.5333  data_time: 0.0224  lr: 2.8557e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:31:31 d2.utils.events]: \u001b[0m eta: 0:27:36  iter: 8939  total_loss: 2.489  loss_cls_stage0: 0.3459  loss_box_reg_stage0: 0.2609  loss_cls_stage1: 0.2818  loss_box_reg_stage1: 0.381  loss_cls_stage2: 0.2002  loss_box_reg_stage2: 0.3204  loss_mask: 0.5382  loss_rpn_cls: 0.06604  loss_rpn_loc: 0.04212  validation_loss: 2.177  time: 1.5334  data_time: 0.0222  lr: 2.752e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:32:03 d2.utils.events]: \u001b[0m eta: 0:27:04  iter: 8959  total_loss: 2.3  loss_cls_stage0: 0.3072  loss_box_reg_stage0: 0.2455  loss_cls_stage1: 0.2484  loss_box_reg_stage1: 0.3405  loss_cls_stage2: 0.1764  loss_box_reg_stage2: 0.3014  loss_mask: 0.5434  loss_rpn_cls: 0.05156  loss_rpn_loc: 0.03288  validation_loss: 2.177  time: 1.5335  data_time: 0.0218  lr: 2.6501e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:32:34 d2.utils.events]: \u001b[0m eta: 0:26:33  iter: 8979  total_loss: 2.393  loss_cls_stage0: 0.3409  loss_box_reg_stage0: 0.2943  loss_cls_stage1: 0.2904  loss_box_reg_stage1: 0.3912  loss_cls_stage2: 0.1939  loss_box_reg_stage2: 0.3118  loss_mask: 0.5383  loss_rpn_cls: 0.05616  loss_rpn_loc: 0.03697  validation_loss: 2.177  time: 1.5336  data_time: 0.0253  lr: 2.5501e-06  max_mem: 12121M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/27 01:33:08 d2.data.common]: \u001b[0mSerializing 879 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/27 01:33:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.90 MiB\n",
      "\u001b[32m[03/27 01:33:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 879 images\n",
      "\u001b[32m[03/27 01:33:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/879. 0.0812 s / img. ETA=0:01:53\n",
      "\u001b[32m[03/27 01:33:15 d2.evaluation.evaluator]: \u001b[0mInference done 53/879. 0.0811 s / img. ETA=0:01:39\n",
      "\u001b[32m[03/27 01:33:20 d2.evaluation.evaluator]: \u001b[0mInference done 93/879. 0.0812 s / img. ETA=0:01:37\n",
      "\u001b[32m[03/27 01:33:25 d2.evaluation.evaluator]: \u001b[0mInference done 132/879. 0.0813 s / img. ETA=0:01:33\n",
      "\u001b[32m[03/27 01:33:30 d2.evaluation.evaluator]: \u001b[0mInference done 172/879. 0.0813 s / img. ETA=0:01:29\n",
      "\u001b[32m[03/27 01:33:35 d2.evaluation.evaluator]: \u001b[0mInference done 211/879. 0.0814 s / img. ETA=0:01:24\n",
      "\u001b[32m[03/27 01:33:40 d2.evaluation.evaluator]: \u001b[0mInference done 250/879. 0.0814 s / img. ETA=0:01:20\n",
      "\u001b[32m[03/27 01:33:45 d2.evaluation.evaluator]: \u001b[0mInference done 291/879. 0.0813 s / img. ETA=0:01:14\n",
      "\u001b[32m[03/27 01:33:50 d2.evaluation.evaluator]: \u001b[0mInference done 333/879. 0.0813 s / img. ETA=0:01:08\n",
      "\u001b[32m[03/27 01:33:55 d2.evaluation.evaluator]: \u001b[0mInference done 377/879. 0.0812 s / img. ETA=0:01:02\n",
      "\u001b[32m[03/27 01:34:00 d2.evaluation.evaluator]: \u001b[0mInference done 419/879. 0.0811 s / img. ETA=0:00:57\n",
      "\u001b[32m[03/27 01:34:06 d2.evaluation.evaluator]: \u001b[0mInference done 462/879. 0.0811 s / img. ETA=0:00:51\n",
      "\u001b[32m[03/27 01:34:11 d2.evaluation.evaluator]: \u001b[0mInference done 505/879. 0.0810 s / img. ETA=0:00:46\n",
      "\u001b[32m[03/27 01:34:16 d2.evaluation.evaluator]: \u001b[0mInference done 547/879. 0.0810 s / img. ETA=0:00:40\n",
      "\u001b[32m[03/27 01:34:21 d2.evaluation.evaluator]: \u001b[0mInference done 584/879. 0.0811 s / img. ETA=0:00:36\n",
      "\u001b[32m[03/27 01:34:26 d2.evaluation.evaluator]: \u001b[0mInference done 625/879. 0.0811 s / img. ETA=0:00:31\n",
      "\u001b[32m[03/27 01:34:31 d2.evaluation.evaluator]: \u001b[0mInference done 667/879. 0.0811 s / img. ETA=0:00:26\n",
      "\u001b[32m[03/27 01:34:36 d2.evaluation.evaluator]: \u001b[0mInference done 710/879. 0.0810 s / img. ETA=0:00:20\n",
      "\u001b[32m[03/27 01:34:41 d2.evaluation.evaluator]: \u001b[0mInference done 750/879. 0.0810 s / img. ETA=0:00:15\n",
      "\u001b[32m[03/27 01:34:46 d2.evaluation.evaluator]: \u001b[0mInference done 789/879. 0.0811 s / img. ETA=0:00:11\n",
      "\u001b[32m[03/27 01:34:51 d2.evaluation.evaluator]: \u001b[0mInference done 830/879. 0.0811 s / img. ETA=0:00:06\n",
      "\u001b[32m[03/27 01:34:56 d2.evaluation.evaluator]: \u001b[0mInference done 872/879. 0.0813 s / img. ETA=0:00:00\n",
      "\u001b[32m[03/27 01:34:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:48.109929 (0.123696 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/27 01:34:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:11 (0.081257 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.34 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.089\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.146\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.162\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.044\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.094\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.139\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.185\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.185\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.019\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.062\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.208\n",
      "\u001b[32m[03/27 01:34:58 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold3 in csv format:\n",
      "\u001b[32m[03/27 01:34:58 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/27 01:34:58 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/27 01:34:58 d2.evaluation.testing]: \u001b[0mcopypaste: 8.9370,14.5640,16.1609,0.9240,4.4222,9.3774\n",
      "validation do loss eval 2.381443059096135\n",
      "\u001b[32m[03/27 01:36:29 d2.utils.events]: \u001b[0m eta: 0:26:02  iter: 8999  total_loss: 2.272  loss_cls_stage0: 0.323  loss_box_reg_stage0: 0.2614  loss_cls_stage1: 0.2509  loss_box_reg_stage1: 0.3877  loss_cls_stage2: 0.1874  loss_box_reg_stage2: 0.3183  loss_mask: 0.5678  loss_rpn_cls: 0.05299  loss_rpn_loc: 0.033  validation_loss: 2.244  time: 1.5336  data_time: 0.0233  lr: 2.452e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:37:00 d2.utils.events]: \u001b[0m eta: 0:25:31  iter: 9019  total_loss: 2.179  loss_cls_stage0: 0.3037  loss_box_reg_stage0: 0.2456  loss_cls_stage1: 0.2525  loss_box_reg_stage1: 0.3215  loss_cls_stage2: 0.1744  loss_box_reg_stage2: 0.2962  loss_mask: 0.4785  loss_rpn_cls: 0.05694  loss_rpn_loc: 0.03433  validation_loss: 2.244  time: 1.5336  data_time: 0.0242  lr: 2.3558e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:37:31 d2.utils.events]: \u001b[0m eta: 0:25:00  iter: 9039  total_loss: 2.291  loss_cls_stage0: 0.3208  loss_box_reg_stage0: 0.2474  loss_cls_stage1: 0.2642  loss_box_reg_stage1: 0.3549  loss_cls_stage2: 0.1991  loss_box_reg_stage2: 0.3226  loss_mask: 0.4819  loss_rpn_cls: 0.06223  loss_rpn_loc: 0.03939  validation_loss: 2.244  time: 1.5337  data_time: 0.0245  lr: 2.2614e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:38:02 d2.utils.events]: \u001b[0m eta: 0:24:28  iter: 9059  total_loss: 2.254  loss_cls_stage0: 0.315  loss_box_reg_stage0: 0.2578  loss_cls_stage1: 0.2672  loss_box_reg_stage1: 0.367  loss_cls_stage2: 0.1919  loss_box_reg_stage2: 0.2753  loss_mask: 0.4777  loss_rpn_cls: 0.06511  loss_rpn_loc: 0.03925  validation_loss: 2.244  time: 1.5338  data_time: 0.0249  lr: 2.169e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:38:34 d2.utils.events]: \u001b[0m eta: 0:23:57  iter: 9079  total_loss: 2.454  loss_cls_stage0: 0.3499  loss_box_reg_stage0: 0.2725  loss_cls_stage1: 0.2875  loss_box_reg_stage1: 0.3686  loss_cls_stage2: 0.201  loss_box_reg_stage2: 0.3294  loss_mask: 0.5494  loss_rpn_cls: 0.0651  loss_rpn_loc: 0.03638  validation_loss: 2.244  time: 1.5339  data_time: 0.0240  lr: 2.0784e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:39:05 d2.utils.events]: \u001b[0m eta: 0:23:26  iter: 9099  total_loss: 2.507  loss_cls_stage0: 0.3447  loss_box_reg_stage0: 0.2906  loss_cls_stage1: 0.2916  loss_box_reg_stage1: 0.4042  loss_cls_stage2: 0.2138  loss_box_reg_stage2: 0.317  loss_mask: 0.5004  loss_rpn_cls: 0.05564  loss_rpn_loc: 0.03881  validation_loss: 2.244  time: 1.5340  data_time: 0.0236  lr: 1.9897e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:39:37 d2.utils.events]: \u001b[0m eta: 0:22:55  iter: 9119  total_loss: 2.529  loss_cls_stage0: 0.3466  loss_box_reg_stage0: 0.2773  loss_cls_stage1: 0.2783  loss_box_reg_stage1: 0.3744  loss_cls_stage2: 0.1991  loss_box_reg_stage2: 0.3034  loss_mask: 0.5555  loss_rpn_cls: 0.05996  loss_rpn_loc: 0.03535  validation_loss: 2.244  time: 1.5340  data_time: 0.0237  lr: 1.9029e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:40:08 d2.utils.events]: \u001b[0m eta: 0:22:24  iter: 9139  total_loss: 2.673  loss_cls_stage0: 0.3936  loss_box_reg_stage0: 0.3073  loss_cls_stage1: 0.3035  loss_box_reg_stage1: 0.4125  loss_cls_stage2: 0.2138  loss_box_reg_stage2: 0.3266  loss_mask: 0.515  loss_rpn_cls: 0.06198  loss_rpn_loc: 0.03695  validation_loss: 2.244  time: 1.5341  data_time: 0.0231  lr: 1.818e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:40:40 d2.utils.events]: \u001b[0m eta: 0:21:52  iter: 9159  total_loss: 2.343  loss_cls_stage0: 0.3271  loss_box_reg_stage0: 0.2588  loss_cls_stage1: 0.2681  loss_box_reg_stage1: 0.3782  loss_cls_stage2: 0.207  loss_box_reg_stage2: 0.3116  loss_mask: 0.5284  loss_rpn_cls: 0.06804  loss_rpn_loc: 0.03599  validation_loss: 2.244  time: 1.5342  data_time: 0.0240  lr: 1.735e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:41:11 d2.utils.events]: \u001b[0m eta: 0:21:21  iter: 9179  total_loss: 2.32  loss_cls_stage0: 0.332  loss_box_reg_stage0: 0.2471  loss_cls_stage1: 0.2749  loss_box_reg_stage1: 0.3651  loss_cls_stage2: 0.1955  loss_box_reg_stage2: 0.2937  loss_mask: 0.5229  loss_rpn_cls: 0.06992  loss_rpn_loc: 0.03836  validation_loss: 2.244  time: 1.5343  data_time: 0.0232  lr: 1.6539e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:41:42 d2.utils.events]: \u001b[0m eta: 0:20:50  iter: 9199  total_loss: 2.419  loss_cls_stage0: 0.3344  loss_box_reg_stage0: 0.2551  loss_cls_stage1: 0.2775  loss_box_reg_stage1: 0.3672  loss_cls_stage2: 0.2049  loss_box_reg_stage2: 0.3099  loss_mask: 0.4812  loss_rpn_cls: 0.06432  loss_rpn_loc: 0.03577  validation_loss: 2.244  time: 1.5344  data_time: 0.0223  lr: 1.5748e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:42:14 d2.utils.events]: \u001b[0m eta: 0:20:19  iter: 9219  total_loss: 2.282  loss_cls_stage0: 0.3186  loss_box_reg_stage0: 0.2386  loss_cls_stage1: 0.2609  loss_box_reg_stage1: 0.3473  loss_cls_stage2: 0.1929  loss_box_reg_stage2: 0.3033  loss_mask: 0.5304  loss_rpn_cls: 0.05684  loss_rpn_loc: 0.03386  validation_loss: 2.244  time: 1.5344  data_time: 0.0237  lr: 1.4975e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:42:45 d2.utils.events]: \u001b[0m eta: 0:19:47  iter: 9239  total_loss: 2.587  loss_cls_stage0: 0.3557  loss_box_reg_stage0: 0.2935  loss_cls_stage1: 0.2922  loss_box_reg_stage1: 0.3971  loss_cls_stage2: 0.2147  loss_box_reg_stage2: 0.309  loss_mask: 0.5213  loss_rpn_cls: 0.05589  loss_rpn_loc: 0.03734  validation_loss: 2.244  time: 1.5345  data_time: 0.0245  lr: 1.4221e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:43:16 d2.utils.events]: \u001b[0m eta: 0:19:16  iter: 9259  total_loss: 2.493  loss_cls_stage0: 0.3527  loss_box_reg_stage0: 0.283  loss_cls_stage1: 0.2972  loss_box_reg_stage1: 0.3975  loss_cls_stage2: 0.2131  loss_box_reg_stage2: 0.3126  loss_mask: 0.5383  loss_rpn_cls: 0.07054  loss_rpn_loc: 0.04098  validation_loss: 2.244  time: 1.5346  data_time: 0.0250  lr: 1.3487e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:43:48 d2.utils.events]: \u001b[0m eta: 0:18:45  iter: 9279  total_loss: 2.534  loss_cls_stage0: 0.3573  loss_box_reg_stage0: 0.2824  loss_cls_stage1: 0.3031  loss_box_reg_stage1: 0.3909  loss_cls_stage2: 0.2101  loss_box_reg_stage2: 0.3009  loss_mask: 0.5255  loss_rpn_cls: 0.0704  loss_rpn_loc: 0.03616  validation_loss: 2.244  time: 1.5347  data_time: 0.0238  lr: 1.2772e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:44:19 d2.utils.events]: \u001b[0m eta: 0:18:14  iter: 9299  total_loss: 2.195  loss_cls_stage0: 0.3058  loss_box_reg_stage0: 0.2459  loss_cls_stage1: 0.247  loss_box_reg_stage1: 0.34  loss_cls_stage2: 0.1856  loss_box_reg_stage2: 0.287  loss_mask: 0.5126  loss_rpn_cls: 0.05705  loss_rpn_loc: 0.03718  validation_loss: 2.244  time: 1.5347  data_time: 0.0244  lr: 1.2076e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:44:50 d2.utils.events]: \u001b[0m eta: 0:17:43  iter: 9319  total_loss: 2.427  loss_cls_stage0: 0.3213  loss_box_reg_stage0: 0.2577  loss_cls_stage1: 0.2624  loss_box_reg_stage1: 0.3784  loss_cls_stage2: 0.2024  loss_box_reg_stage2: 0.297  loss_mask: 0.4915  loss_rpn_cls: 0.05547  loss_rpn_loc: 0.03543  validation_loss: 2.244  time: 1.5348  data_time: 0.0227  lr: 1.1399e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:45:22 d2.utils.events]: \u001b[0m eta: 0:17:11  iter: 9339  total_loss: 2.339  loss_cls_stage0: 0.3277  loss_box_reg_stage0: 0.2462  loss_cls_stage1: 0.264  loss_box_reg_stage1: 0.3687  loss_cls_stage2: 0.1896  loss_box_reg_stage2: 0.3228  loss_mask: 0.5436  loss_rpn_cls: 0.0679  loss_rpn_loc: 0.03852  validation_loss: 2.244  time: 1.5349  data_time: 0.0230  lr: 1.0742e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:45:53 d2.utils.events]: \u001b[0m eta: 0:16:40  iter: 9359  total_loss: 2.432  loss_cls_stage0: 0.325  loss_box_reg_stage0: 0.2681  loss_cls_stage1: 0.2646  loss_box_reg_stage1: 0.3683  loss_cls_stage2: 0.19  loss_box_reg_stage2: 0.316  loss_mask: 0.5458  loss_rpn_cls: 0.0598  loss_rpn_loc: 0.03294  validation_loss: 2.244  time: 1.5349  data_time: 0.0235  lr: 1.0104e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:46:25 d2.utils.events]: \u001b[0m eta: 0:16:09  iter: 9379  total_loss: 2.44  loss_cls_stage0: 0.3506  loss_box_reg_stage0: 0.2874  loss_cls_stage1: 0.2798  loss_box_reg_stage1: 0.3874  loss_cls_stage2: 0.1991  loss_box_reg_stage2: 0.2907  loss_mask: 0.5505  loss_rpn_cls: 0.06642  loss_rpn_loc: 0.03848  validation_loss: 2.244  time: 1.5350  data_time: 0.0228  lr: 9.4852e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:46:56 d2.utils.events]: \u001b[0m eta: 0:15:38  iter: 9399  total_loss: 2.434  loss_cls_stage0: 0.3393  loss_box_reg_stage0: 0.2778  loss_cls_stage1: 0.2785  loss_box_reg_stage1: 0.3827  loss_cls_stage2: 0.2011  loss_box_reg_stage2: 0.3121  loss_mask: 0.529  loss_rpn_cls: 0.06323  loss_rpn_loc: 0.04158  validation_loss: 2.244  time: 1.5351  data_time: 0.0231  lr: 8.8858e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:47:27 d2.utils.events]: \u001b[0m eta: 0:15:07  iter: 9419  total_loss: 2.231  loss_cls_stage0: 0.31  loss_box_reg_stage0: 0.2416  loss_cls_stage1: 0.2652  loss_box_reg_stage1: 0.3744  loss_cls_stage2: 0.1852  loss_box_reg_stage2: 0.3057  loss_mask: 0.4544  loss_rpn_cls: 0.05901  loss_rpn_loc: 0.03455  validation_loss: 2.244  time: 1.5351  data_time: 0.0219  lr: 8.3059e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:47:58 d2.utils.events]: \u001b[0m eta: 0:14:35  iter: 9439  total_loss: 2.28  loss_cls_stage0: 0.3176  loss_box_reg_stage0: 0.2387  loss_cls_stage1: 0.2631  loss_box_reg_stage1: 0.3391  loss_cls_stage2: 0.2059  loss_box_reg_stage2: 0.3069  loss_mask: 0.523  loss_rpn_cls: 0.05679  loss_rpn_loc: 0.03278  validation_loss: 2.244  time: 1.5352  data_time: 0.0239  lr: 7.7453e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:48:30 d2.utils.events]: \u001b[0m eta: 0:14:04  iter: 9459  total_loss: 2.363  loss_cls_stage0: 0.3388  loss_box_reg_stage0: 0.2697  loss_cls_stage1: 0.2665  loss_box_reg_stage1: 0.3627  loss_cls_stage2: 0.1915  loss_box_reg_stage2: 0.3162  loss_mask: 0.5557  loss_rpn_cls: 0.06184  loss_rpn_loc: 0.03616  validation_loss: 2.244  time: 1.5352  data_time: 0.0236  lr: 7.2042e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:49:01 d2.utils.events]: \u001b[0m eta: 0:13:32  iter: 9479  total_loss: 2.506  loss_cls_stage0: 0.3506  loss_box_reg_stage0: 0.2629  loss_cls_stage1: 0.2914  loss_box_reg_stage1: 0.381  loss_cls_stage2: 0.2038  loss_box_reg_stage2: 0.3284  loss_mask: 0.5222  loss_rpn_cls: 0.06813  loss_rpn_loc: 0.03961  validation_loss: 2.244  time: 1.5353  data_time: 0.0234  lr: 6.6826e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:49:33 d2.utils.events]: \u001b[0m eta: 0:13:01  iter: 9499  total_loss: 2.332  loss_cls_stage0: 0.3351  loss_box_reg_stage0: 0.2758  loss_cls_stage1: 0.2735  loss_box_reg_stage1: 0.3773  loss_cls_stage2: 0.1955  loss_box_reg_stage2: 0.3102  loss_mask: 0.4768  loss_rpn_cls: 0.05666  loss_rpn_loc: 0.03551  validation_loss: 2.244  time: 1.5354  data_time: 0.0235  lr: 6.1804e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:50:04 d2.utils.events]: \u001b[0m eta: 0:12:30  iter: 9519  total_loss: 2.321  loss_cls_stage0: 0.3359  loss_box_reg_stage0: 0.2812  loss_cls_stage1: 0.278  loss_box_reg_stage1: 0.3706  loss_cls_stage2: 0.1955  loss_box_reg_stage2: 0.3052  loss_mask: 0.5193  loss_rpn_cls: 0.06589  loss_rpn_loc: 0.03785  validation_loss: 2.244  time: 1.5355  data_time: 0.0232  lr: 5.6977e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:50:36 d2.utils.events]: \u001b[0m eta: 0:11:59  iter: 9539  total_loss: 2.568  loss_cls_stage0: 0.3623  loss_box_reg_stage0: 0.3063  loss_cls_stage1: 0.3055  loss_box_reg_stage1: 0.4132  loss_cls_stage2: 0.218  loss_box_reg_stage2: 0.2989  loss_mask: 0.5082  loss_rpn_cls: 0.07147  loss_rpn_loc: 0.03971  validation_loss: 2.244  time: 1.5355  data_time: 0.0227  lr: 5.2346e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:51:07 d2.utils.events]: \u001b[0m eta: 0:11:28  iter: 9559  total_loss: 2.323  loss_cls_stage0: 0.3176  loss_box_reg_stage0: 0.2531  loss_cls_stage1: 0.2655  loss_box_reg_stage1: 0.3558  loss_cls_stage2: 0.188  loss_box_reg_stage2: 0.2897  loss_mask: 0.5013  loss_rpn_cls: 0.06696  loss_rpn_loc: 0.03349  validation_loss: 2.244  time: 1.5356  data_time: 0.0222  lr: 4.791e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:51:38 d2.utils.events]: \u001b[0m eta: 0:10:56  iter: 9579  total_loss: 2.471  loss_cls_stage0: 0.3602  loss_box_reg_stage0: 0.2783  loss_cls_stage1: 0.304  loss_box_reg_stage1: 0.3781  loss_cls_stage2: 0.2197  loss_box_reg_stage2: 0.3052  loss_mask: 0.5614  loss_rpn_cls: 0.05851  loss_rpn_loc: 0.03394  validation_loss: 2.244  time: 1.5357  data_time: 0.0223  lr: 4.3669e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:52:09 d2.utils.events]: \u001b[0m eta: 0:10:25  iter: 9599  total_loss: 2.132  loss_cls_stage0: 0.2981  loss_box_reg_stage0: 0.2385  loss_cls_stage1: 0.2467  loss_box_reg_stage1: 0.3371  loss_cls_stage2: 0.1649  loss_box_reg_stage2: 0.267  loss_mask: 0.5473  loss_rpn_cls: 0.05711  loss_rpn_loc: 0.03208  validation_loss: 2.244  time: 1.5357  data_time: 0.0236  lr: 3.9624e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:52:41 d2.utils.events]: \u001b[0m eta: 0:09:54  iter: 9619  total_loss: 2.365  loss_cls_stage0: 0.3277  loss_box_reg_stage0: 0.2658  loss_cls_stage1: 0.2625  loss_box_reg_stage1: 0.3878  loss_cls_stage2: 0.192  loss_box_reg_stage2: 0.305  loss_mask: 0.5441  loss_rpn_cls: 0.06342  loss_rpn_loc: 0.03301  validation_loss: 2.244  time: 1.5358  data_time: 0.0241  lr: 3.5774e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:53:12 d2.utils.events]: \u001b[0m eta: 0:09:22  iter: 9639  total_loss: 2.323  loss_cls_stage0: 0.3122  loss_box_reg_stage0: 0.2539  loss_cls_stage1: 0.2612  loss_box_reg_stage1: 0.3628  loss_cls_stage2: 0.1806  loss_box_reg_stage2: 0.3087  loss_mask: 0.5251  loss_rpn_cls: 0.07049  loss_rpn_loc: 0.03671  validation_loss: 2.244  time: 1.5358  data_time: 0.0226  lr: 3.2121e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:53:43 d2.utils.events]: \u001b[0m eta: 0:08:51  iter: 9659  total_loss: 2.326  loss_cls_stage0: 0.3276  loss_box_reg_stage0: 0.2514  loss_cls_stage1: 0.2658  loss_box_reg_stage1: 0.3477  loss_cls_stage2: 0.1957  loss_box_reg_stage2: 0.3185  loss_mask: 0.5435  loss_rpn_cls: 0.06515  loss_rpn_loc: 0.03755  validation_loss: 2.244  time: 1.5359  data_time: 0.0236  lr: 2.8664e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:54:15 d2.utils.events]: \u001b[0m eta: 0:08:20  iter: 9679  total_loss: 2.327  loss_cls_stage0: 0.3457  loss_box_reg_stage0: 0.2706  loss_cls_stage1: 0.2825  loss_box_reg_stage1: 0.3647  loss_cls_stage2: 0.1985  loss_box_reg_stage2: 0.2892  loss_mask: 0.5271  loss_rpn_cls: 0.06961  loss_rpn_loc: 0.03514  validation_loss: 2.244  time: 1.5360  data_time: 0.0235  lr: 2.5403e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:54:46 d2.utils.events]: \u001b[0m eta: 0:07:49  iter: 9699  total_loss: 2.447  loss_cls_stage0: 0.3509  loss_box_reg_stage0: 0.2753  loss_cls_stage1: 0.2999  loss_box_reg_stage1: 0.3888  loss_cls_stage2: 0.2203  loss_box_reg_stage2: 0.3266  loss_mask: 0.5063  loss_rpn_cls: 0.05615  loss_rpn_loc: 0.0355  validation_loss: 2.244  time: 1.5360  data_time: 0.0256  lr: 2.2338e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:55:17 d2.utils.events]: \u001b[0m eta: 0:07:17  iter: 9719  total_loss: 2.257  loss_cls_stage0: 0.2945  loss_box_reg_stage0: 0.253  loss_cls_stage1: 0.2569  loss_box_reg_stage1: 0.3732  loss_cls_stage2: 0.1981  loss_box_reg_stage2: 0.3263  loss_mask: 0.5134  loss_rpn_cls: 0.06136  loss_rpn_loc: 0.03408  validation_loss: 2.244  time: 1.5361  data_time: 0.0257  lr: 1.947e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:55:49 d2.utils.events]: \u001b[0m eta: 0:06:46  iter: 9739  total_loss: 2.473  loss_cls_stage0: 0.3644  loss_box_reg_stage0: 0.2806  loss_cls_stage1: 0.3099  loss_box_reg_stage1: 0.3702  loss_cls_stage2: 0.2087  loss_box_reg_stage2: 0.2834  loss_mask: 0.4973  loss_rpn_cls: 0.06142  loss_rpn_loc: 0.03708  validation_loss: 2.244  time: 1.5362  data_time: 0.0253  lr: 1.6799e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:56:20 d2.utils.events]: \u001b[0m eta: 0:06:15  iter: 9759  total_loss: 2.458  loss_cls_stage0: 0.3461  loss_box_reg_stage0: 0.2776  loss_cls_stage1: 0.2788  loss_box_reg_stage1: 0.3728  loss_cls_stage2: 0.2042  loss_box_reg_stage2: 0.3073  loss_mask: 0.5493  loss_rpn_cls: 0.05739  loss_rpn_loc: 0.03648  validation_loss: 2.244  time: 1.5362  data_time: 0.0250  lr: 1.4324e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:56:51 d2.utils.events]: \u001b[0m eta: 0:05:43  iter: 9779  total_loss: 2.216  loss_cls_stage0: 0.2971  loss_box_reg_stage0: 0.2446  loss_cls_stage1: 0.2519  loss_box_reg_stage1: 0.345  loss_cls_stage2: 0.182  loss_box_reg_stage2: 0.2814  loss_mask: 0.5062  loss_rpn_cls: 0.06664  loss_rpn_loc: 0.03249  validation_loss: 2.244  time: 1.5363  data_time: 0.0241  lr: 1.2046e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:57:23 d2.utils.events]: \u001b[0m eta: 0:05:12  iter: 9799  total_loss: 2.351  loss_cls_stage0: 0.3227  loss_box_reg_stage0: 0.2576  loss_cls_stage1: 0.269  loss_box_reg_stage1: 0.3503  loss_cls_stage2: 0.1971  loss_box_reg_stage2: 0.2837  loss_mask: 0.5505  loss_rpn_cls: 0.06116  loss_rpn_loc: 0.03307  validation_loss: 2.244  time: 1.5363  data_time: 0.0239  lr: 9.9652e-08  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:57:54 d2.utils.events]: \u001b[0m eta: 0:04:41  iter: 9819  total_loss: 2.431  loss_cls_stage0: 0.3104  loss_box_reg_stage0: 0.2624  loss_cls_stage1: 0.2569  loss_box_reg_stage1: 0.3687  loss_cls_stage2: 0.1995  loss_box_reg_stage2: 0.3217  loss_mask: 0.5046  loss_rpn_cls: 0.06711  loss_rpn_loc: 0.03683  validation_loss: 2.244  time: 1.5364  data_time: 0.0244  lr: 8.0813e-08  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:58:26 d2.utils.events]: \u001b[0m eta: 0:04:10  iter: 9839  total_loss: 2.533  loss_cls_stage0: 0.3611  loss_box_reg_stage0: 0.2751  loss_cls_stage1: 0.3111  loss_box_reg_stage1: 0.396  loss_cls_stage2: 0.217  loss_box_reg_stage2: 0.3028  loss_mask: 0.5345  loss_rpn_cls: 0.05842  loss_rpn_loc: 0.03484  validation_loss: 2.244  time: 1.5365  data_time: 0.0229  lr: 6.3944e-08  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:58:57 d2.utils.events]: \u001b[0m eta: 0:03:38  iter: 9859  total_loss: 2.53  loss_cls_stage0: 0.3612  loss_box_reg_stage0: 0.2839  loss_cls_stage1: 0.2862  loss_box_reg_stage1: 0.3962  loss_cls_stage2: 0.1999  loss_box_reg_stage2: 0.3045  loss_mask: 0.5721  loss_rpn_cls: 0.06599  loss_rpn_loc: 0.04129  validation_loss: 2.244  time: 1.5365  data_time: 0.0233  lr: 4.9046e-08  max_mem: 12121M\n",
      "\u001b[32m[03/27 01:59:28 d2.utils.events]: \u001b[0m eta: 0:03:07  iter: 9879  total_loss: 2.396  loss_cls_stage0: 0.3235  loss_box_reg_stage0: 0.2601  loss_cls_stage1: 0.2741  loss_box_reg_stage1: 0.3699  loss_cls_stage2: 0.1856  loss_box_reg_stage2: 0.2809  loss_mask: 0.5351  loss_rpn_cls: 0.05554  loss_rpn_loc: 0.03323  validation_loss: 2.244  time: 1.5366  data_time: 0.0231  lr: 3.6121e-08  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:00:00 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 9899  total_loss: 2.393  loss_cls_stage0: 0.3235  loss_box_reg_stage0: 0.2586  loss_cls_stage1: 0.2742  loss_box_reg_stage1: 0.3671  loss_cls_stage2: 0.1967  loss_box_reg_stage2: 0.3105  loss_mask: 0.5291  loss_rpn_cls: 0.06051  loss_rpn_loc: 0.03709  validation_loss: 2.244  time: 1.5367  data_time: 0.0244  lr: 2.5168e-08  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:00:31 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 9919  total_loss: 2.412  loss_cls_stage0: 0.3314  loss_box_reg_stage0: 0.2609  loss_cls_stage1: 0.2652  loss_box_reg_stage1: 0.3834  loss_cls_stage2: 0.1976  loss_box_reg_stage2: 0.2995  loss_mask: 0.5282  loss_rpn_cls: 0.0561  loss_rpn_loc: 0.03552  validation_loss: 2.244  time: 1.5367  data_time: 0.0221  lr: 1.6188e-08  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:01:03 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 9939  total_loss: 2.373  loss_cls_stage0: 0.3395  loss_box_reg_stage0: 0.2712  loss_cls_stage1: 0.2732  loss_box_reg_stage1: 0.3697  loss_cls_stage2: 0.1969  loss_box_reg_stage2: 0.2851  loss_mask: 0.5524  loss_rpn_cls: 0.06532  loss_rpn_loc: 0.04075  validation_loss: 2.244  time: 1.5368  data_time: 0.0235  lr: 9.1809e-09  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:01:34 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 9959  total_loss: 2.457  loss_cls_stage0: 0.3459  loss_box_reg_stage0: 0.2754  loss_cls_stage1: 0.277  loss_box_reg_stage1: 0.3675  loss_cls_stage2: 0.1854  loss_box_reg_stage2: 0.2998  loss_mask: 0.5377  loss_rpn_cls: 0.06478  loss_rpn_loc: 0.03891  validation_loss: 2.244  time: 1.5369  data_time: 0.0243  lr: 4.1476e-09  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:02:05 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 9979  total_loss: 2.363  loss_cls_stage0: 0.3217  loss_box_reg_stage0: 0.2667  loss_cls_stage1: 0.2805  loss_box_reg_stage1: 0.3811  loss_cls_stage2: 0.2105  loss_box_reg_stage2: 0.3199  loss_mask: 0.52  loss_rpn_cls: 0.06251  loss_rpn_loc: 0.03879  validation_loss: 2.244  time: 1.5369  data_time: 0.0231  lr: 1.0881e-09  max_mem: 12121M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/27 02:02:40 d2.data.common]: \u001b[0mSerializing 879 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/27 02:02:40 d2.data.common]: \u001b[0mSerialized dataset takes 0.90 MiB\n",
      "\u001b[32m[03/27 02:02:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 879 images\n",
      "\u001b[32m[03/27 02:02:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/879. 0.0810 s / img. ETA=0:01:50\n",
      "\u001b[32m[03/27 02:02:47 d2.evaluation.evaluator]: \u001b[0mInference done 54/879. 0.0813 s / img. ETA=0:01:38\n",
      "\u001b[32m[03/27 02:02:52 d2.evaluation.evaluator]: \u001b[0mInference done 94/879. 0.0814 s / img. ETA=0:01:36\n",
      "\u001b[32m[03/27 02:02:57 d2.evaluation.evaluator]: \u001b[0mInference done 134/879. 0.0814 s / img. ETA=0:01:32\n",
      "\u001b[32m[03/27 02:03:02 d2.evaluation.evaluator]: \u001b[0mInference done 177/879. 0.0814 s / img. ETA=0:01:26\n",
      "\u001b[32m[03/27 02:03:07 d2.evaluation.evaluator]: \u001b[0mInference done 218/879. 0.0814 s / img. ETA=0:01:21\n",
      "\u001b[32m[03/27 02:03:12 d2.evaluation.evaluator]: \u001b[0mInference done 259/879. 0.0814 s / img. ETA=0:01:16\n",
      "\u001b[32m[03/27 02:03:17 d2.evaluation.evaluator]: \u001b[0mInference done 301/879. 0.0814 s / img. ETA=0:01:11\n",
      "\u001b[32m[03/27 02:03:22 d2.evaluation.evaluator]: \u001b[0mInference done 344/879. 0.0813 s / img. ETA=0:01:05\n",
      "\u001b[32m[03/27 02:03:27 d2.evaluation.evaluator]: \u001b[0mInference done 386/879. 0.0813 s / img. ETA=0:01:00\n",
      "\u001b[32m[03/27 02:03:33 d2.evaluation.evaluator]: \u001b[0mInference done 430/879. 0.0812 s / img. ETA=0:00:54\n",
      "\u001b[32m[03/27 02:03:38 d2.evaluation.evaluator]: \u001b[0mInference done 471/879. 0.0812 s / img. ETA=0:00:49\n",
      "\u001b[32m[03/27 02:03:43 d2.evaluation.evaluator]: \u001b[0mInference done 515/879. 0.0812 s / img. ETA=0:00:44\n",
      "\u001b[32m[03/27 02:03:48 d2.evaluation.evaluator]: \u001b[0mInference done 554/879. 0.0812 s / img. ETA=0:00:39\n",
      "\u001b[32m[03/27 02:03:53 d2.evaluation.evaluator]: \u001b[0mInference done 595/879. 0.0812 s / img. ETA=0:00:34\n",
      "\u001b[32m[03/27 02:03:58 d2.evaluation.evaluator]: \u001b[0mInference done 640/879. 0.0812 s / img. ETA=0:00:28\n",
      "\u001b[32m[03/27 02:04:03 d2.evaluation.evaluator]: \u001b[0mInference done 682/879. 0.0812 s / img. ETA=0:00:23\n",
      "\u001b[32m[03/27 02:04:08 d2.evaluation.evaluator]: \u001b[0mInference done 724/879. 0.0812 s / img. ETA=0:00:18\n",
      "\u001b[32m[03/27 02:04:13 d2.evaluation.evaluator]: \u001b[0mInference done 767/879. 0.0812 s / img. ETA=0:00:13\n",
      "\u001b[32m[03/27 02:04:18 d2.evaluation.evaluator]: \u001b[0mInference done 805/879. 0.0812 s / img. ETA=0:00:08\n",
      "\u001b[32m[03/27 02:04:23 d2.evaluation.evaluator]: \u001b[0mInference done 850/879. 0.0812 s / img. ETA=0:00:03\n",
      "\u001b[32m[03/27 02:04:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:45.801177 (0.121054 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/27 02:04:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:10 (0.081194 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.31 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.147\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.163\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.045\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.095\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.140\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.062\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.209\n",
      "\u001b[32m[03/27 02:04:27 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold3 in csv format:\n",
      "\u001b[32m[03/27 02:04:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/27 02:04:27 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/27 02:04:27 d2.evaluation.testing]: \u001b[0mcopypaste: 9.0079,14.6972,16.2660,0.9089,4.4651,9.4618\n",
      "validation do loss eval 2.3871190509404214\n",
      "\u001b[32m[03/27 02:05:59 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 2.208  loss_cls_stage0: 0.2986  loss_box_reg_stage0: 0.2505  loss_cls_stage1: 0.2357  loss_box_reg_stage1: 0.3545  loss_cls_stage2: 0.1875  loss_box_reg_stage2: 0.3072  loss_mask: 0.5239  loss_rpn_cls: 0.06569  loss_rpn_loc: 0.03442  validation_loss: 2.255  time: 1.5370  data_time: 0.0225  lr: 2.4674e-12  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:05:59 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 4:16:06 (1.5370 s / it)\n",
      "\u001b[32m[03/27 02:05:59 d2.engine.hooks]: \u001b[0mTotal training time: 4:47:49 (0:31:42 on hooks)\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/27 02:05:59 d2.data.common]: \u001b[0mSerializing 879 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/27 02:05:59 d2.data.common]: \u001b[0mSerialized dataset takes 0.90 MiB\n",
      "\u001b[32m[03/27 02:05:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 879 images\n",
      "\u001b[32m[03/27 02:06:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/879. 0.0823 s / img. ETA=0:02:03\n",
      "\u001b[32m[03/27 02:06:06 d2.evaluation.evaluator]: \u001b[0mInference done 53/879. 0.0811 s / img. ETA=0:01:42\n",
      "\u001b[32m[03/27 02:06:12 d2.evaluation.evaluator]: \u001b[0mInference done 94/879. 0.0813 s / img. ETA=0:01:38\n",
      "\u001b[32m[03/27 02:06:17 d2.evaluation.evaluator]: \u001b[0mInference done 134/879. 0.0814 s / img. ETA=0:01:33\n",
      "\u001b[32m[03/27 02:06:22 d2.evaluation.evaluator]: \u001b[0mInference done 177/879. 0.0813 s / img. ETA=0:01:27\n",
      "\u001b[32m[03/27 02:06:27 d2.evaluation.evaluator]: \u001b[0mInference done 218/879. 0.0813 s / img. ETA=0:01:21\n",
      "\u001b[32m[03/27 02:06:32 d2.evaluation.evaluator]: \u001b[0mInference done 259/879. 0.0814 s / img. ETA=0:01:16\n",
      "\u001b[32m[03/27 02:06:37 d2.evaluation.evaluator]: \u001b[0mInference done 301/879. 0.0813 s / img. ETA=0:01:11\n",
      "\u001b[32m[03/27 02:06:42 d2.evaluation.evaluator]: \u001b[0mInference done 344/879. 0.0813 s / img. ETA=0:01:05\n",
      "\u001b[32m[03/27 02:06:47 d2.evaluation.evaluator]: \u001b[0mInference done 387/879. 0.0812 s / img. ETA=0:01:00\n",
      "\u001b[32m[03/27 02:06:52 d2.evaluation.evaluator]: \u001b[0mInference done 431/879. 0.0812 s / img. ETA=0:00:54\n",
      "\u001b[32m[03/27 02:06:57 d2.evaluation.evaluator]: \u001b[0mInference done 474/879. 0.0812 s / img. ETA=0:00:49\n",
      "\u001b[32m[03/27 02:07:02 d2.evaluation.evaluator]: \u001b[0mInference done 518/879. 0.0811 s / img. ETA=0:00:43\n",
      "\u001b[32m[03/27 02:07:08 d2.evaluation.evaluator]: \u001b[0mInference done 559/879. 0.0812 s / img. ETA=0:00:38\n",
      "\u001b[32m[03/27 02:07:13 d2.evaluation.evaluator]: \u001b[0mInference done 600/879. 0.0812 s / img. ETA=0:00:33\n",
      "\u001b[32m[03/27 02:07:18 d2.evaluation.evaluator]: \u001b[0mInference done 645/879. 0.0811 s / img. ETA=0:00:28\n",
      "\u001b[32m[03/27 02:07:23 d2.evaluation.evaluator]: \u001b[0mInference done 688/879. 0.0811 s / img. ETA=0:00:23\n",
      "\u001b[32m[03/27 02:07:28 d2.evaluation.evaluator]: \u001b[0mInference done 731/879. 0.0811 s / img. ETA=0:00:17\n",
      "\u001b[32m[03/27 02:07:33 d2.evaluation.evaluator]: \u001b[0mInference done 771/879. 0.0811 s / img. ETA=0:00:13\n",
      "\u001b[32m[03/27 02:07:38 d2.evaluation.evaluator]: \u001b[0mInference done 811/879. 0.0811 s / img. ETA=0:00:08\n",
      "\u001b[32m[03/27 02:07:43 d2.evaluation.evaluator]: \u001b[0mInference done 856/879. 0.0811 s / img. ETA=0:00:02\n",
      "\u001b[32m[03/27 02:07:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:45.346100 (0.120533 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/27 02:07:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:10 (0.081072 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.32 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.147\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.163\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.045\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.095\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.140\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.062\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.209\n",
      "\u001b[32m[03/27 02:07:46 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold3 in csv format:\n",
      "\u001b[32m[03/27 02:07:46 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/27 02:07:46 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/27 02:07:46 d2.evaluation.testing]: \u001b[0mcopypaste: 9.0079,14.6972,16.2660,0.9089,4.4651,9.4618\n",
      "cfg.OUTPUT_DIR ./output -> /home/yamaguchi-milkcocholate/VinBigData/src/VinBigData-ObjectDetection/detectron2_results/results01/fold-4\n",
      "\u001b[32m[03/27 02:07:48 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): CascadeROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): ModuleList(\n",
      "      (0): FastRCNNConvFCHead(\n",
      "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "        (fc_relu1): ReLU()\n",
      "        (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (fc_relu2): ReLU()\n",
      "      )\n",
      "      (1): FastRCNNConvFCHead(\n",
      "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "        (fc_relu1): ReLU()\n",
      "        (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (fc_relu2): ReLU()\n",
      "      )\n",
      "      (2): FastRCNNConvFCHead(\n",
      "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "        (fc_relu1): ReLU()\n",
      "        (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (fc_relu2): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (box_predictor): ModuleList(\n",
      "      (0): FastRCNNOutputLayers(\n",
      "        (cls_score): Linear(in_features=1024, out_features=15, bias=True)\n",
      "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      )\n",
      "      (1): FastRCNNOutputLayers(\n",
      "        (cls_score): Linear(in_features=1024, out_features=15, bias=True)\n",
      "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      )\n",
      "      (2): FastRCNNOutputLayers(\n",
      "        (cls_score): Linear(in_features=1024, out_features=15, bias=True)\n",
      "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 14, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[AlbumentationsMapper] Augmentations used in training: Compose([\n",
      "  HorizontalFlip(always_apply=False, p=0.5),\n",
      "  ShiftScaleRotate(always_apply=False, p=0.5, shift_limit_x=(-0.0625, 0.0625), shift_limit_y=(-0.0625, 0.0625), scale_limit=(-0.15000000000000002, 0.1499999999999999), rotate_limit=(-10, 10), interpolation=1, border_mode=4, value=None, mask_value=None),\n",
      "  RandomBrightnessContrast(always_apply=False, p=0.5, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), brightness_by_max=True),\n",
      "  Blur(always_apply=False, p=0.4, blur_limit=(3, 10)),\n",
      "  IAAAffine(always_apply=False, p=0.5, scale=(1.0, 1.0), translate_percent=None, translate_px=None, rotate=(-0.0, 0.0), shear=(-0.0, 0.0), order=1, cval=0, mode='reflect'),\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/27 02:07:48 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 3521 images left.\n",
      "\u001b[32m[03/27 02:07:48 d2.data.build]: \u001b[0mDistribution of instances among all 14 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "| Aortic enla.. | 2693         |  Atelectasis  | 182          | Calcification | 607          |\n",
      "| Cardiomegaly  | 1908         | Consolidation | 346          |      ILD      | 579          |\n",
      "| Infiltration  | 771          | Lung Opacity  | 1559         |  Nodule/Mass  | 1491         |\n",
      "| Other lesion  | 1465         | Pleural eff.. | 1413         | Pleural thi.. | 3210         |\n",
      "| Pneumothorax  | 105          | Pulmonary f.. | 2687         |               |              |\n",
      "|     total     | 19016        |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/27 02:07:48 d2.data.common]: \u001b[0mSerializing 3521 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/27 02:07:49 d2.data.common]: \u001b[0mSerialized dataset takes 3.63 MiB\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/27 02:07:49 d2.data.build]: \u001b[0mDistribution of instances among all 14 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "| Aortic enla.. | 682          |  Atelectasis  | 50           | Calcification | 136          |\n",
      "| Cardiomegaly  | 475          | Consolidation | 77           |      ILD      | 142          |\n",
      "| Infiltration  | 172          | Lung Opacity  | 420          |  Nodule/Mass  | 361          |\n",
      "| Other lesion  | 342          | Pleural eff.. | 335          | Pleural thi.. | 815          |\n",
      "| Pneumothorax  | 24           | Pulmonary f.. | 667          |               |              |\n",
      "|     total     | 4698         |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/27 02:07:49 d2.data.common]: \u001b[0mSerializing 857 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/27 02:07:49 d2.data.common]: \u001b[0mSerialized dataset takes 0.89 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'proposal_generator.anchor_generator.cell_anchors.0' to the model due to incompatible shapes: (3, 4) in the checkpoint but (5, 4) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.anchor_generator.cell_anchors.1' to the model due to incompatible shapes: (3, 4) in the checkpoint but (5, 4) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.anchor_generator.cell_anchors.2' to the model due to incompatible shapes: (3, 4) in the checkpoint but (5, 4) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.anchor_generator.cell_anchors.3' to the model due to incompatible shapes: (3, 4) in the checkpoint but (5, 4) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.anchor_generator.cell_anchors.4' to the model due to incompatible shapes: (3, 4) in the checkpoint but (5, 4) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.objectness_logits.weight' to the model due to incompatible shapes: (3, 256, 1, 1) in the checkpoint but (5, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.objectness_logits.bias' to the model due to incompatible shapes: (3,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.anchor_deltas.weight' to the model due to incompatible shapes: (12, 256, 1, 1) in the checkpoint but (20, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.anchor_deltas.bias' to the model due to incompatible shapes: (12,) in the checkpoint but (20,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.0.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (15, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.0.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (15,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.1.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (15, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.1.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (15,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.2.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (15, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.2.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (15,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (14, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (14,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/27 02:07:49 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/27 02:08:16 d2.utils.events]: \u001b[0m eta: 3:43:11  iter: 19  total_loss: 10.08  loss_cls_stage0: 2.787  loss_box_reg_stage0: 0.02327  loss_cls_stage1: 2.971  loss_box_reg_stage1: 0.04603  loss_cls_stage2: 2.668  loss_box_reg_stage2: 0.03412  loss_mask: 0.6932  loss_rpn_cls: 0.8001  loss_rpn_loc: 0.05141  time: 1.3430  data_time: 0.0476  lr: 1.9981e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:08:43 d2.utils.events]: \u001b[0m eta: 3:42:57  iter: 39  total_loss: 9.471  loss_cls_stage0: 2.611  loss_box_reg_stage0: 0.02392  loss_cls_stage1: 2.772  loss_box_reg_stage1: 0.05176  loss_cls_stage2: 2.481  loss_box_reg_stage2: 0.03455  loss_mask: 0.6934  loss_rpn_cls: 0.7906  loss_rpn_loc: 0.05844  time: 1.3460  data_time: 0.0242  lr: 3.996e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:09:10 d2.utils.events]: \u001b[0m eta: 3:42:22  iter: 59  total_loss: 8.199  loss_cls_stage0: 2.2  loss_box_reg_stage0: 0.01827  loss_cls_stage1: 2.332  loss_box_reg_stage1: 0.04347  loss_cls_stage2: 2.06  loss_box_reg_stage2: 0.02771  loss_mask: 0.6924  loss_rpn_cls: 0.7698  loss_rpn_loc: 0.04792  time: 1.3441  data_time: 0.0237  lr: 5.9936e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:09:37 d2.utils.events]: \u001b[0m eta: 3:41:54  iter: 79  total_loss: 6.454  loss_cls_stage0: 1.655  loss_box_reg_stage0: 0.0208  loss_cls_stage1: 1.756  loss_box_reg_stage1: 0.04578  loss_cls_stage2: 1.505  loss_box_reg_stage2: 0.03297  loss_mask: 0.6928  loss_rpn_cls: 0.7393  loss_rpn_loc: 0.05039  time: 1.3439  data_time: 0.0248  lr: 7.9909e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:10:04 d2.utils.events]: \u001b[0m eta: 3:41:36  iter: 99  total_loss: 4.611  loss_cls_stage0: 1.052  loss_box_reg_stage0: 0.02441  loss_cls_stage1: 1.075  loss_box_reg_stage1: 0.05255  loss_cls_stage2: 0.8973  loss_box_reg_stage2: 0.04167  loss_mask: 0.6917  loss_rpn_cls: 0.6992  loss_rpn_loc: 0.05935  time: 1.3450  data_time: 0.0238  lr: 9.9877e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:10:31 d2.utils.events]: \u001b[0m eta: 3:41:22  iter: 119  total_loss: 3.154  loss_cls_stage0: 0.6033  loss_box_reg_stage0: 0.02389  loss_cls_stage1: 0.5755  loss_box_reg_stage1: 0.05217  loss_cls_stage2: 0.4726  loss_box_reg_stage2: 0.03434  loss_mask: 0.6915  loss_rpn_cls: 0.6494  loss_rpn_loc: 0.05836  time: 1.3480  data_time: 0.0242  lr: 1.1984e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:10:58 d2.utils.events]: \u001b[0m eta: 3:41:15  iter: 139  total_loss: 2.541  loss_cls_stage0: 0.3654  loss_box_reg_stage0: 0.02453  loss_cls_stage1: 0.3829  loss_box_reg_stage1: 0.05089  loss_cls_stage2: 0.311  loss_box_reg_stage2: 0.03613  loss_mask: 0.6911  loss_rpn_cls: 0.5912  loss_rpn_loc: 0.05574  time: 1.3520  data_time: 0.0245  lr: 1.3979e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:11:27 d2.utils.events]: \u001b[0m eta: 3:41:15  iter: 159  total_loss: 2.388  loss_cls_stage0: 0.319  loss_box_reg_stage0: 0.03974  loss_cls_stage1: 0.3647  loss_box_reg_stage1: 0.05673  loss_cls_stage2: 0.3082  loss_box_reg_stage2: 0.03231  loss_mask: 0.6911  loss_rpn_cls: 0.5225  loss_rpn_loc: 0.05248  time: 1.3596  data_time: 0.0238  lr: 1.5974e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:11:55 d2.utils.events]: \u001b[0m eta: 3:41:14  iter: 179  total_loss: 2.48  loss_cls_stage0: 0.3394  loss_box_reg_stage0: 0.05896  loss_cls_stage1: 0.4  loss_box_reg_stage1: 0.06771  loss_cls_stage2: 0.3519  loss_box_reg_stage2: 0.04691  loss_mask: 0.6883  loss_rpn_cls: 0.4626  loss_rpn_loc: 0.05812  time: 1.3690  data_time: 0.0245  lr: 1.7968e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:12:25 d2.utils.events]: \u001b[0m eta: 3:41:22  iter: 199  total_loss: 2.361  loss_cls_stage0: 0.3318  loss_box_reg_stage0: 0.08751  loss_cls_stage1: 0.3689  loss_box_reg_stage1: 0.08751  loss_cls_stage2: 0.3388  loss_box_reg_stage2: 0.04782  loss_mask: 0.6876  loss_rpn_cls: 0.3918  loss_rpn_loc: 0.05369  time: 1.3786  data_time: 0.0247  lr: 1.9961e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:12:54 d2.utils.events]: \u001b[0m eta: 3:41:26  iter: 219  total_loss: 2.238  loss_cls_stage0: 0.3034  loss_box_reg_stage0: 0.1015  loss_cls_stage1: 0.3053  loss_box_reg_stage1: 0.09952  loss_cls_stage2: 0.2844  loss_box_reg_stage2: 0.05445  loss_mask: 0.6874  loss_rpn_cls: 0.3358  loss_rpn_loc: 0.05595  time: 1.3883  data_time: 0.0250  lr: 2.1952e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:13:24 d2.utils.events]: \u001b[0m eta: 3:42:27  iter: 239  total_loss: 1.998  loss_cls_stage0: 0.273  loss_box_reg_stage0: 0.1052  loss_cls_stage1: 0.2298  loss_box_reg_stage1: 0.09718  loss_cls_stage2: 0.2037  loss_box_reg_stage2: 0.05195  loss_mask: 0.6834  loss_rpn_cls: 0.2849  loss_rpn_loc: 0.04948  time: 1.3961  data_time: 0.0249  lr: 2.3942e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:13:54 d2.utils.events]: \u001b[0m eta: 3:43:50  iter: 259  total_loss: 1.872  loss_cls_stage0: 0.2485  loss_box_reg_stage0: 0.1011  loss_cls_stage1: 0.2002  loss_box_reg_stage1: 0.0985  loss_cls_stage2: 0.1696  loss_box_reg_stage2: 0.05105  loss_mask: 0.682  loss_rpn_cls: 0.2542  loss_rpn_loc: 0.04822  time: 1.4031  data_time: 0.0243  lr: 2.5931e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:14:24 d2.utils.events]: \u001b[0m eta: 3:46:06  iter: 279  total_loss: 1.806  loss_cls_stage0: 0.2411  loss_box_reg_stage0: 0.1013  loss_cls_stage1: 0.1878  loss_box_reg_stage1: 0.0963  loss_cls_stage2: 0.1434  loss_box_reg_stage2: 0.05631  loss_mask: 0.6814  loss_rpn_cls: 0.2214  loss_rpn_loc: 0.04686  time: 1.4091  data_time: 0.0251  lr: 2.7918e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:14:54 d2.utils.events]: \u001b[0m eta: 3:48:00  iter: 299  total_loss: 1.878  loss_cls_stage0: 0.2566  loss_box_reg_stage0: 0.1199  loss_cls_stage1: 0.2026  loss_box_reg_stage1: 0.1041  loss_cls_stage2: 0.1529  loss_box_reg_stage2: 0.06332  loss_mask: 0.6782  loss_rpn_cls: 0.2208  loss_rpn_loc: 0.05641  time: 1.4150  data_time: 0.0249  lr: 2.9904e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:15:23 d2.utils.events]: \u001b[0m eta: 3:51:33  iter: 319  total_loss: 1.822  loss_cls_stage0: 0.2509  loss_box_reg_stage0: 0.1134  loss_cls_stage1: 0.1973  loss_box_reg_stage1: 0.1155  loss_cls_stage2: 0.1338  loss_box_reg_stage2: 0.05937  loss_mask: 0.6783  loss_rpn_cls: 0.1936  loss_rpn_loc: 0.04752  time: 1.4196  data_time: 0.0245  lr: 3.1888e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:15:53 d2.utils.events]: \u001b[0m eta: 3:52:57  iter: 339  total_loss: 1.723  loss_cls_stage0: 0.2371  loss_box_reg_stage0: 0.1068  loss_cls_stage1: 0.1778  loss_box_reg_stage1: 0.1032  loss_cls_stage2: 0.1257  loss_box_reg_stage2: 0.05408  loss_mask: 0.6782  loss_rpn_cls: 0.1759  loss_rpn_loc: 0.04634  time: 1.4236  data_time: 0.0244  lr: 3.387e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:16:23 d2.utils.events]: \u001b[0m eta: 3:53:38  iter: 359  total_loss: 1.8  loss_cls_stage0: 0.2604  loss_box_reg_stage0: 0.1109  loss_cls_stage1: 0.1793  loss_box_reg_stage1: 0.1015  loss_cls_stage2: 0.1235  loss_box_reg_stage2: 0.06075  loss_mask: 0.6746  loss_rpn_cls: 0.1761  loss_rpn_loc: 0.04843  time: 1.4279  data_time: 0.0242  lr: 3.585e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:16:53 d2.utils.events]: \u001b[0m eta: 3:54:38  iter: 379  total_loss: 1.751  loss_cls_stage0: 0.2623  loss_box_reg_stage0: 0.1183  loss_cls_stage1: 0.1795  loss_box_reg_stage1: 0.1079  loss_cls_stage2: 0.1315  loss_box_reg_stage2: 0.06146  loss_mask: 0.6669  loss_rpn_cls: 0.1862  loss_rpn_loc: 0.05131  time: 1.4314  data_time: 0.0242  lr: 3.7828e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:17:23 d2.utils.events]: \u001b[0m eta: 3:54:38  iter: 399  total_loss: 1.744  loss_cls_stage0: 0.259  loss_box_reg_stage0: 0.1124  loss_cls_stage1: 0.1844  loss_box_reg_stage1: 0.09192  loss_cls_stage2: 0.138  loss_box_reg_stage2: 0.06704  loss_mask: 0.674  loss_rpn_cls: 0.1732  loss_rpn_loc: 0.04561  time: 1.4347  data_time: 0.0243  lr: 3.9803e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:17:53 d2.utils.events]: \u001b[0m eta: 3:54:44  iter: 419  total_loss: 1.778  loss_cls_stage0: 0.2597  loss_box_reg_stage0: 0.1188  loss_cls_stage1: 0.1841  loss_box_reg_stage1: 0.09444  loss_cls_stage2: 0.1389  loss_box_reg_stage2: 0.0611  loss_mask: 0.6702  loss_rpn_cls: 0.1849  loss_rpn_loc: 0.04969  time: 1.4382  data_time: 0.0234  lr: 4.1777e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:18:23 d2.utils.events]: \u001b[0m eta: 3:54:36  iter: 439  total_loss: 1.752  loss_cls_stage0: 0.2649  loss_box_reg_stage0: 0.1279  loss_cls_stage1: 0.1772  loss_box_reg_stage1: 0.1006  loss_cls_stage2: 0.1319  loss_box_reg_stage2: 0.06561  loss_mask: 0.6735  loss_rpn_cls: 0.171  loss_rpn_loc: 0.04679  time: 1.4410  data_time: 0.0242  lr: 4.3747e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:18:53 d2.utils.events]: \u001b[0m eta: 3:54:24  iter: 459  total_loss: 1.715  loss_cls_stage0: 0.2698  loss_box_reg_stage0: 0.1233  loss_cls_stage1: 0.1796  loss_box_reg_stage1: 0.1108  loss_cls_stage2: 0.1234  loss_box_reg_stage2: 0.06672  loss_mask: 0.6644  loss_rpn_cls: 0.1424  loss_rpn_loc: 0.03917  time: 1.4436  data_time: 0.0257  lr: 4.5716e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:19:23 d2.utils.events]: \u001b[0m eta: 3:54:16  iter: 479  total_loss: 1.824  loss_cls_stage0: 0.2971  loss_box_reg_stage0: 0.1539  loss_cls_stage1: 0.1904  loss_box_reg_stage1: 0.1233  loss_cls_stage2: 0.1264  loss_box_reg_stage2: 0.07239  loss_mask: 0.656  loss_rpn_cls: 0.1507  loss_rpn_loc: 0.04322  time: 1.4465  data_time: 0.0248  lr: 4.7681e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:19:54 d2.utils.events]: \u001b[0m eta: 3:54:01  iter: 499  total_loss: 1.89  loss_cls_stage0: 0.2974  loss_box_reg_stage0: 0.1411  loss_cls_stage1: 0.205  loss_box_reg_stage1: 0.1243  loss_cls_stage2: 0.1322  loss_box_reg_stage2: 0.07291  loss_mask: 0.6745  loss_rpn_cls: 0.1672  loss_rpn_loc: 0.0464  time: 1.4488  data_time: 0.0244  lr: 4.9644e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:20:24 d2.utils.events]: \u001b[0m eta: 3:53:56  iter: 519  total_loss: 1.893  loss_cls_stage0: 0.3228  loss_box_reg_stage0: 0.1517  loss_cls_stage1: 0.2136  loss_box_reg_stage1: 0.1322  loss_cls_stage2: 0.1451  loss_box_reg_stage2: 0.07562  loss_mask: 0.654  loss_rpn_cls: 0.1731  loss_rpn_loc: 0.0531  time: 1.4514  data_time: 0.0245  lr: 5.1604e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:20:54 d2.utils.events]: \u001b[0m eta: 3:53:46  iter: 539  total_loss: 1.818  loss_cls_stage0: 0.3033  loss_box_reg_stage0: 0.1553  loss_cls_stage1: 0.1978  loss_box_reg_stage1: 0.1167  loss_cls_stage2: 0.1256  loss_box_reg_stage2: 0.0645  loss_mask: 0.6704  loss_rpn_cls: 0.1453  loss_rpn_loc: 0.04006  time: 1.4534  data_time: 0.0246  lr: 5.356e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:21:24 d2.utils.events]: \u001b[0m eta: 3:53:25  iter: 559  total_loss: 1.758  loss_cls_stage0: 0.2845  loss_box_reg_stage0: 0.1447  loss_cls_stage1: 0.1878  loss_box_reg_stage1: 0.1166  loss_cls_stage2: 0.1252  loss_box_reg_stage2: 0.06496  loss_mask: 0.656  loss_rpn_cls: 0.1557  loss_rpn_loc: 0.04345  time: 1.4551  data_time: 0.0232  lr: 5.5514e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:21:54 d2.utils.events]: \u001b[0m eta: 3:53:08  iter: 579  total_loss: 1.982  loss_cls_stage0: 0.3367  loss_box_reg_stage0: 0.171  loss_cls_stage1: 0.2197  loss_box_reg_stage1: 0.1361  loss_cls_stage2: 0.143  loss_box_reg_stage2: 0.07594  loss_mask: 0.6505  loss_rpn_cls: 0.1711  loss_rpn_loc: 0.04871  time: 1.4569  data_time: 0.0321  lr: 5.7464e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:22:24 d2.utils.events]: \u001b[0m eta: 3:52:45  iter: 599  total_loss: 1.793  loss_cls_stage0: 0.3009  loss_box_reg_stage0: 0.1501  loss_cls_stage1: 0.2028  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.1346  loss_box_reg_stage2: 0.07304  loss_mask: 0.6403  loss_rpn_cls: 0.1475  loss_rpn_loc: 0.04399  time: 1.4584  data_time: 0.0238  lr: 5.9411e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:22:54 d2.utils.events]: \u001b[0m eta: 3:52:22  iter: 619  total_loss: 1.882  loss_cls_stage0: 0.3144  loss_box_reg_stage0: 0.1526  loss_cls_stage1: 0.2114  loss_box_reg_stage1: 0.1231  loss_cls_stage2: 0.1452  loss_box_reg_stage2: 0.07389  loss_mask: 0.6661  loss_rpn_cls: 0.1588  loss_rpn_loc: 0.04522  time: 1.4600  data_time: 0.0253  lr: 6.1354e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:23:25 d2.utils.events]: \u001b[0m eta: 3:52:00  iter: 639  total_loss: 2.013  loss_cls_stage0: 0.3335  loss_box_reg_stage0: 0.1636  loss_cls_stage1: 0.2364  loss_box_reg_stage1: 0.1455  loss_cls_stage2: 0.153  loss_box_reg_stage2: 0.08803  loss_mask: 0.6527  loss_rpn_cls: 0.1542  loss_rpn_loc: 0.04711  time: 1.4615  data_time: 0.0317  lr: 6.3294e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:23:54 d2.utils.events]: \u001b[0m eta: 3:51:30  iter: 659  total_loss: 1.738  loss_cls_stage0: 0.2801  loss_box_reg_stage0: 0.1194  loss_cls_stage1: 0.1999  loss_box_reg_stage1: 0.1057  loss_cls_stage2: 0.1266  loss_box_reg_stage2: 0.06465  loss_mask: 0.6658  loss_rpn_cls: 0.1436  loss_rpn_loc: 0.03753  time: 1.4624  data_time: 0.0247  lr: 6.523e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:24:24 d2.utils.events]: \u001b[0m eta: 3:51:01  iter: 679  total_loss: 1.76  loss_cls_stage0: 0.2771  loss_box_reg_stage0: 0.1298  loss_cls_stage1: 0.1842  loss_box_reg_stage1: 0.1108  loss_cls_stage2: 0.1239  loss_box_reg_stage2: 0.07348  loss_mask: 0.67  loss_rpn_cls: 0.1333  loss_rpn_loc: 0.03572  time: 1.4634  data_time: 0.0252  lr: 6.7162e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:24:54 d2.utils.events]: \u001b[0m eta: 3:50:32  iter: 699  total_loss: 1.962  loss_cls_stage0: 0.3139  loss_box_reg_stage0: 0.1556  loss_cls_stage1: 0.223  loss_box_reg_stage1: 0.1398  loss_cls_stage2: 0.1446  loss_box_reg_stage2: 0.08057  loss_mask: 0.6754  loss_rpn_cls: 0.1406  loss_rpn_loc: 0.04316  time: 1.4647  data_time: 0.0243  lr: 6.909e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:25:25 d2.utils.events]: \u001b[0m eta: 3:50:08  iter: 719  total_loss: 1.927  loss_cls_stage0: 0.3271  loss_box_reg_stage0: 0.1623  loss_cls_stage1: 0.2256  loss_box_reg_stage1: 0.1443  loss_cls_stage2: 0.1474  loss_box_reg_stage2: 0.08853  loss_mask: 0.6572  loss_rpn_cls: 0.1381  loss_rpn_loc: 0.04033  time: 1.4658  data_time: 0.0246  lr: 7.1015e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:25:55 d2.utils.events]: \u001b[0m eta: 3:49:41  iter: 739  total_loss: 1.884  loss_cls_stage0: 0.3109  loss_box_reg_stage0: 0.1606  loss_cls_stage1: 0.217  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.1376  loss_box_reg_stage2: 0.07834  loss_mask: 0.6685  loss_rpn_cls: 0.1403  loss_rpn_loc: 0.04192  time: 1.4668  data_time: 0.0244  lr: 7.2934e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:26:25 d2.utils.events]: \u001b[0m eta: 3:49:16  iter: 759  total_loss: 1.966  loss_cls_stage0: 0.3386  loss_box_reg_stage0: 0.1754  loss_cls_stage1: 0.2287  loss_box_reg_stage1: 0.1575  loss_cls_stage2: 0.1452  loss_box_reg_stage2: 0.09022  loss_mask: 0.6616  loss_rpn_cls: 0.1337  loss_rpn_loc: 0.04202  time: 1.4678  data_time: 0.0242  lr: 7.485e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:26:55 d2.utils.events]: \u001b[0m eta: 3:48:46  iter: 779  total_loss: 1.795  loss_cls_stage0: 0.3019  loss_box_reg_stage0: 0.1549  loss_cls_stage1: 0.2046  loss_box_reg_stage1: 0.1293  loss_cls_stage2: 0.1359  loss_box_reg_stage2: 0.08092  loss_mask: 0.6435  loss_rpn_cls: 0.1326  loss_rpn_loc: 0.03964  time: 1.4684  data_time: 0.0250  lr: 7.6761e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:27:25 d2.utils.events]: \u001b[0m eta: 3:48:17  iter: 799  total_loss: 1.849  loss_cls_stage0: 0.3186  loss_box_reg_stage0: 0.1643  loss_cls_stage1: 0.212  loss_box_reg_stage1: 0.1382  loss_cls_stage2: 0.1371  loss_box_reg_stage2: 0.08335  loss_mask: 0.6604  loss_rpn_cls: 0.1409  loss_rpn_loc: 0.04353  time: 1.4692  data_time: 0.0243  lr: 7.8668e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:27:55 d2.utils.events]: \u001b[0m eta: 3:47:47  iter: 819  total_loss: 1.865  loss_cls_stage0: 0.3036  loss_box_reg_stage0: 0.1531  loss_cls_stage1: 0.2031  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.1462  loss_box_reg_stage2: 0.07602  loss_mask: 0.6476  loss_rpn_cls: 0.1483  loss_rpn_loc: 0.04668  time: 1.4698  data_time: 0.0237  lr: 8.057e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:28:25 d2.utils.events]: \u001b[0m eta: 3:47:18  iter: 839  total_loss: 1.782  loss_cls_stage0: 0.3014  loss_box_reg_stage0: 0.1554  loss_cls_stage1: 0.2123  loss_box_reg_stage1: 0.1304  loss_cls_stage2: 0.1332  loss_box_reg_stage2: 0.07196  loss_mask: 0.628  loss_rpn_cls: 0.132  loss_rpn_loc: 0.04177  time: 1.4706  data_time: 0.0237  lr: 8.2467e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:28:55 d2.utils.events]: \u001b[0m eta: 3:46:48  iter: 859  total_loss: 1.962  loss_cls_stage0: 0.3251  loss_box_reg_stage0: 0.142  loss_cls_stage1: 0.2353  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.1416  loss_box_reg_stage2: 0.07856  loss_mask: 0.6612  loss_rpn_cls: 0.1435  loss_rpn_loc: 0.04484  time: 1.4712  data_time: 0.0246  lr: 8.4359e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:29:25 d2.utils.events]: \u001b[0m eta: 3:46:24  iter: 879  total_loss: 2.068  loss_cls_stage0: 0.3566  loss_box_reg_stage0: 0.1862  loss_cls_stage1: 0.2477  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.1598  loss_box_reg_stage2: 0.1028  loss_mask: 0.6763  loss_rpn_cls: 0.1318  loss_rpn_loc: 0.04298  time: 1.4720  data_time: 0.0241  lr: 8.6247e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:29:55 d2.utils.events]: \u001b[0m eta: 3:45:55  iter: 899  total_loss: 1.935  loss_cls_stage0: 0.331  loss_box_reg_stage0: 0.1613  loss_cls_stage1: 0.2375  loss_box_reg_stage1: 0.1439  loss_cls_stage2: 0.1528  loss_box_reg_stage2: 0.0808  loss_mask: 0.6137  loss_rpn_cls: 0.1364  loss_rpn_loc: 0.04377  time: 1.4728  data_time: 0.0238  lr: 8.8129e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:30:25 d2.utils.events]: \u001b[0m eta: 3:45:25  iter: 919  total_loss: 1.888  loss_cls_stage0: 0.3269  loss_box_reg_stage0: 0.1679  loss_cls_stage1: 0.2231  loss_box_reg_stage1: 0.1432  loss_cls_stage2: 0.1555  loss_box_reg_stage2: 0.09193  loss_mask: 0.6604  loss_rpn_cls: 0.1293  loss_rpn_loc: 0.04138  time: 1.4733  data_time: 0.0242  lr: 9.0006e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:30:55 d2.utils.events]: \u001b[0m eta: 3:44:56  iter: 939  total_loss: 1.904  loss_cls_stage0: 0.2995  loss_box_reg_stage0: 0.1427  loss_cls_stage1: 0.219  loss_box_reg_stage1: 0.1358  loss_cls_stage2: 0.1575  loss_box_reg_stage2: 0.09409  loss_mask: 0.6552  loss_rpn_cls: 0.135  loss_rpn_loc: 0.03683  time: 1.4739  data_time: 0.0241  lr: 9.1878e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:31:25 d2.utils.events]: \u001b[0m eta: 3:44:28  iter: 959  total_loss: 1.83  loss_cls_stage0: 0.3077  loss_box_reg_stage0: 0.1569  loss_cls_stage1: 0.2272  loss_box_reg_stage1: 0.1653  loss_cls_stage2: 0.1451  loss_box_reg_stage2: 0.09887  loss_mask: 0.6417  loss_rpn_cls: 0.1192  loss_rpn_loc: 0.03607  time: 1.4744  data_time: 0.0242  lr: 9.3744e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:31:55 d2.utils.events]: \u001b[0m eta: 3:43:57  iter: 979  total_loss: 1.76  loss_cls_stage0: 0.2856  loss_box_reg_stage0: 0.1467  loss_cls_stage1: 0.2022  loss_box_reg_stage1: 0.1309  loss_cls_stage2: 0.1334  loss_box_reg_stage2: 0.07737  loss_mask: 0.6352  loss_rpn_cls: 0.1221  loss_rpn_loc: 0.03882  time: 1.4747  data_time: 0.0245  lr: 9.5605e-05  max_mem: 12121M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/27 02:32:27 d2.data.common]: \u001b[0mSerializing 857 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/27 02:32:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.89 MiB\n",
      "\u001b[32m[03/27 02:32:27 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'vinbigdata_valid_fold4' to COCO format ...)\n",
      "\u001b[32m[03/27 02:32:27 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
      "\u001b[32m[03/27 02:32:27 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 857, #annotations: 4698\n",
      "\u001b[32m[03/27 02:32:27 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at '/home/yamaguchi-milkcocholate/VinBigData/src/VinBigData-ObjectDetection/detectron2_results/results01/fold-4/inference/vinbigdata_valid_fold4_coco_format.json' ...\n",
      "\u001b[32m[03/27 02:32:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 857 images\n",
      "\u001b[32m[03/27 02:32:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/857. 0.0759 s / img. ETA=0:01:06\n",
      "\u001b[32m[03/27 02:32:34 d2.evaluation.evaluator]: \u001b[0mInference done 75/857. 0.0760 s / img. ETA=0:01:01\n",
      "\u001b[32m[03/27 02:32:39 d2.evaluation.evaluator]: \u001b[0mInference done 139/857. 0.0761 s / img. ETA=0:00:56\n",
      "\u001b[32m[03/27 02:32:44 d2.evaluation.evaluator]: \u001b[0mInference done 203/857. 0.0761 s / img. ETA=0:00:51\n",
      "\u001b[32m[03/27 02:32:49 d2.evaluation.evaluator]: \u001b[0mInference done 267/857. 0.0761 s / img. ETA=0:00:46\n",
      "\u001b[32m[03/27 02:32:54 d2.evaluation.evaluator]: \u001b[0mInference done 331/857. 0.0761 s / img. ETA=0:00:41\n",
      "\u001b[32m[03/27 02:32:59 d2.evaluation.evaluator]: \u001b[0mInference done 395/857. 0.0761 s / img. ETA=0:00:36\n",
      "\u001b[32m[03/27 02:33:04 d2.evaluation.evaluator]: \u001b[0mInference done 459/857. 0.0761 s / img. ETA=0:00:31\n",
      "\u001b[32m[03/27 02:33:09 d2.evaluation.evaluator]: \u001b[0mInference done 522/857. 0.0761 s / img. ETA=0:00:26\n",
      "\u001b[32m[03/27 02:33:14 d2.evaluation.evaluator]: \u001b[0mInference done 585/857. 0.0762 s / img. ETA=0:00:21\n",
      "\u001b[32m[03/27 02:33:19 d2.evaluation.evaluator]: \u001b[0mInference done 649/857. 0.0762 s / img. ETA=0:00:16\n",
      "\u001b[32m[03/27 02:33:24 d2.evaluation.evaluator]: \u001b[0mInference done 713/857. 0.0762 s / img. ETA=0:00:11\n",
      "\u001b[32m[03/27 02:33:29 d2.evaluation.evaluator]: \u001b[0mInference done 776/857. 0.0763 s / img. ETA=0:00:06\n",
      "\u001b[32m[03/27 02:33:34 d2.evaluation.evaluator]: \u001b[0mInference done 840/857. 0.0763 s / img. ETA=0:00:01\n",
      "\u001b[32m[03/27 02:33:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:07.416740 (0.079128 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/27 02:33:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:05 (0.076299 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.37 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "\u001b[32m[03/27 02:33:36 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold4 in csv format:\n",
      "\u001b[32m[03/27 02:33:36 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/27 02:33:36 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/27 02:33:36 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n",
      "validation do loss eval 1.964801260355622\n",
      "\u001b[32m[03/27 02:35:02 d2.utils.events]: \u001b[0m eta: 3:43:28  iter: 999  total_loss: 1.903  loss_cls_stage0: 0.3002  loss_box_reg_stage0: 0.1529  loss_cls_stage1: 0.2217  loss_box_reg_stage1: 0.1533  loss_cls_stage2: 0.1467  loss_box_reg_stage2: 0.08832  loss_mask: 0.6746  loss_rpn_cls: 0.1247  loss_rpn_loc: 0.03502  validation_loss: 1.965  time: 1.4753  data_time: 0.0239  lr: 9.746e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:35:32 d2.utils.events]: \u001b[0m eta: 3:43:02  iter: 1019  total_loss: 1.708  loss_cls_stage0: 0.2874  loss_box_reg_stage0: 0.1426  loss_cls_stage1: 0.2012  loss_box_reg_stage1: 0.1291  loss_cls_stage2: 0.1328  loss_box_reg_stage2: 0.07581  loss_mask: 0.6342  loss_rpn_cls: 0.11  loss_rpn_loc: 0.03523  validation_loss: 1.965  time: 1.4750  data_time: 0.0244  lr: 9.746e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:36:01 d2.utils.events]: \u001b[0m eta: 3:42:36  iter: 1039  total_loss: 1.803  loss_cls_stage0: 0.2922  loss_box_reg_stage0: 0.1448  loss_cls_stage1: 0.2041  loss_box_reg_stage1: 0.1367  loss_cls_stage2: 0.1407  loss_box_reg_stage2: 0.08307  loss_mask: 0.6236  loss_rpn_cls: 0.1174  loss_rpn_loc: 0.03373  validation_loss: 1.965  time: 1.4753  data_time: 0.0242  lr: 9.736e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:36:32 d2.utils.events]: \u001b[0m eta: 3:42:12  iter: 1059  total_loss: 1.936  loss_cls_stage0: 0.2962  loss_box_reg_stage0: 0.1524  loss_cls_stage1: 0.2222  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.152  loss_box_reg_stage2: 0.09959  loss_mask: 0.6454  loss_rpn_cls: 0.104  loss_rpn_loc: 0.03745  validation_loss: 1.965  time: 1.4758  data_time: 0.0241  lr: 9.7258e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:37:01 d2.utils.events]: \u001b[0m eta: 3:41:47  iter: 1079  total_loss: 1.881  loss_cls_stage0: 0.305  loss_box_reg_stage0: 0.1509  loss_cls_stage1: 0.2221  loss_box_reg_stage1: 0.1448  loss_cls_stage2: 0.1486  loss_box_reg_stage2: 0.09022  loss_mask: 0.5973  loss_rpn_cls: 0.1247  loss_rpn_loc: 0.04108  validation_loss: 1.965  time: 1.4761  data_time: 0.0248  lr: 9.7155e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:37:31 d2.utils.events]: \u001b[0m eta: 3:41:22  iter: 1099  total_loss: 1.847  loss_cls_stage0: 0.2996  loss_box_reg_stage0: 0.1485  loss_cls_stage1: 0.2195  loss_box_reg_stage1: 0.1446  loss_cls_stage2: 0.1484  loss_box_reg_stage2: 0.08892  loss_mask: 0.6362  loss_rpn_cls: 0.1255  loss_rpn_loc: 0.03561  validation_loss: 1.965  time: 1.4765  data_time: 0.0241  lr: 9.7049e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:38:01 d2.utils.events]: \u001b[0m eta: 3:40:57  iter: 1119  total_loss: 1.883  loss_cls_stage0: 0.3074  loss_box_reg_stage0: 0.1557  loss_cls_stage1: 0.2157  loss_box_reg_stage1: 0.1424  loss_cls_stage2: 0.151  loss_box_reg_stage2: 0.08847  loss_mask: 0.6528  loss_rpn_cls: 0.1295  loss_rpn_loc: 0.03981  validation_loss: 1.965  time: 1.4768  data_time: 0.0236  lr: 9.6942e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:38:31 d2.utils.events]: \u001b[0m eta: 3:40:30  iter: 1139  total_loss: 1.936  loss_cls_stage0: 0.2965  loss_box_reg_stage0: 0.1543  loss_cls_stage1: 0.2267  loss_box_reg_stage1: 0.1605  loss_cls_stage2: 0.1508  loss_box_reg_stage2: 0.09614  loss_mask: 0.6442  loss_rpn_cls: 0.1404  loss_rpn_loc: 0.03941  validation_loss: 1.965  time: 1.4770  data_time: 0.0231  lr: 9.6833e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:39:01 d2.utils.events]: \u001b[0m eta: 3:40:07  iter: 1159  total_loss: 1.936  loss_cls_stage0: 0.3125  loss_box_reg_stage0: 0.1583  loss_cls_stage1: 0.2276  loss_box_reg_stage1: 0.1585  loss_cls_stage2: 0.1502  loss_box_reg_stage2: 0.09795  loss_mask: 0.6467  loss_rpn_cls: 0.1201  loss_rpn_loc: 0.03927  validation_loss: 1.965  time: 1.4774  data_time: 0.0300  lr: 9.6722e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:39:31 d2.utils.events]: \u001b[0m eta: 3:39:41  iter: 1179  total_loss: 1.818  loss_cls_stage0: 0.2838  loss_box_reg_stage0: 0.1371  loss_cls_stage1: 0.2192  loss_box_reg_stage1: 0.1485  loss_cls_stage2: 0.1443  loss_box_reg_stage2: 0.08994  loss_mask: 0.6644  loss_rpn_cls: 0.1281  loss_rpn_loc: 0.03823  validation_loss: 1.965  time: 1.4777  data_time: 0.0238  lr: 9.6609e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:40:01 d2.utils.events]: \u001b[0m eta: 3:39:15  iter: 1199  total_loss: 1.852  loss_cls_stage0: 0.3057  loss_box_reg_stage0: 0.1505  loss_cls_stage1: 0.2286  loss_box_reg_stage1: 0.1648  loss_cls_stage2: 0.1559  loss_box_reg_stage2: 0.09898  loss_mask: 0.6359  loss_rpn_cls: 0.1112  loss_rpn_loc: 0.03791  validation_loss: 1.965  time: 1.4781  data_time: 0.0244  lr: 9.6495e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:40:31 d2.utils.events]: \u001b[0m eta: 3:38:52  iter: 1219  total_loss: 1.957  loss_cls_stage0: 0.3154  loss_box_reg_stage0: 0.1508  loss_cls_stage1: 0.2416  loss_box_reg_stage1: 0.1592  loss_cls_stage2: 0.1554  loss_box_reg_stage2: 0.1015  loss_mask: 0.6731  loss_rpn_cls: 0.1253  loss_rpn_loc: 0.03974  validation_loss: 1.965  time: 1.4784  data_time: 0.0228  lr: 9.6378e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:41:01 d2.utils.events]: \u001b[0m eta: 3:38:27  iter: 1239  total_loss: 1.821  loss_cls_stage0: 0.2956  loss_box_reg_stage0: 0.1464  loss_cls_stage1: 0.2255  loss_box_reg_stage1: 0.1496  loss_cls_stage2: 0.1589  loss_box_reg_stage2: 0.09956  loss_mask: 0.6119  loss_rpn_cls: 0.1251  loss_rpn_loc: 0.0386  validation_loss: 1.965  time: 1.4787  data_time: 0.0244  lr: 9.626e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:41:31 d2.utils.events]: \u001b[0m eta: 3:38:02  iter: 1259  total_loss: 2.023  loss_cls_stage0: 0.3234  loss_box_reg_stage0: 0.1595  loss_cls_stage1: 0.2463  loss_box_reg_stage1: 0.1706  loss_cls_stage2: 0.1585  loss_box_reg_stage2: 0.1014  loss_mask: 0.6357  loss_rpn_cls: 0.1274  loss_rpn_loc: 0.03833  validation_loss: 1.965  time: 1.4791  data_time: 0.0251  lr: 9.614e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:42:01 d2.utils.events]: \u001b[0m eta: 3:37:37  iter: 1279  total_loss: 2.052  loss_cls_stage0: 0.3391  loss_box_reg_stage0: 0.171  loss_cls_stage1: 0.2477  loss_box_reg_stage1: 0.1811  loss_cls_stage2: 0.1615  loss_box_reg_stage2: 0.1092  loss_mask: 0.6385  loss_rpn_cls: 0.1201  loss_rpn_loc: 0.04107  validation_loss: 1.965  time: 1.4795  data_time: 0.0227  lr: 9.6018e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:42:31 d2.utils.events]: \u001b[0m eta: 3:37:07  iter: 1299  total_loss: 1.908  loss_cls_stage0: 0.2869  loss_box_reg_stage0: 0.1494  loss_cls_stage1: 0.2368  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.1604  loss_box_reg_stage2: 0.1015  loss_mask: 0.6449  loss_rpn_cls: 0.1157  loss_rpn_loc: 0.03601  validation_loss: 1.965  time: 1.4797  data_time: 0.0236  lr: 9.5894e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:43:01 d2.utils.events]: \u001b[0m eta: 3:36:40  iter: 1319  total_loss: 1.97  loss_cls_stage0: 0.3211  loss_box_reg_stage0: 0.1684  loss_cls_stage1: 0.2482  loss_box_reg_stage1: 0.1783  loss_cls_stage2: 0.1576  loss_box_reg_stage2: 0.1152  loss_mask: 0.6348  loss_rpn_cls: 0.1065  loss_rpn_loc: 0.04003  validation_loss: 1.965  time: 1.4801  data_time: 0.0239  lr: 9.5768e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:43:31 d2.utils.events]: \u001b[0m eta: 3:36:13  iter: 1339  total_loss: 1.935  loss_cls_stage0: 0.2818  loss_box_reg_stage0: 0.1404  loss_cls_stage1: 0.2262  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.1515  loss_box_reg_stage2: 0.1011  loss_mask: 0.6381  loss_rpn_cls: 0.1102  loss_rpn_loc: 0.03625  validation_loss: 1.965  time: 1.4804  data_time: 0.0234  lr: 9.5641e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:44:01 d2.utils.events]: \u001b[0m eta: 3:35:44  iter: 1359  total_loss: 1.796  loss_cls_stage0: 0.2795  loss_box_reg_stage0: 0.1452  loss_cls_stage1: 0.2118  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.1419  loss_box_reg_stage2: 0.09786  loss_mask: 0.621  loss_rpn_cls: 0.1201  loss_rpn_loc: 0.04145  validation_loss: 1.965  time: 1.4807  data_time: 0.0239  lr: 9.5512e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:44:31 d2.utils.events]: \u001b[0m eta: 3:35:17  iter: 1379  total_loss: 2.054  loss_cls_stage0: 0.3222  loss_box_reg_stage0: 0.1672  loss_cls_stage1: 0.2584  loss_box_reg_stage1: 0.1873  loss_cls_stage2: 0.1838  loss_box_reg_stage2: 0.1273  loss_mask: 0.5939  loss_rpn_cls: 0.1261  loss_rpn_loc: 0.04186  validation_loss: 1.965  time: 1.4811  data_time: 0.0249  lr: 9.5381e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:45:01 d2.utils.events]: \u001b[0m eta: 3:34:47  iter: 1399  total_loss: 1.82  loss_cls_stage0: 0.2791  loss_box_reg_stage0: 0.1465  loss_cls_stage1: 0.2124  loss_box_reg_stage1: 0.1581  loss_cls_stage2: 0.1414  loss_box_reg_stage2: 0.09286  loss_mask: 0.6145  loss_rpn_cls: 0.1167  loss_rpn_loc: 0.04171  validation_loss: 1.965  time: 1.4813  data_time: 0.0243  lr: 9.5248e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:45:32 d2.utils.events]: \u001b[0m eta: 3:34:18  iter: 1419  total_loss: 1.942  loss_cls_stage0: 0.3136  loss_box_reg_stage0: 0.1684  loss_cls_stage1: 0.2492  loss_box_reg_stage1: 0.1902  loss_cls_stage2: 0.1664  loss_box_reg_stage2: 0.1151  loss_mask: 0.6675  loss_rpn_cls: 0.1105  loss_rpn_loc: 0.036  validation_loss: 1.965  time: 1.4818  data_time: 0.0257  lr: 9.5113e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:46:02 d2.utils.events]: \u001b[0m eta: 3:33:50  iter: 1439  total_loss: 2.095  loss_cls_stage0: 0.353  loss_box_reg_stage0: 0.1819  loss_cls_stage1: 0.2709  loss_box_reg_stage1: 0.1961  loss_cls_stage2: 0.186  loss_box_reg_stage2: 0.1165  loss_mask: 0.6194  loss_rpn_cls: 0.1297  loss_rpn_loc: 0.04409  validation_loss: 1.965  time: 1.4822  data_time: 0.0228  lr: 9.4977e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:46:32 d2.utils.events]: \u001b[0m eta: 3:33:20  iter: 1459  total_loss: 1.932  loss_cls_stage0: 0.3178  loss_box_reg_stage0: 0.166  loss_cls_stage1: 0.2348  loss_box_reg_stage1: 0.1714  loss_cls_stage2: 0.1573  loss_box_reg_stage2: 0.1034  loss_mask: 0.6339  loss_rpn_cls: 0.1035  loss_rpn_loc: 0.03814  validation_loss: 1.965  time: 1.4825  data_time: 0.0241  lr: 9.4839e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:47:02 d2.utils.events]: \u001b[0m eta: 3:32:50  iter: 1479  total_loss: 1.914  loss_cls_stage0: 0.3091  loss_box_reg_stage0: 0.1616  loss_cls_stage1: 0.2415  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.1707  loss_box_reg_stage2: 0.1189  loss_mask: 0.5855  loss_rpn_cls: 0.1103  loss_rpn_loc: 0.03805  validation_loss: 1.965  time: 1.4828  data_time: 0.0241  lr: 9.4699e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:47:32 d2.utils.events]: \u001b[0m eta: 3:32:16  iter: 1499  total_loss: 1.821  loss_cls_stage0: 0.2889  loss_box_reg_stage0: 0.1478  loss_cls_stage1: 0.2209  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.1493  loss_box_reg_stage2: 0.09352  loss_mask: 0.6016  loss_rpn_cls: 0.1113  loss_rpn_loc: 0.03842  validation_loss: 1.965  time: 1.4830  data_time: 0.0232  lr: 9.4557e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:48:02 d2.utils.events]: \u001b[0m eta: 3:31:44  iter: 1519  total_loss: 1.988  loss_cls_stage0: 0.3313  loss_box_reg_stage0: 0.1739  loss_cls_stage1: 0.249  loss_box_reg_stage1: 0.1839  loss_cls_stage2: 0.1643  loss_box_reg_stage2: 0.1112  loss_mask: 0.6338  loss_rpn_cls: 0.1274  loss_rpn_loc: 0.04376  validation_loss: 1.965  time: 1.4833  data_time: 0.0235  lr: 9.4414e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:48:32 d2.utils.events]: \u001b[0m eta: 3:31:10  iter: 1539  total_loss: 1.803  loss_cls_stage0: 0.2781  loss_box_reg_stage0: 0.1356  loss_cls_stage1: 0.2096  loss_box_reg_stage1: 0.1495  loss_cls_stage2: 0.1522  loss_box_reg_stage2: 0.09762  loss_mask: 0.6173  loss_rpn_cls: 0.101  loss_rpn_loc: 0.03293  validation_loss: 1.965  time: 1.4834  data_time: 0.0242  lr: 9.4269e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:49:02 d2.utils.events]: \u001b[0m eta: 3:30:39  iter: 1559  total_loss: 1.838  loss_cls_stage0: 0.2865  loss_box_reg_stage0: 0.1519  loss_cls_stage1: 0.227  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.1642  loss_box_reg_stage2: 0.1136  loss_mask: 0.6592  loss_rpn_cls: 0.09919  loss_rpn_loc: 0.03478  validation_loss: 1.965  time: 1.4837  data_time: 0.0232  lr: 9.4122e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:49:32 d2.utils.events]: \u001b[0m eta: 3:30:09  iter: 1579  total_loss: 2.191  loss_cls_stage0: 0.3482  loss_box_reg_stage0: 0.1726  loss_cls_stage1: 0.2718  loss_box_reg_stage1: 0.1962  loss_cls_stage2: 0.1906  loss_box_reg_stage2: 0.1328  loss_mask: 0.634  loss_rpn_cls: 0.1238  loss_rpn_loc: 0.04459  validation_loss: 1.965  time: 1.4841  data_time: 0.0234  lr: 9.3973e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:50:03 d2.utils.events]: \u001b[0m eta: 3:29:39  iter: 1599  total_loss: 1.879  loss_cls_stage0: 0.2937  loss_box_reg_stage0: 0.1497  loss_cls_stage1: 0.2266  loss_box_reg_stage1: 0.1683  loss_cls_stage2: 0.1573  loss_box_reg_stage2: 0.1123  loss_mask: 0.5915  loss_rpn_cls: 0.1103  loss_rpn_loc: 0.03956  validation_loss: 1.965  time: 1.4844  data_time: 0.0241  lr: 9.3823e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:50:32 d2.utils.events]: \u001b[0m eta: 3:29:07  iter: 1619  total_loss: 1.823  loss_cls_stage0: 0.2707  loss_box_reg_stage0: 0.1328  loss_cls_stage1: 0.2213  loss_box_reg_stage1: 0.1529  loss_cls_stage2: 0.1523  loss_box_reg_stage2: 0.1062  loss_mask: 0.6051  loss_rpn_cls: 0.1066  loss_rpn_loc: 0.03596  validation_loss: 1.965  time: 1.4845  data_time: 0.0248  lr: 9.3671e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:51:03 d2.utils.events]: \u001b[0m eta: 3:28:36  iter: 1639  total_loss: 1.813  loss_cls_stage0: 0.2869  loss_box_reg_stage0: 0.1512  loss_cls_stage1: 0.2264  loss_box_reg_stage1: 0.1607  loss_cls_stage2: 0.1546  loss_box_reg_stage2: 0.1138  loss_mask: 0.6107  loss_rpn_cls: 0.1071  loss_rpn_loc: 0.03898  validation_loss: 1.965  time: 1.4848  data_time: 0.0239  lr: 9.3517e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:51:33 d2.utils.events]: \u001b[0m eta: 3:28:07  iter: 1659  total_loss: 1.844  loss_cls_stage0: 0.2931  loss_box_reg_stage0: 0.1549  loss_cls_stage1: 0.2217  loss_box_reg_stage1: 0.1729  loss_cls_stage2: 0.1567  loss_box_reg_stage2: 0.1267  loss_mask: 0.6031  loss_rpn_cls: 0.1036  loss_rpn_loc: 0.03574  validation_loss: 1.965  time: 1.4850  data_time: 0.0236  lr: 9.3361e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:52:03 d2.utils.events]: \u001b[0m eta: 3:27:40  iter: 1679  total_loss: 1.967  loss_cls_stage0: 0.3331  loss_box_reg_stage0: 0.1649  loss_cls_stage1: 0.2371  loss_box_reg_stage1: 0.1877  loss_cls_stage2: 0.1599  loss_box_reg_stage2: 0.115  loss_mask: 0.5843  loss_rpn_cls: 0.1171  loss_rpn_loc: 0.04587  validation_loss: 1.965  time: 1.4852  data_time: 0.0238  lr: 9.3204e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:52:33 d2.utils.events]: \u001b[0m eta: 3:27:08  iter: 1699  total_loss: 1.786  loss_cls_stage0: 0.2628  loss_box_reg_stage0: 0.1354  loss_cls_stage1: 0.2021  loss_box_reg_stage1: 0.1509  loss_cls_stage2: 0.1522  loss_box_reg_stage2: 0.1069  loss_mask: 0.6134  loss_rpn_cls: 0.1089  loss_rpn_loc: 0.03741  validation_loss: 1.965  time: 1.4854  data_time: 0.0225  lr: 9.3045e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:53:03 d2.utils.events]: \u001b[0m eta: 3:26:37  iter: 1719  total_loss: 1.888  loss_cls_stage0: 0.2998  loss_box_reg_stage0: 0.1537  loss_cls_stage1: 0.2312  loss_box_reg_stage1: 0.1719  loss_cls_stage2: 0.1597  loss_box_reg_stage2: 0.1085  loss_mask: 0.5922  loss_rpn_cls: 0.1237  loss_rpn_loc: 0.0451  validation_loss: 1.965  time: 1.4855  data_time: 0.0234  lr: 9.2884e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:53:33 d2.utils.events]: \u001b[0m eta: 3:26:06  iter: 1739  total_loss: 1.836  loss_cls_stage0: 0.2883  loss_box_reg_stage0: 0.1516  loss_cls_stage1: 0.2312  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.156  loss_box_reg_stage2: 0.1111  loss_mask: 0.6062  loss_rpn_cls: 0.09804  loss_rpn_loc: 0.03585  validation_loss: 1.965  time: 1.4858  data_time: 0.0234  lr: 9.2722e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:54:03 d2.utils.events]: \u001b[0m eta: 3:25:35  iter: 1759  total_loss: 1.845  loss_cls_stage0: 0.287  loss_box_reg_stage0: 0.1512  loss_cls_stage1: 0.2231  loss_box_reg_stage1: 0.1548  loss_cls_stage2: 0.1522  loss_box_reg_stage2: 0.1098  loss_mask: 0.6187  loss_rpn_cls: 0.1102  loss_rpn_loc: 0.0405  validation_loss: 1.965  time: 1.4860  data_time: 0.0244  lr: 9.2558e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:54:33 d2.utils.events]: \u001b[0m eta: 3:25:06  iter: 1779  total_loss: 1.703  loss_cls_stage0: 0.2707  loss_box_reg_stage0: 0.1347  loss_cls_stage1: 0.2146  loss_box_reg_stage1: 0.1623  loss_cls_stage2: 0.1419  loss_box_reg_stage2: 0.1099  loss_mask: 0.5727  loss_rpn_cls: 0.09936  loss_rpn_loc: 0.03336  validation_loss: 1.965  time: 1.4861  data_time: 0.0235  lr: 9.2392e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:55:03 d2.utils.events]: \u001b[0m eta: 3:24:36  iter: 1799  total_loss: 1.791  loss_cls_stage0: 0.2995  loss_box_reg_stage0: 0.1582  loss_cls_stage1: 0.2249  loss_box_reg_stage1: 0.1613  loss_cls_stage2: 0.1465  loss_box_reg_stage2: 0.1008  loss_mask: 0.5474  loss_rpn_cls: 0.09991  loss_rpn_loc: 0.03675  validation_loss: 1.965  time: 1.4863  data_time: 0.0243  lr: 9.2225e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:55:33 d2.utils.events]: \u001b[0m eta: 3:24:08  iter: 1819  total_loss: 1.921  loss_cls_stage0: 0.3124  loss_box_reg_stage0: 0.1605  loss_cls_stage1: 0.244  loss_box_reg_stage1: 0.1806  loss_cls_stage2: 0.1785  loss_box_reg_stage2: 0.1317  loss_mask: 0.6094  loss_rpn_cls: 0.1105  loss_rpn_loc: 0.03978  validation_loss: 1.965  time: 1.4865  data_time: 0.0259  lr: 9.2056e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:56:03 d2.utils.events]: \u001b[0m eta: 3:23:39  iter: 1839  total_loss: 1.888  loss_cls_stage0: 0.2871  loss_box_reg_stage0: 0.1496  loss_cls_stage1: 0.2382  loss_box_reg_stage1: 0.1943  loss_cls_stage2: 0.1733  loss_box_reg_stage2: 0.1279  loss_mask: 0.5728  loss_rpn_cls: 0.1095  loss_rpn_loc: 0.03918  validation_loss: 1.965  time: 1.4867  data_time: 0.0246  lr: 9.1885e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:56:33 d2.utils.events]: \u001b[0m eta: 3:23:08  iter: 1859  total_loss: 1.897  loss_cls_stage0: 0.2868  loss_box_reg_stage0: 0.1468  loss_cls_stage1: 0.2289  loss_box_reg_stage1: 0.1637  loss_cls_stage2: 0.1545  loss_box_reg_stage2: 0.1108  loss_mask: 0.5898  loss_rpn_cls: 0.101  loss_rpn_loc: 0.03478  validation_loss: 1.965  time: 1.4869  data_time: 0.0236  lr: 9.1713e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:57:03 d2.utils.events]: \u001b[0m eta: 3:22:38  iter: 1879  total_loss: 1.925  loss_cls_stage0: 0.294  loss_box_reg_stage0: 0.1638  loss_cls_stage1: 0.2236  loss_box_reg_stage1: 0.1732  loss_cls_stage2: 0.1524  loss_box_reg_stage2: 0.1166  loss_mask: 0.6343  loss_rpn_cls: 0.1165  loss_rpn_loc: 0.0432  validation_loss: 1.965  time: 1.4871  data_time: 0.0237  lr: 9.1539e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:57:34 d2.utils.events]: \u001b[0m eta: 3:22:08  iter: 1899  total_loss: 1.944  loss_cls_stage0: 0.2882  loss_box_reg_stage0: 0.1538  loss_cls_stage1: 0.2391  loss_box_reg_stage1: 0.1861  loss_cls_stage2: 0.1624  loss_box_reg_stage2: 0.1229  loss_mask: 0.614  loss_rpn_cls: 0.1004  loss_rpn_loc: 0.0358  validation_loss: 1.965  time: 1.4873  data_time: 0.0243  lr: 9.1363e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:58:04 d2.utils.events]: \u001b[0m eta: 3:21:41  iter: 1919  total_loss: 2.043  loss_cls_stage0: 0.3236  loss_box_reg_stage0: 0.1692  loss_cls_stage1: 0.2533  loss_box_reg_stage1: 0.1903  loss_cls_stage2: 0.1745  loss_box_reg_stage2: 0.1293  loss_mask: 0.6171  loss_rpn_cls: 0.1122  loss_rpn_loc: 0.04228  validation_loss: 1.965  time: 1.4876  data_time: 0.0242  lr: 9.1186e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:58:34 d2.utils.events]: \u001b[0m eta: 3:21:12  iter: 1939  total_loss: 1.878  loss_cls_stage0: 0.2932  loss_box_reg_stage0: 0.1636  loss_cls_stage1: 0.2299  loss_box_reg_stage1: 0.1826  loss_cls_stage2: 0.1598  loss_box_reg_stage2: 0.1175  loss_mask: 0.6069  loss_rpn_cls: 0.1007  loss_rpn_loc: 0.04164  validation_loss: 1.965  time: 1.4878  data_time: 0.0241  lr: 9.1007e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:59:04 d2.utils.events]: \u001b[0m eta: 3:20:45  iter: 1959  total_loss: 1.977  loss_cls_stage0: 0.3011  loss_box_reg_stage0: 0.1586  loss_cls_stage1: 0.2394  loss_box_reg_stage1: 0.1955  loss_cls_stage2: 0.1773  loss_box_reg_stage2: 0.1329  loss_mask: 0.5836  loss_rpn_cls: 0.09605  loss_rpn_loc: 0.03744  validation_loss: 1.965  time: 1.4880  data_time: 0.0234  lr: 9.0826e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 02:59:34 d2.utils.events]: \u001b[0m eta: 3:20:17  iter: 1979  total_loss: 1.832  loss_cls_stage0: 0.304  loss_box_reg_stage0: 0.1642  loss_cls_stage1: 0.2242  loss_box_reg_stage1: 0.1807  loss_cls_stage2: 0.1578  loss_box_reg_stage2: 0.1218  loss_mask: 0.5937  loss_rpn_cls: 0.09667  loss_rpn_loc: 0.03517  validation_loss: 1.965  time: 1.4881  data_time: 0.0247  lr: 9.0644e-05  max_mem: 12121M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/27 03:00:07 d2.data.common]: \u001b[0mSerializing 857 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/27 03:00:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.89 MiB\n",
      "\u001b[32m[03/27 03:00:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 857 images\n",
      "\u001b[32m[03/27 03:00:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/857. 0.0783 s / img. ETA=0:01:13\n",
      "\u001b[32m[03/27 03:00:13 d2.evaluation.evaluator]: \u001b[0mInference done 68/857. 0.0790 s / img. ETA=0:01:10\n",
      "\u001b[32m[03/27 03:00:18 d2.evaluation.evaluator]: \u001b[0mInference done 126/857. 0.0787 s / img. ETA=0:01:04\n",
      "\u001b[32m[03/27 03:00:23 d2.evaluation.evaluator]: \u001b[0mInference done 184/857. 0.0785 s / img. ETA=0:00:58\n",
      "\u001b[32m[03/27 03:00:28 d2.evaluation.evaluator]: \u001b[0mInference done 242/857. 0.0786 s / img. ETA=0:00:53\n",
      "\u001b[32m[03/27 03:00:33 d2.evaluation.evaluator]: \u001b[0mInference done 301/857. 0.0786 s / img. ETA=0:00:48\n",
      "\u001b[32m[03/27 03:00:38 d2.evaluation.evaluator]: \u001b[0mInference done 359/857. 0.0786 s / img. ETA=0:00:43\n",
      "\u001b[32m[03/27 03:00:43 d2.evaluation.evaluator]: \u001b[0mInference done 417/857. 0.0786 s / img. ETA=0:00:38\n",
      "\u001b[32m[03/27 03:00:48 d2.evaluation.evaluator]: \u001b[0mInference done 475/857. 0.0785 s / img. ETA=0:00:33\n",
      "\u001b[32m[03/27 03:00:53 d2.evaluation.evaluator]: \u001b[0mInference done 533/857. 0.0785 s / img. ETA=0:00:28\n",
      "\u001b[32m[03/27 03:00:58 d2.evaluation.evaluator]: \u001b[0mInference done 591/857. 0.0785 s / img. ETA=0:00:23\n",
      "\u001b[32m[03/27 03:01:04 d2.evaluation.evaluator]: \u001b[0mInference done 649/857. 0.0785 s / img. ETA=0:00:18\n",
      "\u001b[32m[03/27 03:01:09 d2.evaluation.evaluator]: \u001b[0mInference done 707/857. 0.0786 s / img. ETA=0:00:13\n",
      "\u001b[32m[03/27 03:01:14 d2.evaluation.evaluator]: \u001b[0mInference done 765/857. 0.0786 s / img. ETA=0:00:08\n",
      "\u001b[32m[03/27 03:01:19 d2.evaluation.evaluator]: \u001b[0mInference done 823/857. 0.0786 s / img. ETA=0:00:02\n",
      "\u001b[32m[03/27 03:01:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:14.186702 (0.087074 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/27 03:01:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:06 (0.078627 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.41 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.031\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.060\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.064\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.017\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.032\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.051\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.051\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.023\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.052\n",
      "\u001b[32m[03/27 03:01:22 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold4 in csv format:\n",
      "\u001b[32m[03/27 03:01:22 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/27 03:01:22 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/27 03:01:22 d2.evaluation.testing]: \u001b[0mcopypaste: 3.0934,5.9942,6.4402,0.0000,1.7067,3.2344\n",
      "validation do loss eval 1.9667855875304159\n",
      "\u001b[32m[03/27 03:02:49 d2.utils.events]: \u001b[0m eta: 3:19:50  iter: 1999  total_loss: 1.85  loss_cls_stage0: 0.2715  loss_box_reg_stage0: 0.1517  loss_cls_stage1: 0.2225  loss_box_reg_stage1: 0.1822  loss_cls_stage2: 0.1503  loss_box_reg_stage2: 0.1136  loss_mask: 0.591  loss_rpn_cls: 0.1002  loss_rpn_loc: 0.04079  validation_loss: 1.966  time: 1.4884  data_time: 0.0238  lr: 9.046e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:03:18 d2.utils.events]: \u001b[0m eta: 3:19:22  iter: 2019  total_loss: 1.851  loss_cls_stage0: 0.2526  loss_box_reg_stage0: 0.1337  loss_cls_stage1: 0.211  loss_box_reg_stage1: 0.1678  loss_cls_stage2: 0.1528  loss_box_reg_stage2: 0.1225  loss_mask: 0.5718  loss_rpn_cls: 0.1043  loss_rpn_loc: 0.03696  validation_loss: 1.966  time: 1.4882  data_time: 0.0242  lr: 9.0275e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:03:49 d2.utils.events]: \u001b[0m eta: 3:18:57  iter: 2039  total_loss: 1.977  loss_cls_stage0: 0.3257  loss_box_reg_stage0: 0.1798  loss_cls_stage1: 0.2483  loss_box_reg_stage1: 0.1919  loss_cls_stage2: 0.1777  loss_box_reg_stage2: 0.1256  loss_mask: 0.5672  loss_rpn_cls: 0.1043  loss_rpn_loc: 0.03928  validation_loss: 1.966  time: 1.4885  data_time: 0.0251  lr: 9.0088e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:04:19 d2.utils.events]: \u001b[0m eta: 3:18:27  iter: 2059  total_loss: 1.873  loss_cls_stage0: 0.2983  loss_box_reg_stage0: 0.1578  loss_cls_stage1: 0.234  loss_box_reg_stage1: 0.1912  loss_cls_stage2: 0.1594  loss_box_reg_stage2: 0.1279  loss_mask: 0.5387  loss_rpn_cls: 0.1074  loss_rpn_loc: 0.04036  validation_loss: 1.966  time: 1.4887  data_time: 0.0240  lr: 8.9899e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:04:49 d2.utils.events]: \u001b[0m eta: 3:17:59  iter: 2079  total_loss: 2.198  loss_cls_stage0: 0.3446  loss_box_reg_stage0: 0.1795  loss_cls_stage1: 0.276  loss_box_reg_stage1: 0.2237  loss_cls_stage2: 0.1965  loss_box_reg_stage2: 0.1588  loss_mask: 0.6113  loss_rpn_cls: 0.1094  loss_rpn_loc: 0.04449  validation_loss: 1.966  time: 1.4890  data_time: 0.0236  lr: 8.9709e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:05:20 d2.utils.events]: \u001b[0m eta: 3:17:33  iter: 2099  total_loss: 1.815  loss_cls_stage0: 0.2739  loss_box_reg_stage0: 0.1535  loss_cls_stage1: 0.2216  loss_box_reg_stage1: 0.191  loss_cls_stage2: 0.1637  loss_box_reg_stage2: 0.1364  loss_mask: 0.6011  loss_rpn_cls: 0.09039  loss_rpn_loc: 0.03462  validation_loss: 1.966  time: 1.4892  data_time: 0.0247  lr: 8.9517e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:05:50 d2.utils.events]: \u001b[0m eta: 3:17:06  iter: 2119  total_loss: 1.995  loss_cls_stage0: 0.3219  loss_box_reg_stage0: 0.1721  loss_cls_stage1: 0.2504  loss_box_reg_stage1: 0.1927  loss_cls_stage2: 0.1792  loss_box_reg_stage2: 0.1469  loss_mask: 0.5706  loss_rpn_cls: 0.1028  loss_rpn_loc: 0.03635  validation_loss: 1.966  time: 1.4894  data_time: 0.0235  lr: 8.9324e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:06:20 d2.utils.events]: \u001b[0m eta: 3:16:37  iter: 2139  total_loss: 1.857  loss_cls_stage0: 0.2738  loss_box_reg_stage0: 0.1423  loss_cls_stage1: 0.2351  loss_box_reg_stage1: 0.1923  loss_cls_stage2: 0.1664  loss_box_reg_stage2: 0.1304  loss_mask: 0.5369  loss_rpn_cls: 0.09142  loss_rpn_loc: 0.03634  validation_loss: 1.966  time: 1.4895  data_time: 0.0260  lr: 8.9129e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:06:50 d2.utils.events]: \u001b[0m eta: 3:16:09  iter: 2159  total_loss: 1.886  loss_cls_stage0: 0.2799  loss_box_reg_stage0: 0.1444  loss_cls_stage1: 0.2336  loss_box_reg_stage1: 0.1721  loss_cls_stage2: 0.1723  loss_box_reg_stage2: 0.1332  loss_mask: 0.5594  loss_rpn_cls: 0.1084  loss_rpn_loc: 0.03845  validation_loss: 1.966  time: 1.4897  data_time: 0.0241  lr: 8.8933e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:07:20 d2.utils.events]: \u001b[0m eta: 3:15:41  iter: 2179  total_loss: 1.919  loss_cls_stage0: 0.2753  loss_box_reg_stage0: 0.149  loss_cls_stage1: 0.2259  loss_box_reg_stage1: 0.1835  loss_cls_stage2: 0.1632  loss_box_reg_stage2: 0.1235  loss_mask: 0.5879  loss_rpn_cls: 0.09908  loss_rpn_loc: 0.03455  validation_loss: 1.966  time: 1.4898  data_time: 0.0243  lr: 8.8735e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:07:50 d2.utils.events]: \u001b[0m eta: 3:15:12  iter: 2199  total_loss: 1.974  loss_cls_stage0: 0.2973  loss_box_reg_stage0: 0.1661  loss_cls_stage1: 0.2266  loss_box_reg_stage1: 0.1853  loss_cls_stage2: 0.1633  loss_box_reg_stage2: 0.1298  loss_mask: 0.5649  loss_rpn_cls: 0.09283  loss_rpn_loc: 0.03684  validation_loss: 1.966  time: 1.4900  data_time: 0.0237  lr: 8.8536e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:08:20 d2.utils.events]: \u001b[0m eta: 3:14:43  iter: 2219  total_loss: 1.837  loss_cls_stage0: 0.2827  loss_box_reg_stage0: 0.1655  loss_cls_stage1: 0.221  loss_box_reg_stage1: 0.1872  loss_cls_stage2: 0.1619  loss_box_reg_stage2: 0.1249  loss_mask: 0.5862  loss_rpn_cls: 0.0868  loss_rpn_loc: 0.03687  validation_loss: 1.966  time: 1.4902  data_time: 0.0236  lr: 8.8335e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:08:51 d2.utils.events]: \u001b[0m eta: 3:14:14  iter: 2239  total_loss: 1.887  loss_cls_stage0: 0.2867  loss_box_reg_stage0: 0.158  loss_cls_stage1: 0.2234  loss_box_reg_stage1: 0.1766  loss_cls_stage2: 0.1658  loss_box_reg_stage2: 0.1263  loss_mask: 0.5979  loss_rpn_cls: 0.1093  loss_rpn_loc: 0.03697  validation_loss: 1.966  time: 1.4903  data_time: 0.0243  lr: 8.8132e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:09:21 d2.utils.events]: \u001b[0m eta: 3:13:45  iter: 2259  total_loss: 1.96  loss_cls_stage0: 0.3074  loss_box_reg_stage0: 0.1617  loss_cls_stage1: 0.2368  loss_box_reg_stage1: 0.1848  loss_cls_stage2: 0.1591  loss_box_reg_stage2: 0.1305  loss_mask: 0.6282  loss_rpn_cls: 0.09964  loss_rpn_loc: 0.03928  validation_loss: 1.966  time: 1.4905  data_time: 0.0245  lr: 8.7928e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:09:51 d2.utils.events]: \u001b[0m eta: 3:13:14  iter: 2279  total_loss: 1.901  loss_cls_stage0: 0.2832  loss_box_reg_stage0: 0.1586  loss_cls_stage1: 0.2309  loss_box_reg_stage1: 0.216  loss_cls_stage2: 0.1613  loss_box_reg_stage2: 0.1422  loss_mask: 0.6212  loss_rpn_cls: 0.1011  loss_rpn_loc: 0.04194  validation_loss: 1.966  time: 1.4907  data_time: 0.0241  lr: 8.7723e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:10:21 d2.utils.events]: \u001b[0m eta: 3:12:48  iter: 2299  total_loss: 1.887  loss_cls_stage0: 0.2786  loss_box_reg_stage0: 0.1393  loss_cls_stage1: 0.2301  loss_box_reg_stage1: 0.1782  loss_cls_stage2: 0.167  loss_box_reg_stage2: 0.1261  loss_mask: 0.5931  loss_rpn_cls: 0.09031  loss_rpn_loc: 0.03709  validation_loss: 1.966  time: 1.4909  data_time: 0.0233  lr: 8.7516e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:10:52 d2.utils.events]: \u001b[0m eta: 3:12:16  iter: 2319  total_loss: 2.003  loss_cls_stage0: 0.2959  loss_box_reg_stage0: 0.1612  loss_cls_stage1: 0.2372  loss_box_reg_stage1: 0.1898  loss_cls_stage2: 0.1713  loss_box_reg_stage2: 0.1367  loss_mask: 0.5925  loss_rpn_cls: 0.0896  loss_rpn_loc: 0.03514  validation_loss: 1.966  time: 1.4910  data_time: 0.0234  lr: 8.7308e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:11:22 d2.utils.events]: \u001b[0m eta: 3:11:50  iter: 2339  total_loss: 1.829  loss_cls_stage0: 0.2895  loss_box_reg_stage0: 0.1537  loss_cls_stage1: 0.238  loss_box_reg_stage1: 0.195  loss_cls_stage2: 0.1641  loss_box_reg_stage2: 0.1301  loss_mask: 0.5702  loss_rpn_cls: 0.09048  loss_rpn_loc: 0.03561  validation_loss: 1.966  time: 1.4912  data_time: 0.0240  lr: 8.7098e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:11:52 d2.utils.events]: \u001b[0m eta: 3:11:23  iter: 2359  total_loss: 2.024  loss_cls_stage0: 0.325  loss_box_reg_stage0: 0.1844  loss_cls_stage1: 0.2495  loss_box_reg_stage1: 0.2123  loss_cls_stage2: 0.1683  loss_box_reg_stage2: 0.1428  loss_mask: 0.6173  loss_rpn_cls: 0.1139  loss_rpn_loc: 0.04196  validation_loss: 1.966  time: 1.4914  data_time: 0.0249  lr: 8.6886e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:12:22 d2.utils.events]: \u001b[0m eta: 3:10:53  iter: 2379  total_loss: 1.982  loss_cls_stage0: 0.3045  loss_box_reg_stage0: 0.1698  loss_cls_stage1: 0.2354  loss_box_reg_stage1: 0.2016  loss_cls_stage2: 0.1596  loss_box_reg_stage2: 0.1404  loss_mask: 0.605  loss_rpn_cls: 0.09424  loss_rpn_loc: 0.03702  validation_loss: 1.966  time: 1.4915  data_time: 0.0222  lr: 8.6673e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:12:53 d2.utils.events]: \u001b[0m eta: 3:10:27  iter: 2399  total_loss: 1.914  loss_cls_stage0: 0.2849  loss_box_reg_stage0: 0.162  loss_cls_stage1: 0.2275  loss_box_reg_stage1: 0.1939  loss_cls_stage2: 0.1597  loss_box_reg_stage2: 0.1316  loss_mask: 0.553  loss_rpn_cls: 0.1046  loss_rpn_loc: 0.03994  validation_loss: 1.966  time: 1.4917  data_time: 0.0239  lr: 8.6459e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:13:23 d2.utils.events]: \u001b[0m eta: 3:09:58  iter: 2419  total_loss: 1.938  loss_cls_stage0: 0.2918  loss_box_reg_stage0: 0.1679  loss_cls_stage1: 0.2353  loss_box_reg_stage1: 0.1946  loss_cls_stage2: 0.1653  loss_box_reg_stage2: 0.1314  loss_mask: 0.5928  loss_rpn_cls: 0.09737  loss_rpn_loc: 0.03972  validation_loss: 1.966  time: 1.4918  data_time: 0.0256  lr: 8.6243e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:13:53 d2.utils.events]: \u001b[0m eta: 3:09:26  iter: 2439  total_loss: 1.796  loss_cls_stage0: 0.2668  loss_box_reg_stage0: 0.1443  loss_cls_stage1: 0.215  loss_box_reg_stage1: 0.1743  loss_cls_stage2: 0.1528  loss_box_reg_stage2: 0.1297  loss_mask: 0.5901  loss_rpn_cls: 0.09289  loss_rpn_loc: 0.03578  validation_loss: 1.966  time: 1.4919  data_time: 0.0244  lr: 8.6026e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:14:23 d2.utils.events]: \u001b[0m eta: 3:08:57  iter: 2459  total_loss: 1.773  loss_cls_stage0: 0.2685  loss_box_reg_stage0: 0.1556  loss_cls_stage1: 0.2212  loss_box_reg_stage1: 0.1916  loss_cls_stage2: 0.1638  loss_box_reg_stage2: 0.1322  loss_mask: 0.562  loss_rpn_cls: 0.1014  loss_rpn_loc: 0.03876  validation_loss: 1.966  time: 1.4921  data_time: 0.0238  lr: 8.5808e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:14:53 d2.utils.events]: \u001b[0m eta: 3:08:27  iter: 2479  total_loss: 1.816  loss_cls_stage0: 0.2575  loss_box_reg_stage0: 0.151  loss_cls_stage1: 0.2061  loss_box_reg_stage1: 0.1826  loss_cls_stage2: 0.1466  loss_box_reg_stage2: 0.1389  loss_mask: 0.5567  loss_rpn_cls: 0.08696  loss_rpn_loc: 0.03326  validation_loss: 1.966  time: 1.4922  data_time: 0.0234  lr: 8.5588e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:15:23 d2.utils.events]: \u001b[0m eta: 3:08:01  iter: 2499  total_loss: 2.01  loss_cls_stage0: 0.312  loss_box_reg_stage0: 0.1777  loss_cls_stage1: 0.2507  loss_box_reg_stage1: 0.2065  loss_cls_stage2: 0.1783  loss_box_reg_stage2: 0.1486  loss_mask: 0.5996  loss_rpn_cls: 0.09364  loss_rpn_loc: 0.041  validation_loss: 1.966  time: 1.4924  data_time: 0.0228  lr: 8.5366e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:15:54 d2.utils.events]: \u001b[0m eta: 3:07:31  iter: 2519  total_loss: 1.875  loss_cls_stage0: 0.2745  loss_box_reg_stage0: 0.1631  loss_cls_stage1: 0.2226  loss_box_reg_stage1: 0.205  loss_cls_stage2: 0.1605  loss_box_reg_stage2: 0.1389  loss_mask: 0.5619  loss_rpn_cls: 0.09429  loss_rpn_loc: 0.03579  validation_loss: 1.966  time: 1.4925  data_time: 0.0232  lr: 8.5144e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:16:24 d2.utils.events]: \u001b[0m eta: 3:07:04  iter: 2539  total_loss: 2.052  loss_cls_stage0: 0.314  loss_box_reg_stage0: 0.1808  loss_cls_stage1: 0.2516  loss_box_reg_stage1: 0.2185  loss_cls_stage2: 0.1854  loss_box_reg_stage2: 0.15  loss_mask: 0.6069  loss_rpn_cls: 0.09438  loss_rpn_loc: 0.03821  validation_loss: 1.966  time: 1.4927  data_time: 0.0240  lr: 8.492e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:16:54 d2.utils.events]: \u001b[0m eta: 3:06:36  iter: 2559  total_loss: 1.931  loss_cls_stage0: 0.2986  loss_box_reg_stage0: 0.177  loss_cls_stage1: 0.2349  loss_box_reg_stage1: 0.2098  loss_cls_stage2: 0.1623  loss_box_reg_stage2: 0.1488  loss_mask: 0.5968  loss_rpn_cls: 0.08899  loss_rpn_loc: 0.0396  validation_loss: 1.966  time: 1.4929  data_time: 0.0243  lr: 8.4694e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:17:24 d2.utils.events]: \u001b[0m eta: 3:06:04  iter: 2579  total_loss: 1.95  loss_cls_stage0: 0.2662  loss_box_reg_stage0: 0.1549  loss_cls_stage1: 0.214  loss_box_reg_stage1: 0.1857  loss_cls_stage2: 0.1585  loss_box_reg_stage2: 0.1417  loss_mask: 0.5887  loss_rpn_cls: 0.08961  loss_rpn_loc: 0.03936  validation_loss: 1.966  time: 1.4930  data_time: 0.0231  lr: 8.4467e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:17:55 d2.utils.events]: \u001b[0m eta: 3:05:36  iter: 2599  total_loss: 1.9  loss_cls_stage0: 0.2795  loss_box_reg_stage0: 0.1719  loss_cls_stage1: 0.2195  loss_box_reg_stage1: 0.1936  loss_cls_stage2: 0.1597  loss_box_reg_stage2: 0.1282  loss_mask: 0.5501  loss_rpn_cls: 0.09346  loss_rpn_loc: 0.03486  validation_loss: 1.966  time: 1.4931  data_time: 0.0242  lr: 8.4239e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:18:25 d2.utils.events]: \u001b[0m eta: 3:05:09  iter: 2619  total_loss: 1.989  loss_cls_stage0: 0.3223  loss_box_reg_stage0: 0.1803  loss_cls_stage1: 0.2409  loss_box_reg_stage1: 0.2147  loss_cls_stage2: 0.1726  loss_box_reg_stage2: 0.1573  loss_mask: 0.5713  loss_rpn_cls: 0.0961  loss_rpn_loc: 0.0355  validation_loss: 1.966  time: 1.4933  data_time: 0.0243  lr: 8.4009e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:18:55 d2.utils.events]: \u001b[0m eta: 3:04:40  iter: 2639  total_loss: 1.915  loss_cls_stage0: 0.2986  loss_box_reg_stage0: 0.1694  loss_cls_stage1: 0.2331  loss_box_reg_stage1: 0.2136  loss_cls_stage2: 0.1664  loss_box_reg_stage2: 0.1575  loss_mask: 0.5376  loss_rpn_cls: 0.08459  loss_rpn_loc: 0.03639  validation_loss: 1.966  time: 1.4934  data_time: 0.0237  lr: 8.3778e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:19:26 d2.utils.events]: \u001b[0m eta: 3:04:12  iter: 2659  total_loss: 2.027  loss_cls_stage0: 0.3221  loss_box_reg_stage0: 0.1933  loss_cls_stage1: 0.2432  loss_box_reg_stage1: 0.2163  loss_cls_stage2: 0.1767  loss_box_reg_stage2: 0.1532  loss_mask: 0.5753  loss_rpn_cls: 0.08818  loss_rpn_loc: 0.0384  validation_loss: 1.966  time: 1.4936  data_time: 0.0239  lr: 8.3546e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:19:56 d2.utils.events]: \u001b[0m eta: 3:03:42  iter: 2679  total_loss: 1.895  loss_cls_stage0: 0.2874  loss_box_reg_stage0: 0.1742  loss_cls_stage1: 0.2218  loss_box_reg_stage1: 0.2121  loss_cls_stage2: 0.1534  loss_box_reg_stage2: 0.1566  loss_mask: 0.5893  loss_rpn_cls: 0.07801  loss_rpn_loc: 0.03449  validation_loss: 1.966  time: 1.4938  data_time: 0.0242  lr: 8.3312e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:20:26 d2.utils.events]: \u001b[0m eta: 3:03:14  iter: 2699  total_loss: 1.933  loss_cls_stage0: 0.2873  loss_box_reg_stage0: 0.165  loss_cls_stage1: 0.2325  loss_box_reg_stage1: 0.1996  loss_cls_stage2: 0.1753  loss_box_reg_stage2: 0.1579  loss_mask: 0.5672  loss_rpn_cls: 0.09796  loss_rpn_loc: 0.03856  validation_loss: 1.966  time: 1.4939  data_time: 0.0230  lr: 8.3077e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:20:57 d2.utils.events]: \u001b[0m eta: 3:02:45  iter: 2719  total_loss: 2.026  loss_cls_stage0: 0.3026  loss_box_reg_stage0: 0.1753  loss_cls_stage1: 0.2398  loss_box_reg_stage1: 0.2268  loss_cls_stage2: 0.1831  loss_box_reg_stage2: 0.1746  loss_mask: 0.5853  loss_rpn_cls: 0.08595  loss_rpn_loc: 0.03858  validation_loss: 1.966  time: 1.4941  data_time: 0.0231  lr: 8.2841e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:21:27 d2.utils.events]: \u001b[0m eta: 3:02:18  iter: 2739  total_loss: 2.045  loss_cls_stage0: 0.3126  loss_box_reg_stage0: 0.1996  loss_cls_stage1: 0.2381  loss_box_reg_stage1: 0.2279  loss_cls_stage2: 0.1572  loss_box_reg_stage2: 0.1613  loss_mask: 0.5461  loss_rpn_cls: 0.1  loss_rpn_loc: 0.04578  validation_loss: 1.966  time: 1.4943  data_time: 0.0234  lr: 8.2604e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:21:58 d2.utils.events]: \u001b[0m eta: 3:01:50  iter: 2759  total_loss: 2.128  loss_cls_stage0: 0.3138  loss_box_reg_stage0: 0.1772  loss_cls_stage1: 0.245  loss_box_reg_stage1: 0.2278  loss_cls_stage2: 0.1868  loss_box_reg_stage2: 0.1652  loss_mask: 0.5876  loss_rpn_cls: 0.09507  loss_rpn_loc: 0.03685  validation_loss: 1.966  time: 1.4945  data_time: 0.0236  lr: 8.2365e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:22:28 d2.utils.events]: \u001b[0m eta: 3:01:21  iter: 2779  total_loss: 2.138  loss_cls_stage0: 0.3311  loss_box_reg_stage0: 0.1718  loss_cls_stage1: 0.2614  loss_box_reg_stage1: 0.2054  loss_cls_stage2: 0.1846  loss_box_reg_stage2: 0.1704  loss_mask: 0.61  loss_rpn_cls: 0.084  loss_rpn_loc: 0.03761  validation_loss: 1.966  time: 1.4947  data_time: 0.0243  lr: 8.2125e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:22:58 d2.utils.events]: \u001b[0m eta: 3:00:51  iter: 2799  total_loss: 1.864  loss_cls_stage0: 0.2449  loss_box_reg_stage0: 0.1366  loss_cls_stage1: 0.196  loss_box_reg_stage1: 0.1845  loss_cls_stage2: 0.1491  loss_box_reg_stage2: 0.1504  loss_mask: 0.566  loss_rpn_cls: 0.08707  loss_rpn_loc: 0.03654  validation_loss: 1.966  time: 1.4948  data_time: 0.0242  lr: 8.1883e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:23:28 d2.utils.events]: \u001b[0m eta: 3:00:22  iter: 2819  total_loss: 1.892  loss_cls_stage0: 0.2773  loss_box_reg_stage0: 0.1725  loss_cls_stage1: 0.2171  loss_box_reg_stage1: 0.2069  loss_cls_stage2: 0.1546  loss_box_reg_stage2: 0.1519  loss_mask: 0.5268  loss_rpn_cls: 0.09621  loss_rpn_loc: 0.03692  validation_loss: 1.966  time: 1.4949  data_time: 0.0238  lr: 8.1641e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:23:59 d2.utils.events]: \u001b[0m eta: 2:59:55  iter: 2839  total_loss: 1.931  loss_cls_stage0: 0.3073  loss_box_reg_stage0: 0.1929  loss_cls_stage1: 0.2475  loss_box_reg_stage1: 0.2387  loss_cls_stage2: 0.1787  loss_box_reg_stage2: 0.1741  loss_mask: 0.559  loss_rpn_cls: 0.08182  loss_rpn_loc: 0.03766  validation_loss: 1.966  time: 1.4951  data_time: 0.0237  lr: 8.1397e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:24:29 d2.utils.events]: \u001b[0m eta: 2:59:29  iter: 2859  total_loss: 2.045  loss_cls_stage0: 0.307  loss_box_reg_stage0: 0.1708  loss_cls_stage1: 0.2563  loss_box_reg_stage1: 0.2276  loss_cls_stage2: 0.1818  loss_box_reg_stage2: 0.1691  loss_mask: 0.5388  loss_rpn_cls: 0.1008  loss_rpn_loc: 0.04296  validation_loss: 1.966  time: 1.4953  data_time: 0.0242  lr: 8.1152e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:25:00 d2.utils.events]: \u001b[0m eta: 2:59:00  iter: 2879  total_loss: 2.012  loss_cls_stage0: 0.2913  loss_box_reg_stage0: 0.1854  loss_cls_stage1: 0.2295  loss_box_reg_stage1: 0.2274  loss_cls_stage2: 0.172  loss_box_reg_stage2: 0.1647  loss_mask: 0.5818  loss_rpn_cls: 0.1031  loss_rpn_loc: 0.04161  validation_loss: 1.966  time: 1.4954  data_time: 0.0237  lr: 8.0905e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:25:30 d2.utils.events]: \u001b[0m eta: 2:58:31  iter: 2899  total_loss: 2.129  loss_cls_stage0: 0.3548  loss_box_reg_stage0: 0.2196  loss_cls_stage1: 0.2683  loss_box_reg_stage1: 0.2472  loss_cls_stage2: 0.187  loss_box_reg_stage2: 0.1802  loss_mask: 0.5633  loss_rpn_cls: 0.09094  loss_rpn_loc: 0.03522  validation_loss: 1.966  time: 1.4956  data_time: 0.0247  lr: 8.0658e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:26:01 d2.utils.events]: \u001b[0m eta: 2:58:03  iter: 2919  total_loss: 2.061  loss_cls_stage0: 0.3187  loss_box_reg_stage0: 0.2012  loss_cls_stage1: 0.2548  loss_box_reg_stage1: 0.2295  loss_cls_stage2: 0.1776  loss_box_reg_stage2: 0.1706  loss_mask: 0.5932  loss_rpn_cls: 0.07791  loss_rpn_loc: 0.03591  validation_loss: 1.966  time: 1.4958  data_time: 0.0241  lr: 8.0409e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:26:31 d2.utils.events]: \u001b[0m eta: 2:57:34  iter: 2939  total_loss: 1.926  loss_cls_stage0: 0.297  loss_box_reg_stage0: 0.1802  loss_cls_stage1: 0.229  loss_box_reg_stage1: 0.2241  loss_cls_stage2: 0.1711  loss_box_reg_stage2: 0.1676  loss_mask: 0.5473  loss_rpn_cls: 0.0758  loss_rpn_loc: 0.03271  validation_loss: 1.966  time: 1.4960  data_time: 0.0236  lr: 8.0159e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:27:01 d2.utils.events]: \u001b[0m eta: 2:57:05  iter: 2959  total_loss: 1.992  loss_cls_stage0: 0.2965  loss_box_reg_stage0: 0.1911  loss_cls_stage1: 0.2401  loss_box_reg_stage1: 0.2163  loss_cls_stage2: 0.1707  loss_box_reg_stage2: 0.153  loss_mask: 0.5665  loss_rpn_cls: 0.09193  loss_rpn_loc: 0.04001  validation_loss: 1.966  time: 1.4961  data_time: 0.0240  lr: 7.9908e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:27:32 d2.utils.events]: \u001b[0m eta: 2:56:37  iter: 2979  total_loss: 1.998  loss_cls_stage0: 0.3086  loss_box_reg_stage0: 0.1772  loss_cls_stage1: 0.2446  loss_box_reg_stage1: 0.2219  loss_cls_stage2: 0.1725  loss_box_reg_stage2: 0.1586  loss_mask: 0.5077  loss_rpn_cls: 0.1025  loss_rpn_loc: 0.03972  validation_loss: 1.966  time: 1.4963  data_time: 0.0238  lr: 7.9655e-05  max_mem: 12121M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/27 03:28:04 d2.data.common]: \u001b[0mSerializing 857 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/27 03:28:04 d2.data.common]: \u001b[0mSerialized dataset takes 0.89 MiB\n",
      "\u001b[32m[03/27 03:28:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 857 images\n",
      "\u001b[32m[03/27 03:28:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/857. 0.0809 s / img. ETA=0:01:34\n",
      "\u001b[32m[03/27 03:28:11 d2.evaluation.evaluator]: \u001b[0mInference done 58/857. 0.0800 s / img. ETA=0:01:26\n",
      "\u001b[32m[03/27 03:28:16 d2.evaluation.evaluator]: \u001b[0mInference done 103/857. 0.0813 s / img. ETA=0:01:22\n",
      "\u001b[32m[03/27 03:28:21 d2.evaluation.evaluator]: \u001b[0mInference done 150/857. 0.0808 s / img. ETA=0:01:16\n",
      "\u001b[32m[03/27 03:28:26 d2.evaluation.evaluator]: \u001b[0mInference done 198/857. 0.0806 s / img. ETA=0:01:11\n",
      "\u001b[32m[03/27 03:28:31 d2.evaluation.evaluator]: \u001b[0mInference done 245/857. 0.0804 s / img. ETA=0:01:06\n",
      "\u001b[32m[03/27 03:28:36 d2.evaluation.evaluator]: \u001b[0mInference done 293/857. 0.0803 s / img. ETA=0:01:00\n",
      "\u001b[32m[03/27 03:28:41 d2.evaluation.evaluator]: \u001b[0mInference done 340/857. 0.0802 s / img. ETA=0:00:55\n",
      "\u001b[32m[03/27 03:28:46 d2.evaluation.evaluator]: \u001b[0mInference done 387/857. 0.0802 s / img. ETA=0:00:50\n",
      "\u001b[32m[03/27 03:28:51 d2.evaluation.evaluator]: \u001b[0mInference done 435/857. 0.0801 s / img. ETA=0:00:45\n",
      "\u001b[32m[03/27 03:28:57 d2.evaluation.evaluator]: \u001b[0mInference done 482/857. 0.0801 s / img. ETA=0:00:40\n",
      "\u001b[32m[03/27 03:29:02 d2.evaluation.evaluator]: \u001b[0mInference done 530/857. 0.0801 s / img. ETA=0:00:34\n",
      "\u001b[32m[03/27 03:29:07 d2.evaluation.evaluator]: \u001b[0mInference done 578/857. 0.0801 s / img. ETA=0:00:29\n",
      "\u001b[32m[03/27 03:29:12 d2.evaluation.evaluator]: \u001b[0mInference done 625/857. 0.0801 s / img. ETA=0:00:24\n",
      "\u001b[32m[03/27 03:29:17 d2.evaluation.evaluator]: \u001b[0mInference done 673/857. 0.0801 s / img. ETA=0:00:19\n",
      "\u001b[32m[03/27 03:29:22 d2.evaluation.evaluator]: \u001b[0mInference done 719/857. 0.0801 s / img. ETA=0:00:14\n",
      "\u001b[32m[03/27 03:29:27 d2.evaluation.evaluator]: \u001b[0mInference done 767/857. 0.0801 s / img. ETA=0:00:09\n",
      "\u001b[32m[03/27 03:29:32 d2.evaluation.evaluator]: \u001b[0mInference done 816/857. 0.0801 s / img. ETA=0:00:04\n",
      "\u001b[32m[03/27 03:29:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:31.001290 (0.106809 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/27 03:29:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:08 (0.080045 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.42 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.052\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.094\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.099\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.024\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.053\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.078\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.087\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.087\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.032\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.089\n",
      "\u001b[32m[03/27 03:29:37 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold4 in csv format:\n",
      "\u001b[32m[03/27 03:29:37 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/27 03:29:37 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/27 03:29:37 d2.evaluation.testing]: \u001b[0mcopypaste: 5.2208,9.3998,9.8817,0.2166,2.3957,5.2939\n",
      "validation do loss eval 1.9805229463366751\n",
      "\u001b[32m[03/27 03:31:05 d2.utils.events]: \u001b[0m eta: 2:56:08  iter: 2999  total_loss: 1.952  loss_cls_stage0: 0.2712  loss_box_reg_stage0: 0.1731  loss_cls_stage1: 0.2113  loss_box_reg_stage1: 0.2115  loss_cls_stage2: 0.166  loss_box_reg_stage2: 0.164  loss_mask: 0.6126  loss_rpn_cls: 0.08364  loss_rpn_loc: 0.03188  validation_loss: 1.967  time: 1.4964  data_time: 0.0236  lr: 7.9402e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:31:35 d2.utils.events]: \u001b[0m eta: 2:55:40  iter: 3019  total_loss: 2.177  loss_cls_stage0: 0.3137  loss_box_reg_stage0: 0.2063  loss_cls_stage1: 0.2612  loss_box_reg_stage1: 0.264  loss_cls_stage2: 0.1833  loss_box_reg_stage2: 0.1779  loss_mask: 0.6112  loss_rpn_cls: 0.09043  loss_rpn_loc: 0.03948  validation_loss: 1.967  time: 1.4964  data_time: 0.0250  lr: 7.9147e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:32:05 d2.utils.events]: \u001b[0m eta: 2:55:10  iter: 3039  total_loss: 1.89  loss_cls_stage0: 0.2993  loss_box_reg_stage0: 0.1711  loss_cls_stage1: 0.2299  loss_box_reg_stage1: 0.2054  loss_cls_stage2: 0.1651  loss_box_reg_stage2: 0.1636  loss_mask: 0.5511  loss_rpn_cls: 0.08683  loss_rpn_loc: 0.03913  validation_loss: 1.967  time: 1.4966  data_time: 0.0242  lr: 7.8891e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:32:36 d2.utils.events]: \u001b[0m eta: 2:54:41  iter: 3059  total_loss: 2.035  loss_cls_stage0: 0.2853  loss_box_reg_stage0: 0.1862  loss_cls_stage1: 0.2236  loss_box_reg_stage1: 0.2326  loss_cls_stage2: 0.1661  loss_box_reg_stage2: 0.1718  loss_mask: 0.5639  loss_rpn_cls: 0.09428  loss_rpn_loc: 0.04633  validation_loss: 1.967  time: 1.4969  data_time: 0.0236  lr: 7.8634e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:33:06 d2.utils.events]: \u001b[0m eta: 2:54:11  iter: 3079  total_loss: 1.96  loss_cls_stage0: 0.2809  loss_box_reg_stage0: 0.1742  loss_cls_stage1: 0.2376  loss_box_reg_stage1: 0.2314  loss_cls_stage2: 0.1775  loss_box_reg_stage2: 0.1709  loss_mask: 0.6  loss_rpn_cls: 0.07456  loss_rpn_loc: 0.03464  validation_loss: 1.967  time: 1.4970  data_time: 0.0232  lr: 7.8376e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:33:37 d2.utils.events]: \u001b[0m eta: 2:53:42  iter: 3099  total_loss: 2.059  loss_cls_stage0: 0.2909  loss_box_reg_stage0: 0.1857  loss_cls_stage1: 0.242  loss_box_reg_stage1: 0.2506  loss_cls_stage2: 0.1769  loss_box_reg_stage2: 0.1922  loss_mask: 0.6022  loss_rpn_cls: 0.07392  loss_rpn_loc: 0.03193  validation_loss: 1.967  time: 1.4972  data_time: 0.0242  lr: 7.8117e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:34:07 d2.utils.events]: \u001b[0m eta: 2:53:12  iter: 3119  total_loss: 2.131  loss_cls_stage0: 0.3109  loss_box_reg_stage0: 0.1942  loss_cls_stage1: 0.2494  loss_box_reg_stage1: 0.2457  loss_cls_stage2: 0.1791  loss_box_reg_stage2: 0.1861  loss_mask: 0.598  loss_rpn_cls: 0.08489  loss_rpn_loc: 0.03933  validation_loss: 1.967  time: 1.4974  data_time: 0.0237  lr: 7.7857e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:34:38 d2.utils.events]: \u001b[0m eta: 2:52:45  iter: 3139  total_loss: 2.061  loss_cls_stage0: 0.305  loss_box_reg_stage0: 0.1937  loss_cls_stage1: 0.2333  loss_box_reg_stage1: 0.2432  loss_cls_stage2: 0.1713  loss_box_reg_stage2: 0.1803  loss_mask: 0.5883  loss_rpn_cls: 0.08211  loss_rpn_loc: 0.03728  validation_loss: 1.967  time: 1.4975  data_time: 0.0241  lr: 7.7595e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:35:08 d2.utils.events]: \u001b[0m eta: 2:52:17  iter: 3159  total_loss: 2.018  loss_cls_stage0: 0.2942  loss_box_reg_stage0: 0.1949  loss_cls_stage1: 0.23  loss_box_reg_stage1: 0.2354  loss_cls_stage2: 0.1724  loss_box_reg_stage2: 0.1677  loss_mask: 0.55  loss_rpn_cls: 0.1012  loss_rpn_loc: 0.04042  validation_loss: 1.967  time: 1.4977  data_time: 0.0235  lr: 7.7333e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:35:39 d2.utils.events]: \u001b[0m eta: 2:51:49  iter: 3179  total_loss: 1.885  loss_cls_stage0: 0.2843  loss_box_reg_stage0: 0.1752  loss_cls_stage1: 0.2403  loss_box_reg_stage1: 0.2217  loss_cls_stage2: 0.1619  loss_box_reg_stage2: 0.1686  loss_mask: 0.5566  loss_rpn_cls: 0.08223  loss_rpn_loc: 0.03268  validation_loss: 1.967  time: 1.4979  data_time: 0.0238  lr: 7.7069e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:36:09 d2.utils.events]: \u001b[0m eta: 2:51:21  iter: 3199  total_loss: 2.077  loss_cls_stage0: 0.3073  loss_box_reg_stage0: 0.1926  loss_cls_stage1: 0.2483  loss_box_reg_stage1: 0.2497  loss_cls_stage2: 0.1856  loss_box_reg_stage2: 0.1786  loss_mask: 0.5727  loss_rpn_cls: 0.08548  loss_rpn_loc: 0.03966  validation_loss: 1.967  time: 1.4980  data_time: 0.0237  lr: 7.6805e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:36:40 d2.utils.events]: \u001b[0m eta: 2:50:52  iter: 3219  total_loss: 2.162  loss_cls_stage0: 0.3253  loss_box_reg_stage0: 0.2082  loss_cls_stage1: 0.2532  loss_box_reg_stage1: 0.2519  loss_cls_stage2: 0.1706  loss_box_reg_stage2: 0.1826  loss_mask: 0.5952  loss_rpn_cls: 0.07908  loss_rpn_loc: 0.03684  validation_loss: 1.967  time: 1.4982  data_time: 0.0248  lr: 7.6539e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:37:10 d2.utils.events]: \u001b[0m eta: 2:50:22  iter: 3239  total_loss: 1.893  loss_cls_stage0: 0.2592  loss_box_reg_stage0: 0.1524  loss_cls_stage1: 0.2107  loss_box_reg_stage1: 0.2065  loss_cls_stage2: 0.1587  loss_box_reg_stage2: 0.1779  loss_mask: 0.5736  loss_rpn_cls: 0.08382  loss_rpn_loc: 0.0363  validation_loss: 1.967  time: 1.4983  data_time: 0.0249  lr: 7.6272e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:37:41 d2.utils.events]: \u001b[0m eta: 2:49:55  iter: 3259  total_loss: 2.199  loss_cls_stage0: 0.3424  loss_box_reg_stage0: 0.2174  loss_cls_stage1: 0.2719  loss_box_reg_stage1: 0.2928  loss_cls_stage2: 0.1894  loss_box_reg_stage2: 0.2114  loss_mask: 0.551  loss_rpn_cls: 0.07803  loss_rpn_loc: 0.04177  validation_loss: 1.967  time: 1.4986  data_time: 0.0239  lr: 7.6004e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:38:11 d2.utils.events]: \u001b[0m eta: 2:49:28  iter: 3279  total_loss: 1.882  loss_cls_stage0: 0.2628  loss_box_reg_stage0: 0.1738  loss_cls_stage1: 0.2225  loss_box_reg_stage1: 0.2389  loss_cls_stage2: 0.1543  loss_box_reg_stage2: 0.1791  loss_mask: 0.5677  loss_rpn_cls: 0.07698  loss_rpn_loc: 0.03313  validation_loss: 1.967  time: 1.4987  data_time: 0.0228  lr: 7.5735e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:38:42 d2.utils.events]: \u001b[0m eta: 2:48:59  iter: 3299  total_loss: 1.939  loss_cls_stage0: 0.2863  loss_box_reg_stage0: 0.1731  loss_cls_stage1: 0.2261  loss_box_reg_stage1: 0.2364  loss_cls_stage2: 0.1558  loss_box_reg_stage2: 0.177  loss_mask: 0.5546  loss_rpn_cls: 0.08095  loss_rpn_loc: 0.03683  validation_loss: 1.967  time: 1.4989  data_time: 0.0244  lr: 7.5466e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:39:12 d2.utils.events]: \u001b[0m eta: 2:48:30  iter: 3319  total_loss: 2.037  loss_cls_stage0: 0.2954  loss_box_reg_stage0: 0.182  loss_cls_stage1: 0.2464  loss_box_reg_stage1: 0.236  loss_cls_stage2: 0.1735  loss_box_reg_stage2: 0.1841  loss_mask: 0.5846  loss_rpn_cls: 0.08943  loss_rpn_loc: 0.04036  validation_loss: 1.967  time: 1.4991  data_time: 0.0246  lr: 7.5195e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:39:43 d2.utils.events]: \u001b[0m eta: 2:48:03  iter: 3339  total_loss: 2.062  loss_cls_stage0: 0.3004  loss_box_reg_stage0: 0.1946  loss_cls_stage1: 0.2494  loss_box_reg_stage1: 0.2567  loss_cls_stage2: 0.1698  loss_box_reg_stage2: 0.1895  loss_mask: 0.5361  loss_rpn_cls: 0.08884  loss_rpn_loc: 0.03889  validation_loss: 1.967  time: 1.4993  data_time: 0.0236  lr: 7.4923e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:40:14 d2.utils.events]: \u001b[0m eta: 2:47:35  iter: 3359  total_loss: 1.981  loss_cls_stage0: 0.2812  loss_box_reg_stage0: 0.1831  loss_cls_stage1: 0.2322  loss_box_reg_stage1: 0.2289  loss_cls_stage2: 0.1643  loss_box_reg_stage2: 0.1711  loss_mask: 0.5815  loss_rpn_cls: 0.07844  loss_rpn_loc: 0.03681  validation_loss: 1.967  time: 1.4994  data_time: 0.0243  lr: 7.465e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:40:44 d2.utils.events]: \u001b[0m eta: 2:47:07  iter: 3379  total_loss: 2.184  loss_cls_stage0: 0.3305  loss_box_reg_stage0: 0.212  loss_cls_stage1: 0.2688  loss_box_reg_stage1: 0.2728  loss_cls_stage2: 0.1874  loss_box_reg_stage2: 0.1984  loss_mask: 0.5944  loss_rpn_cls: 0.07612  loss_rpn_loc: 0.03739  validation_loss: 1.967  time: 1.4996  data_time: 0.0238  lr: 7.4376e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:41:15 d2.utils.events]: \u001b[0m eta: 2:46:41  iter: 3399  total_loss: 2.264  loss_cls_stage0: 0.3264  loss_box_reg_stage0: 0.225  loss_cls_stage1: 0.2727  loss_box_reg_stage1: 0.2975  loss_cls_stage2: 0.1929  loss_box_reg_stage2: 0.2066  loss_mask: 0.5485  loss_rpn_cls: 0.08541  loss_rpn_loc: 0.03983  validation_loss: 1.967  time: 1.4998  data_time: 0.0245  lr: 7.4101e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:41:45 d2.utils.events]: \u001b[0m eta: 2:46:13  iter: 3419  total_loss: 1.933  loss_cls_stage0: 0.2798  loss_box_reg_stage0: 0.1935  loss_cls_stage1: 0.2264  loss_box_reg_stage1: 0.2311  loss_cls_stage2: 0.1556  loss_box_reg_stage2: 0.2015  loss_mask: 0.5496  loss_rpn_cls: 0.07214  loss_rpn_loc: 0.02963  validation_loss: 1.967  time: 1.5000  data_time: 0.0239  lr: 7.3826e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:42:16 d2.utils.events]: \u001b[0m eta: 2:45:50  iter: 3439  total_loss: 2.166  loss_cls_stage0: 0.3198  loss_box_reg_stage0: 0.2274  loss_cls_stage1: 0.2521  loss_box_reg_stage1: 0.2781  loss_cls_stage2: 0.1845  loss_box_reg_stage2: 0.1922  loss_mask: 0.5145  loss_rpn_cls: 0.07647  loss_rpn_loc: 0.04177  validation_loss: 1.967  time: 1.5002  data_time: 0.0239  lr: 7.3549e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:42:47 d2.utils.events]: \u001b[0m eta: 2:45:23  iter: 3459  total_loss: 2.023  loss_cls_stage0: 0.2967  loss_box_reg_stage0: 0.209  loss_cls_stage1: 0.233  loss_box_reg_stage1: 0.2543  loss_cls_stage2: 0.1667  loss_box_reg_stage2: 0.2023  loss_mask: 0.6248  loss_rpn_cls: 0.07401  loss_rpn_loc: 0.03359  validation_loss: 1.967  time: 1.5003  data_time: 0.0232  lr: 7.3271e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:43:18 d2.utils.events]: \u001b[0m eta: 2:45:00  iter: 3479  total_loss: 2.239  loss_cls_stage0: 0.3358  loss_box_reg_stage0: 0.2367  loss_cls_stage1: 0.2612  loss_box_reg_stage1: 0.2907  loss_cls_stage2: 0.1741  loss_box_reg_stage2: 0.2005  loss_mask: 0.5719  loss_rpn_cls: 0.07888  loss_rpn_loc: 0.03939  validation_loss: 1.967  time: 1.5006  data_time: 0.0230  lr: 7.2993e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:43:48 d2.utils.events]: \u001b[0m eta: 2:44:30  iter: 3499  total_loss: 2.156  loss_cls_stage0: 0.3277  loss_box_reg_stage0: 0.2178  loss_cls_stage1: 0.2514  loss_box_reg_stage1: 0.2653  loss_cls_stage2: 0.1685  loss_box_reg_stage2: 0.1855  loss_mask: 0.5686  loss_rpn_cls: 0.085  loss_rpn_loc: 0.03971  validation_loss: 1.967  time: 1.5007  data_time: 0.0241  lr: 7.2714e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:44:19 d2.utils.events]: \u001b[0m eta: 2:44:04  iter: 3519  total_loss: 2.114  loss_cls_stage0: 0.3249  loss_box_reg_stage0: 0.2048  loss_cls_stage1: 0.2641  loss_box_reg_stage1: 0.2554  loss_cls_stage2: 0.1896  loss_box_reg_stage2: 0.2081  loss_mask: 0.596  loss_rpn_cls: 0.07245  loss_rpn_loc: 0.03261  validation_loss: 1.967  time: 1.5009  data_time: 0.0243  lr: 7.2433e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:44:49 d2.utils.events]: \u001b[0m eta: 2:43:36  iter: 3539  total_loss: 1.806  loss_cls_stage0: 0.2667  loss_box_reg_stage0: 0.1796  loss_cls_stage1: 0.2094  loss_box_reg_stage1: 0.2308  loss_cls_stage2: 0.1592  loss_box_reg_stage2: 0.1961  loss_mask: 0.5431  loss_rpn_cls: 0.09225  loss_rpn_loc: 0.03396  validation_loss: 1.967  time: 1.5011  data_time: 0.0240  lr: 7.2152e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:45:20 d2.utils.events]: \u001b[0m eta: 2:43:10  iter: 3559  total_loss: 2.131  loss_cls_stage0: 0.3113  loss_box_reg_stage0: 0.2103  loss_cls_stage1: 0.2409  loss_box_reg_stage1: 0.2672  loss_cls_stage2: 0.1854  loss_box_reg_stage2: 0.2072  loss_mask: 0.576  loss_rpn_cls: 0.08092  loss_rpn_loc: 0.03636  validation_loss: 1.967  time: 1.5012  data_time: 0.0248  lr: 7.187e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:45:51 d2.utils.events]: \u001b[0m eta: 2:42:42  iter: 3579  total_loss: 2.142  loss_cls_stage0: 0.318  loss_box_reg_stage0: 0.2084  loss_cls_stage1: 0.2617  loss_box_reg_stage1: 0.2606  loss_cls_stage2: 0.1807  loss_box_reg_stage2: 0.1964  loss_mask: 0.6043  loss_rpn_cls: 0.07567  loss_rpn_loc: 0.03674  validation_loss: 1.967  time: 1.5014  data_time: 0.0241  lr: 7.1587e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:46:21 d2.utils.events]: \u001b[0m eta: 2:42:14  iter: 3599  total_loss: 2.148  loss_cls_stage0: 0.3155  loss_box_reg_stage0: 0.2111  loss_cls_stage1: 0.2418  loss_box_reg_stage1: 0.254  loss_cls_stage2: 0.1783  loss_box_reg_stage2: 0.2098  loss_mask: 0.577  loss_rpn_cls: 0.08444  loss_rpn_loc: 0.03849  validation_loss: 1.967  time: 1.5016  data_time: 0.0243  lr: 7.1303e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:46:52 d2.utils.events]: \u001b[0m eta: 2:41:45  iter: 3619  total_loss: 2.002  loss_cls_stage0: 0.2671  loss_box_reg_stage0: 0.187  loss_cls_stage1: 0.2126  loss_box_reg_stage1: 0.24  loss_cls_stage2: 0.1583  loss_box_reg_stage2: 0.1805  loss_mask: 0.5728  loss_rpn_cls: 0.08695  loss_rpn_loc: 0.03924  validation_loss: 1.967  time: 1.5017  data_time: 0.0242  lr: 7.1019e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:47:23 d2.utils.events]: \u001b[0m eta: 2:41:19  iter: 3639  total_loss: 1.979  loss_cls_stage0: 0.2902  loss_box_reg_stage0: 0.2019  loss_cls_stage1: 0.2189  loss_box_reg_stage1: 0.2607  loss_cls_stage2: 0.1646  loss_box_reg_stage2: 0.1965  loss_mask: 0.5172  loss_rpn_cls: 0.07942  loss_rpn_loc: 0.03576  validation_loss: 1.967  time: 1.5019  data_time: 0.0233  lr: 7.0733e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:47:53 d2.utils.events]: \u001b[0m eta: 2:40:47  iter: 3659  total_loss: 1.865  loss_cls_stage0: 0.2678  loss_box_reg_stage0: 0.1687  loss_cls_stage1: 0.2147  loss_box_reg_stage1: 0.2372  loss_cls_stage2: 0.1656  loss_box_reg_stage2: 0.201  loss_mask: 0.5403  loss_rpn_cls: 0.08323  loss_rpn_loc: 0.03862  validation_loss: 1.967  time: 1.5020  data_time: 0.0242  lr: 7.0447e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:48:24 d2.utils.events]: \u001b[0m eta: 2:40:19  iter: 3679  total_loss: 2.123  loss_cls_stage0: 0.3286  loss_box_reg_stage0: 0.2112  loss_cls_stage1: 0.2453  loss_box_reg_stage1: 0.2629  loss_cls_stage2: 0.1781  loss_box_reg_stage2: 0.2092  loss_mask: 0.5584  loss_rpn_cls: 0.07462  loss_rpn_loc: 0.03744  validation_loss: 1.967  time: 1.5022  data_time: 0.0248  lr: 7.016e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:48:55 d2.utils.events]: \u001b[0m eta: 2:39:51  iter: 3699  total_loss: 2.083  loss_cls_stage0: 0.3145  loss_box_reg_stage0: 0.22  loss_cls_stage1: 0.2434  loss_box_reg_stage1: 0.2786  loss_cls_stage2: 0.1733  loss_box_reg_stage2: 0.2213  loss_mask: 0.5292  loss_rpn_cls: 0.08161  loss_rpn_loc: 0.03528  validation_loss: 1.967  time: 1.5024  data_time: 0.0246  lr: 6.9872e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:49:26 d2.utils.events]: \u001b[0m eta: 2:39:23  iter: 3719  total_loss: 2.103  loss_cls_stage0: 0.326  loss_box_reg_stage0: 0.2231  loss_cls_stage1: 0.2398  loss_box_reg_stage1: 0.2537  loss_cls_stage2: 0.1791  loss_box_reg_stage2: 0.2028  loss_mask: 0.5528  loss_rpn_cls: 0.08687  loss_rpn_loc: 0.04115  validation_loss: 1.967  time: 1.5026  data_time: 0.0244  lr: 6.9583e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:49:56 d2.utils.events]: \u001b[0m eta: 2:38:55  iter: 3739  total_loss: 2.107  loss_cls_stage0: 0.2857  loss_box_reg_stage0: 0.2175  loss_cls_stage1: 0.2402  loss_box_reg_stage1: 0.2804  loss_cls_stage2: 0.1727  loss_box_reg_stage2: 0.2068  loss_mask: 0.5693  loss_rpn_cls: 0.07217  loss_rpn_loc: 0.03569  validation_loss: 1.967  time: 1.5028  data_time: 0.0254  lr: 6.9294e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:50:27 d2.utils.events]: \u001b[0m eta: 2:38:29  iter: 3759  total_loss: 2.216  loss_cls_stage0: 0.3449  loss_box_reg_stage0: 0.2418  loss_cls_stage1: 0.2771  loss_box_reg_stage1: 0.2935  loss_cls_stage2: 0.1968  loss_box_reg_stage2: 0.202  loss_mask: 0.5297  loss_rpn_cls: 0.08403  loss_rpn_loc: 0.0437  validation_loss: 1.967  time: 1.5030  data_time: 0.0236  lr: 6.9003e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:50:58 d2.utils.events]: \u001b[0m eta: 2:38:00  iter: 3779  total_loss: 2.219  loss_cls_stage0: 0.3506  loss_box_reg_stage0: 0.2371  loss_cls_stage1: 0.2666  loss_box_reg_stage1: 0.2676  loss_cls_stage2: 0.1811  loss_box_reg_stage2: 0.1941  loss_mask: 0.5423  loss_rpn_cls: 0.08445  loss_rpn_loc: 0.04169  validation_loss: 1.967  time: 1.5032  data_time: 0.0236  lr: 6.8713e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:51:28 d2.utils.events]: \u001b[0m eta: 2:37:32  iter: 3799  total_loss: 1.966  loss_cls_stage0: 0.2709  loss_box_reg_stage0: 0.1854  loss_cls_stage1: 0.2275  loss_box_reg_stage1: 0.2481  loss_cls_stage2: 0.1738  loss_box_reg_stage2: 0.2085  loss_mask: 0.547  loss_rpn_cls: 0.06966  loss_rpn_loc: 0.03383  validation_loss: 1.967  time: 1.5033  data_time: 0.0230  lr: 6.8421e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:51:59 d2.utils.events]: \u001b[0m eta: 2:37:02  iter: 3819  total_loss: 2.126  loss_cls_stage0: 0.2785  loss_box_reg_stage0: 0.1971  loss_cls_stage1: 0.2379  loss_box_reg_stage1: 0.277  loss_cls_stage2: 0.1742  loss_box_reg_stage2: 0.225  loss_mask: 0.5598  loss_rpn_cls: 0.07404  loss_rpn_loc: 0.03635  validation_loss: 1.967  time: 1.5035  data_time: 0.0239  lr: 6.8128e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:52:30 d2.utils.events]: \u001b[0m eta: 2:36:35  iter: 3839  total_loss: 2.096  loss_cls_stage0: 0.3185  loss_box_reg_stage0: 0.2267  loss_cls_stage1: 0.2431  loss_box_reg_stage1: 0.2737  loss_cls_stage2: 0.1642  loss_box_reg_stage2: 0.2068  loss_mask: 0.5235  loss_rpn_cls: 0.06643  loss_rpn_loc: 0.03112  validation_loss: 1.967  time: 1.5036  data_time: 0.0307  lr: 6.7835e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:53:01 d2.utils.events]: \u001b[0m eta: 2:36:07  iter: 3859  total_loss: 2.328  loss_cls_stage0: 0.335  loss_box_reg_stage0: 0.2353  loss_cls_stage1: 0.2717  loss_box_reg_stage1: 0.2805  loss_cls_stage2: 0.1885  loss_box_reg_stage2: 0.1951  loss_mask: 0.5978  loss_rpn_cls: 0.07275  loss_rpn_loc: 0.03674  validation_loss: 1.967  time: 1.5038  data_time: 0.0243  lr: 6.7541e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:53:31 d2.utils.events]: \u001b[0m eta: 2:35:38  iter: 3879  total_loss: 2.109  loss_cls_stage0: 0.3323  loss_box_reg_stage0: 0.2261  loss_cls_stage1: 0.2537  loss_box_reg_stage1: 0.273  loss_cls_stage2: 0.1797  loss_box_reg_stage2: 0.2082  loss_mask: 0.5594  loss_rpn_cls: 0.07422  loss_rpn_loc: 0.03743  validation_loss: 1.967  time: 1.5040  data_time: 0.0243  lr: 6.7247e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:54:02 d2.utils.events]: \u001b[0m eta: 2:35:08  iter: 3899  total_loss: 2.313  loss_cls_stage0: 0.3384  loss_box_reg_stage0: 0.2407  loss_cls_stage1: 0.268  loss_box_reg_stage1: 0.299  loss_cls_stage2: 0.1851  loss_box_reg_stage2: 0.2199  loss_mask: 0.5605  loss_rpn_cls: 0.08234  loss_rpn_loc: 0.03837  validation_loss: 1.967  time: 1.5042  data_time: 0.0236  lr: 6.6952e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:54:33 d2.utils.events]: \u001b[0m eta: 2:34:39  iter: 3919  total_loss: 1.894  loss_cls_stage0: 0.277  loss_box_reg_stage0: 0.1998  loss_cls_stage1: 0.2074  loss_box_reg_stage1: 0.2533  loss_cls_stage2: 0.1528  loss_box_reg_stage2: 0.2136  loss_mask: 0.5414  loss_rpn_cls: 0.07775  loss_rpn_loc: 0.03525  validation_loss: 1.967  time: 1.5043  data_time: 0.0234  lr: 6.6656e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:55:04 d2.utils.events]: \u001b[0m eta: 2:34:10  iter: 3939  total_loss: 2.185  loss_cls_stage0: 0.3098  loss_box_reg_stage0: 0.2159  loss_cls_stage1: 0.2558  loss_box_reg_stage1: 0.2762  loss_cls_stage2: 0.1794  loss_box_reg_stage2: 0.2198  loss_mask: 0.5826  loss_rpn_cls: 0.07038  loss_rpn_loc: 0.03411  validation_loss: 1.967  time: 1.5045  data_time: 0.0224  lr: 6.6359e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:55:34 d2.utils.events]: \u001b[0m eta: 2:33:42  iter: 3959  total_loss: 2.208  loss_cls_stage0: 0.3034  loss_box_reg_stage0: 0.208  loss_cls_stage1: 0.2584  loss_box_reg_stage1: 0.2794  loss_cls_stage2: 0.1817  loss_box_reg_stage2: 0.2263  loss_mask: 0.6169  loss_rpn_cls: 0.07888  loss_rpn_loc: 0.03616  validation_loss: 1.967  time: 1.5047  data_time: 0.0247  lr: 6.6062e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 03:56:05 d2.utils.events]: \u001b[0m eta: 2:33:14  iter: 3979  total_loss: 2.179  loss_cls_stage0: 0.3369  loss_box_reg_stage0: 0.2383  loss_cls_stage1: 0.2642  loss_box_reg_stage1: 0.3  loss_cls_stage2: 0.1813  loss_box_reg_stage2: 0.2024  loss_mask: 0.547  loss_rpn_cls: 0.07811  loss_rpn_loc: 0.0393  validation_loss: 1.967  time: 1.5049  data_time: 0.0241  lr: 6.5764e-05  max_mem: 12121M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/27 03:56:38 d2.data.common]: \u001b[0mSerializing 857 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/27 03:56:38 d2.data.common]: \u001b[0mSerialized dataset takes 0.89 MiB\n",
      "\u001b[32m[03/27 03:56:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 857 images\n",
      "\u001b[32m[03/27 03:56:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/857. 0.0795 s / img. ETA=0:01:38\n",
      "\u001b[32m[03/27 03:56:45 d2.evaluation.evaluator]: \u001b[0mInference done 55/857. 0.0799 s / img. ETA=0:01:31\n",
      "\u001b[32m[03/27 03:56:50 d2.evaluation.evaluator]: \u001b[0mInference done 102/857. 0.0799 s / img. ETA=0:01:23\n",
      "\u001b[32m[03/27 03:56:55 d2.evaluation.evaluator]: \u001b[0mInference done 150/857. 0.0798 s / img. ETA=0:01:16\n",
      "\u001b[32m[03/27 03:57:00 d2.evaluation.evaluator]: \u001b[0mInference done 199/857. 0.0798 s / img. ETA=0:01:10\n",
      "\u001b[32m[03/27 03:57:05 d2.evaluation.evaluator]: \u001b[0mInference done 248/857. 0.0797 s / img. ETA=0:01:04\n",
      "\u001b[32m[03/27 03:57:10 d2.evaluation.evaluator]: \u001b[0mInference done 296/857. 0.0802 s / img. ETA=0:00:59\n",
      "\u001b[32m[03/27 03:57:15 d2.evaluation.evaluator]: \u001b[0mInference done 344/857. 0.0802 s / img. ETA=0:00:54\n",
      "\u001b[32m[03/27 03:57:21 d2.evaluation.evaluator]: \u001b[0mInference done 393/857. 0.0801 s / img. ETA=0:00:49\n",
      "\u001b[32m[03/27 03:57:26 d2.evaluation.evaluator]: \u001b[0mInference done 442/857. 0.0801 s / img. ETA=0:00:43\n",
      "\u001b[32m[03/27 03:57:31 d2.evaluation.evaluator]: \u001b[0mInference done 492/857. 0.0800 s / img. ETA=0:00:38\n",
      "\u001b[32m[03/27 03:57:36 d2.evaluation.evaluator]: \u001b[0mInference done 541/857. 0.0800 s / img. ETA=0:00:33\n",
      "\u001b[32m[03/27 03:57:41 d2.evaluation.evaluator]: \u001b[0mInference done 590/857. 0.0800 s / img. ETA=0:00:27\n",
      "\u001b[32m[03/27 03:57:46 d2.evaluation.evaluator]: \u001b[0mInference done 637/857. 0.0800 s / img. ETA=0:00:23\n",
      "\u001b[32m[03/27 03:57:51 d2.evaluation.evaluator]: \u001b[0mInference done 685/857. 0.0800 s / img. ETA=0:00:18\n",
      "\u001b[32m[03/27 03:57:56 d2.evaluation.evaluator]: \u001b[0mInference done 735/857. 0.0800 s / img. ETA=0:00:12\n",
      "\u001b[32m[03/27 03:58:01 d2.evaluation.evaluator]: \u001b[0mInference done 784/857. 0.0799 s / img. ETA=0:00:07\n",
      "\u001b[32m[03/27 03:58:06 d2.evaluation.evaluator]: \u001b[0mInference done 835/857. 0.0799 s / img. ETA=0:00:02\n",
      "\u001b[32m[03/27 03:58:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:28.927767 (0.104375 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/27 03:58:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:08 (0.079878 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.26 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.066\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.113\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.120\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.027\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.098\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.118\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.118\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.035\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.125\n",
      "\u001b[32m[03/27 03:58:09 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold4 in csv format:\n",
      "\u001b[32m[03/27 03:58:09 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/27 03:58:09 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/27 03:58:09 d2.evaluation.testing]: \u001b[0mcopypaste: 6.6008,11.2564,12.0331,0.2166,2.7429,6.8147\n",
      "validation do loss eval 2.103840438781503\n",
      "\u001b[32m[03/27 03:59:37 d2.utils.events]: \u001b[0m eta: 2:32:45  iter: 3999  total_loss: 2.341  loss_cls_stage0: 0.3541  loss_box_reg_stage0: 0.2504  loss_cls_stage1: 0.2793  loss_box_reg_stage1: 0.309  loss_cls_stage2: 0.1927  loss_box_reg_stage2: 0.2303  loss_mask: 0.6238  loss_rpn_cls: 0.08887  loss_rpn_loc: 0.03985  validation_loss: 1.974  time: 1.5051  data_time: 0.0245  lr: 6.5466e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:00:08 d2.utils.events]: \u001b[0m eta: 2:32:15  iter: 4019  total_loss: 2.138  loss_cls_stage0: 0.3149  loss_box_reg_stage0: 0.2139  loss_cls_stage1: 0.2463  loss_box_reg_stage1: 0.3006  loss_cls_stage2: 0.1676  loss_box_reg_stage2: 0.2038  loss_mask: 0.5582  loss_rpn_cls: 0.0711  loss_rpn_loc: 0.03586  validation_loss: 1.974  time: 1.5051  data_time: 0.0243  lr: 6.5167e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:00:38 d2.utils.events]: \u001b[0m eta: 2:31:46  iter: 4039  total_loss: 1.961  loss_cls_stage0: 0.29  loss_box_reg_stage0: 0.2004  loss_cls_stage1: 0.231  loss_box_reg_stage1: 0.2677  loss_cls_stage2: 0.158  loss_box_reg_stage2: 0.2043  loss_mask: 0.577  loss_rpn_cls: 0.07114  loss_rpn_loc: 0.03188  validation_loss: 1.974  time: 1.5052  data_time: 0.0254  lr: 6.4867e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:01:09 d2.utils.events]: \u001b[0m eta: 2:31:16  iter: 4059  total_loss: 2.083  loss_cls_stage0: 0.3098  loss_box_reg_stage0: 0.208  loss_cls_stage1: 0.2451  loss_box_reg_stage1: 0.2781  loss_cls_stage2: 0.1895  loss_box_reg_stage2: 0.2423  loss_mask: 0.5657  loss_rpn_cls: 0.07756  loss_rpn_loc: 0.03432  validation_loss: 1.974  time: 1.5054  data_time: 0.0241  lr: 6.4567e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:01:40 d2.utils.events]: \u001b[0m eta: 2:30:46  iter: 4079  total_loss: 1.971  loss_cls_stage0: 0.2742  loss_box_reg_stage0: 0.1927  loss_cls_stage1: 0.2288  loss_box_reg_stage1: 0.2702  loss_cls_stage2: 0.1564  loss_box_reg_stage2: 0.203  loss_mask: 0.5641  loss_rpn_cls: 0.08213  loss_rpn_loc: 0.03517  validation_loss: 1.974  time: 1.5055  data_time: 0.0238  lr: 6.4266e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:02:11 d2.utils.events]: \u001b[0m eta: 2:30:19  iter: 4099  total_loss: 2.121  loss_cls_stage0: 0.3013  loss_box_reg_stage0: 0.2208  loss_cls_stage1: 0.2423  loss_box_reg_stage1: 0.2856  loss_cls_stage2: 0.1724  loss_box_reg_stage2: 0.2263  loss_mask: 0.5622  loss_rpn_cls: 0.07392  loss_rpn_loc: 0.03225  validation_loss: 1.974  time: 1.5057  data_time: 0.0238  lr: 6.3965e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:02:41 d2.utils.events]: \u001b[0m eta: 2:29:50  iter: 4119  total_loss: 2.101  loss_cls_stage0: 0.3181  loss_box_reg_stage0: 0.221  loss_cls_stage1: 0.2509  loss_box_reg_stage1: 0.2811  loss_cls_stage2: 0.1797  loss_box_reg_stage2: 0.1951  loss_mask: 0.5305  loss_rpn_cls: 0.07426  loss_rpn_loc: 0.03617  validation_loss: 1.974  time: 1.5059  data_time: 0.0232  lr: 6.3663e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:03:12 d2.utils.events]: \u001b[0m eta: 2:29:21  iter: 4139  total_loss: 2.097  loss_cls_stage0: 0.292  loss_box_reg_stage0: 0.2261  loss_cls_stage1: 0.2421  loss_box_reg_stage1: 0.2946  loss_cls_stage2: 0.1722  loss_box_reg_stage2: 0.2209  loss_mask: 0.6212  loss_rpn_cls: 0.07085  loss_rpn_loc: 0.03429  validation_loss: 1.974  time: 1.5061  data_time: 0.0232  lr: 6.336e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:03:43 d2.utils.events]: \u001b[0m eta: 2:28:53  iter: 4159  total_loss: 2.339  loss_cls_stage0: 0.3391  loss_box_reg_stage0: 0.2481  loss_cls_stage1: 0.2739  loss_box_reg_stage1: 0.3051  loss_cls_stage2: 0.1962  loss_box_reg_stage2: 0.2261  loss_mask: 0.5846  loss_rpn_cls: 0.07955  loss_rpn_loc: 0.04595  validation_loss: 1.974  time: 1.5063  data_time: 0.0241  lr: 6.3057e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:04:14 d2.utils.events]: \u001b[0m eta: 2:28:23  iter: 4179  total_loss: 1.924  loss_cls_stage0: 0.2834  loss_box_reg_stage0: 0.1887  loss_cls_stage1: 0.2183  loss_box_reg_stage1: 0.2702  loss_cls_stage2: 0.1647  loss_box_reg_stage2: 0.1991  loss_mask: 0.5509  loss_rpn_cls: 0.07789  loss_rpn_loc: 0.03212  validation_loss: 1.974  time: 1.5064  data_time: 0.0250  lr: 6.2754e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:04:45 d2.utils.events]: \u001b[0m eta: 2:27:54  iter: 4199  total_loss: 2.379  loss_cls_stage0: 0.3398  loss_box_reg_stage0: 0.2438  loss_cls_stage1: 0.2799  loss_box_reg_stage1: 0.3175  loss_cls_stage2: 0.2  loss_box_reg_stage2: 0.2488  loss_mask: 0.572  loss_rpn_cls: 0.07858  loss_rpn_loc: 0.0429  validation_loss: 1.974  time: 1.5066  data_time: 0.0250  lr: 6.245e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:05:16 d2.utils.events]: \u001b[0m eta: 2:27:24  iter: 4219  total_loss: 2.206  loss_cls_stage0: 0.3279  loss_box_reg_stage0: 0.2473  loss_cls_stage1: 0.2672  loss_box_reg_stage1: 0.2923  loss_cls_stage2: 0.1847  loss_box_reg_stage2: 0.2188  loss_mask: 0.5773  loss_rpn_cls: 0.07829  loss_rpn_loc: 0.04081  validation_loss: 1.974  time: 1.5067  data_time: 0.0231  lr: 6.2145e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:05:47 d2.utils.events]: \u001b[0m eta: 2:26:55  iter: 4239  total_loss: 2.068  loss_cls_stage0: 0.2902  loss_box_reg_stage0: 0.21  loss_cls_stage1: 0.2397  loss_box_reg_stage1: 0.2865  loss_cls_stage2: 0.1756  loss_box_reg_stage2: 0.2209  loss_mask: 0.568  loss_rpn_cls: 0.07339  loss_rpn_loc: 0.03354  validation_loss: 1.974  time: 1.5069  data_time: 0.0244  lr: 6.184e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:06:17 d2.utils.events]: \u001b[0m eta: 2:26:24  iter: 4259  total_loss: 2.133  loss_cls_stage0: 0.2739  loss_box_reg_stage0: 0.2077  loss_cls_stage1: 0.2285  loss_box_reg_stage1: 0.2845  loss_cls_stage2: 0.1661  loss_box_reg_stage2: 0.2264  loss_mask: 0.556  loss_rpn_cls: 0.07381  loss_rpn_loc: 0.03744  validation_loss: 1.974  time: 1.5071  data_time: 0.0248  lr: 6.1535e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:06:48 d2.utils.events]: \u001b[0m eta: 2:25:57  iter: 4279  total_loss: 2.271  loss_cls_stage0: 0.3242  loss_box_reg_stage0: 0.2172  loss_cls_stage1: 0.2663  loss_box_reg_stage1: 0.2796  loss_cls_stage2: 0.1938  loss_box_reg_stage2: 0.225  loss_mask: 0.5301  loss_rpn_cls: 0.07242  loss_rpn_loc: 0.03588  validation_loss: 1.974  time: 1.5072  data_time: 0.0233  lr: 6.1229e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:07:19 d2.utils.events]: \u001b[0m eta: 2:25:28  iter: 4299  total_loss: 2.104  loss_cls_stage0: 0.2881  loss_box_reg_stage0: 0.2046  loss_cls_stage1: 0.2361  loss_box_reg_stage1: 0.2846  loss_cls_stage2: 0.1775  loss_box_reg_stage2: 0.2286  loss_mask: 0.531  loss_rpn_cls: 0.06947  loss_rpn_loc: 0.03625  validation_loss: 1.974  time: 1.5074  data_time: 0.0243  lr: 6.0922e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:07:50 d2.utils.events]: \u001b[0m eta: 2:25:00  iter: 4319  total_loss: 2.198  loss_cls_stage0: 0.3197  loss_box_reg_stage0: 0.2256  loss_cls_stage1: 0.259  loss_box_reg_stage1: 0.2902  loss_cls_stage2: 0.1833  loss_box_reg_stage2: 0.2264  loss_mask: 0.5764  loss_rpn_cls: 0.07012  loss_rpn_loc: 0.03822  validation_loss: 1.974  time: 1.5075  data_time: 0.0234  lr: 6.0616e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:08:21 d2.utils.events]: \u001b[0m eta: 2:24:30  iter: 4339  total_loss: 2.116  loss_cls_stage0: 0.2937  loss_box_reg_stage0: 0.2164  loss_cls_stage1: 0.234  loss_box_reg_stage1: 0.2877  loss_cls_stage2: 0.175  loss_box_reg_stage2: 0.2515  loss_mask: 0.5519  loss_rpn_cls: 0.07258  loss_rpn_loc: 0.03363  validation_loss: 1.974  time: 1.5077  data_time: 0.0250  lr: 6.0309e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:08:51 d2.utils.events]: \u001b[0m eta: 2:24:03  iter: 4359  total_loss: 2.155  loss_cls_stage0: 0.3306  loss_box_reg_stage0: 0.2228  loss_cls_stage1: 0.2545  loss_box_reg_stage1: 0.3022  loss_cls_stage2: 0.1801  loss_box_reg_stage2: 0.2326  loss_mask: 0.5332  loss_rpn_cls: 0.06879  loss_rpn_loc: 0.03791  validation_loss: 1.974  time: 1.5078  data_time: 0.0240  lr: 6.0001e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:09:22 d2.utils.events]: \u001b[0m eta: 2:23:32  iter: 4379  total_loss: 2.142  loss_cls_stage0: 0.294  loss_box_reg_stage0: 0.2165  loss_cls_stage1: 0.2408  loss_box_reg_stage1: 0.3  loss_cls_stage2: 0.1768  loss_box_reg_stage2: 0.244  loss_mask: 0.5285  loss_rpn_cls: 0.06731  loss_rpn_loc: 0.03717  validation_loss: 1.974  time: 1.5080  data_time: 0.0236  lr: 5.9693e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:09:53 d2.utils.events]: \u001b[0m eta: 2:23:01  iter: 4399  total_loss: 2.191  loss_cls_stage0: 0.3089  loss_box_reg_stage0: 0.212  loss_cls_stage1: 0.2561  loss_box_reg_stage1: 0.2833  loss_cls_stage2: 0.1754  loss_box_reg_stage2: 0.2376  loss_mask: 0.5686  loss_rpn_cls: 0.08357  loss_rpn_loc: 0.04015  validation_loss: 1.974  time: 1.5081  data_time: 0.0231  lr: 5.9384e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:10:24 d2.utils.events]: \u001b[0m eta: 2:22:33  iter: 4419  total_loss: 2.209  loss_cls_stage0: 0.3367  loss_box_reg_stage0: 0.2384  loss_cls_stage1: 0.2573  loss_box_reg_stage1: 0.2839  loss_cls_stage2: 0.1909  loss_box_reg_stage2: 0.2265  loss_mask: 0.578  loss_rpn_cls: 0.06777  loss_rpn_loc: 0.03765  validation_loss: 1.974  time: 1.5083  data_time: 0.0242  lr: 5.9076e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:10:55 d2.utils.events]: \u001b[0m eta: 2:22:03  iter: 4439  total_loss: 2.237  loss_cls_stage0: 0.3379  loss_box_reg_stage0: 0.2444  loss_cls_stage1: 0.2687  loss_box_reg_stage1: 0.312  loss_cls_stage2: 0.1868  loss_box_reg_stage2: 0.252  loss_mask: 0.5381  loss_rpn_cls: 0.07714  loss_rpn_loc: 0.03743  validation_loss: 1.974  time: 1.5085  data_time: 0.0239  lr: 5.8767e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:11:26 d2.utils.events]: \u001b[0m eta: 2:21:35  iter: 4459  total_loss: 2.154  loss_cls_stage0: 0.3146  loss_box_reg_stage0: 0.221  loss_cls_stage1: 0.2535  loss_box_reg_stage1: 0.2807  loss_cls_stage2: 0.1821  loss_box_reg_stage2: 0.2316  loss_mask: 0.5731  loss_rpn_cls: 0.06619  loss_rpn_loc: 0.03548  validation_loss: 1.974  time: 1.5087  data_time: 0.0236  lr: 5.8457e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:11:57 d2.utils.events]: \u001b[0m eta: 2:21:05  iter: 4479  total_loss: 2.194  loss_cls_stage0: 0.3089  loss_box_reg_stage0: 0.2193  loss_cls_stage1: 0.2382  loss_box_reg_stage1: 0.2997  loss_cls_stage2: 0.1776  loss_box_reg_stage2: 0.2455  loss_mask: 0.5549  loss_rpn_cls: 0.07933  loss_rpn_loc: 0.03703  validation_loss: 1.974  time: 1.5089  data_time: 0.0233  lr: 5.8147e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:12:28 d2.utils.events]: \u001b[0m eta: 2:20:35  iter: 4499  total_loss: 2.198  loss_cls_stage0: 0.326  loss_box_reg_stage0: 0.232  loss_cls_stage1: 0.2565  loss_box_reg_stage1: 0.3045  loss_cls_stage2: 0.1818  loss_box_reg_stage2: 0.2353  loss_mask: 0.5841  loss_rpn_cls: 0.06802  loss_rpn_loc: 0.03649  validation_loss: 1.974  time: 1.5090  data_time: 0.0224  lr: 5.7837e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:12:59 d2.utils.events]: \u001b[0m eta: 2:20:05  iter: 4519  total_loss: 2.361  loss_cls_stage0: 0.3457  loss_box_reg_stage0: 0.2537  loss_cls_stage1: 0.2719  loss_box_reg_stage1: 0.328  loss_cls_stage2: 0.1939  loss_box_reg_stage2: 0.2477  loss_mask: 0.5836  loss_rpn_cls: 0.08039  loss_rpn_loc: 0.04498  validation_loss: 1.974  time: 1.5092  data_time: 0.0243  lr: 5.7527e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:13:30 d2.utils.events]: \u001b[0m eta: 2:19:35  iter: 4539  total_loss: 2.035  loss_cls_stage0: 0.3168  loss_box_reg_stage0: 0.2236  loss_cls_stage1: 0.253  loss_box_reg_stage1: 0.2908  loss_cls_stage2: 0.1654  loss_box_reg_stage2: 0.2288  loss_mask: 0.5583  loss_rpn_cls: 0.06858  loss_rpn_loc: 0.03553  validation_loss: 1.974  time: 1.5094  data_time: 0.0241  lr: 5.7216e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:14:01 d2.utils.events]: \u001b[0m eta: 2:19:05  iter: 4559  total_loss: 2.235  loss_cls_stage0: 0.317  loss_box_reg_stage0: 0.2269  loss_cls_stage1: 0.2629  loss_box_reg_stage1: 0.2953  loss_cls_stage2: 0.1787  loss_box_reg_stage2: 0.2384  loss_mask: 0.5571  loss_rpn_cls: 0.06252  loss_rpn_loc: 0.03648  validation_loss: 1.974  time: 1.5095  data_time: 0.0250  lr: 5.6905e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:14:32 d2.utils.events]: \u001b[0m eta: 2:18:37  iter: 4579  total_loss: 2.259  loss_cls_stage0: 0.3442  loss_box_reg_stage0: 0.2478  loss_cls_stage1: 0.2593  loss_box_reg_stage1: 0.3193  loss_cls_stage2: 0.1825  loss_box_reg_stage2: 0.2398  loss_mask: 0.5459  loss_rpn_cls: 0.08154  loss_rpn_loc: 0.04089  validation_loss: 1.974  time: 1.5097  data_time: 0.0248  lr: 5.6594e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:15:03 d2.utils.events]: \u001b[0m eta: 2:18:07  iter: 4599  total_loss: 2.164  loss_cls_stage0: 0.3044  loss_box_reg_stage0: 0.2188  loss_cls_stage1: 0.2611  loss_box_reg_stage1: 0.3049  loss_cls_stage2: 0.1933  loss_box_reg_stage2: 0.2375  loss_mask: 0.5811  loss_rpn_cls: 0.06539  loss_rpn_loc: 0.03452  validation_loss: 1.974  time: 1.5098  data_time: 0.0248  lr: 5.6282e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:15:34 d2.utils.events]: \u001b[0m eta: 2:17:38  iter: 4619  total_loss: 2.108  loss_cls_stage0: 0.2941  loss_box_reg_stage0: 0.2014  loss_cls_stage1: 0.2499  loss_box_reg_stage1: 0.2813  loss_cls_stage2: 0.1791  loss_box_reg_stage2: 0.2196  loss_mask: 0.5649  loss_rpn_cls: 0.07279  loss_rpn_loc: 0.03863  validation_loss: 1.974  time: 1.5100  data_time: 0.0301  lr: 5.597e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:16:05 d2.utils.events]: \u001b[0m eta: 2:17:08  iter: 4639  total_loss: 2.282  loss_cls_stage0: 0.3296  loss_box_reg_stage0: 0.2403  loss_cls_stage1: 0.2681  loss_box_reg_stage1: 0.3276  loss_cls_stage2: 0.186  loss_box_reg_stage2: 0.2465  loss_mask: 0.5716  loss_rpn_cls: 0.07639  loss_rpn_loc: 0.03602  validation_loss: 1.974  time: 1.5101  data_time: 0.0250  lr: 5.5658e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:16:35 d2.utils.events]: \u001b[0m eta: 2:16:41  iter: 4659  total_loss: 2.267  loss_cls_stage0: 0.3026  loss_box_reg_stage0: 0.2199  loss_cls_stage1: 0.2329  loss_box_reg_stage1: 0.31  loss_cls_stage2: 0.1766  loss_box_reg_stage2: 0.2484  loss_mask: 0.5974  loss_rpn_cls: 0.07082  loss_rpn_loc: 0.03324  validation_loss: 1.974  time: 1.5103  data_time: 0.0226  lr: 5.5346e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:17:06 d2.utils.events]: \u001b[0m eta: 2:16:11  iter: 4679  total_loss: 2.171  loss_cls_stage0: 0.3129  loss_box_reg_stage0: 0.2131  loss_cls_stage1: 0.2476  loss_box_reg_stage1: 0.2889  loss_cls_stage2: 0.1786  loss_box_reg_stage2: 0.24  loss_mask: 0.592  loss_rpn_cls: 0.06723  loss_rpn_loc: 0.03327  validation_loss: 1.974  time: 1.5104  data_time: 0.0229  lr: 5.5034e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:17:37 d2.utils.events]: \u001b[0m eta: 2:15:40  iter: 4699  total_loss: 2.135  loss_cls_stage0: 0.309  loss_box_reg_stage0: 0.2232  loss_cls_stage1: 0.2443  loss_box_reg_stage1: 0.2862  loss_cls_stage2: 0.1739  loss_box_reg_stage2: 0.2319  loss_mask: 0.5401  loss_rpn_cls: 0.08042  loss_rpn_loc: 0.04095  validation_loss: 1.974  time: 1.5105  data_time: 0.0235  lr: 5.4721e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:18:08 d2.utils.events]: \u001b[0m eta: 2:15:13  iter: 4719  total_loss: 2.195  loss_cls_stage0: 0.3044  loss_box_reg_stage0: 0.2362  loss_cls_stage1: 0.2514  loss_box_reg_stage1: 0.3165  loss_cls_stage2: 0.1746  loss_box_reg_stage2: 0.2482  loss_mask: 0.5225  loss_rpn_cls: 0.0675  loss_rpn_loc: 0.03794  validation_loss: 1.974  time: 1.5107  data_time: 0.0237  lr: 5.4408e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:18:39 d2.utils.events]: \u001b[0m eta: 2:14:43  iter: 4739  total_loss: 2.342  loss_cls_stage0: 0.3362  loss_box_reg_stage0: 0.2564  loss_cls_stage1: 0.2692  loss_box_reg_stage1: 0.3229  loss_cls_stage2: 0.1955  loss_box_reg_stage2: 0.2501  loss_mask: 0.5535  loss_rpn_cls: 0.07083  loss_rpn_loc: 0.04078  validation_loss: 1.974  time: 1.5108  data_time: 0.0246  lr: 5.4095e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:19:10 d2.utils.events]: \u001b[0m eta: 2:14:14  iter: 4759  total_loss: 2.147  loss_cls_stage0: 0.3229  loss_box_reg_stage0: 0.2383  loss_cls_stage1: 0.2491  loss_box_reg_stage1: 0.3028  loss_cls_stage2: 0.1785  loss_box_reg_stage2: 0.2362  loss_mask: 0.5235  loss_rpn_cls: 0.06922  loss_rpn_loc: 0.03141  validation_loss: 1.974  time: 1.5110  data_time: 0.0235  lr: 5.3782e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:19:41 d2.utils.events]: \u001b[0m eta: 2:13:43  iter: 4779  total_loss: 2.111  loss_cls_stage0: 0.3077  loss_box_reg_stage0: 0.2204  loss_cls_stage1: 0.2544  loss_box_reg_stage1: 0.3018  loss_cls_stage2: 0.1676  loss_box_reg_stage2: 0.2349  loss_mask: 0.5269  loss_rpn_cls: 0.07112  loss_rpn_loc: 0.03519  validation_loss: 1.974  time: 1.5111  data_time: 0.0241  lr: 5.3469e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:20:12 d2.utils.events]: \u001b[0m eta: 2:13:14  iter: 4799  total_loss: 2.055  loss_cls_stage0: 0.2733  loss_box_reg_stage0: 0.2133  loss_cls_stage1: 0.2267  loss_box_reg_stage1: 0.2907  loss_cls_stage2: 0.1676  loss_box_reg_stage2: 0.2254  loss_mask: 0.5639  loss_rpn_cls: 0.07109  loss_rpn_loc: 0.03779  validation_loss: 1.974  time: 1.5113  data_time: 0.0241  lr: 5.3155e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:20:43 d2.utils.events]: \u001b[0m eta: 2:12:44  iter: 4819  total_loss: 2.174  loss_cls_stage0: 0.3024  loss_box_reg_stage0: 0.2228  loss_cls_stage1: 0.2536  loss_box_reg_stage1: 0.2933  loss_cls_stage2: 0.1729  loss_box_reg_stage2: 0.2444  loss_mask: 0.5696  loss_rpn_cls: 0.07154  loss_rpn_loc: 0.03764  validation_loss: 1.974  time: 1.5114  data_time: 0.0251  lr: 5.2842e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:21:14 d2.utils.events]: \u001b[0m eta: 2:12:16  iter: 4839  total_loss: 2.283  loss_cls_stage0: 0.3128  loss_box_reg_stage0: 0.2418  loss_cls_stage1: 0.2738  loss_box_reg_stage1: 0.3178  loss_cls_stage2: 0.1943  loss_box_reg_stage2: 0.2488  loss_mask: 0.5354  loss_rpn_cls: 0.0737  loss_rpn_loc: 0.03678  validation_loss: 1.974  time: 1.5116  data_time: 0.0242  lr: 5.2528e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:21:45 d2.utils.events]: \u001b[0m eta: 2:11:45  iter: 4859  total_loss: 2.166  loss_cls_stage0: 0.3003  loss_box_reg_stage0: 0.2283  loss_cls_stage1: 0.2457  loss_box_reg_stage1: 0.3192  loss_cls_stage2: 0.1632  loss_box_reg_stage2: 0.2303  loss_mask: 0.5394  loss_rpn_cls: 0.06987  loss_rpn_loc: 0.03459  validation_loss: 1.974  time: 1.5117  data_time: 0.0240  lr: 5.2214e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:22:15 d2.utils.events]: \u001b[0m eta: 2:11:14  iter: 4879  total_loss: 2.156  loss_cls_stage0: 0.2942  loss_box_reg_stage0: 0.2054  loss_cls_stage1: 0.2465  loss_box_reg_stage1: 0.2968  loss_cls_stage2: 0.1904  loss_box_reg_stage2: 0.2424  loss_mask: 0.5535  loss_rpn_cls: 0.06973  loss_rpn_loc: 0.03485  validation_loss: 1.974  time: 1.5118  data_time: 0.0237  lr: 5.19e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:22:46 d2.utils.events]: \u001b[0m eta: 2:10:44  iter: 4899  total_loss: 2.258  loss_cls_stage0: 0.3402  loss_box_reg_stage0: 0.2323  loss_cls_stage1: 0.2718  loss_box_reg_stage1: 0.3308  loss_cls_stage2: 0.1918  loss_box_reg_stage2: 0.2482  loss_mask: 0.5646  loss_rpn_cls: 0.07287  loss_rpn_loc: 0.03836  validation_loss: 1.974  time: 1.5120  data_time: 0.0231  lr: 5.1586e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:23:17 d2.utils.events]: \u001b[0m eta: 2:10:14  iter: 4919  total_loss: 2.278  loss_cls_stage0: 0.307  loss_box_reg_stage0: 0.2308  loss_cls_stage1: 0.2509  loss_box_reg_stage1: 0.3123  loss_cls_stage2: 0.1879  loss_box_reg_stage2: 0.2549  loss_mask: 0.5812  loss_rpn_cls: 0.06918  loss_rpn_loc: 0.03507  validation_loss: 1.974  time: 1.5121  data_time: 0.0225  lr: 5.1272e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:23:48 d2.utils.events]: \u001b[0m eta: 2:09:46  iter: 4939  total_loss: 2.26  loss_cls_stage0: 0.3164  loss_box_reg_stage0: 0.2309  loss_cls_stage1: 0.2674  loss_box_reg_stage1: 0.3164  loss_cls_stage2: 0.194  loss_box_reg_stage2: 0.2513  loss_mask: 0.5568  loss_rpn_cls: 0.06134  loss_rpn_loc: 0.03632  validation_loss: 1.974  time: 1.5123  data_time: 0.0239  lr: 5.0958e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:24:19 d2.utils.events]: \u001b[0m eta: 2:09:17  iter: 4959  total_loss: 2.164  loss_cls_stage0: 0.3156  loss_box_reg_stage0: 0.2419  loss_cls_stage1: 0.2559  loss_box_reg_stage1: 0.3303  loss_cls_stage2: 0.1783  loss_box_reg_stage2: 0.2519  loss_mask: 0.5208  loss_rpn_cls: 0.06095  loss_rpn_loc: 0.03412  validation_loss: 1.974  time: 1.5124  data_time: 0.0247  lr: 5.0644e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:24:50 d2.utils.events]: \u001b[0m eta: 2:08:46  iter: 4979  total_loss: 2.046  loss_cls_stage0: 0.2729  loss_box_reg_stage0: 0.1943  loss_cls_stage1: 0.2197  loss_box_reg_stage1: 0.2983  loss_cls_stage2: 0.1736  loss_box_reg_stage2: 0.2424  loss_mask: 0.5638  loss_rpn_cls: 0.0734  loss_rpn_loc: 0.03457  validation_loss: 1.974  time: 1.5125  data_time: 0.0248  lr: 5.033e-05  max_mem: 12121M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/27 04:25:23 d2.data.common]: \u001b[0mSerializing 857 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/27 04:25:23 d2.data.common]: \u001b[0mSerialized dataset takes 0.89 MiB\n",
      "\u001b[32m[03/27 04:25:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 857 images\n",
      "\u001b[32m[03/27 04:25:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/857. 0.0804 s / img. ETA=0:01:35\n",
      "\u001b[32m[03/27 04:25:30 d2.evaluation.evaluator]: \u001b[0mInference done 58/857. 0.0802 s / img. ETA=0:01:26\n",
      "\u001b[32m[03/27 04:25:35 d2.evaluation.evaluator]: \u001b[0mInference done 105/857. 0.0801 s / img. ETA=0:01:20\n",
      "\u001b[32m[03/27 04:25:40 d2.evaluation.evaluator]: \u001b[0mInference done 154/857. 0.0800 s / img. ETA=0:01:14\n",
      "\u001b[32m[03/27 04:25:45 d2.evaluation.evaluator]: \u001b[0mInference done 201/857. 0.0800 s / img. ETA=0:01:09\n",
      "\u001b[32m[03/27 04:25:50 d2.evaluation.evaluator]: \u001b[0mInference done 250/857. 0.0799 s / img. ETA=0:01:04\n",
      "\u001b[32m[03/27 04:25:55 d2.evaluation.evaluator]: \u001b[0mInference done 299/857. 0.0799 s / img. ETA=0:00:58\n",
      "\u001b[32m[03/27 04:26:00 d2.evaluation.evaluator]: \u001b[0mInference done 346/857. 0.0800 s / img. ETA=0:00:53\n",
      "\u001b[32m[03/27 04:26:05 d2.evaluation.evaluator]: \u001b[0mInference done 395/857. 0.0800 s / img. ETA=0:00:48\n",
      "\u001b[32m[03/27 04:26:10 d2.evaluation.evaluator]: \u001b[0mInference done 444/857. 0.0800 s / img. ETA=0:00:43\n",
      "\u001b[32m[03/27 04:26:15 d2.evaluation.evaluator]: \u001b[0mInference done 493/857. 0.0802 s / img. ETA=0:00:38\n",
      "\u001b[32m[03/27 04:26:20 d2.evaluation.evaluator]: \u001b[0mInference done 542/857. 0.0802 s / img. ETA=0:00:32\n",
      "\u001b[32m[03/27 04:26:26 d2.evaluation.evaluator]: \u001b[0mInference done 590/857. 0.0802 s / img. ETA=0:00:27\n",
      "\u001b[32m[03/27 04:26:31 d2.evaluation.evaluator]: \u001b[0mInference done 638/857. 0.0802 s / img. ETA=0:00:22\n",
      "\u001b[32m[03/27 04:26:36 d2.evaluation.evaluator]: \u001b[0mInference done 686/857. 0.0802 s / img. ETA=0:00:17\n",
      "\u001b[32m[03/27 04:26:41 d2.evaluation.evaluator]: \u001b[0mInference done 735/857. 0.0801 s / img. ETA=0:00:12\n",
      "\u001b[32m[03/27 04:26:46 d2.evaluation.evaluator]: \u001b[0mInference done 783/857. 0.0801 s / img. ETA=0:00:07\n",
      "\u001b[32m[03/27 04:26:51 d2.evaluation.evaluator]: \u001b[0mInference done 833/857. 0.0801 s / img. ETA=0:00:02\n",
      "\u001b[32m[03/27 04:26:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:28.936854 (0.104386 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/27 04:26:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:08 (0.080072 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.27 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.076\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.127\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.138\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.032\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.079\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.109\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.136\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.136\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.145\n",
      "\u001b[32m[03/27 04:26:54 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold4 in csv format:\n",
      "\u001b[32m[03/27 04:26:54 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/27 04:26:54 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/27 04:26:54 d2.evaluation.testing]: \u001b[0mcopypaste: 7.5824,12.7057,13.8244,0.6483,3.1815,7.9134\n",
      "validation do loss eval 2.213378697394664\n",
      "\u001b[32m[03/27 04:28:22 d2.utils.events]: \u001b[0m eta: 2:08:15  iter: 4999  total_loss: 2.187  loss_cls_stage0: 0.2981  loss_box_reg_stage0: 0.2215  loss_cls_stage1: 0.2429  loss_box_reg_stage1: 0.302  loss_cls_stage2: 0.1801  loss_box_reg_stage2: 0.2596  loss_mask: 0.5649  loss_rpn_cls: 0.07642  loss_rpn_loc: 0.03924  validation_loss: 1.981  time: 1.5127  data_time: 0.0235  lr: 5.0016e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:28:53 d2.utils.events]: \u001b[0m eta: 2:07:45  iter: 5019  total_loss: 2.287  loss_cls_stage0: 0.3111  loss_box_reg_stage0: 0.237  loss_cls_stage1: 0.2634  loss_box_reg_stage1: 0.3434  loss_cls_stage2: 0.1966  loss_box_reg_stage2: 0.2829  loss_mask: 0.5793  loss_rpn_cls: 0.06723  loss_rpn_loc: 0.03551  validation_loss: 1.981  time: 1.5128  data_time: 0.0236  lr: 4.9702e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:29:24 d2.utils.events]: \u001b[0m eta: 2:07:15  iter: 5039  total_loss: 2.333  loss_cls_stage0: 0.3242  loss_box_reg_stage0: 0.2217  loss_cls_stage1: 0.2724  loss_box_reg_stage1: 0.3287  loss_cls_stage2: 0.204  loss_box_reg_stage2: 0.256  loss_mask: 0.6006  loss_rpn_cls: 0.06389  loss_rpn_loc: 0.0348  validation_loss: 1.981  time: 1.5129  data_time: 0.0238  lr: 4.9387e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:29:55 d2.utils.events]: \u001b[0m eta: 2:06:45  iter: 5059  total_loss: 2.051  loss_cls_stage0: 0.2856  loss_box_reg_stage0: 0.2184  loss_cls_stage1: 0.2271  loss_box_reg_stage1: 0.2998  loss_cls_stage2: 0.1864  loss_box_reg_stage2: 0.2464  loss_mask: 0.5567  loss_rpn_cls: 0.05742  loss_rpn_loc: 0.02981  validation_loss: 1.981  time: 1.5130  data_time: 0.0239  lr: 4.9073e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:30:25 d2.utils.events]: \u001b[0m eta: 2:06:15  iter: 5079  total_loss: 2.154  loss_cls_stage0: 0.2995  loss_box_reg_stage0: 0.1975  loss_cls_stage1: 0.2467  loss_box_reg_stage1: 0.3009  loss_cls_stage2: 0.1761  loss_box_reg_stage2: 0.2673  loss_mask: 0.5524  loss_rpn_cls: 0.06661  loss_rpn_loc: 0.03217  validation_loss: 1.981  time: 1.5131  data_time: 0.0248  lr: 4.8759e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:30:57 d2.utils.events]: \u001b[0m eta: 2:05:44  iter: 5099  total_loss: 2.24  loss_cls_stage0: 0.331  loss_box_reg_stage0: 0.2447  loss_cls_stage1: 0.257  loss_box_reg_stage1: 0.3248  loss_cls_stage2: 0.1839  loss_box_reg_stage2: 0.2636  loss_mask: 0.5143  loss_rpn_cls: 0.06679  loss_rpn_loc: 0.0398  validation_loss: 1.981  time: 1.5133  data_time: 0.0238  lr: 4.8445e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:31:27 d2.utils.events]: \u001b[0m eta: 2:05:13  iter: 5119  total_loss: 2.04  loss_cls_stage0: 0.2773  loss_box_reg_stage0: 0.2127  loss_cls_stage1: 0.248  loss_box_reg_stage1: 0.2912  loss_cls_stage2: 0.174  loss_box_reg_stage2: 0.2463  loss_mask: 0.545  loss_rpn_cls: 0.06916  loss_rpn_loc: 0.0326  validation_loss: 1.981  time: 1.5134  data_time: 0.0242  lr: 4.8131e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:31:58 d2.utils.events]: \u001b[0m eta: 2:04:43  iter: 5139  total_loss: 2.27  loss_cls_stage0: 0.3112  loss_box_reg_stage0: 0.2368  loss_cls_stage1: 0.2783  loss_box_reg_stage1: 0.3258  loss_cls_stage2: 0.1958  loss_box_reg_stage2: 0.2683  loss_mask: 0.54  loss_rpn_cls: 0.07052  loss_rpn_loc: 0.03158  validation_loss: 1.981  time: 1.5135  data_time: 0.0241  lr: 4.7817e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:32:29 d2.utils.events]: \u001b[0m eta: 2:04:12  iter: 5159  total_loss: 2.228  loss_cls_stage0: 0.3008  loss_box_reg_stage0: 0.2354  loss_cls_stage1: 0.2436  loss_box_reg_stage1: 0.3217  loss_cls_stage2: 0.1779  loss_box_reg_stage2: 0.2586  loss_mask: 0.5128  loss_rpn_cls: 0.06542  loss_rpn_loc: 0.03632  validation_loss: 1.981  time: 1.5137  data_time: 0.0231  lr: 4.7503e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:33:00 d2.utils.events]: \u001b[0m eta: 2:03:43  iter: 5179  total_loss: 2.16  loss_cls_stage0: 0.2814  loss_box_reg_stage0: 0.2224  loss_cls_stage1: 0.2384  loss_box_reg_stage1: 0.3155  loss_cls_stage2: 0.1776  loss_box_reg_stage2: 0.2426  loss_mask: 0.5778  loss_rpn_cls: 0.06296  loss_rpn_loc: 0.03434  validation_loss: 1.981  time: 1.5138  data_time: 0.0235  lr: 4.719e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:33:31 d2.utils.events]: \u001b[0m eta: 2:03:13  iter: 5199  total_loss: 2.322  loss_cls_stage0: 0.3071  loss_box_reg_stage0: 0.245  loss_cls_stage1: 0.2696  loss_box_reg_stage1: 0.3512  loss_cls_stage2: 0.2014  loss_box_reg_stage2: 0.2693  loss_mask: 0.5058  loss_rpn_cls: 0.06573  loss_rpn_loc: 0.03391  validation_loss: 1.981  time: 1.5140  data_time: 0.0236  lr: 4.6876e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:34:03 d2.utils.events]: \u001b[0m eta: 2:02:43  iter: 5219  total_loss: 2.278  loss_cls_stage0: 0.3173  loss_box_reg_stage0: 0.2487  loss_cls_stage1: 0.2611  loss_box_reg_stage1: 0.3291  loss_cls_stage2: 0.172  loss_box_reg_stage2: 0.2654  loss_mask: 0.5583  loss_rpn_cls: 0.06311  loss_rpn_loc: 0.03711  validation_loss: 1.981  time: 1.5141  data_time: 0.0241  lr: 4.6563e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:34:34 d2.utils.events]: \u001b[0m eta: 2:02:12  iter: 5239  total_loss: 2.321  loss_cls_stage0: 0.3469  loss_box_reg_stage0: 0.2558  loss_cls_stage1: 0.2713  loss_box_reg_stage1: 0.3215  loss_cls_stage2: 0.1802  loss_box_reg_stage2: 0.2472  loss_mask: 0.5713  loss_rpn_cls: 0.06746  loss_rpn_loc: 0.03895  validation_loss: 1.981  time: 1.5143  data_time: 0.0236  lr: 4.6249e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:35:05 d2.utils.events]: \u001b[0m eta: 2:01:43  iter: 5259  total_loss: 2.35  loss_cls_stage0: 0.3384  loss_box_reg_stage0: 0.2484  loss_cls_stage1: 0.2822  loss_box_reg_stage1: 0.3433  loss_cls_stage2: 0.2012  loss_box_reg_stage2: 0.2715  loss_mask: 0.5501  loss_rpn_cls: 0.07025  loss_rpn_loc: 0.0376  validation_loss: 1.981  time: 1.5144  data_time: 0.0290  lr: 4.5936e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:35:36 d2.utils.events]: \u001b[0m eta: 2:01:13  iter: 5279  total_loss: 2.159  loss_cls_stage0: 0.2872  loss_box_reg_stage0: 0.2109  loss_cls_stage1: 0.2334  loss_box_reg_stage1: 0.3104  loss_cls_stage2: 0.177  loss_box_reg_stage2: 0.2581  loss_mask: 0.5154  loss_rpn_cls: 0.07101  loss_rpn_loc: 0.03432  validation_loss: 1.981  time: 1.5146  data_time: 0.0236  lr: 4.5623e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:36:07 d2.utils.events]: \u001b[0m eta: 2:00:44  iter: 5299  total_loss: 2.222  loss_cls_stage0: 0.3378  loss_box_reg_stage0: 0.257  loss_cls_stage1: 0.2672  loss_box_reg_stage1: 0.326  loss_cls_stage2: 0.1884  loss_box_reg_stage2: 0.2531  loss_mask: 0.5216  loss_rpn_cls: 0.06805  loss_rpn_loc: 0.03425  validation_loss: 1.981  time: 1.5147  data_time: 0.0239  lr: 4.531e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:36:38 d2.utils.events]: \u001b[0m eta: 2:00:15  iter: 5319  total_loss: 2.356  loss_cls_stage0: 0.3652  loss_box_reg_stage0: 0.2653  loss_cls_stage1: 0.2891  loss_box_reg_stage1: 0.3268  loss_cls_stage2: 0.1957  loss_box_reg_stage2: 0.2487  loss_mask: 0.5646  loss_rpn_cls: 0.06741  loss_rpn_loc: 0.03728  validation_loss: 1.981  time: 1.5149  data_time: 0.0234  lr: 4.4998e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:37:09 d2.utils.events]: \u001b[0m eta: 1:59:46  iter: 5339  total_loss: 2.515  loss_cls_stage0: 0.3509  loss_box_reg_stage0: 0.2586  loss_cls_stage1: 0.2799  loss_box_reg_stage1: 0.3382  loss_cls_stage2: 0.1981  loss_box_reg_stage2: 0.2816  loss_mask: 0.5538  loss_rpn_cls: 0.07466  loss_rpn_loc: 0.04183  validation_loss: 1.981  time: 1.5150  data_time: 0.0241  lr: 4.4685e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:37:40 d2.utils.events]: \u001b[0m eta: 1:59:16  iter: 5359  total_loss: 2.219  loss_cls_stage0: 0.3156  loss_box_reg_stage0: 0.2313  loss_cls_stage1: 0.2514  loss_box_reg_stage1: 0.3146  loss_cls_stage2: 0.1732  loss_box_reg_stage2: 0.2603  loss_mask: 0.5473  loss_rpn_cls: 0.06333  loss_rpn_loc: 0.03626  validation_loss: 1.981  time: 1.5152  data_time: 0.0232  lr: 4.4373e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:38:11 d2.utils.events]: \u001b[0m eta: 1:58:45  iter: 5379  total_loss: 2.202  loss_cls_stage0: 0.3239  loss_box_reg_stage0: 0.2314  loss_cls_stage1: 0.262  loss_box_reg_stage1: 0.2932  loss_cls_stage2: 0.1808  loss_box_reg_stage2: 0.2271  loss_mask: 0.5603  loss_rpn_cls: 0.0707  loss_rpn_loc: 0.03448  validation_loss: 1.981  time: 1.5152  data_time: 0.0233  lr: 4.4061e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:38:42 d2.utils.events]: \u001b[0m eta: 1:58:16  iter: 5399  total_loss: 2.283  loss_cls_stage0: 0.3283  loss_box_reg_stage0: 0.2518  loss_cls_stage1: 0.2691  loss_box_reg_stage1: 0.3318  loss_cls_stage2: 0.1871  loss_box_reg_stage2: 0.2537  loss_mask: 0.5505  loss_rpn_cls: 0.05571  loss_rpn_loc: 0.03521  validation_loss: 1.981  time: 1.5154  data_time: 0.0245  lr: 4.3749e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:39:13 d2.utils.events]: \u001b[0m eta: 1:57:47  iter: 5419  total_loss: 2.332  loss_cls_stage0: 0.3017  loss_box_reg_stage0: 0.2409  loss_cls_stage1: 0.2502  loss_box_reg_stage1: 0.3264  loss_cls_stage2: 0.186  loss_box_reg_stage2: 0.2714  loss_mask: 0.56  loss_rpn_cls: 0.0707  loss_rpn_loc: 0.04132  validation_loss: 1.981  time: 1.5155  data_time: 0.0234  lr: 4.3437e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:39:44 d2.utils.events]: \u001b[0m eta: 1:57:17  iter: 5439  total_loss: 2.209  loss_cls_stage0: 0.2986  loss_box_reg_stage0: 0.2309  loss_cls_stage1: 0.2462  loss_box_reg_stage1: 0.3273  loss_cls_stage2: 0.1777  loss_box_reg_stage2: 0.2636  loss_mask: 0.5802  loss_rpn_cls: 0.06814  loss_rpn_loc: 0.03697  validation_loss: 1.981  time: 1.5157  data_time: 0.0239  lr: 4.3126e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:40:15 d2.utils.events]: \u001b[0m eta: 1:56:47  iter: 5459  total_loss: 2.218  loss_cls_stage0: 0.3151  loss_box_reg_stage0: 0.2445  loss_cls_stage1: 0.2586  loss_box_reg_stage1: 0.3254  loss_cls_stage2: 0.1819  loss_box_reg_stage2: 0.2748  loss_mask: 0.535  loss_rpn_cls: 0.06172  loss_rpn_loc: 0.03657  validation_loss: 1.981  time: 1.5158  data_time: 0.0235  lr: 4.2815e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:40:46 d2.utils.events]: \u001b[0m eta: 1:56:16  iter: 5479  total_loss: 2.198  loss_cls_stage0: 0.2895  loss_box_reg_stage0: 0.2172  loss_cls_stage1: 0.2493  loss_box_reg_stage1: 0.3075  loss_cls_stage2: 0.1828  loss_box_reg_stage2: 0.2576  loss_mask: 0.533  loss_rpn_cls: 0.06497  loss_rpn_loc: 0.03334  validation_loss: 1.981  time: 1.5159  data_time: 0.0237  lr: 4.2504e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:41:17 d2.utils.events]: \u001b[0m eta: 1:55:45  iter: 5499  total_loss: 2.25  loss_cls_stage0: 0.3161  loss_box_reg_stage0: 0.2321  loss_cls_stage1: 0.2654  loss_box_reg_stage1: 0.3393  loss_cls_stage2: 0.1913  loss_box_reg_stage2: 0.2882  loss_mask: 0.5434  loss_rpn_cls: 0.06767  loss_rpn_loc: 0.03452  validation_loss: 1.981  time: 1.5160  data_time: 0.0236  lr: 4.2194e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:41:48 d2.utils.events]: \u001b[0m eta: 1:55:15  iter: 5519  total_loss: 2.252  loss_cls_stage0: 0.3228  loss_box_reg_stage0: 0.239  loss_cls_stage1: 0.2783  loss_box_reg_stage1: 0.3417  loss_cls_stage2: 0.1957  loss_box_reg_stage2: 0.2724  loss_mask: 0.4991  loss_rpn_cls: 0.0671  loss_rpn_loc: 0.03407  validation_loss: 1.981  time: 1.5162  data_time: 0.0222  lr: 4.1884e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:42:19 d2.utils.events]: \u001b[0m eta: 1:54:46  iter: 5539  total_loss: 2.331  loss_cls_stage0: 0.327  loss_box_reg_stage0: 0.2517  loss_cls_stage1: 0.2583  loss_box_reg_stage1: 0.3378  loss_cls_stage2: 0.1756  loss_box_reg_stage2: 0.277  loss_mask: 0.5484  loss_rpn_cls: 0.07241  loss_rpn_loc: 0.03947  validation_loss: 1.981  time: 1.5163  data_time: 0.0238  lr: 4.1574e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:42:51 d2.utils.events]: \u001b[0m eta: 1:54:15  iter: 5559  total_loss: 2.441  loss_cls_stage0: 0.3323  loss_box_reg_stage0: 0.2591  loss_cls_stage1: 0.2732  loss_box_reg_stage1: 0.361  loss_cls_stage2: 0.206  loss_box_reg_stage2: 0.315  loss_mask: 0.571  loss_rpn_cls: 0.07653  loss_rpn_loc: 0.04147  validation_loss: 1.981  time: 1.5165  data_time: 0.0225  lr: 4.1264e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:43:22 d2.utils.events]: \u001b[0m eta: 1:53:45  iter: 5579  total_loss: 2.322  loss_cls_stage0: 0.3218  loss_box_reg_stage0: 0.243  loss_cls_stage1: 0.2724  loss_box_reg_stage1: 0.3415  loss_cls_stage2: 0.1846  loss_box_reg_stage2: 0.2714  loss_mask: 0.5511  loss_rpn_cls: 0.05879  loss_rpn_loc: 0.03361  validation_loss: 1.981  time: 1.5166  data_time: 0.0247  lr: 4.0955e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:43:53 d2.utils.events]: \u001b[0m eta: 1:53:16  iter: 5599  total_loss: 2.269  loss_cls_stage0: 0.3063  loss_box_reg_stage0: 0.2403  loss_cls_stage1: 0.2517  loss_box_reg_stage1: 0.3566  loss_cls_stage2: 0.183  loss_box_reg_stage2: 0.2917  loss_mask: 0.566  loss_rpn_cls: 0.06575  loss_rpn_loc: 0.03409  validation_loss: 1.981  time: 1.5167  data_time: 0.0245  lr: 4.0646e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:44:24 d2.utils.events]: \u001b[0m eta: 1:52:46  iter: 5619  total_loss: 2.311  loss_cls_stage0: 0.3297  loss_box_reg_stage0: 0.2536  loss_cls_stage1: 0.2813  loss_box_reg_stage1: 0.3349  loss_cls_stage2: 0.2025  loss_box_reg_stage2: 0.2914  loss_mask: 0.5378  loss_rpn_cls: 0.05965  loss_rpn_loc: 0.03873  validation_loss: 1.981  time: 1.5169  data_time: 0.0245  lr: 4.0338e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:44:55 d2.utils.events]: \u001b[0m eta: 1:52:15  iter: 5639  total_loss: 2.439  loss_cls_stage0: 0.3488  loss_box_reg_stage0: 0.2665  loss_cls_stage1: 0.2957  loss_box_reg_stage1: 0.3548  loss_cls_stage2: 0.2046  loss_box_reg_stage2: 0.2639  loss_mask: 0.5874  loss_rpn_cls: 0.06708  loss_rpn_loc: 0.03766  validation_loss: 1.981  time: 1.5170  data_time: 0.0268  lr: 4.003e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:45:26 d2.utils.events]: \u001b[0m eta: 1:51:45  iter: 5659  total_loss: 2.195  loss_cls_stage0: 0.3129  loss_box_reg_stage0: 0.2027  loss_cls_stage1: 0.2579  loss_box_reg_stage1: 0.2924  loss_cls_stage2: 0.1778  loss_box_reg_stage2: 0.2559  loss_mask: 0.5749  loss_rpn_cls: 0.06188  loss_rpn_loc: 0.03342  validation_loss: 1.981  time: 1.5171  data_time: 0.0238  lr: 3.9722e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:45:57 d2.utils.events]: \u001b[0m eta: 1:51:16  iter: 5679  total_loss: 2.245  loss_cls_stage0: 0.3064  loss_box_reg_stage0: 0.2337  loss_cls_stage1: 0.2596  loss_box_reg_stage1: 0.3274  loss_cls_stage2: 0.1988  loss_box_reg_stage2: 0.2933  loss_mask: 0.5217  loss_rpn_cls: 0.06851  loss_rpn_loc: 0.03775  validation_loss: 1.981  time: 1.5173  data_time: 0.0216  lr: 3.9415e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:46:28 d2.utils.events]: \u001b[0m eta: 1:50:47  iter: 5699  total_loss: 2.171  loss_cls_stage0: 0.303  loss_box_reg_stage0: 0.2394  loss_cls_stage1: 0.2364  loss_box_reg_stage1: 0.3035  loss_cls_stage2: 0.1625  loss_box_reg_stage2: 0.2591  loss_mask: 0.5809  loss_rpn_cls: 0.0613  loss_rpn_loc: 0.03598  validation_loss: 1.981  time: 1.5174  data_time: 0.0230  lr: 3.9108e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:46:59 d2.utils.events]: \u001b[0m eta: 1:50:17  iter: 5719  total_loss: 2.328  loss_cls_stage0: 0.3175  loss_box_reg_stage0: 0.2443  loss_cls_stage1: 0.268  loss_box_reg_stage1: 0.3289  loss_cls_stage2: 0.1956  loss_box_reg_stage2: 0.2958  loss_mask: 0.5849  loss_rpn_cls: 0.06752  loss_rpn_loc: 0.03606  validation_loss: 1.981  time: 1.5175  data_time: 0.0229  lr: 3.8802e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:47:30 d2.utils.events]: \u001b[0m eta: 1:49:47  iter: 5739  total_loss: 2.309  loss_cls_stage0: 0.3137  loss_box_reg_stage0: 0.2406  loss_cls_stage1: 0.2601  loss_box_reg_stage1: 0.3216  loss_cls_stage2: 0.1928  loss_box_reg_stage2: 0.2806  loss_mask: 0.5633  loss_rpn_cls: 0.05281  loss_rpn_loc: 0.03447  validation_loss: 1.981  time: 1.5176  data_time: 0.0239  lr: 3.8496e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:48:02 d2.utils.events]: \u001b[0m eta: 1:49:16  iter: 5759  total_loss: 2.29  loss_cls_stage0: 0.3157  loss_box_reg_stage0: 0.2483  loss_cls_stage1: 0.2575  loss_box_reg_stage1: 0.3347  loss_cls_stage2: 0.1872  loss_box_reg_stage2: 0.279  loss_mask: 0.5275  loss_rpn_cls: 0.07498  loss_rpn_loc: 0.03765  validation_loss: 1.981  time: 1.5178  data_time: 0.0245  lr: 3.819e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:48:33 d2.utils.events]: \u001b[0m eta: 1:48:47  iter: 5779  total_loss: 2.193  loss_cls_stage0: 0.3173  loss_box_reg_stage0: 0.2395  loss_cls_stage1: 0.2584  loss_box_reg_stage1: 0.3213  loss_cls_stage2: 0.1776  loss_box_reg_stage2: 0.2583  loss_mask: 0.5281  loss_rpn_cls: 0.0621  loss_rpn_loc: 0.03314  validation_loss: 1.981  time: 1.5179  data_time: 0.0235  lr: 3.7885e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:49:04 d2.utils.events]: \u001b[0m eta: 1:48:17  iter: 5799  total_loss: 2.371  loss_cls_stage0: 0.3441  loss_box_reg_stage0: 0.2541  loss_cls_stage1: 0.2706  loss_box_reg_stage1: 0.3471  loss_cls_stage2: 0.2007  loss_box_reg_stage2: 0.2688  loss_mask: 0.5726  loss_rpn_cls: 0.08129  loss_rpn_loc: 0.04086  validation_loss: 1.981  time: 1.5181  data_time: 0.0239  lr: 3.7581e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:49:35 d2.utils.events]: \u001b[0m eta: 1:47:47  iter: 5819  total_loss: 2.349  loss_cls_stage0: 0.3078  loss_box_reg_stage0: 0.2395  loss_cls_stage1: 0.2633  loss_box_reg_stage1: 0.3417  loss_cls_stage2: 0.1967  loss_box_reg_stage2: 0.2973  loss_mask: 0.5403  loss_rpn_cls: 0.06578  loss_rpn_loc: 0.03691  validation_loss: 1.981  time: 1.5182  data_time: 0.0248  lr: 3.7277e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:50:06 d2.utils.events]: \u001b[0m eta: 1:47:18  iter: 5839  total_loss: 2.318  loss_cls_stage0: 0.3367  loss_box_reg_stage0: 0.2471  loss_cls_stage1: 0.2754  loss_box_reg_stage1: 0.3416  loss_cls_stage2: 0.1929  loss_box_reg_stage2: 0.2703  loss_mask: 0.5134  loss_rpn_cls: 0.06879  loss_rpn_loc: 0.03569  validation_loss: 1.981  time: 1.5184  data_time: 0.0236  lr: 3.6973e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:50:38 d2.utils.events]: \u001b[0m eta: 1:46:50  iter: 5859  total_loss: 2.388  loss_cls_stage0: 0.3345  loss_box_reg_stage0: 0.243  loss_cls_stage1: 0.2843  loss_box_reg_stage1: 0.3658  loss_cls_stage2: 0.187  loss_box_reg_stage2: 0.2688  loss_mask: 0.5497  loss_rpn_cls: 0.06296  loss_rpn_loc: 0.03676  validation_loss: 1.981  time: 1.5185  data_time: 0.0244  lr: 3.667e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:51:09 d2.utils.events]: \u001b[0m eta: 1:46:20  iter: 5879  total_loss: 2.332  loss_cls_stage0: 0.3338  loss_box_reg_stage0: 0.2609  loss_cls_stage1: 0.2888  loss_box_reg_stage1: 0.35  loss_cls_stage2: 0.1979  loss_box_reg_stage2: 0.2848  loss_mask: 0.5056  loss_rpn_cls: 0.05985  loss_rpn_loc: 0.03608  validation_loss: 1.981  time: 1.5186  data_time: 0.0226  lr: 3.6368e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:51:40 d2.utils.events]: \u001b[0m eta: 1:45:50  iter: 5899  total_loss: 2.367  loss_cls_stage0: 0.3371  loss_box_reg_stage0: 0.2543  loss_cls_stage1: 0.289  loss_box_reg_stage1: 0.3549  loss_cls_stage2: 0.2006  loss_box_reg_stage2: 0.2815  loss_mask: 0.5248  loss_rpn_cls: 0.06724  loss_rpn_loc: 0.04058  validation_loss: 1.981  time: 1.5188  data_time: 0.0230  lr: 3.6066e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:52:11 d2.utils.events]: \u001b[0m eta: 1:45:20  iter: 5919  total_loss: 2.338  loss_cls_stage0: 0.3211  loss_box_reg_stage0: 0.2435  loss_cls_stage1: 0.2692  loss_box_reg_stage1: 0.3503  loss_cls_stage2: 0.2052  loss_box_reg_stage2: 0.2847  loss_mask: 0.5434  loss_rpn_cls: 0.06122  loss_rpn_loc: 0.03734  validation_loss: 1.981  time: 1.5190  data_time: 0.0252  lr: 3.5764e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:52:43 d2.utils.events]: \u001b[0m eta: 1:44:49  iter: 5939  total_loss: 2.391  loss_cls_stage0: 0.3377  loss_box_reg_stage0: 0.2719  loss_cls_stage1: 0.2818  loss_box_reg_stage1: 0.3718  loss_cls_stage2: 0.2055  loss_box_reg_stage2: 0.2841  loss_mask: 0.5637  loss_rpn_cls: 0.05851  loss_rpn_loc: 0.03617  validation_loss: 1.981  time: 1.5191  data_time: 0.0319  lr: 3.5463e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:53:13 d2.utils.events]: \u001b[0m eta: 1:44:19  iter: 5959  total_loss: 2.169  loss_cls_stage0: 0.3047  loss_box_reg_stage0: 0.2397  loss_cls_stage1: 0.2399  loss_box_reg_stage1: 0.3383  loss_cls_stage2: 0.1715  loss_box_reg_stage2: 0.2555  loss_mask: 0.5558  loss_rpn_cls: 0.05949  loss_rpn_loc: 0.03464  validation_loss: 1.981  time: 1.5192  data_time: 0.0237  lr: 3.5163e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:53:45 d2.utils.events]: \u001b[0m eta: 1:43:48  iter: 5979  total_loss: 2.429  loss_cls_stage0: 0.3394  loss_box_reg_stage0: 0.2413  loss_cls_stage1: 0.2786  loss_box_reg_stage1: 0.3509  loss_cls_stage2: 0.1968  loss_box_reg_stage2: 0.288  loss_mask: 0.5288  loss_rpn_cls: 0.07234  loss_rpn_loc: 0.03731  validation_loss: 1.981  time: 1.5193  data_time: 0.0231  lr: 3.4863e-05  max_mem: 12121M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/27 04:54:18 d2.data.common]: \u001b[0mSerializing 857 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/27 04:54:18 d2.data.common]: \u001b[0mSerialized dataset takes 0.89 MiB\n",
      "\u001b[32m[03/27 04:54:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 857 images\n",
      "\u001b[32m[03/27 04:54:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/857. 0.0809 s / img. ETA=0:01:42\n",
      "\u001b[32m[03/27 04:54:25 d2.evaluation.evaluator]: \u001b[0mInference done 55/857. 0.0806 s / img. ETA=0:01:31\n",
      "\u001b[32m[03/27 04:54:30 d2.evaluation.evaluator]: \u001b[0mInference done 99/857. 0.0807 s / img. ETA=0:01:27\n",
      "\u001b[32m[03/27 04:54:35 d2.evaluation.evaluator]: \u001b[0mInference done 145/857. 0.0805 s / img. ETA=0:01:20\n",
      "\u001b[32m[03/27 04:54:40 d2.evaluation.evaluator]: \u001b[0mInference done 190/857. 0.0805 s / img. ETA=0:01:15\n",
      "\u001b[32m[03/27 04:54:45 d2.evaluation.evaluator]: \u001b[0mInference done 235/857. 0.0805 s / img. ETA=0:01:10\n",
      "\u001b[32m[03/27 04:54:50 d2.evaluation.evaluator]: \u001b[0mInference done 282/857. 0.0804 s / img. ETA=0:01:04\n",
      "\u001b[32m[03/27 04:54:55 d2.evaluation.evaluator]: \u001b[0mInference done 328/857. 0.0804 s / img. ETA=0:00:59\n",
      "\u001b[32m[03/27 04:55:00 d2.evaluation.evaluator]: \u001b[0mInference done 374/857. 0.0804 s / img. ETA=0:00:53\n",
      "\u001b[32m[03/27 04:55:05 d2.evaluation.evaluator]: \u001b[0mInference done 420/857. 0.0804 s / img. ETA=0:00:48\n",
      "\u001b[32m[03/27 04:55:10 d2.evaluation.evaluator]: \u001b[0mInference done 466/857. 0.0804 s / img. ETA=0:00:43\n",
      "\u001b[32m[03/27 04:55:15 d2.evaluation.evaluator]: \u001b[0mInference done 514/857. 0.0804 s / img. ETA=0:00:37\n",
      "\u001b[32m[03/27 04:55:20 d2.evaluation.evaluator]: \u001b[0mInference done 558/857. 0.0806 s / img. ETA=0:00:33\n",
      "\u001b[32m[03/27 04:55:25 d2.evaluation.evaluator]: \u001b[0mInference done 602/857. 0.0806 s / img. ETA=0:00:28\n",
      "\u001b[32m[03/27 04:55:30 d2.evaluation.evaluator]: \u001b[0mInference done 647/857. 0.0806 s / img. ETA=0:00:23\n",
      "\u001b[32m[03/27 04:55:36 d2.evaluation.evaluator]: \u001b[0mInference done 692/857. 0.0806 s / img. ETA=0:00:18\n",
      "\u001b[32m[03/27 04:55:41 d2.evaluation.evaluator]: \u001b[0mInference done 739/857. 0.0806 s / img. ETA=0:00:13\n",
      "\u001b[32m[03/27 04:55:46 d2.evaluation.evaluator]: \u001b[0mInference done 784/857. 0.0805 s / img. ETA=0:00:08\n",
      "\u001b[32m[03/27 04:55:51 d2.evaluation.evaluator]: \u001b[0mInference done 832/857. 0.0805 s / img. ETA=0:00:02\n",
      "\u001b[32m[03/27 04:55:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:34.425133 (0.110828 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/27 04:55:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:08 (0.080475 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.082\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.136\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.149\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.034\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.087\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.117\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.149\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.149\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.011\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.045\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.163\n",
      "\u001b[32m[03/27 04:55:54 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold4 in csv format:\n",
      "\u001b[32m[03/27 04:55:54 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/27 04:55:54 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/27 04:55:54 d2.evaluation.testing]: \u001b[0mcopypaste: 8.2043,13.6108,14.9385,0.7909,3.3909,8.6725\n",
      "validation do loss eval 2.3420348770981936\n",
      "\u001b[32m[03/27 04:57:23 d2.utils.events]: \u001b[0m eta: 1:43:18  iter: 5999  total_loss: 2.408  loss_cls_stage0: 0.3409  loss_box_reg_stage0: 0.2656  loss_cls_stage1: 0.2752  loss_box_reg_stage1: 0.3638  loss_cls_stage2: 0.1903  loss_box_reg_stage2: 0.3075  loss_mask: 0.5075  loss_rpn_cls: 0.06711  loss_rpn_loc: 0.03646  validation_loss: 2.042  time: 1.5195  data_time: 0.0248  lr: 3.4564e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:57:54 d2.utils.events]: \u001b[0m eta: 1:42:48  iter: 6019  total_loss: 2.309  loss_cls_stage0: 0.3529  loss_box_reg_stage0: 0.2633  loss_cls_stage1: 0.282  loss_box_reg_stage1: 0.3409  loss_cls_stage2: 0.198  loss_box_reg_stage2: 0.271  loss_mask: 0.6155  loss_rpn_cls: 0.0714  loss_rpn_loc: 0.03979  validation_loss: 2.042  time: 1.5195  data_time: 0.0254  lr: 3.4266e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:58:25 d2.utils.events]: \u001b[0m eta: 1:42:18  iter: 6039  total_loss: 2.239  loss_cls_stage0: 0.3091  loss_box_reg_stage0: 0.2468  loss_cls_stage1: 0.2584  loss_box_reg_stage1: 0.3171  loss_cls_stage2: 0.1852  loss_box_reg_stage2: 0.2578  loss_mask: 0.5508  loss_rpn_cls: 0.06307  loss_rpn_loc: 0.03768  validation_loss: 2.042  time: 1.5197  data_time: 0.0244  lr: 3.3968e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:58:56 d2.utils.events]: \u001b[0m eta: 1:41:47  iter: 6059  total_loss: 2.293  loss_cls_stage0: 0.3146  loss_box_reg_stage0: 0.2358  loss_cls_stage1: 0.2559  loss_box_reg_stage1: 0.3358  loss_cls_stage2: 0.1747  loss_box_reg_stage2: 0.2687  loss_mask: 0.5409  loss_rpn_cls: 0.07152  loss_rpn_loc: 0.03833  validation_loss: 2.042  time: 1.5198  data_time: 0.0236  lr: 3.367e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:59:28 d2.utils.events]: \u001b[0m eta: 1:41:17  iter: 6079  total_loss: 2.461  loss_cls_stage0: 0.3456  loss_box_reg_stage0: 0.2619  loss_cls_stage1: 0.2952  loss_box_reg_stage1: 0.3639  loss_cls_stage2: 0.1979  loss_box_reg_stage2: 0.2709  loss_mask: 0.5241  loss_rpn_cls: 0.06638  loss_rpn_loc: 0.03589  validation_loss: 2.042  time: 1.5200  data_time: 0.0235  lr: 3.3374e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 04:59:59 d2.utils.events]: \u001b[0m eta: 1:40:46  iter: 6099  total_loss: 2.219  loss_cls_stage0: 0.2783  loss_box_reg_stage0: 0.2324  loss_cls_stage1: 0.2349  loss_box_reg_stage1: 0.339  loss_cls_stage2: 0.1701  loss_box_reg_stage2: 0.2876  loss_mask: 0.5399  loss_rpn_cls: 0.05935  loss_rpn_loc: 0.0309  validation_loss: 2.042  time: 1.5201  data_time: 0.0244  lr: 3.3078e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:00:30 d2.utils.events]: \u001b[0m eta: 1:40:18  iter: 6119  total_loss: 2.418  loss_cls_stage0: 0.3423  loss_box_reg_stage0: 0.2701  loss_cls_stage1: 0.2675  loss_box_reg_stage1: 0.3672  loss_cls_stage2: 0.1978  loss_box_reg_stage2: 0.278  loss_mask: 0.5447  loss_rpn_cls: 0.06749  loss_rpn_loc: 0.03602  validation_loss: 2.042  time: 1.5202  data_time: 0.0254  lr: 3.2783e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:01:01 d2.utils.events]: \u001b[0m eta: 1:39:48  iter: 6139  total_loss: 2.245  loss_cls_stage0: 0.3199  loss_box_reg_stage0: 0.247  loss_cls_stage1: 0.2565  loss_box_reg_stage1: 0.3298  loss_cls_stage2: 0.171  loss_box_reg_stage2: 0.2506  loss_mask: 0.5142  loss_rpn_cls: 0.06114  loss_rpn_loc: 0.03849  validation_loss: 2.042  time: 1.5203  data_time: 0.0239  lr: 3.2488e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:01:32 d2.utils.events]: \u001b[0m eta: 1:39:17  iter: 6159  total_loss: 2.261  loss_cls_stage0: 0.3177  loss_box_reg_stage0: 0.2446  loss_cls_stage1: 0.2716  loss_box_reg_stage1: 0.3449  loss_cls_stage2: 0.1839  loss_box_reg_stage2: 0.2845  loss_mask: 0.4975  loss_rpn_cls: 0.06862  loss_rpn_loc: 0.03448  validation_loss: 2.042  time: 1.5204  data_time: 0.0241  lr: 3.2194e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:02:03 d2.utils.events]: \u001b[0m eta: 1:38:47  iter: 6179  total_loss: 2.319  loss_cls_stage0: 0.3378  loss_box_reg_stage0: 0.2502  loss_cls_stage1: 0.2707  loss_box_reg_stage1: 0.3343  loss_cls_stage2: 0.202  loss_box_reg_stage2: 0.2669  loss_mask: 0.5532  loss_rpn_cls: 0.06534  loss_rpn_loc: 0.03363  validation_loss: 2.042  time: 1.5206  data_time: 0.0247  lr: 3.1901e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:02:35 d2.utils.events]: \u001b[0m eta: 1:38:16  iter: 6199  total_loss: 2.292  loss_cls_stage0: 0.3162  loss_box_reg_stage0: 0.2514  loss_cls_stage1: 0.257  loss_box_reg_stage1: 0.359  loss_cls_stage2: 0.1899  loss_box_reg_stage2: 0.3011  loss_mask: 0.5764  loss_rpn_cls: 0.06813  loss_rpn_loc: 0.03505  validation_loss: 2.042  time: 1.5207  data_time: 0.0240  lr: 3.1608e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:03:06 d2.utils.events]: \u001b[0m eta: 1:37:45  iter: 6219  total_loss: 2.171  loss_cls_stage0: 0.3022  loss_box_reg_stage0: 0.2442  loss_cls_stage1: 0.2467  loss_box_reg_stage1: 0.3211  loss_cls_stage2: 0.1787  loss_box_reg_stage2: 0.2855  loss_mask: 0.5318  loss_rpn_cls: 0.06231  loss_rpn_loc: 0.03374  validation_loss: 2.042  time: 1.5208  data_time: 0.0239  lr: 3.1317e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:03:37 d2.utils.events]: \u001b[0m eta: 1:37:14  iter: 6239  total_loss: 2.305  loss_cls_stage0: 0.3109  loss_box_reg_stage0: 0.2379  loss_cls_stage1: 0.2651  loss_box_reg_stage1: 0.3394  loss_cls_stage2: 0.1826  loss_box_reg_stage2: 0.2974  loss_mask: 0.5536  loss_rpn_cls: 0.05331  loss_rpn_loc: 0.03526  validation_loss: 2.042  time: 1.5209  data_time: 0.0237  lr: 3.1026e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:04:08 d2.utils.events]: \u001b[0m eta: 1:36:43  iter: 6259  total_loss: 2.392  loss_cls_stage0: 0.3382  loss_box_reg_stage0: 0.2606  loss_cls_stage1: 0.287  loss_box_reg_stage1: 0.371  loss_cls_stage2: 0.2071  loss_box_reg_stage2: 0.2716  loss_mask: 0.5678  loss_rpn_cls: 0.0753  loss_rpn_loc: 0.0403  validation_loss: 2.042  time: 1.5210  data_time: 0.0231  lr: 3.0735e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:04:40 d2.utils.events]: \u001b[0m eta: 1:36:13  iter: 6279  total_loss: 2.542  loss_cls_stage0: 0.3903  loss_box_reg_stage0: 0.2954  loss_cls_stage1: 0.2979  loss_box_reg_stage1: 0.3886  loss_cls_stage2: 0.2093  loss_box_reg_stage2: 0.3125  loss_mask: 0.5266  loss_rpn_cls: 0.06364  loss_rpn_loc: 0.04117  validation_loss: 2.042  time: 1.5212  data_time: 0.0242  lr: 3.0446e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:05:11 d2.utils.events]: \u001b[0m eta: 1:35:42  iter: 6299  total_loss: 2.29  loss_cls_stage0: 0.2915  loss_box_reg_stage0: 0.2302  loss_cls_stage1: 0.2493  loss_box_reg_stage1: 0.3455  loss_cls_stage2: 0.1795  loss_box_reg_stage2: 0.2744  loss_mask: 0.5575  loss_rpn_cls: 0.06042  loss_rpn_loc: 0.03639  validation_loss: 2.042  time: 1.5213  data_time: 0.0229  lr: 3.0157e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:05:42 d2.utils.events]: \u001b[0m eta: 1:35:12  iter: 6319  total_loss: 2.411  loss_cls_stage0: 0.3412  loss_box_reg_stage0: 0.2686  loss_cls_stage1: 0.2657  loss_box_reg_stage1: 0.3539  loss_cls_stage2: 0.1902  loss_box_reg_stage2: 0.295  loss_mask: 0.5729  loss_rpn_cls: 0.06893  loss_rpn_loc: 0.03905  validation_loss: 2.042  time: 1.5215  data_time: 0.0236  lr: 2.9869e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:06:14 d2.utils.events]: \u001b[0m eta: 1:34:41  iter: 6339  total_loss: 2.348  loss_cls_stage0: 0.3475  loss_box_reg_stage0: 0.2641  loss_cls_stage1: 0.2767  loss_box_reg_stage1: 0.3596  loss_cls_stage2: 0.1912  loss_box_reg_stage2: 0.2852  loss_mask: 0.5423  loss_rpn_cls: 0.07047  loss_rpn_loc: 0.03169  validation_loss: 2.042  time: 1.5216  data_time: 0.0240  lr: 2.9582e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:06:45 d2.utils.events]: \u001b[0m eta: 1:34:11  iter: 6359  total_loss: 2.457  loss_cls_stage0: 0.3422  loss_box_reg_stage0: 0.2724  loss_cls_stage1: 0.2793  loss_box_reg_stage1: 0.3486  loss_cls_stage2: 0.1925  loss_box_reg_stage2: 0.2859  loss_mask: 0.5827  loss_rpn_cls: 0.05786  loss_rpn_loc: 0.03502  validation_loss: 2.042  time: 1.5218  data_time: 0.0236  lr: 2.9296e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:07:16 d2.utils.events]: \u001b[0m eta: 1:33:43  iter: 6379  total_loss: 2.507  loss_cls_stage0: 0.3423  loss_box_reg_stage0: 0.2515  loss_cls_stage1: 0.2916  loss_box_reg_stage1: 0.3666  loss_cls_stage2: 0.2101  loss_box_reg_stage2: 0.306  loss_mask: 0.5507  loss_rpn_cls: 0.06017  loss_rpn_loc: 0.03607  validation_loss: 2.042  time: 1.5219  data_time: 0.0230  lr: 2.901e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:07:48 d2.utils.events]: \u001b[0m eta: 1:33:14  iter: 6399  total_loss: 2.464  loss_cls_stage0: 0.3513  loss_box_reg_stage0: 0.2723  loss_cls_stage1: 0.297  loss_box_reg_stage1: 0.3781  loss_cls_stage2: 0.2065  loss_box_reg_stage2: 0.2982  loss_mask: 0.5093  loss_rpn_cls: 0.06227  loss_rpn_loc: 0.03933  validation_loss: 2.042  time: 1.5220  data_time: 0.0234  lr: 2.8725e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:08:19 d2.utils.events]: \u001b[0m eta: 1:32:44  iter: 6419  total_loss: 2.3  loss_cls_stage0: 0.3133  loss_box_reg_stage0: 0.2408  loss_cls_stage1: 0.2582  loss_box_reg_stage1: 0.3495  loss_cls_stage2: 0.1938  loss_box_reg_stage2: 0.2818  loss_mask: 0.5112  loss_rpn_cls: 0.06721  loss_rpn_loc: 0.03857  validation_loss: 2.042  time: 1.5222  data_time: 0.0239  lr: 2.8441e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:08:50 d2.utils.events]: \u001b[0m eta: 1:32:13  iter: 6439  total_loss: 2.218  loss_cls_stage0: 0.3147  loss_box_reg_stage0: 0.2315  loss_cls_stage1: 0.2546  loss_box_reg_stage1: 0.3202  loss_cls_stage2: 0.1841  loss_box_reg_stage2: 0.2749  loss_mask: 0.5603  loss_rpn_cls: 0.06059  loss_rpn_loc: 0.03641  validation_loss: 2.042  time: 1.5223  data_time: 0.0246  lr: 2.8158e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:09:21 d2.utils.events]: \u001b[0m eta: 1:31:44  iter: 6459  total_loss: 2.439  loss_cls_stage0: 0.342  loss_box_reg_stage0: 0.2659  loss_cls_stage1: 0.2888  loss_box_reg_stage1: 0.3755  loss_cls_stage2: 0.204  loss_box_reg_stage2: 0.3  loss_mask: 0.5475  loss_rpn_cls: 0.06493  loss_rpn_loc: 0.03331  validation_loss: 2.042  time: 1.5224  data_time: 0.0236  lr: 2.7876e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:09:53 d2.utils.events]: \u001b[0m eta: 1:31:15  iter: 6479  total_loss: 2.414  loss_cls_stage0: 0.3285  loss_box_reg_stage0: 0.2636  loss_cls_stage1: 0.2876  loss_box_reg_stage1: 0.3707  loss_cls_stage2: 0.1891  loss_box_reg_stage2: 0.2977  loss_mask: 0.5188  loss_rpn_cls: 0.07584  loss_rpn_loc: 0.03673  validation_loss: 2.042  time: 1.5225  data_time: 0.0226  lr: 2.7595e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:10:24 d2.utils.events]: \u001b[0m eta: 1:30:44  iter: 6499  total_loss: 2.208  loss_cls_stage0: 0.2952  loss_box_reg_stage0: 0.2495  loss_cls_stage1: 0.2369  loss_box_reg_stage1: 0.3513  loss_cls_stage2: 0.1668  loss_box_reg_stage2: 0.2781  loss_mask: 0.4918  loss_rpn_cls: 0.06934  loss_rpn_loc: 0.03596  validation_loss: 2.042  time: 1.5227  data_time: 0.0237  lr: 2.7314e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:10:55 d2.utils.events]: \u001b[0m eta: 1:30:14  iter: 6519  total_loss: 2.395  loss_cls_stage0: 0.3102  loss_box_reg_stage0: 0.2645  loss_cls_stage1: 0.2596  loss_box_reg_stage1: 0.3687  loss_cls_stage2: 0.1837  loss_box_reg_stage2: 0.2824  loss_mask: 0.6022  loss_rpn_cls: 0.0704  loss_rpn_loc: 0.0376  validation_loss: 2.042  time: 1.5228  data_time: 0.0236  lr: 2.7035e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:11:26 d2.utils.events]: \u001b[0m eta: 1:29:43  iter: 6539  total_loss: 2.306  loss_cls_stage0: 0.3323  loss_box_reg_stage0: 0.2497  loss_cls_stage1: 0.2784  loss_box_reg_stage1: 0.3441  loss_cls_stage2: 0.191  loss_box_reg_stage2: 0.2901  loss_mask: 0.5658  loss_rpn_cls: 0.06799  loss_rpn_loc: 0.03531  validation_loss: 2.042  time: 1.5229  data_time: 0.0237  lr: 2.6756e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:11:57 d2.utils.events]: \u001b[0m eta: 1:29:12  iter: 6559  total_loss: 2.33  loss_cls_stage0: 0.314  loss_box_reg_stage0: 0.2492  loss_cls_stage1: 0.2618  loss_box_reg_stage1: 0.3253  loss_cls_stage2: 0.1918  loss_box_reg_stage2: 0.2703  loss_mask: 0.5507  loss_rpn_cls: 0.05994  loss_rpn_loc: 0.03228  validation_loss: 2.042  time: 1.5230  data_time: 0.0233  lr: 2.6479e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:12:29 d2.utils.events]: \u001b[0m eta: 1:28:41  iter: 6579  total_loss: 2.299  loss_cls_stage0: 0.3152  loss_box_reg_stage0: 0.2437  loss_cls_stage1: 0.264  loss_box_reg_stage1: 0.3577  loss_cls_stage2: 0.1804  loss_box_reg_stage2: 0.2913  loss_mask: 0.505  loss_rpn_cls: 0.06741  loss_rpn_loc: 0.03315  validation_loss: 2.042  time: 1.5231  data_time: 0.0231  lr: 2.6202e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:13:00 d2.utils.events]: \u001b[0m eta: 1:28:10  iter: 6599  total_loss: 2.25  loss_cls_stage0: 0.31  loss_box_reg_stage0: 0.246  loss_cls_stage1: 0.2504  loss_box_reg_stage1: 0.3522  loss_cls_stage2: 0.1859  loss_box_reg_stage2: 0.3157  loss_mask: 0.5226  loss_rpn_cls: 0.0557  loss_rpn_loc: 0.03118  validation_loss: 2.042  time: 1.5232  data_time: 0.0258  lr: 2.5926e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:13:31 d2.utils.events]: \u001b[0m eta: 1:27:39  iter: 6619  total_loss: 2.617  loss_cls_stage0: 0.3611  loss_box_reg_stage0: 0.2847  loss_cls_stage1: 0.3116  loss_box_reg_stage1: 0.3928  loss_cls_stage2: 0.2281  loss_box_reg_stage2: 0.2894  loss_mask: 0.5528  loss_rpn_cls: 0.06022  loss_rpn_loc: 0.03817  validation_loss: 2.042  time: 1.5233  data_time: 0.0236  lr: 2.5651e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:14:02 d2.utils.events]: \u001b[0m eta: 1:27:07  iter: 6639  total_loss: 2.211  loss_cls_stage0: 0.3143  loss_box_reg_stage0: 0.2342  loss_cls_stage1: 0.2625  loss_box_reg_stage1: 0.3099  loss_cls_stage2: 0.1907  loss_box_reg_stage2: 0.2808  loss_mask: 0.577  loss_rpn_cls: 0.06234  loss_rpn_loc: 0.03321  validation_loss: 2.042  time: 1.5234  data_time: 0.0237  lr: 2.5377e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:14:34 d2.utils.events]: \u001b[0m eta: 1:26:36  iter: 6659  total_loss: 2.396  loss_cls_stage0: 0.3302  loss_box_reg_stage0: 0.2669  loss_cls_stage1: 0.2756  loss_box_reg_stage1: 0.3541  loss_cls_stage2: 0.2048  loss_box_reg_stage2: 0.302  loss_mask: 0.5156  loss_rpn_cls: 0.07242  loss_rpn_loc: 0.03732  validation_loss: 2.042  time: 1.5235  data_time: 0.0241  lr: 2.5104e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:15:05 d2.utils.events]: \u001b[0m eta: 1:26:06  iter: 6679  total_loss: 2.358  loss_cls_stage0: 0.3107  loss_box_reg_stage0: 0.2462  loss_cls_stage1: 0.2645  loss_box_reg_stage1: 0.3722  loss_cls_stage2: 0.1952  loss_box_reg_stage2: 0.316  loss_mask: 0.5272  loss_rpn_cls: 0.05907  loss_rpn_loc: 0.03265  validation_loss: 2.042  time: 1.5236  data_time: 0.0253  lr: 2.4832e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:15:36 d2.utils.events]: \u001b[0m eta: 1:25:36  iter: 6699  total_loss: 2.398  loss_cls_stage0: 0.3497  loss_box_reg_stage0: 0.2391  loss_cls_stage1: 0.2925  loss_box_reg_stage1: 0.3575  loss_cls_stage2: 0.2149  loss_box_reg_stage2: 0.2872  loss_mask: 0.5597  loss_rpn_cls: 0.06239  loss_rpn_loc: 0.03874  validation_loss: 2.042  time: 1.5238  data_time: 0.0244  lr: 2.4561e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:16:07 d2.utils.events]: \u001b[0m eta: 1:25:05  iter: 6719  total_loss: 2.18  loss_cls_stage0: 0.3027  loss_box_reg_stage0: 0.2371  loss_cls_stage1: 0.2565  loss_box_reg_stage1: 0.3377  loss_cls_stage2: 0.1883  loss_box_reg_stage2: 0.3011  loss_mask: 0.5456  loss_rpn_cls: 0.06289  loss_rpn_loc: 0.0352  validation_loss: 2.042  time: 1.5239  data_time: 0.0235  lr: 2.4291e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:16:39 d2.utils.events]: \u001b[0m eta: 1:24:34  iter: 6739  total_loss: 2.31  loss_cls_stage0: 0.3236  loss_box_reg_stage0: 0.252  loss_cls_stage1: 0.2722  loss_box_reg_stage1: 0.3244  loss_cls_stage2: 0.1943  loss_box_reg_stage2: 0.2717  loss_mask: 0.562  loss_rpn_cls: 0.05585  loss_rpn_loc: 0.03326  validation_loss: 2.042  time: 1.5240  data_time: 0.0241  lr: 2.4023e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:17:10 d2.utils.events]: \u001b[0m eta: 1:24:03  iter: 6759  total_loss: 2.536  loss_cls_stage0: 0.3466  loss_box_reg_stage0: 0.268  loss_cls_stage1: 0.2862  loss_box_reg_stage1: 0.3678  loss_cls_stage2: 0.2071  loss_box_reg_stage2: 0.3066  loss_mask: 0.5754  loss_rpn_cls: 0.06921  loss_rpn_loc: 0.04573  validation_loss: 2.042  time: 1.5241  data_time: 0.0241  lr: 2.3755e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:17:41 d2.utils.events]: \u001b[0m eta: 1:23:33  iter: 6779  total_loss: 2.541  loss_cls_stage0: 0.3477  loss_box_reg_stage0: 0.2822  loss_cls_stage1: 0.3009  loss_box_reg_stage1: 0.3738  loss_cls_stage2: 0.2145  loss_box_reg_stage2: 0.2943  loss_mask: 0.5349  loss_rpn_cls: 0.06256  loss_rpn_loc: 0.03933  validation_loss: 2.042  time: 1.5243  data_time: 0.0241  lr: 2.3488e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:18:13 d2.utils.events]: \u001b[0m eta: 1:23:02  iter: 6799  total_loss: 2.302  loss_cls_stage0: 0.3286  loss_box_reg_stage0: 0.2588  loss_cls_stage1: 0.2628  loss_box_reg_stage1: 0.3663  loss_cls_stage2: 0.1856  loss_box_reg_stage2: 0.2783  loss_mask: 0.5155  loss_rpn_cls: 0.05321  loss_rpn_loc: 0.03348  validation_loss: 2.042  time: 1.5244  data_time: 0.0243  lr: 2.3222e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:18:44 d2.utils.events]: \u001b[0m eta: 1:22:32  iter: 6819  total_loss: 2.386  loss_cls_stage0: 0.3411  loss_box_reg_stage0: 0.2484  loss_cls_stage1: 0.2839  loss_box_reg_stage1: 0.3557  loss_cls_stage2: 0.1968  loss_box_reg_stage2: 0.2726  loss_mask: 0.5367  loss_rpn_cls: 0.06911  loss_rpn_loc: 0.03696  validation_loss: 2.042  time: 1.5245  data_time: 0.0236  lr: 2.2957e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:19:15 d2.utils.events]: \u001b[0m eta: 1:22:01  iter: 6839  total_loss: 2.493  loss_cls_stage0: 0.3442  loss_box_reg_stage0: 0.2624  loss_cls_stage1: 0.2931  loss_box_reg_stage1: 0.3773  loss_cls_stage2: 0.2136  loss_box_reg_stage2: 0.3005  loss_mask: 0.5336  loss_rpn_cls: 0.07023  loss_rpn_loc: 0.0354  validation_loss: 2.042  time: 1.5246  data_time: 0.0233  lr: 2.2693e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:19:46 d2.utils.events]: \u001b[0m eta: 1:21:30  iter: 6859  total_loss: 2.332  loss_cls_stage0: 0.2967  loss_box_reg_stage0: 0.2424  loss_cls_stage1: 0.2606  loss_box_reg_stage1: 0.3581  loss_cls_stage2: 0.1978  loss_box_reg_stage2: 0.2845  loss_mask: 0.5718  loss_rpn_cls: 0.06992  loss_rpn_loc: 0.03881  validation_loss: 2.042  time: 1.5247  data_time: 0.0224  lr: 2.2431e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:20:18 d2.utils.events]: \u001b[0m eta: 1:20:59  iter: 6879  total_loss: 2.406  loss_cls_stage0: 0.3289  loss_box_reg_stage0: 0.2512  loss_cls_stage1: 0.2777  loss_box_reg_stage1: 0.3703  loss_cls_stage2: 0.1969  loss_box_reg_stage2: 0.2873  loss_mask: 0.5842  loss_rpn_cls: 0.05434  loss_rpn_loc: 0.0366  validation_loss: 2.042  time: 1.5248  data_time: 0.0230  lr: 2.2169e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:20:49 d2.utils.events]: \u001b[0m eta: 1:20:29  iter: 6899  total_loss: 2.59  loss_cls_stage0: 0.3539  loss_box_reg_stage0: 0.2659  loss_cls_stage1: 0.3053  loss_box_reg_stage1: 0.3879  loss_cls_stage2: 0.2383  loss_box_reg_stage2: 0.3472  loss_mask: 0.581  loss_rpn_cls: 0.06214  loss_rpn_loc: 0.03667  validation_loss: 2.042  time: 1.5250  data_time: 0.0230  lr: 2.1909e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:21:21 d2.utils.events]: \u001b[0m eta: 1:19:58  iter: 6919  total_loss: 2.391  loss_cls_stage0: 0.3551  loss_box_reg_stage0: 0.2629  loss_cls_stage1: 0.2911  loss_box_reg_stage1: 0.357  loss_cls_stage2: 0.2055  loss_box_reg_stage2: 0.2944  loss_mask: 0.5429  loss_rpn_cls: 0.06028  loss_rpn_loc: 0.0375  validation_loss: 2.042  time: 1.5251  data_time: 0.0231  lr: 2.1649e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:21:52 d2.utils.events]: \u001b[0m eta: 1:19:27  iter: 6939  total_loss: 2.295  loss_cls_stage0: 0.3155  loss_box_reg_stage0: 0.259  loss_cls_stage1: 0.2613  loss_box_reg_stage1: 0.3425  loss_cls_stage2: 0.1957  loss_box_reg_stage2: 0.2884  loss_mask: 0.5546  loss_rpn_cls: 0.06539  loss_rpn_loc: 0.03793  validation_loss: 2.042  time: 1.5252  data_time: 0.0241  lr: 2.1391e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:22:23 d2.utils.events]: \u001b[0m eta: 1:18:56  iter: 6959  total_loss: 2.266  loss_cls_stage0: 0.3142  loss_box_reg_stage0: 0.2343  loss_cls_stage1: 0.252  loss_box_reg_stage1: 0.3291  loss_cls_stage2: 0.1731  loss_box_reg_stage2: 0.2722  loss_mask: 0.4959  loss_rpn_cls: 0.05423  loss_rpn_loc: 0.03022  validation_loss: 2.042  time: 1.5253  data_time: 0.0244  lr: 2.1134e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:22:55 d2.utils.events]: \u001b[0m eta: 1:18:26  iter: 6979  total_loss: 2.586  loss_cls_stage0: 0.3768  loss_box_reg_stage0: 0.2827  loss_cls_stage1: 0.2997  loss_box_reg_stage1: 0.3653  loss_cls_stage2: 0.213  loss_box_reg_stage2: 0.304  loss_mask: 0.5439  loss_rpn_cls: 0.07842  loss_rpn_loc: 0.04296  validation_loss: 2.042  time: 1.5255  data_time: 0.0240  lr: 2.0878e-05  max_mem: 12121M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/27 05:23:28 d2.data.common]: \u001b[0mSerializing 857 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/27 05:23:28 d2.data.common]: \u001b[0mSerialized dataset takes 0.89 MiB\n",
      "\u001b[32m[03/27 05:23:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 857 images\n",
      "\u001b[32m[03/27 05:23:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/857. 0.0806 s / img. ETA=0:01:39\n",
      "\u001b[32m[03/27 05:23:35 d2.evaluation.evaluator]: \u001b[0mInference done 57/857. 0.0804 s / img. ETA=0:01:29\n",
      "\u001b[32m[03/27 05:23:40 d2.evaluation.evaluator]: \u001b[0mInference done 102/857. 0.0805 s / img. ETA=0:01:24\n",
      "\u001b[32m[03/27 05:23:45 d2.evaluation.evaluator]: \u001b[0mInference done 149/857. 0.0804 s / img. ETA=0:01:18\n",
      "\u001b[32m[03/27 05:23:50 d2.evaluation.evaluator]: \u001b[0mInference done 195/857. 0.0804 s / img. ETA=0:01:13\n",
      "\u001b[32m[03/27 05:23:55 d2.evaluation.evaluator]: \u001b[0mInference done 242/857. 0.0804 s / img. ETA=0:01:07\n",
      "\u001b[32m[03/27 05:24:00 d2.evaluation.evaluator]: \u001b[0mInference done 290/857. 0.0803 s / img. ETA=0:01:01\n",
      "\u001b[32m[03/27 05:24:05 d2.evaluation.evaluator]: \u001b[0mInference done 337/857. 0.0803 s / img. ETA=0:00:56\n",
      "\u001b[32m[03/27 05:24:10 d2.evaluation.evaluator]: \u001b[0mInference done 385/857. 0.0802 s / img. ETA=0:00:51\n",
      "\u001b[32m[03/27 05:24:15 d2.evaluation.evaluator]: \u001b[0mInference done 432/857. 0.0802 s / img. ETA=0:00:46\n",
      "\u001b[32m[03/27 05:24:20 d2.evaluation.evaluator]: \u001b[0mInference done 480/857. 0.0802 s / img. ETA=0:00:40\n",
      "\u001b[32m[03/27 05:24:25 d2.evaluation.evaluator]: \u001b[0mInference done 529/857. 0.0802 s / img. ETA=0:00:35\n",
      "\u001b[32m[03/27 05:24:31 d2.evaluation.evaluator]: \u001b[0mInference done 576/857. 0.0802 s / img. ETA=0:00:30\n",
      "\u001b[32m[03/27 05:24:36 d2.evaluation.evaluator]: \u001b[0mInference done 622/857. 0.0802 s / img. ETA=0:00:25\n",
      "\u001b[32m[03/27 05:24:41 d2.evaluation.evaluator]: \u001b[0mInference done 669/857. 0.0802 s / img. ETA=0:00:20\n",
      "\u001b[32m[03/27 05:24:46 d2.evaluation.evaluator]: \u001b[0mInference done 716/857. 0.0802 s / img. ETA=0:00:15\n",
      "\u001b[32m[03/27 05:24:51 d2.evaluation.evaluator]: \u001b[0mInference done 763/857. 0.0802 s / img. ETA=0:00:10\n",
      "\u001b[32m[03/27 05:24:56 d2.evaluation.evaluator]: \u001b[0mInference done 810/857. 0.0802 s / img. ETA=0:00:05\n",
      "\u001b[32m[03/27 05:25:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:31.686960 (0.107614 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/27 05:25:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:08 (0.080205 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.44 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.085\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.141\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.155\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.035\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.091\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.120\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.156\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.156\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.048\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.173\n",
      "\u001b[32m[03/27 05:25:02 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold4 in csv format:\n",
      "\u001b[32m[03/27 05:25:02 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/27 05:25:02 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/27 05:25:02 d2.evaluation.testing]: \u001b[0mcopypaste: 8.5137,14.1389,15.5320,0.7734,3.5133,9.0533\n",
      "validation do loss eval 2.4065040842365897\n",
      "\u001b[32m[03/27 05:26:30 d2.utils.events]: \u001b[0m eta: 1:17:55  iter: 6999  total_loss: 2.235  loss_cls_stage0: 0.3075  loss_box_reg_stage0: 0.2805  loss_cls_stage1: 0.2401  loss_box_reg_stage1: 0.3609  loss_cls_stage2: 0.1678  loss_box_reg_stage2: 0.3082  loss_mask: 0.5063  loss_rpn_cls: 0.06005  loss_rpn_loc: 0.03362  validation_loss: 2.104  time: 1.5256  data_time: 0.0239  lr: 2.0623e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:27:01 d2.utils.events]: \u001b[0m eta: 1:17:25  iter: 7019  total_loss: 2.483  loss_cls_stage0: 0.3437  loss_box_reg_stage0: 0.2648  loss_cls_stage1: 0.293  loss_box_reg_stage1: 0.3708  loss_cls_stage2: 0.2076  loss_box_reg_stage2: 0.3075  loss_mask: 0.5141  loss_rpn_cls: 0.06119  loss_rpn_loc: 0.03848  validation_loss: 2.104  time: 1.5256  data_time: 0.0243  lr: 2.037e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:27:33 d2.utils.events]: \u001b[0m eta: 1:16:55  iter: 7039  total_loss: 2.414  loss_cls_stage0: 0.3356  loss_box_reg_stage0: 0.2769  loss_cls_stage1: 0.2738  loss_box_reg_stage1: 0.37  loss_cls_stage2: 0.2012  loss_box_reg_stage2: 0.276  loss_mask: 0.5324  loss_rpn_cls: 0.07026  loss_rpn_loc: 0.03704  validation_loss: 2.104  time: 1.5258  data_time: 0.0271  lr: 2.0117e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:28:04 d2.utils.events]: \u001b[0m eta: 1:16:24  iter: 7059  total_loss: 2.444  loss_cls_stage0: 0.3251  loss_box_reg_stage0: 0.2614  loss_cls_stage1: 0.28  loss_box_reg_stage1: 0.4016  loss_cls_stage2: 0.222  loss_box_reg_stage2: 0.3311  loss_mask: 0.5416  loss_rpn_cls: 0.06481  loss_rpn_loc: 0.03809  validation_loss: 2.104  time: 1.5259  data_time: 0.0257  lr: 1.9866e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:28:35 d2.utils.events]: \u001b[0m eta: 1:15:53  iter: 7079  total_loss: 2.364  loss_cls_stage0: 0.3196  loss_box_reg_stage0: 0.2485  loss_cls_stage1: 0.2777  loss_box_reg_stage1: 0.3478  loss_cls_stage2: 0.1914  loss_box_reg_stage2: 0.2807  loss_mask: 0.5321  loss_rpn_cls: 0.06809  loss_rpn_loc: 0.03987  validation_loss: 2.104  time: 1.5260  data_time: 0.0336  lr: 1.9616e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:29:07 d2.utils.events]: \u001b[0m eta: 1:15:22  iter: 7099  total_loss: 2.242  loss_cls_stage0: 0.2993  loss_box_reg_stage0: 0.2262  loss_cls_stage1: 0.2465  loss_box_reg_stage1: 0.3385  loss_cls_stage2: 0.1919  loss_box_reg_stage2: 0.2913  loss_mask: 0.5567  loss_rpn_cls: 0.05627  loss_rpn_loc: 0.03111  validation_loss: 2.104  time: 1.5261  data_time: 0.0242  lr: 1.9367e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:29:38 d2.utils.events]: \u001b[0m eta: 1:14:51  iter: 7119  total_loss: 2.405  loss_cls_stage0: 0.3474  loss_box_reg_stage0: 0.2789  loss_cls_stage1: 0.2853  loss_box_reg_stage1: 0.3823  loss_cls_stage2: 0.1974  loss_box_reg_stage2: 0.285  loss_mask: 0.5452  loss_rpn_cls: 0.06762  loss_rpn_loc: 0.04133  validation_loss: 2.104  time: 1.5262  data_time: 0.0245  lr: 1.9119e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:30:09 d2.utils.events]: \u001b[0m eta: 1:14:20  iter: 7139  total_loss: 2.409  loss_cls_stage0: 0.3353  loss_box_reg_stage0: 0.268  loss_cls_stage1: 0.2786  loss_box_reg_stage1: 0.3566  loss_cls_stage2: 0.1965  loss_box_reg_stage2: 0.2681  loss_mask: 0.5378  loss_rpn_cls: 0.0621  loss_rpn_loc: 0.03891  validation_loss: 2.104  time: 1.5263  data_time: 0.0236  lr: 1.8873e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:30:40 d2.utils.events]: \u001b[0m eta: 1:13:50  iter: 7159  total_loss: 2.259  loss_cls_stage0: 0.328  loss_box_reg_stage0: 0.2427  loss_cls_stage1: 0.2726  loss_box_reg_stage1: 0.355  loss_cls_stage2: 0.1963  loss_box_reg_stage2: 0.2958  loss_mask: 0.5047  loss_rpn_cls: 0.05756  loss_rpn_loc: 0.0344  validation_loss: 2.104  time: 1.5264  data_time: 0.0245  lr: 1.8628e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:31:12 d2.utils.events]: \u001b[0m eta: 1:13:19  iter: 7179  total_loss: 2.34  loss_cls_stage0: 0.3169  loss_box_reg_stage0: 0.267  loss_cls_stage1: 0.2677  loss_box_reg_stage1: 0.3605  loss_cls_stage2: 0.1765  loss_box_reg_stage2: 0.2914  loss_mask: 0.5683  loss_rpn_cls: 0.05725  loss_rpn_loc: 0.03756  validation_loss: 2.104  time: 1.5265  data_time: 0.0247  lr: 1.8384e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:31:43 d2.utils.events]: \u001b[0m eta: 1:12:47  iter: 7199  total_loss: 2.355  loss_cls_stage0: 0.3398  loss_box_reg_stage0: 0.2413  loss_cls_stage1: 0.2841  loss_box_reg_stage1: 0.3323  loss_cls_stage2: 0.2052  loss_box_reg_stage2: 0.2612  loss_mask: 0.5467  loss_rpn_cls: 0.07378  loss_rpn_loc: 0.03838  validation_loss: 2.104  time: 1.5266  data_time: 0.0251  lr: 1.8141e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:32:14 d2.utils.events]: \u001b[0m eta: 1:12:15  iter: 7219  total_loss: 2.177  loss_cls_stage0: 0.2864  loss_box_reg_stage0: 0.2406  loss_cls_stage1: 0.2355  loss_box_reg_stage1: 0.345  loss_cls_stage2: 0.1697  loss_box_reg_stage2: 0.2733  loss_mask: 0.4844  loss_rpn_cls: 0.06063  loss_rpn_loc: 0.03211  validation_loss: 2.104  time: 1.5267  data_time: 0.0243  lr: 1.7899e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:32:46 d2.utils.events]: \u001b[0m eta: 1:11:44  iter: 7239  total_loss: 2.34  loss_cls_stage0: 0.3532  loss_box_reg_stage0: 0.2704  loss_cls_stage1: 0.2914  loss_box_reg_stage1: 0.3599  loss_cls_stage2: 0.1936  loss_box_reg_stage2: 0.2896  loss_mask: 0.5534  loss_rpn_cls: 0.06926  loss_rpn_loc: 0.03944  validation_loss: 2.104  time: 1.5268  data_time: 0.0248  lr: 1.7659e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:33:17 d2.utils.events]: \u001b[0m eta: 1:11:13  iter: 7259  total_loss: 2.271  loss_cls_stage0: 0.3253  loss_box_reg_stage0: 0.244  loss_cls_stage1: 0.2737  loss_box_reg_stage1: 0.346  loss_cls_stage2: 0.1863  loss_box_reg_stage2: 0.2812  loss_mask: 0.5577  loss_rpn_cls: 0.06017  loss_rpn_loc: 0.03164  validation_loss: 2.104  time: 1.5269  data_time: 0.0234  lr: 1.742e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:33:48 d2.utils.events]: \u001b[0m eta: 1:10:40  iter: 7279  total_loss: 2.389  loss_cls_stage0: 0.3388  loss_box_reg_stage0: 0.2616  loss_cls_stage1: 0.2715  loss_box_reg_stage1: 0.3645  loss_cls_stage2: 0.1973  loss_box_reg_stage2: 0.3115  loss_mask: 0.526  loss_rpn_cls: 0.05867  loss_rpn_loc: 0.04152  validation_loss: 2.104  time: 1.5270  data_time: 0.0238  lr: 1.7183e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:34:19 d2.utils.events]: \u001b[0m eta: 1:10:10  iter: 7299  total_loss: 2.372  loss_cls_stage0: 0.3543  loss_box_reg_stage0: 0.2698  loss_cls_stage1: 0.2949  loss_box_reg_stage1: 0.3575  loss_cls_stage2: 0.2095  loss_box_reg_stage2: 0.3224  loss_mask: 0.5257  loss_rpn_cls: 0.0614  loss_rpn_loc: 0.03984  validation_loss: 2.104  time: 1.5271  data_time: 0.0253  lr: 1.6946e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:34:51 d2.utils.events]: \u001b[0m eta: 1:09:39  iter: 7319  total_loss: 2.325  loss_cls_stage0: 0.3347  loss_box_reg_stage0: 0.2615  loss_cls_stage1: 0.2641  loss_box_reg_stage1: 0.353  loss_cls_stage2: 0.1942  loss_box_reg_stage2: 0.2843  loss_mask: 0.5037  loss_rpn_cls: 0.06913  loss_rpn_loc: 0.03714  validation_loss: 2.104  time: 1.5272  data_time: 0.0245  lr: 1.6711e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:35:22 d2.utils.events]: \u001b[0m eta: 1:09:08  iter: 7339  total_loss: 2.354  loss_cls_stage0: 0.3309  loss_box_reg_stage0: 0.2521  loss_cls_stage1: 0.2737  loss_box_reg_stage1: 0.3477  loss_cls_stage2: 0.2  loss_box_reg_stage2: 0.2925  loss_mask: 0.5227  loss_rpn_cls: 0.06267  loss_rpn_loc: 0.03679  validation_loss: 2.104  time: 1.5273  data_time: 0.0238  lr: 1.6477e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:35:54 d2.utils.events]: \u001b[0m eta: 1:08:37  iter: 7359  total_loss: 2.477  loss_cls_stage0: 0.3616  loss_box_reg_stage0: 0.282  loss_cls_stage1: 0.2929  loss_box_reg_stage1: 0.3754  loss_cls_stage2: 0.2066  loss_box_reg_stage2: 0.2917  loss_mask: 0.5398  loss_rpn_cls: 0.06254  loss_rpn_loc: 0.03654  validation_loss: 2.104  time: 1.5274  data_time: 0.0252  lr: 1.6245e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:36:25 d2.utils.events]: \u001b[0m eta: 1:08:06  iter: 7379  total_loss: 2.352  loss_cls_stage0: 0.3253  loss_box_reg_stage0: 0.2682  loss_cls_stage1: 0.2749  loss_box_reg_stage1: 0.3751  loss_cls_stage2: 0.2038  loss_box_reg_stage2: 0.2972  loss_mask: 0.5535  loss_rpn_cls: 0.05875  loss_rpn_loc: 0.03759  validation_loss: 2.104  time: 1.5275  data_time: 0.0250  lr: 1.6014e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:36:56 d2.utils.events]: \u001b[0m eta: 1:07:34  iter: 7399  total_loss: 2.249  loss_cls_stage0: 0.3023  loss_box_reg_stage0: 0.2415  loss_cls_stage1: 0.2516  loss_box_reg_stage1: 0.3595  loss_cls_stage2: 0.1808  loss_box_reg_stage2: 0.3037  loss_mask: 0.5184  loss_rpn_cls: 0.06945  loss_rpn_loc: 0.03828  validation_loss: 2.104  time: 1.5276  data_time: 0.0233  lr: 1.5784e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:37:27 d2.utils.events]: \u001b[0m eta: 1:07:03  iter: 7419  total_loss: 2.326  loss_cls_stage0: 0.3332  loss_box_reg_stage0: 0.2675  loss_cls_stage1: 0.263  loss_box_reg_stage1: 0.3402  loss_cls_stage2: 0.1848  loss_box_reg_stage2: 0.2849  loss_mask: 0.5516  loss_rpn_cls: 0.06159  loss_rpn_loc: 0.03831  validation_loss: 2.104  time: 1.5277  data_time: 0.0253  lr: 1.5556e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:37:59 d2.utils.events]: \u001b[0m eta: 1:06:32  iter: 7439  total_loss: 2.395  loss_cls_stage0: 0.3224  loss_box_reg_stage0: 0.2569  loss_cls_stage1: 0.257  loss_box_reg_stage1: 0.3601  loss_cls_stage2: 0.1819  loss_box_reg_stage2: 0.3082  loss_mask: 0.5678  loss_rpn_cls: 0.06648  loss_rpn_loc: 0.03507  validation_loss: 2.104  time: 1.5278  data_time: 0.0242  lr: 1.5329e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:38:30 d2.utils.events]: \u001b[0m eta: 1:06:01  iter: 7459  total_loss: 2.284  loss_cls_stage0: 0.3257  loss_box_reg_stage0: 0.2536  loss_cls_stage1: 0.2739  loss_box_reg_stage1: 0.3583  loss_cls_stage2: 0.1915  loss_box_reg_stage2: 0.3071  loss_mask: 0.487  loss_rpn_cls: 0.06434  loss_rpn_loc: 0.03074  validation_loss: 2.104  time: 1.5279  data_time: 0.0249  lr: 1.5103e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:39:01 d2.utils.events]: \u001b[0m eta: 1:05:30  iter: 7479  total_loss: 2.404  loss_cls_stage0: 0.33  loss_box_reg_stage0: 0.2506  loss_cls_stage1: 0.2716  loss_box_reg_stage1: 0.3557  loss_cls_stage2: 0.2029  loss_box_reg_stage2: 0.2881  loss_mask: 0.5663  loss_rpn_cls: 0.05751  loss_rpn_loc: 0.0334  validation_loss: 2.104  time: 1.5280  data_time: 0.0239  lr: 1.4879e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:39:33 d2.utils.events]: \u001b[0m eta: 1:05:00  iter: 7499  total_loss: 2.422  loss_cls_stage0: 0.3245  loss_box_reg_stage0: 0.2506  loss_cls_stage1: 0.2684  loss_box_reg_stage1: 0.364  loss_cls_stage2: 0.1983  loss_box_reg_stage2: 0.3078  loss_mask: 0.5564  loss_rpn_cls: 0.06306  loss_rpn_loc: 0.03414  validation_loss: 2.104  time: 1.5281  data_time: 0.0239  lr: 1.4656e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:40:04 d2.utils.events]: \u001b[0m eta: 1:04:29  iter: 7519  total_loss: 2.185  loss_cls_stage0: 0.2909  loss_box_reg_stage0: 0.2301  loss_cls_stage1: 0.2502  loss_box_reg_stage1: 0.3288  loss_cls_stage2: 0.1769  loss_box_reg_stage2: 0.2771  loss_mask: 0.5233  loss_rpn_cls: 0.05904  loss_rpn_loc: 0.03514  validation_loss: 2.104  time: 1.5282  data_time: 0.0240  lr: 1.4434e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:40:35 d2.utils.events]: \u001b[0m eta: 1:03:59  iter: 7539  total_loss: 2.465  loss_cls_stage0: 0.3551  loss_box_reg_stage0: 0.2728  loss_cls_stage1: 0.2996  loss_box_reg_stage1: 0.3736  loss_cls_stage2: 0.2125  loss_box_reg_stage2: 0.2942  loss_mask: 0.5444  loss_rpn_cls: 0.07515  loss_rpn_loc: 0.04393  validation_loss: 2.104  time: 1.5283  data_time: 0.0312  lr: 1.4214e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:41:07 d2.utils.events]: \u001b[0m eta: 1:03:29  iter: 7559  total_loss: 2.537  loss_cls_stage0: 0.3555  loss_box_reg_stage0: 0.2553  loss_cls_stage1: 0.305  loss_box_reg_stage1: 0.3784  loss_cls_stage2: 0.2166  loss_box_reg_stage2: 0.2672  loss_mask: 0.5339  loss_rpn_cls: 0.06245  loss_rpn_loc: 0.04052  validation_loss: 2.104  time: 1.5284  data_time: 0.0247  lr: 1.3995e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:41:38 d2.utils.events]: \u001b[0m eta: 1:02:57  iter: 7579  total_loss: 2.204  loss_cls_stage0: 0.2933  loss_box_reg_stage0: 0.2353  loss_cls_stage1: 0.2473  loss_box_reg_stage1: 0.3383  loss_cls_stage2: 0.1778  loss_box_reg_stage2: 0.3002  loss_mask: 0.5158  loss_rpn_cls: 0.05809  loss_rpn_loc: 0.0307  validation_loss: 2.104  time: 1.5285  data_time: 0.0238  lr: 1.3778e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:42:09 d2.utils.events]: \u001b[0m eta: 1:02:27  iter: 7599  total_loss: 2.597  loss_cls_stage0: 0.3587  loss_box_reg_stage0: 0.2929  loss_cls_stage1: 0.3148  loss_box_reg_stage1: 0.3875  loss_cls_stage2: 0.2201  loss_box_reg_stage2: 0.3005  loss_mask: 0.5396  loss_rpn_cls: 0.07019  loss_rpn_loc: 0.04027  validation_loss: 2.104  time: 1.5286  data_time: 0.0237  lr: 1.3562e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:42:41 d2.utils.events]: \u001b[0m eta: 1:01:55  iter: 7619  total_loss: 2.271  loss_cls_stage0: 0.3326  loss_box_reg_stage0: 0.2517  loss_cls_stage1: 0.2542  loss_box_reg_stage1: 0.3439  loss_cls_stage2: 0.1778  loss_box_reg_stage2: 0.3043  loss_mask: 0.542  loss_rpn_cls: 0.05638  loss_rpn_loc: 0.03141  validation_loss: 2.104  time: 1.5287  data_time: 0.0250  lr: 1.3348e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:43:12 d2.utils.events]: \u001b[0m eta: 1:01:25  iter: 7639  total_loss: 2.486  loss_cls_stage0: 0.3703  loss_box_reg_stage0: 0.2914  loss_cls_stage1: 0.294  loss_box_reg_stage1: 0.3873  loss_cls_stage2: 0.2161  loss_box_reg_stage2: 0.2757  loss_mask: 0.4977  loss_rpn_cls: 0.0631  loss_rpn_loc: 0.03672  validation_loss: 2.104  time: 1.5288  data_time: 0.0254  lr: 1.3135e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:43:43 d2.utils.events]: \u001b[0m eta: 1:00:53  iter: 7659  total_loss: 2.238  loss_cls_stage0: 0.3115  loss_box_reg_stage0: 0.2604  loss_cls_stage1: 0.2771  loss_box_reg_stage1: 0.3388  loss_cls_stage2: 0.2015  loss_box_reg_stage2: 0.3035  loss_mask: 0.5482  loss_rpn_cls: 0.05105  loss_rpn_loc: 0.03455  validation_loss: 2.104  time: 1.5289  data_time: 0.0238  lr: 1.2923e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:44:15 d2.utils.events]: \u001b[0m eta: 1:00:22  iter: 7679  total_loss: 2.357  loss_cls_stage0: 0.3307  loss_box_reg_stage0: 0.2411  loss_cls_stage1: 0.2873  loss_box_reg_stage1: 0.3752  loss_cls_stage2: 0.2132  loss_box_reg_stage2: 0.311  loss_mask: 0.4803  loss_rpn_cls: 0.05286  loss_rpn_loc: 0.03357  validation_loss: 2.104  time: 1.5290  data_time: 0.0254  lr: 1.2713e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:44:46 d2.utils.events]: \u001b[0m eta: 0:59:51  iter: 7699  total_loss: 2.167  loss_cls_stage0: 0.316  loss_box_reg_stage0: 0.2463  loss_cls_stage1: 0.2634  loss_box_reg_stage1: 0.3328  loss_cls_stage2: 0.1929  loss_box_reg_stage2: 0.2713  loss_mask: 0.4897  loss_rpn_cls: 0.05999  loss_rpn_loc: 0.03526  validation_loss: 2.104  time: 1.5291  data_time: 0.0219  lr: 1.2505e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:45:17 d2.utils.events]: \u001b[0m eta: 0:59:20  iter: 7719  total_loss: 2.444  loss_cls_stage0: 0.3026  loss_box_reg_stage0: 0.2458  loss_cls_stage1: 0.2634  loss_box_reg_stage1: 0.378  loss_cls_stage2: 0.1954  loss_box_reg_stage2: 0.3098  loss_mask: 0.5445  loss_rpn_cls: 0.06339  loss_rpn_loc: 0.03766  validation_loss: 2.104  time: 1.5292  data_time: 0.0256  lr: 1.2298e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:45:49 d2.utils.events]: \u001b[0m eta: 0:58:50  iter: 7739  total_loss: 2.434  loss_cls_stage0: 0.328  loss_box_reg_stage0: 0.2771  loss_cls_stage1: 0.2708  loss_box_reg_stage1: 0.3873  loss_cls_stage2: 0.1984  loss_box_reg_stage2: 0.3245  loss_mask: 0.4784  loss_rpn_cls: 0.0635  loss_rpn_loc: 0.03882  validation_loss: 2.104  time: 1.5293  data_time: 0.0242  lr: 1.2092e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:46:20 d2.utils.events]: \u001b[0m eta: 0:58:18  iter: 7759  total_loss: 2.432  loss_cls_stage0: 0.3514  loss_box_reg_stage0: 0.2817  loss_cls_stage1: 0.2939  loss_box_reg_stage1: 0.3755  loss_cls_stage2: 0.2136  loss_box_reg_stage2: 0.3  loss_mask: 0.5198  loss_rpn_cls: 0.05973  loss_rpn_loc: 0.0353  validation_loss: 2.104  time: 1.5294  data_time: 0.0246  lr: 1.1888e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:46:52 d2.utils.events]: \u001b[0m eta: 0:57:47  iter: 7779  total_loss: 2.399  loss_cls_stage0: 0.3325  loss_box_reg_stage0: 0.2703  loss_cls_stage1: 0.2868  loss_box_reg_stage1: 0.4094  loss_cls_stage2: 0.2188  loss_box_reg_stage2: 0.3184  loss_mask: 0.5534  loss_rpn_cls: 0.06145  loss_rpn_loc: 0.0342  validation_loss: 2.104  time: 1.5295  data_time: 0.0257  lr: 1.1685e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:47:23 d2.utils.events]: \u001b[0m eta: 0:57:16  iter: 7799  total_loss: 2.537  loss_cls_stage0: 0.37  loss_box_reg_stage0: 0.2935  loss_cls_stage1: 0.2952  loss_box_reg_stage1: 0.4047  loss_cls_stage2: 0.2166  loss_box_reg_stage2: 0.3207  loss_mask: 0.5275  loss_rpn_cls: 0.06218  loss_rpn_loc: 0.04019  validation_loss: 2.104  time: 1.5296  data_time: 0.0235  lr: 1.1484e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:47:54 d2.utils.events]: \u001b[0m eta: 0:56:45  iter: 7819  total_loss: 2.398  loss_cls_stage0: 0.3317  loss_box_reg_stage0: 0.2759  loss_cls_stage1: 0.2687  loss_box_reg_stage1: 0.3787  loss_cls_stage2: 0.1961  loss_box_reg_stage2: 0.3017  loss_mask: 0.5213  loss_rpn_cls: 0.05169  loss_rpn_loc: 0.03332  validation_loss: 2.104  time: 1.5297  data_time: 0.0235  lr: 1.1285e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:48:26 d2.utils.events]: \u001b[0m eta: 0:56:14  iter: 7839  total_loss: 2.426  loss_cls_stage0: 0.3397  loss_box_reg_stage0: 0.2667  loss_cls_stage1: 0.2888  loss_box_reg_stage1: 0.3713  loss_cls_stage2: 0.2062  loss_box_reg_stage2: 0.28  loss_mask: 0.5453  loss_rpn_cls: 0.05919  loss_rpn_loc: 0.03389  validation_loss: 2.104  time: 1.5298  data_time: 0.0239  lr: 1.1087e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:48:57 d2.utils.events]: \u001b[0m eta: 0:55:43  iter: 7859  total_loss: 2.444  loss_cls_stage0: 0.346  loss_box_reg_stage0: 0.3035  loss_cls_stage1: 0.2829  loss_box_reg_stage1: 0.385  loss_cls_stage2: 0.2026  loss_box_reg_stage2: 0.3302  loss_mask: 0.5301  loss_rpn_cls: 0.05964  loss_rpn_loc: 0.03908  validation_loss: 2.104  time: 1.5299  data_time: 0.0241  lr: 1.089e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:49:29 d2.utils.events]: \u001b[0m eta: 0:55:12  iter: 7879  total_loss: 2.295  loss_cls_stage0: 0.3168  loss_box_reg_stage0: 0.2348  loss_cls_stage1: 0.2538  loss_box_reg_stage1: 0.3448  loss_cls_stage2: 0.1884  loss_box_reg_stage2: 0.2977  loss_mask: 0.5544  loss_rpn_cls: 0.05963  loss_rpn_loc: 0.03099  validation_loss: 2.104  time: 1.5300  data_time: 0.0230  lr: 1.0695e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:50:00 d2.utils.events]: \u001b[0m eta: 0:54:40  iter: 7899  total_loss: 2.266  loss_cls_stage0: 0.3071  loss_box_reg_stage0: 0.2518  loss_cls_stage1: 0.2636  loss_box_reg_stage1: 0.3515  loss_cls_stage2: 0.2  loss_box_reg_stage2: 0.3167  loss_mask: 0.5351  loss_rpn_cls: 0.05162  loss_rpn_loc: 0.03166  validation_loss: 2.104  time: 1.5301  data_time: 0.0217  lr: 1.0502e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:50:31 d2.utils.events]: \u001b[0m eta: 0:54:09  iter: 7919  total_loss: 2.522  loss_cls_stage0: 0.33  loss_box_reg_stage0: 0.2742  loss_cls_stage1: 0.2838  loss_box_reg_stage1: 0.3774  loss_cls_stage2: 0.2039  loss_box_reg_stage2: 0.3136  loss_mask: 0.6056  loss_rpn_cls: 0.05306  loss_rpn_loc: 0.03717  validation_loss: 2.104  time: 1.5302  data_time: 0.0221  lr: 1.031e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:51:03 d2.utils.events]: \u001b[0m eta: 0:53:38  iter: 7939  total_loss: 2.267  loss_cls_stage0: 0.3005  loss_box_reg_stage0: 0.2496  loss_cls_stage1: 0.2414  loss_box_reg_stage1: 0.3529  loss_cls_stage2: 0.1781  loss_box_reg_stage2: 0.3096  loss_mask: 0.5449  loss_rpn_cls: 0.05771  loss_rpn_loc: 0.03419  validation_loss: 2.104  time: 1.5303  data_time: 0.0248  lr: 1.012e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:51:34 d2.utils.events]: \u001b[0m eta: 0:53:07  iter: 7959  total_loss: 2.254  loss_cls_stage0: 0.3179  loss_box_reg_stage0: 0.2575  loss_cls_stage1: 0.244  loss_box_reg_stage1: 0.3682  loss_cls_stage2: 0.1792  loss_box_reg_stage2: 0.3093  loss_mask: 0.4987  loss_rpn_cls: 0.0556  loss_rpn_loc: 0.03638  validation_loss: 2.104  time: 1.5304  data_time: 0.0228  lr: 9.931e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:52:06 d2.utils.events]: \u001b[0m eta: 0:52:36  iter: 7979  total_loss: 2.409  loss_cls_stage0: 0.3399  loss_box_reg_stage0: 0.2585  loss_cls_stage1: 0.2875  loss_box_reg_stage1: 0.3832  loss_cls_stage2: 0.2124  loss_box_reg_stage2: 0.3394  loss_mask: 0.4865  loss_rpn_cls: 0.05557  loss_rpn_loc: 0.03404  validation_loss: 2.104  time: 1.5305  data_time: 0.0245  lr: 9.7439e-06  max_mem: 12121M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/27 05:52:39 d2.data.common]: \u001b[0mSerializing 857 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/27 05:52:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.89 MiB\n",
      "\u001b[32m[03/27 05:52:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 857 images\n",
      "\u001b[32m[03/27 05:52:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/857. 0.0829 s / img. ETA=0:01:55\n",
      "\u001b[32m[03/27 05:52:46 d2.evaluation.evaluator]: \u001b[0mInference done 52/857. 0.0817 s / img. ETA=0:01:40\n",
      "\u001b[32m[03/27 05:52:51 d2.evaluation.evaluator]: \u001b[0mInference done 92/857. 0.0818 s / img. ETA=0:01:36\n",
      "\u001b[32m[03/27 05:52:56 d2.evaluation.evaluator]: \u001b[0mInference done 135/857. 0.0816 s / img. ETA=0:01:28\n",
      "\u001b[32m[03/27 05:53:01 d2.evaluation.evaluator]: \u001b[0mInference done 177/857. 0.0816 s / img. ETA=0:01:23\n",
      "\u001b[32m[03/27 05:53:06 d2.evaluation.evaluator]: \u001b[0mInference done 219/857. 0.0816 s / img. ETA=0:01:18\n",
      "\u001b[32m[03/27 05:53:12 d2.evaluation.evaluator]: \u001b[0mInference done 262/857. 0.0815 s / img. ETA=0:01:12\n",
      "\u001b[32m[03/27 05:53:17 d2.evaluation.evaluator]: \u001b[0mInference done 307/857. 0.0814 s / img. ETA=0:01:06\n",
      "\u001b[32m[03/27 05:53:22 d2.evaluation.evaluator]: \u001b[0mInference done 347/857. 0.0815 s / img. ETA=0:01:01\n",
      "\u001b[32m[03/27 05:53:27 d2.evaluation.evaluator]: \u001b[0mInference done 391/857. 0.0815 s / img. ETA=0:00:56\n",
      "\u001b[32m[03/27 05:53:32 d2.evaluation.evaluator]: \u001b[0mInference done 434/857. 0.0814 s / img. ETA=0:00:50\n",
      "\u001b[32m[03/27 05:53:37 d2.evaluation.evaluator]: \u001b[0mInference done 477/857. 0.0814 s / img. ETA=0:00:45\n",
      "\u001b[32m[03/27 05:53:42 d2.evaluation.evaluator]: \u001b[0mInference done 522/857. 0.0813 s / img. ETA=0:00:39\n",
      "\u001b[32m[03/27 05:53:47 d2.evaluation.evaluator]: \u001b[0mInference done 563/857. 0.0814 s / img. ETA=0:00:35\n",
      "\u001b[32m[03/27 05:53:52 d2.evaluation.evaluator]: \u001b[0mInference done 605/857. 0.0814 s / img. ETA=0:00:30\n",
      "\u001b[32m[03/27 05:53:57 d2.evaluation.evaluator]: \u001b[0mInference done 648/857. 0.0814 s / img. ETA=0:00:25\n",
      "\u001b[32m[03/27 05:54:02 d2.evaluation.evaluator]: \u001b[0mInference done 689/857. 0.0814 s / img. ETA=0:00:20\n",
      "\u001b[32m[03/27 05:54:07 d2.evaluation.evaluator]: \u001b[0mInference done 733/857. 0.0814 s / img. ETA=0:00:14\n",
      "\u001b[32m[03/27 05:54:12 d2.evaluation.evaluator]: \u001b[0mInference done 775/857. 0.0814 s / img. ETA=0:00:09\n",
      "\u001b[32m[03/27 05:54:18 d2.evaluation.evaluator]: \u001b[0mInference done 818/857. 0.0814 s / img. ETA=0:00:04\n",
      "\u001b[32m[03/27 05:54:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:41.861931 (0.119556 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/27 05:54:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:09 (0.081345 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.50 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.089\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.150\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.163\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.037\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.096\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.131\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.179\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.180\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.053\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.202\n",
      "\u001b[32m[03/27 05:54:23 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold4 in csv format:\n",
      "\u001b[32m[03/27 05:54:23 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/27 05:54:23 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/27 05:54:23 d2.evaluation.testing]: \u001b[0mcopypaste: 8.9381,14.9668,16.3324,0.9747,3.6706,9.5699\n",
      "validation do loss eval 2.4013743724250434\n",
      "\u001b[32m[03/27 05:55:53 d2.utils.events]: \u001b[0m eta: 0:52:05  iter: 7999  total_loss: 2.497  loss_cls_stage0: 0.3471  loss_box_reg_stage0: 0.2807  loss_cls_stage1: 0.2842  loss_box_reg_stage1: 0.3662  loss_cls_stage2: 0.2046  loss_box_reg_stage2: 0.3102  loss_mask: 0.5545  loss_rpn_cls: 0.06583  loss_rpn_loc: 0.04187  validation_loss: 2.159  time: 1.5306  data_time: 0.0240  lr: 9.5584e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:56:23 d2.utils.events]: \u001b[0m eta: 0:51:33  iter: 8019  total_loss: 2.406  loss_cls_stage0: 0.3306  loss_box_reg_stage0: 0.2604  loss_cls_stage1: 0.2679  loss_box_reg_stage1: 0.3498  loss_cls_stage2: 0.2064  loss_box_reg_stage2: 0.3113  loss_mask: 0.5715  loss_rpn_cls: 0.06098  loss_rpn_loc: 0.03707  validation_loss: 2.159  time: 1.5306  data_time: 0.0252  lr: 9.3744e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:56:55 d2.utils.events]: \u001b[0m eta: 0:51:02  iter: 8039  total_loss: 2.329  loss_cls_stage0: 0.3144  loss_box_reg_stage0: 0.2344  loss_cls_stage1: 0.2649  loss_box_reg_stage1: 0.3525  loss_cls_stage2: 0.1995  loss_box_reg_stage2: 0.3168  loss_mask: 0.5663  loss_rpn_cls: 0.06177  loss_rpn_loc: 0.03689  validation_loss: 2.159  time: 1.5307  data_time: 0.0232  lr: 9.1921e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:57:26 d2.utils.events]: \u001b[0m eta: 0:50:31  iter: 8059  total_loss: 2.395  loss_cls_stage0: 0.3715  loss_box_reg_stage0: 0.2634  loss_cls_stage1: 0.2916  loss_box_reg_stage1: 0.37  loss_cls_stage2: 0.2  loss_box_reg_stage2: 0.2694  loss_mask: 0.5293  loss_rpn_cls: 0.05992  loss_rpn_loc: 0.03563  validation_loss: 2.159  time: 1.5308  data_time: 0.0253  lr: 9.0114e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:57:57 d2.utils.events]: \u001b[0m eta: 0:50:00  iter: 8079  total_loss: 2.531  loss_cls_stage0: 0.3351  loss_box_reg_stage0: 0.266  loss_cls_stage1: 0.289  loss_box_reg_stage1: 0.3786  loss_cls_stage2: 0.2068  loss_box_reg_stage2: 0.3055  loss_mask: 0.5342  loss_rpn_cls: 0.06445  loss_rpn_loc: 0.0389  validation_loss: 2.159  time: 1.5309  data_time: 0.0253  lr: 8.8323e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:58:29 d2.utils.events]: \u001b[0m eta: 0:49:30  iter: 8099  total_loss: 2.482  loss_cls_stage0: 0.3655  loss_box_reg_stage0: 0.2876  loss_cls_stage1: 0.2877  loss_box_reg_stage1: 0.3812  loss_cls_stage2: 0.2124  loss_box_reg_stage2: 0.3122  loss_mask: 0.5378  loss_rpn_cls: 0.06511  loss_rpn_loc: 0.03811  validation_loss: 2.159  time: 1.5310  data_time: 0.0239  lr: 8.6548e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:59:01 d2.utils.events]: \u001b[0m eta: 0:48:59  iter: 8119  total_loss: 2.394  loss_cls_stage0: 0.3497  loss_box_reg_stage0: 0.2806  loss_cls_stage1: 0.2905  loss_box_reg_stage1: 0.3727  loss_cls_stage2: 0.1907  loss_box_reg_stage2: 0.3097  loss_mask: 0.5275  loss_rpn_cls: 0.0742  loss_rpn_loc: 0.04002  validation_loss: 2.159  time: 1.5312  data_time: 0.0233  lr: 8.479e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 05:59:32 d2.utils.events]: \u001b[0m eta: 0:48:27  iter: 8139  total_loss: 2.385  loss_cls_stage0: 0.3357  loss_box_reg_stage0: 0.2601  loss_cls_stage1: 0.2702  loss_box_reg_stage1: 0.3618  loss_cls_stage2: 0.2088  loss_box_reg_stage2: 0.2817  loss_mask: 0.5169  loss_rpn_cls: 0.06093  loss_rpn_loc: 0.0381  validation_loss: 2.159  time: 1.5312  data_time: 0.0245  lr: 8.3047e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:00:03 d2.utils.events]: \u001b[0m eta: 0:47:56  iter: 8159  total_loss: 2.259  loss_cls_stage0: 0.2937  loss_box_reg_stage0: 0.2435  loss_cls_stage1: 0.2598  loss_box_reg_stage1: 0.336  loss_cls_stage2: 0.1906  loss_box_reg_stage2: 0.2974  loss_mask: 0.5249  loss_rpn_cls: 0.06118  loss_rpn_loc: 0.03207  validation_loss: 2.159  time: 1.5313  data_time: 0.0238  lr: 8.1322e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:00:35 d2.utils.events]: \u001b[0m eta: 0:47:24  iter: 8179  total_loss: 2.402  loss_cls_stage0: 0.3253  loss_box_reg_stage0: 0.2747  loss_cls_stage1: 0.2635  loss_box_reg_stage1: 0.3716  loss_cls_stage2: 0.1866  loss_box_reg_stage2: 0.3102  loss_mask: 0.536  loss_rpn_cls: 0.06885  loss_rpn_loc: 0.03884  validation_loss: 2.159  time: 1.5314  data_time: 0.0248  lr: 7.9613e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:01:06 d2.utils.events]: \u001b[0m eta: 0:46:54  iter: 8199  total_loss: 2.48  loss_cls_stage0: 0.3231  loss_box_reg_stage0: 0.253  loss_cls_stage1: 0.2754  loss_box_reg_stage1: 0.365  loss_cls_stage2: 0.1961  loss_box_reg_stage2: 0.3042  loss_mask: 0.5499  loss_rpn_cls: 0.05935  loss_rpn_loc: 0.03406  validation_loss: 2.159  time: 1.5315  data_time: 0.0234  lr: 7.792e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:01:38 d2.utils.events]: \u001b[0m eta: 0:46:23  iter: 8219  total_loss: 2.386  loss_cls_stage0: 0.323  loss_box_reg_stage0: 0.247  loss_cls_stage1: 0.2742  loss_box_reg_stage1: 0.3367  loss_cls_stage2: 0.194  loss_box_reg_stage2: 0.299  loss_mask: 0.5239  loss_rpn_cls: 0.06492  loss_rpn_loc: 0.03632  validation_loss: 2.159  time: 1.5316  data_time: 0.0239  lr: 7.6244e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:02:09 d2.utils.events]: \u001b[0m eta: 0:45:52  iter: 8239  total_loss: 2.418  loss_cls_stage0: 0.3409  loss_box_reg_stage0: 0.2656  loss_cls_stage1: 0.2807  loss_box_reg_stage1: 0.3708  loss_cls_stage2: 0.2034  loss_box_reg_stage2: 0.3163  loss_mask: 0.5195  loss_rpn_cls: 0.0773  loss_rpn_loc: 0.03653  validation_loss: 2.159  time: 1.5317  data_time: 0.0249  lr: 7.4585e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:02:40 d2.utils.events]: \u001b[0m eta: 0:45:21  iter: 8259  total_loss: 2.319  loss_cls_stage0: 0.3107  loss_box_reg_stage0: 0.2448  loss_cls_stage1: 0.2648  loss_box_reg_stage1: 0.3694  loss_cls_stage2: 0.2024  loss_box_reg_stage2: 0.336  loss_mask: 0.5499  loss_rpn_cls: 0.05803  loss_rpn_loc: 0.03459  validation_loss: 2.159  time: 1.5318  data_time: 0.0235  lr: 7.2943e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:03:12 d2.utils.events]: \u001b[0m eta: 0:44:49  iter: 8279  total_loss: 2.318  loss_cls_stage0: 0.3294  loss_box_reg_stage0: 0.2573  loss_cls_stage1: 0.2633  loss_box_reg_stage1: 0.3733  loss_cls_stage2: 0.1814  loss_box_reg_stage2: 0.2841  loss_mask: 0.5503  loss_rpn_cls: 0.05922  loss_rpn_loc: 0.03404  validation_loss: 2.159  time: 1.5319  data_time: 0.0243  lr: 7.1318e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:03:43 d2.utils.events]: \u001b[0m eta: 0:44:18  iter: 8299  total_loss: 2.272  loss_cls_stage0: 0.3121  loss_box_reg_stage0: 0.2434  loss_cls_stage1: 0.2509  loss_box_reg_stage1: 0.3667  loss_cls_stage2: 0.1903  loss_box_reg_stage2: 0.3156  loss_mask: 0.5144  loss_rpn_cls: 0.06569  loss_rpn_loc: 0.03875  validation_loss: 2.159  time: 1.5320  data_time: 0.0241  lr: 6.9709e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:04:15 d2.utils.events]: \u001b[0m eta: 0:43:47  iter: 8319  total_loss: 2.479  loss_cls_stage0: 0.3666  loss_box_reg_stage0: 0.2828  loss_cls_stage1: 0.2932  loss_box_reg_stage1: 0.3873  loss_cls_stage2: 0.2115  loss_box_reg_stage2: 0.2959  loss_mask: 0.5182  loss_rpn_cls: 0.06126  loss_rpn_loc: 0.04156  validation_loss: 2.159  time: 1.5321  data_time: 0.0239  lr: 6.8117e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:04:46 d2.utils.events]: \u001b[0m eta: 0:43:16  iter: 8339  total_loss: 2.324  loss_cls_stage0: 0.3162  loss_box_reg_stage0: 0.2467  loss_cls_stage1: 0.2638  loss_box_reg_stage1: 0.3754  loss_cls_stage2: 0.1858  loss_box_reg_stage2: 0.3288  loss_mask: 0.5421  loss_rpn_cls: 0.06608  loss_rpn_loc: 0.03404  validation_loss: 2.159  time: 1.5321  data_time: 0.0242  lr: 6.6543e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:05:17 d2.utils.events]: \u001b[0m eta: 0:42:44  iter: 8359  total_loss: 2.432  loss_cls_stage0: 0.3246  loss_box_reg_stage0: 0.2474  loss_cls_stage1: 0.2693  loss_box_reg_stage1: 0.3536  loss_cls_stage2: 0.1935  loss_box_reg_stage2: 0.3088  loss_mask: 0.5655  loss_rpn_cls: 0.06535  loss_rpn_loc: 0.03496  validation_loss: 2.159  time: 1.5322  data_time: 0.0255  lr: 6.4986e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:05:49 d2.utils.events]: \u001b[0m eta: 0:42:13  iter: 8379  total_loss: 2.485  loss_cls_stage0: 0.356  loss_box_reg_stage0: 0.275  loss_cls_stage1: 0.2865  loss_box_reg_stage1: 0.3918  loss_cls_stage2: 0.2082  loss_box_reg_stage2: 0.3096  loss_mask: 0.5592  loss_rpn_cls: 0.06107  loss_rpn_loc: 0.03797  validation_loss: 2.159  time: 1.5323  data_time: 0.0246  lr: 6.3445e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:06:20 d2.utils.events]: \u001b[0m eta: 0:41:42  iter: 8399  total_loss: 2.406  loss_cls_stage0: 0.3222  loss_box_reg_stage0: 0.2584  loss_cls_stage1: 0.2641  loss_box_reg_stage1: 0.3794  loss_cls_stage2: 0.1885  loss_box_reg_stage2: 0.2953  loss_mask: 0.5339  loss_rpn_cls: 0.06393  loss_rpn_loc: 0.03631  validation_loss: 2.159  time: 1.5324  data_time: 0.0247  lr: 6.1922e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:06:51 d2.utils.events]: \u001b[0m eta: 0:41:11  iter: 8419  total_loss: 2.478  loss_cls_stage0: 0.3504  loss_box_reg_stage0: 0.278  loss_cls_stage1: 0.2914  loss_box_reg_stage1: 0.3968  loss_cls_stage2: 0.211  loss_box_reg_stage2: 0.3032  loss_mask: 0.5514  loss_rpn_cls: 0.05938  loss_rpn_loc: 0.03825  validation_loss: 2.159  time: 1.5325  data_time: 0.0233  lr: 6.0417e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:07:23 d2.utils.events]: \u001b[0m eta: 0:40:40  iter: 8439  total_loss: 2.38  loss_cls_stage0: 0.344  loss_box_reg_stage0: 0.2719  loss_cls_stage1: 0.2927  loss_box_reg_stage1: 0.3838  loss_cls_stage2: 0.2018  loss_box_reg_stage2: 0.3167  loss_mask: 0.5105  loss_rpn_cls: 0.05924  loss_rpn_loc: 0.03437  validation_loss: 2.159  time: 1.5326  data_time: 0.0225  lr: 5.8928e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:07:54 d2.utils.events]: \u001b[0m eta: 0:40:09  iter: 8459  total_loss: 2.434  loss_cls_stage0: 0.3178  loss_box_reg_stage0: 0.2674  loss_cls_stage1: 0.2541  loss_box_reg_stage1: 0.3681  loss_cls_stage2: 0.1892  loss_box_reg_stage2: 0.3033  loss_mask: 0.529  loss_rpn_cls: 0.0644  loss_rpn_loc: 0.03683  validation_loss: 2.159  time: 1.5327  data_time: 0.0252  lr: 5.7457e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:08:26 d2.utils.events]: \u001b[0m eta: 0:39:37  iter: 8479  total_loss: 2.412  loss_cls_stage0: 0.3429  loss_box_reg_stage0: 0.2706  loss_cls_stage1: 0.2742  loss_box_reg_stage1: 0.3689  loss_cls_stage2: 0.1884  loss_box_reg_stage2: 0.3078  loss_mask: 0.5362  loss_rpn_cls: 0.06078  loss_rpn_loc: 0.03532  validation_loss: 2.159  time: 1.5327  data_time: 0.0232  lr: 5.6004e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:08:57 d2.utils.events]: \u001b[0m eta: 0:39:06  iter: 8499  total_loss: 2.27  loss_cls_stage0: 0.2777  loss_box_reg_stage0: 0.2361  loss_cls_stage1: 0.2364  loss_box_reg_stage1: 0.3555  loss_cls_stage2: 0.177  loss_box_reg_stage2: 0.2916  loss_mask: 0.5049  loss_rpn_cls: 0.06558  loss_rpn_loc: 0.03945  validation_loss: 2.159  time: 1.5328  data_time: 0.0250  lr: 5.4568e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:09:28 d2.utils.events]: \u001b[0m eta: 0:38:34  iter: 8519  total_loss: 2.17  loss_cls_stage0: 0.29  loss_box_reg_stage0: 0.2258  loss_cls_stage1: 0.25  loss_box_reg_stage1: 0.3407  loss_cls_stage2: 0.1857  loss_box_reg_stage2: 0.2806  loss_mask: 0.5085  loss_rpn_cls: 0.05678  loss_rpn_loc: 0.03143  validation_loss: 2.159  time: 1.5329  data_time: 0.0251  lr: 5.315e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:09:59 d2.utils.events]: \u001b[0m eta: 0:38:03  iter: 8539  total_loss: 2.214  loss_cls_stage0: 0.312  loss_box_reg_stage0: 0.2602  loss_cls_stage1: 0.2518  loss_box_reg_stage1: 0.3567  loss_cls_stage2: 0.1973  loss_box_reg_stage2: 0.2972  loss_mask: 0.5478  loss_rpn_cls: 0.05997  loss_rpn_loc: 0.03487  validation_loss: 2.159  time: 1.5329  data_time: 0.0250  lr: 5.1749e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:10:30 d2.utils.events]: \u001b[0m eta: 0:37:32  iter: 8559  total_loss: 2.325  loss_cls_stage0: 0.3212  loss_box_reg_stage0: 0.2522  loss_cls_stage1: 0.2685  loss_box_reg_stage1: 0.3634  loss_cls_stage2: 0.1948  loss_box_reg_stage2: 0.2945  loss_mask: 0.5107  loss_rpn_cls: 0.05599  loss_rpn_loc: 0.0314  validation_loss: 2.159  time: 1.5330  data_time: 0.0249  lr: 5.0366e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:11:02 d2.utils.events]: \u001b[0m eta: 0:37:02  iter: 8579  total_loss: 2.481  loss_cls_stage0: 0.3553  loss_box_reg_stage0: 0.2958  loss_cls_stage1: 0.2843  loss_box_reg_stage1: 0.3905  loss_cls_stage2: 0.193  loss_box_reg_stage2: 0.3079  loss_mask: 0.5191  loss_rpn_cls: 0.05866  loss_rpn_loc: 0.03961  validation_loss: 2.159  time: 1.5331  data_time: 0.0244  lr: 4.9001e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:11:34 d2.utils.events]: \u001b[0m eta: 0:36:30  iter: 8599  total_loss: 2.44  loss_cls_stage0: 0.3545  loss_box_reg_stage0: 0.2883  loss_cls_stage1: 0.2903  loss_box_reg_stage1: 0.3836  loss_cls_stage2: 0.2004  loss_box_reg_stage2: 0.3017  loss_mask: 0.5499  loss_rpn_cls: 0.06027  loss_rpn_loc: 0.03614  validation_loss: 2.159  time: 1.5332  data_time: 0.0223  lr: 4.7653e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:12:05 d2.utils.events]: \u001b[0m eta: 0:35:59  iter: 8619  total_loss: 2.484  loss_cls_stage0: 0.3403  loss_box_reg_stage0: 0.2661  loss_cls_stage1: 0.275  loss_box_reg_stage1: 0.3793  loss_cls_stage2: 0.1993  loss_box_reg_stage2: 0.3103  loss_mask: 0.539  loss_rpn_cls: 0.06216  loss_rpn_loc: 0.03343  validation_loss: 2.159  time: 1.5333  data_time: 0.0227  lr: 4.6324e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:12:36 d2.utils.events]: \u001b[0m eta: 0:35:27  iter: 8639  total_loss: 2.422  loss_cls_stage0: 0.3283  loss_box_reg_stage0: 0.2642  loss_cls_stage1: 0.276  loss_box_reg_stage1: 0.3765  loss_cls_stage2: 0.2115  loss_box_reg_stage2: 0.3039  loss_mask: 0.4942  loss_rpn_cls: 0.05756  loss_rpn_loc: 0.03508  validation_loss: 2.159  time: 1.5334  data_time: 0.0232  lr: 4.5012e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:13:08 d2.utils.events]: \u001b[0m eta: 0:34:56  iter: 8659  total_loss: 2.326  loss_cls_stage0: 0.3276  loss_box_reg_stage0: 0.2476  loss_cls_stage1: 0.2625  loss_box_reg_stage1: 0.3419  loss_cls_stage2: 0.1883  loss_box_reg_stage2: 0.2801  loss_mask: 0.5652  loss_rpn_cls: 0.05623  loss_rpn_loc: 0.03242  validation_loss: 2.159  time: 1.5334  data_time: 0.0234  lr: 4.3718e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:13:39 d2.utils.events]: \u001b[0m eta: 0:34:25  iter: 8679  total_loss: 2.229  loss_cls_stage0: 0.2953  loss_box_reg_stage0: 0.2407  loss_cls_stage1: 0.2393  loss_box_reg_stage1: 0.3549  loss_cls_stage2: 0.1851  loss_box_reg_stage2: 0.3174  loss_mask: 0.5167  loss_rpn_cls: 0.0589  loss_rpn_loc: 0.03362  validation_loss: 2.159  time: 1.5335  data_time: 0.0245  lr: 4.2443e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:14:10 d2.utils.events]: \u001b[0m eta: 0:33:54  iter: 8699  total_loss: 2.329  loss_cls_stage0: 0.3014  loss_box_reg_stage0: 0.2346  loss_cls_stage1: 0.2476  loss_box_reg_stage1: 0.3669  loss_cls_stage2: 0.1758  loss_box_reg_stage2: 0.326  loss_mask: 0.6082  loss_rpn_cls: 0.05487  loss_rpn_loc: 0.03343  validation_loss: 2.159  time: 1.5336  data_time: 0.0255  lr: 4.1185e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:14:41 d2.utils.events]: \u001b[0m eta: 0:33:23  iter: 8719  total_loss: 2.282  loss_cls_stage0: 0.3264  loss_box_reg_stage0: 0.2546  loss_cls_stage1: 0.2528  loss_box_reg_stage1: 0.3508  loss_cls_stage2: 0.1837  loss_box_reg_stage2: 0.3062  loss_mask: 0.5943  loss_rpn_cls: 0.05961  loss_rpn_loc: 0.03533  validation_loss: 2.159  time: 1.5337  data_time: 0.0251  lr: 3.9946e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:15:13 d2.utils.events]: \u001b[0m eta: 0:32:51  iter: 8739  total_loss: 2.466  loss_cls_stage0: 0.3362  loss_box_reg_stage0: 0.3017  loss_cls_stage1: 0.2867  loss_box_reg_stage1: 0.3831  loss_cls_stage2: 0.2035  loss_box_reg_stage2: 0.2931  loss_mask: 0.5486  loss_rpn_cls: 0.06625  loss_rpn_loc: 0.03372  validation_loss: 2.159  time: 1.5337  data_time: 0.0245  lr: 3.8724e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:15:44 d2.utils.events]: \u001b[0m eta: 0:32:20  iter: 8759  total_loss: 2.441  loss_cls_stage0: 0.3426  loss_box_reg_stage0: 0.2502  loss_cls_stage1: 0.2907  loss_box_reg_stage1: 0.3805  loss_cls_stage2: 0.2138  loss_box_reg_stage2: 0.3145  loss_mask: 0.5107  loss_rpn_cls: 0.06556  loss_rpn_loc: 0.03607  validation_loss: 2.159  time: 1.5338  data_time: 0.0235  lr: 3.7521e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:16:16 d2.utils.events]: \u001b[0m eta: 0:31:49  iter: 8779  total_loss: 2.344  loss_cls_stage0: 0.3192  loss_box_reg_stage0: 0.259  loss_cls_stage1: 0.2622  loss_box_reg_stage1: 0.372  loss_cls_stage2: 0.1928  loss_box_reg_stage2: 0.2931  loss_mask: 0.5133  loss_rpn_cls: 0.06428  loss_rpn_loc: 0.03595  validation_loss: 2.159  time: 1.5339  data_time: 0.0237  lr: 3.6336e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:16:47 d2.utils.events]: \u001b[0m eta: 0:31:17  iter: 8799  total_loss: 2.408  loss_cls_stage0: 0.314  loss_box_reg_stage0: 0.2708  loss_cls_stage1: 0.269  loss_box_reg_stage1: 0.3642  loss_cls_stage2: 0.1955  loss_box_reg_stage2: 0.3058  loss_mask: 0.5342  loss_rpn_cls: 0.05923  loss_rpn_loc: 0.03616  validation_loss: 2.159  time: 1.5340  data_time: 0.0237  lr: 3.517e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:17:19 d2.utils.events]: \u001b[0m eta: 0:30:46  iter: 8819  total_loss: 2.547  loss_cls_stage0: 0.3502  loss_box_reg_stage0: 0.2788  loss_cls_stage1: 0.3011  loss_box_reg_stage1: 0.4126  loss_cls_stage2: 0.2238  loss_box_reg_stage2: 0.3265  loss_mask: 0.5164  loss_rpn_cls: 0.05939  loss_rpn_loc: 0.0329  validation_loss: 2.159  time: 1.5341  data_time: 0.0225  lr: 3.4021e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:17:50 d2.utils.events]: \u001b[0m eta: 0:30:15  iter: 8839  total_loss: 2.22  loss_cls_stage0: 0.3046  loss_box_reg_stage0: 0.2592  loss_cls_stage1: 0.2454  loss_box_reg_stage1: 0.3409  loss_cls_stage2: 0.1751  loss_box_reg_stage2: 0.3112  loss_mask: 0.4934  loss_rpn_cls: 0.05153  loss_rpn_loc: 0.03274  validation_loss: 2.159  time: 1.5342  data_time: 0.0234  lr: 3.2892e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:18:21 d2.utils.events]: \u001b[0m eta: 0:29:43  iter: 8859  total_loss: 2.45  loss_cls_stage0: 0.334  loss_box_reg_stage0: 0.2785  loss_cls_stage1: 0.2703  loss_box_reg_stage1: 0.3646  loss_cls_stage2: 0.1857  loss_box_reg_stage2: 0.2899  loss_mask: 0.555  loss_rpn_cls: 0.05235  loss_rpn_loc: 0.0322  validation_loss: 2.159  time: 1.5342  data_time: 0.0244  lr: 3.178e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:18:52 d2.utils.events]: \u001b[0m eta: 0:29:12  iter: 8879  total_loss: 2.214  loss_cls_stage0: 0.284  loss_box_reg_stage0: 0.2322  loss_cls_stage1: 0.242  loss_box_reg_stage1: 0.3406  loss_cls_stage2: 0.1954  loss_box_reg_stage2: 0.311  loss_mask: 0.5405  loss_rpn_cls: 0.05281  loss_rpn_loc: 0.03441  validation_loss: 2.159  time: 1.5343  data_time: 0.0243  lr: 3.0687e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:19:24 d2.utils.events]: \u001b[0m eta: 0:28:41  iter: 8899  total_loss: 2.283  loss_cls_stage0: 0.2902  loss_box_reg_stage0: 0.2376  loss_cls_stage1: 0.26  loss_box_reg_stage1: 0.3654  loss_cls_stage2: 0.1861  loss_box_reg_stage2: 0.3184  loss_mask: 0.5658  loss_rpn_cls: 0.06429  loss_rpn_loc: 0.03367  validation_loss: 2.159  time: 1.5343  data_time: 0.0238  lr: 2.9613e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:19:55 d2.utils.events]: \u001b[0m eta: 0:28:09  iter: 8919  total_loss: 2.429  loss_cls_stage0: 0.3236  loss_box_reg_stage0: 0.2603  loss_cls_stage1: 0.2764  loss_box_reg_stage1: 0.3609  loss_cls_stage2: 0.197  loss_box_reg_stage2: 0.2751  loss_mask: 0.6003  loss_rpn_cls: 0.06178  loss_rpn_loc: 0.03432  validation_loss: 2.159  time: 1.5344  data_time: 0.0232  lr: 2.8557e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:20:26 d2.utils.events]: \u001b[0m eta: 0:27:38  iter: 8939  total_loss: 2.302  loss_cls_stage0: 0.3128  loss_box_reg_stage0: 0.2496  loss_cls_stage1: 0.261  loss_box_reg_stage1: 0.364  loss_cls_stage2: 0.1849  loss_box_reg_stage2: 0.305  loss_mask: 0.5237  loss_rpn_cls: 0.0558  loss_rpn_loc: 0.03202  validation_loss: 2.159  time: 1.5345  data_time: 0.0236  lr: 2.752e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:20:58 d2.utils.events]: \u001b[0m eta: 0:27:07  iter: 8959  total_loss: 2.447  loss_cls_stage0: 0.3319  loss_box_reg_stage0: 0.2743  loss_cls_stage1: 0.2692  loss_box_reg_stage1: 0.3906  loss_cls_stage2: 0.1925  loss_box_reg_stage2: 0.3175  loss_mask: 0.5179  loss_rpn_cls: 0.06673  loss_rpn_loc: 0.04044  validation_loss: 2.159  time: 1.5345  data_time: 0.0229  lr: 2.6501e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:21:29 d2.utils.events]: \u001b[0m eta: 0:26:35  iter: 8979  total_loss: 2.335  loss_cls_stage0: 0.3142  loss_box_reg_stage0: 0.2435  loss_cls_stage1: 0.2603  loss_box_reg_stage1: 0.3504  loss_cls_stage2: 0.1786  loss_box_reg_stage2: 0.29  loss_mask: 0.4959  loss_rpn_cls: 0.06081  loss_rpn_loc: 0.03556  validation_loss: 2.159  time: 1.5346  data_time: 0.0247  lr: 2.5501e-06  max_mem: 12121M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/27 06:22:02 d2.data.common]: \u001b[0mSerializing 857 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/27 06:22:02 d2.data.common]: \u001b[0mSerialized dataset takes 0.89 MiB\n",
      "\u001b[32m[03/27 06:22:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 857 images\n",
      "\u001b[32m[03/27 06:22:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/857. 0.0812 s / img. ETA=0:01:51\n",
      "\u001b[32m[03/27 06:22:09 d2.evaluation.evaluator]: \u001b[0mInference done 53/857. 0.0807 s / img. ETA=0:01:37\n",
      "\u001b[32m[03/27 06:22:14 d2.evaluation.evaluator]: \u001b[0mInference done 94/857. 0.0808 s / img. ETA=0:01:33\n",
      "\u001b[32m[03/27 06:22:19 d2.evaluation.evaluator]: \u001b[0mInference done 138/857. 0.0807 s / img. ETA=0:01:25\n",
      "\u001b[32m[03/27 06:22:24 d2.evaluation.evaluator]: \u001b[0mInference done 179/857. 0.0808 s / img. ETA=0:01:21\n",
      "\u001b[32m[03/27 06:22:29 d2.evaluation.evaluator]: \u001b[0mInference done 221/857. 0.0808 s / img. ETA=0:01:16\n",
      "\u001b[32m[03/27 06:22:34 d2.evaluation.evaluator]: \u001b[0mInference done 266/857. 0.0808 s / img. ETA=0:01:10\n",
      "\u001b[32m[03/27 06:22:40 d2.evaluation.evaluator]: \u001b[0mInference done 309/857. 0.0808 s / img. ETA=0:01:05\n",
      "\u001b[32m[03/27 06:22:45 d2.evaluation.evaluator]: \u001b[0mInference done 353/857. 0.0808 s / img. ETA=0:00:59\n",
      "\u001b[32m[03/27 06:22:50 d2.evaluation.evaluator]: \u001b[0mInference done 397/857. 0.0812 s / img. ETA=0:00:54\n",
      "\u001b[32m[03/27 06:22:55 d2.evaluation.evaluator]: \u001b[0mInference done 443/857. 0.0811 s / img. ETA=0:00:48\n",
      "\u001b[32m[03/27 06:23:00 d2.evaluation.evaluator]: \u001b[0mInference done 489/857. 0.0811 s / img. ETA=0:00:42\n",
      "\u001b[32m[03/27 06:23:05 d2.evaluation.evaluator]: \u001b[0mInference done 535/857. 0.0810 s / img. ETA=0:00:37\n",
      "\u001b[32m[03/27 06:23:10 d2.evaluation.evaluator]: \u001b[0mInference done 579/857. 0.0810 s / img. ETA=0:00:32\n",
      "\u001b[32m[03/27 06:23:15 d2.evaluation.evaluator]: \u001b[0mInference done 623/857. 0.0810 s / img. ETA=0:00:27\n",
      "\u001b[32m[03/27 06:23:20 d2.evaluation.evaluator]: \u001b[0mInference done 668/857. 0.0810 s / img. ETA=0:00:21\n",
      "\u001b[32m[03/27 06:23:25 d2.evaluation.evaluator]: \u001b[0mInference done 713/857. 0.0810 s / img. ETA=0:00:16\n",
      "\u001b[32m[03/27 06:23:30 d2.evaluation.evaluator]: \u001b[0mInference done 758/857. 0.0810 s / img. ETA=0:00:11\n",
      "\u001b[32m[03/27 06:23:35 d2.evaluation.evaluator]: \u001b[0mInference done 803/857. 0.0810 s / img. ETA=0:00:06\n",
      "\u001b[32m[03/27 06:23:40 d2.evaluation.evaluator]: \u001b[0mInference done 851/857. 0.0809 s / img. ETA=0:00:00\n",
      "\u001b[32m[03/27 06:23:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:37.702332 (0.114674 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/27 06:23:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:08 (0.080935 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.32 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.089\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.148\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.163\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.036\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.095\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.129\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.173\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.174\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.051\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.195\n",
      "\u001b[32m[03/27 06:23:42 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold4 in csv format:\n",
      "\u001b[32m[03/27 06:23:42 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/27 06:23:42 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/27 06:23:42 d2.evaluation.testing]: \u001b[0mcopypaste: 8.8993,14.8184,16.2601,1.0036,3.5589,9.5060\n",
      "validation do loss eval 2.4207589336826607\n",
      "\u001b[32m[03/27 06:25:11 d2.utils.events]: \u001b[0m eta: 0:26:03  iter: 8999  total_loss: 2.236  loss_cls_stage0: 0.3313  loss_box_reg_stage0: 0.2496  loss_cls_stage1: 0.2855  loss_box_reg_stage1: 0.3389  loss_cls_stage2: 0.2008  loss_box_reg_stage2: 0.2858  loss_mask: 0.5192  loss_rpn_cls: 0.06371  loss_rpn_loc: 0.03761  validation_loss: 2.213  time: 1.5347  data_time: 0.0244  lr: 2.452e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:25:42 d2.utils.events]: \u001b[0m eta: 0:25:32  iter: 9019  total_loss: 2.557  loss_cls_stage0: 0.3735  loss_box_reg_stage0: 0.2759  loss_cls_stage1: 0.3092  loss_box_reg_stage1: 0.4023  loss_cls_stage2: 0.2107  loss_box_reg_stage2: 0.3204  loss_mask: 0.5196  loss_rpn_cls: 0.06617  loss_rpn_loc: 0.04084  validation_loss: 2.213  time: 1.5347  data_time: 0.0241  lr: 2.3558e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:26:14 d2.utils.events]: \u001b[0m eta: 0:25:01  iter: 9039  total_loss: 2.346  loss_cls_stage0: 0.3237  loss_box_reg_stage0: 0.2471  loss_cls_stage1: 0.2644  loss_box_reg_stage1: 0.3513  loss_cls_stage2: 0.2  loss_box_reg_stage2: 0.2964  loss_mask: 0.4753  loss_rpn_cls: 0.0568  loss_rpn_loc: 0.03273  validation_loss: 2.213  time: 1.5348  data_time: 0.0244  lr: 2.2614e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:26:45 d2.utils.events]: \u001b[0m eta: 0:24:30  iter: 9059  total_loss: 2.389  loss_cls_stage0: 0.3285  loss_box_reg_stage0: 0.2487  loss_cls_stage1: 0.2746  loss_box_reg_stage1: 0.3602  loss_cls_stage2: 0.2053  loss_box_reg_stage2: 0.3169  loss_mask: 0.5169  loss_rpn_cls: 0.06605  loss_rpn_loc: 0.04104  validation_loss: 2.213  time: 1.5348  data_time: 0.0237  lr: 2.169e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:27:16 d2.utils.events]: \u001b[0m eta: 0:23:58  iter: 9079  total_loss: 2.459  loss_cls_stage0: 0.3361  loss_box_reg_stage0: 0.2473  loss_cls_stage1: 0.2844  loss_box_reg_stage1: 0.362  loss_cls_stage2: 0.192  loss_box_reg_stage2: 0.2809  loss_mask: 0.5202  loss_rpn_cls: 0.05642  loss_rpn_loc: 0.03357  validation_loss: 2.213  time: 1.5349  data_time: 0.0235  lr: 2.0784e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:27:48 d2.utils.events]: \u001b[0m eta: 0:23:26  iter: 9099  total_loss: 2.39  loss_cls_stage0: 0.3258  loss_box_reg_stage0: 0.2514  loss_cls_stage1: 0.2613  loss_box_reg_stage1: 0.3815  loss_cls_stage2: 0.1958  loss_box_reg_stage2: 0.3097  loss_mask: 0.5462  loss_rpn_cls: 0.05948  loss_rpn_loc: 0.03452  validation_loss: 2.213  time: 1.5350  data_time: 0.0232  lr: 1.9897e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:28:19 d2.utils.events]: \u001b[0m eta: 0:22:55  iter: 9119  total_loss: 2.413  loss_cls_stage0: 0.3348  loss_box_reg_stage0: 0.2651  loss_cls_stage1: 0.2777  loss_box_reg_stage1: 0.3762  loss_cls_stage2: 0.1905  loss_box_reg_stage2: 0.3066  loss_mask: 0.5359  loss_rpn_cls: 0.05799  loss_rpn_loc: 0.03803  validation_loss: 2.213  time: 1.5350  data_time: 0.0241  lr: 1.9029e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:28:50 d2.utils.events]: \u001b[0m eta: 0:22:24  iter: 9139  total_loss: 2.406  loss_cls_stage0: 0.3539  loss_box_reg_stage0: 0.264  loss_cls_stage1: 0.2743  loss_box_reg_stage1: 0.3619  loss_cls_stage2: 0.1884  loss_box_reg_stage2: 0.285  loss_mask: 0.5477  loss_rpn_cls: 0.0588  loss_rpn_loc: 0.036  validation_loss: 2.213  time: 1.5351  data_time: 0.0239  lr: 1.818e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:29:22 d2.utils.events]: \u001b[0m eta: 0:21:53  iter: 9159  total_loss: 2.339  loss_cls_stage0: 0.3312  loss_box_reg_stage0: 0.2585  loss_cls_stage1: 0.28  loss_box_reg_stage1: 0.3696  loss_cls_stage2: 0.1948  loss_box_reg_stage2: 0.3121  loss_mask: 0.5164  loss_rpn_cls: 0.05355  loss_rpn_loc: 0.03398  validation_loss: 2.213  time: 1.5352  data_time: 0.0246  lr: 1.735e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:29:53 d2.utils.events]: \u001b[0m eta: 0:21:21  iter: 9179  total_loss: 2.274  loss_cls_stage0: 0.3263  loss_box_reg_stage0: 0.2402  loss_cls_stage1: 0.2801  loss_box_reg_stage1: 0.3635  loss_cls_stage2: 0.1957  loss_box_reg_stage2: 0.2837  loss_mask: 0.4715  loss_rpn_cls: 0.0533  loss_rpn_loc: 0.03284  validation_loss: 2.213  time: 1.5352  data_time: 0.0240  lr: 1.6539e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:30:24 d2.utils.events]: \u001b[0m eta: 0:20:50  iter: 9199  total_loss: 2.396  loss_cls_stage0: 0.3577  loss_box_reg_stage0: 0.2804  loss_cls_stage1: 0.2759  loss_box_reg_stage1: 0.3788  loss_cls_stage2: 0.1888  loss_box_reg_stage2: 0.3212  loss_mask: 0.5544  loss_rpn_cls: 0.06058  loss_rpn_loc: 0.03771  validation_loss: 2.213  time: 1.5353  data_time: 0.0251  lr: 1.5748e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:30:56 d2.utils.events]: \u001b[0m eta: 0:20:19  iter: 9219  total_loss: 2.579  loss_cls_stage0: 0.3624  loss_box_reg_stage0: 0.3  loss_cls_stage1: 0.3  loss_box_reg_stage1: 0.3949  loss_cls_stage2: 0.2143  loss_box_reg_stage2: 0.3095  loss_mask: 0.5543  loss_rpn_cls: 0.05665  loss_rpn_loc: 0.04077  validation_loss: 2.213  time: 1.5354  data_time: 0.0267  lr: 1.4975e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:31:27 d2.utils.events]: \u001b[0m eta: 0:19:47  iter: 9239  total_loss: 2.211  loss_cls_stage0: 0.2999  loss_box_reg_stage0: 0.2466  loss_cls_stage1: 0.2499  loss_box_reg_stage1: 0.3569  loss_cls_stage2: 0.1923  loss_box_reg_stage2: 0.3029  loss_mask: 0.5075  loss_rpn_cls: 0.0574  loss_rpn_loc: 0.03504  validation_loss: 2.213  time: 1.5354  data_time: 0.0241  lr: 1.4221e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:31:58 d2.utils.events]: \u001b[0m eta: 0:19:16  iter: 9259  total_loss: 2.312  loss_cls_stage0: 0.32  loss_box_reg_stage0: 0.2476  loss_cls_stage1: 0.2649  loss_box_reg_stage1: 0.3605  loss_cls_stage2: 0.2041  loss_box_reg_stage2: 0.3215  loss_mask: 0.5274  loss_rpn_cls: 0.06688  loss_rpn_loc: 0.03485  validation_loss: 2.213  time: 1.5355  data_time: 0.0241  lr: 1.3487e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:32:29 d2.utils.events]: \u001b[0m eta: 0:18:45  iter: 9279  total_loss: 2.244  loss_cls_stage0: 0.3023  loss_box_reg_stage0: 0.2434  loss_cls_stage1: 0.2442  loss_box_reg_stage1: 0.3403  loss_cls_stage2: 0.1691  loss_box_reg_stage2: 0.2866  loss_mask: 0.5356  loss_rpn_cls: 0.05124  loss_rpn_loc: 0.03382  validation_loss: 2.213  time: 1.5356  data_time: 0.0246  lr: 1.2772e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:33:00 d2.utils.events]: \u001b[0m eta: 0:18:14  iter: 9299  total_loss: 2.165  loss_cls_stage0: 0.2791  loss_box_reg_stage0: 0.2311  loss_cls_stage1: 0.2327  loss_box_reg_stage1: 0.3329  loss_cls_stage2: 0.1852  loss_box_reg_stage2: 0.2851  loss_mask: 0.5276  loss_rpn_cls: 0.06019  loss_rpn_loc: 0.03397  validation_loss: 2.213  time: 1.5356  data_time: 0.0247  lr: 1.2076e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:33:32 d2.utils.events]: \u001b[0m eta: 0:17:42  iter: 9319  total_loss: 2.405  loss_cls_stage0: 0.3339  loss_box_reg_stage0: 0.2835  loss_cls_stage1: 0.2673  loss_box_reg_stage1: 0.4021  loss_cls_stage2: 0.1997  loss_box_reg_stage2: 0.297  loss_mask: 0.5468  loss_rpn_cls: 0.06226  loss_rpn_loc: 0.03558  validation_loss: 2.213  time: 1.5357  data_time: 0.0233  lr: 1.1399e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:34:03 d2.utils.events]: \u001b[0m eta: 0:17:11  iter: 9339  total_loss: 2.504  loss_cls_stage0: 0.3467  loss_box_reg_stage0: 0.2714  loss_cls_stage1: 0.2847  loss_box_reg_stage1: 0.3838  loss_cls_stage2: 0.2131  loss_box_reg_stage2: 0.2872  loss_mask: 0.5482  loss_rpn_cls: 0.05622  loss_rpn_loc: 0.03549  validation_loss: 2.213  time: 1.5358  data_time: 0.0249  lr: 1.0742e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:34:35 d2.utils.events]: \u001b[0m eta: 0:16:40  iter: 9359  total_loss: 1.956  loss_cls_stage0: 0.282  loss_box_reg_stage0: 0.237  loss_cls_stage1: 0.2334  loss_box_reg_stage1: 0.3142  loss_cls_stage2: 0.1627  loss_box_reg_stage2: 0.272  loss_mask: 0.4852  loss_rpn_cls: 0.05758  loss_rpn_loc: 0.03524  validation_loss: 2.213  time: 1.5358  data_time: 0.0240  lr: 1.0104e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:35:06 d2.utils.events]: \u001b[0m eta: 0:16:09  iter: 9379  total_loss: 2.403  loss_cls_stage0: 0.3198  loss_box_reg_stage0: 0.25  loss_cls_stage1: 0.2826  loss_box_reg_stage1: 0.3712  loss_cls_stage2: 0.2197  loss_box_reg_stage2: 0.3175  loss_mask: 0.5616  loss_rpn_cls: 0.06325  loss_rpn_loc: 0.03377  validation_loss: 2.213  time: 1.5359  data_time: 0.0242  lr: 9.4852e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:35:38 d2.utils.events]: \u001b[0m eta: 0:15:37  iter: 9399  total_loss: 2.483  loss_cls_stage0: 0.3251  loss_box_reg_stage0: 0.2612  loss_cls_stage1: 0.2844  loss_box_reg_stage1: 0.3877  loss_cls_stage2: 0.1972  loss_box_reg_stage2: 0.2969  loss_mask: 0.568  loss_rpn_cls: 0.06611  loss_rpn_loc: 0.04075  validation_loss: 2.213  time: 1.5360  data_time: 0.0239  lr: 8.8858e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:36:09 d2.utils.events]: \u001b[0m eta: 0:15:06  iter: 9419  total_loss: 2.434  loss_cls_stage0: 0.3437  loss_box_reg_stage0: 0.2771  loss_cls_stage1: 0.2821  loss_box_reg_stage1: 0.3791  loss_cls_stage2: 0.201  loss_box_reg_stage2: 0.3021  loss_mask: 0.5361  loss_rpn_cls: 0.05446  loss_rpn_loc: 0.03454  validation_loss: 2.213  time: 1.5360  data_time: 0.0234  lr: 8.3059e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:36:40 d2.utils.events]: \u001b[0m eta: 0:14:35  iter: 9439  total_loss: 2.426  loss_cls_stage0: 0.3431  loss_box_reg_stage0: 0.271  loss_cls_stage1: 0.278  loss_box_reg_stage1: 0.3838  loss_cls_stage2: 0.1933  loss_box_reg_stage2: 0.2942  loss_mask: 0.5164  loss_rpn_cls: 0.06528  loss_rpn_loc: 0.03777  validation_loss: 2.213  time: 1.5361  data_time: 0.0247  lr: 7.7453e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:37:11 d2.utils.events]: \u001b[0m eta: 0:14:03  iter: 9459  total_loss: 2.247  loss_cls_stage0: 0.2913  loss_box_reg_stage0: 0.2308  loss_cls_stage1: 0.2541  loss_box_reg_stage1: 0.356  loss_cls_stage2: 0.1829  loss_box_reg_stage2: 0.292  loss_mask: 0.5183  loss_rpn_cls: 0.06119  loss_rpn_loc: 0.0324  validation_loss: 2.213  time: 1.5361  data_time: 0.0241  lr: 7.2042e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:37:43 d2.utils.events]: \u001b[0m eta: 0:13:32  iter: 9479  total_loss: 2.386  loss_cls_stage0: 0.3421  loss_box_reg_stage0: 0.2692  loss_cls_stage1: 0.2664  loss_box_reg_stage1: 0.3583  loss_cls_stage2: 0.1914  loss_box_reg_stage2: 0.2708  loss_mask: 0.5564  loss_rpn_cls: 0.06936  loss_rpn_loc: 0.03419  validation_loss: 2.213  time: 1.5362  data_time: 0.0244  lr: 6.6826e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:38:14 d2.utils.events]: \u001b[0m eta: 0:13:01  iter: 9499  total_loss: 2.283  loss_cls_stage0: 0.3074  loss_box_reg_stage0: 0.2526  loss_cls_stage1: 0.2612  loss_box_reg_stage1: 0.3719  loss_cls_stage2: 0.1897  loss_box_reg_stage2: 0.2967  loss_mask: 0.5252  loss_rpn_cls: 0.06045  loss_rpn_loc: 0.03523  validation_loss: 2.213  time: 1.5362  data_time: 0.0313  lr: 6.1804e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:38:45 d2.utils.events]: \u001b[0m eta: 0:12:29  iter: 9519  total_loss: 2.268  loss_cls_stage0: 0.2986  loss_box_reg_stage0: 0.2359  loss_cls_stage1: 0.2531  loss_box_reg_stage1: 0.338  loss_cls_stage2: 0.1825  loss_box_reg_stage2: 0.2713  loss_mask: 0.4982  loss_rpn_cls: 0.05044  loss_rpn_loc: 0.03205  validation_loss: 2.213  time: 1.5363  data_time: 0.0243  lr: 5.6977e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:39:17 d2.utils.events]: \u001b[0m eta: 0:11:58  iter: 9539  total_loss: 2.418  loss_cls_stage0: 0.3613  loss_box_reg_stage0: 0.279  loss_cls_stage1: 0.2966  loss_box_reg_stage1: 0.3801  loss_cls_stage2: 0.2014  loss_box_reg_stage2: 0.3091  loss_mask: 0.4905  loss_rpn_cls: 0.05955  loss_rpn_loc: 0.03877  validation_loss: 2.213  time: 1.5364  data_time: 0.0243  lr: 5.2346e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:39:48 d2.utils.events]: \u001b[0m eta: 0:11:27  iter: 9559  total_loss: 2.58  loss_cls_stage0: 0.3643  loss_box_reg_stage0: 0.2735  loss_cls_stage1: 0.3016  loss_box_reg_stage1: 0.3868  loss_cls_stage2: 0.2195  loss_box_reg_stage2: 0.3122  loss_mask: 0.5294  loss_rpn_cls: 0.06434  loss_rpn_loc: 0.04138  validation_loss: 2.213  time: 1.5364  data_time: 0.0258  lr: 4.791e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:40:19 d2.utils.events]: \u001b[0m eta: 0:10:55  iter: 9579  total_loss: 2.206  loss_cls_stage0: 0.3058  loss_box_reg_stage0: 0.2473  loss_cls_stage1: 0.2425  loss_box_reg_stage1: 0.3359  loss_cls_stage2: 0.1733  loss_box_reg_stage2: 0.2638  loss_mask: 0.5427  loss_rpn_cls: 0.05994  loss_rpn_loc: 0.0342  validation_loss: 2.213  time: 1.5365  data_time: 0.0241  lr: 4.3669e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:40:51 d2.utils.events]: \u001b[0m eta: 0:10:24  iter: 9599  total_loss: 2.372  loss_cls_stage0: 0.3219  loss_box_reg_stage0: 0.2518  loss_cls_stage1: 0.2675  loss_box_reg_stage1: 0.3511  loss_cls_stage2: 0.1916  loss_box_reg_stage2: 0.3005  loss_mask: 0.5541  loss_rpn_cls: 0.06088  loss_rpn_loc: 0.03528  validation_loss: 2.213  time: 1.5366  data_time: 0.0240  lr: 3.9624e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:41:22 d2.utils.events]: \u001b[0m eta: 0:09:53  iter: 9619  total_loss: 2.264  loss_cls_stage0: 0.3241  loss_box_reg_stage0: 0.2703  loss_cls_stage1: 0.2614  loss_box_reg_stage1: 0.3602  loss_cls_stage2: 0.1836  loss_box_reg_stage2: 0.3122  loss_mask: 0.5367  loss_rpn_cls: 0.05456  loss_rpn_loc: 0.03279  validation_loss: 2.213  time: 1.5366  data_time: 0.0230  lr: 3.5774e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:41:53 d2.utils.events]: \u001b[0m eta: 0:09:21  iter: 9639  total_loss: 2.337  loss_cls_stage0: 0.3071  loss_box_reg_stage0: 0.2416  loss_cls_stage1: 0.2702  loss_box_reg_stage1: 0.3514  loss_cls_stage2: 0.2085  loss_box_reg_stage2: 0.301  loss_mask: 0.4813  loss_rpn_cls: 0.0587  loss_rpn_loc: 0.03374  validation_loss: 2.213  time: 1.5367  data_time: 0.0240  lr: 3.2121e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:42:25 d2.utils.events]: \u001b[0m eta: 0:08:50  iter: 9659  total_loss: 2.369  loss_cls_stage0: 0.3364  loss_box_reg_stage0: 0.2602  loss_cls_stage1: 0.2699  loss_box_reg_stage1: 0.3599  loss_cls_stage2: 0.2004  loss_box_reg_stage2: 0.27  loss_mask: 0.5122  loss_rpn_cls: 0.06069  loss_rpn_loc: 0.03246  validation_loss: 2.213  time: 1.5367  data_time: 0.0248  lr: 2.8664e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:42:56 d2.utils.events]: \u001b[0m eta: 0:08:19  iter: 9679  total_loss: 2.287  loss_cls_stage0: 0.3264  loss_box_reg_stage0: 0.2531  loss_cls_stage1: 0.267  loss_box_reg_stage1: 0.3653  loss_cls_stage2: 0.2011  loss_box_reg_stage2: 0.2995  loss_mask: 0.536  loss_rpn_cls: 0.05265  loss_rpn_loc: 0.03454  validation_loss: 2.213  time: 1.5368  data_time: 0.0240  lr: 2.5403e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:43:27 d2.utils.events]: \u001b[0m eta: 0:07:48  iter: 9699  total_loss: 2.157  loss_cls_stage0: 0.3019  loss_box_reg_stage0: 0.2396  loss_cls_stage1: 0.2458  loss_box_reg_stage1: 0.3253  loss_cls_stage2: 0.1854  loss_box_reg_stage2: 0.3044  loss_mask: 0.5177  loss_rpn_cls: 0.06011  loss_rpn_loc: 0.03229  validation_loss: 2.213  time: 1.5369  data_time: 0.0237  lr: 2.2338e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:43:58 d2.utils.events]: \u001b[0m eta: 0:07:16  iter: 9719  total_loss: 2.326  loss_cls_stage0: 0.3305  loss_box_reg_stage0: 0.2487  loss_cls_stage1: 0.2711  loss_box_reg_stage1: 0.3601  loss_cls_stage2: 0.2013  loss_box_reg_stage2: 0.3052  loss_mask: 0.5147  loss_rpn_cls: 0.05903  loss_rpn_loc: 0.03107  validation_loss: 2.213  time: 1.5369  data_time: 0.0237  lr: 1.947e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:44:30 d2.utils.events]: \u001b[0m eta: 0:06:45  iter: 9739  total_loss: 2.207  loss_cls_stage0: 0.3112  loss_box_reg_stage0: 0.2489  loss_cls_stage1: 0.2571  loss_box_reg_stage1: 0.3425  loss_cls_stage2: 0.1813  loss_box_reg_stage2: 0.2605  loss_mask: 0.5571  loss_rpn_cls: 0.05946  loss_rpn_loc: 0.03094  validation_loss: 2.213  time: 1.5369  data_time: 0.0247  lr: 1.6799e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:45:01 d2.utils.events]: \u001b[0m eta: 0:06:14  iter: 9759  total_loss: 2.558  loss_cls_stage0: 0.3705  loss_box_reg_stage0: 0.2819  loss_cls_stage1: 0.3129  loss_box_reg_stage1: 0.3942  loss_cls_stage2: 0.2209  loss_box_reg_stage2: 0.307  loss_mask: 0.4972  loss_rpn_cls: 0.05468  loss_rpn_loc: 0.03794  validation_loss: 2.213  time: 1.5370  data_time: 0.0245  lr: 1.4324e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:45:33 d2.utils.events]: \u001b[0m eta: 0:05:43  iter: 9779  total_loss: 2.428  loss_cls_stage0: 0.3379  loss_box_reg_stage0: 0.2689  loss_cls_stage1: 0.282  loss_box_reg_stage1: 0.3751  loss_cls_stage2: 0.2058  loss_box_reg_stage2: 0.3187  loss_mask: 0.5119  loss_rpn_cls: 0.05636  loss_rpn_loc: 0.03499  validation_loss: 2.213  time: 1.5371  data_time: 0.0232  lr: 1.2046e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:46:04 d2.utils.events]: \u001b[0m eta: 0:05:12  iter: 9799  total_loss: 2.462  loss_cls_stage0: 0.3516  loss_box_reg_stage0: 0.2811  loss_cls_stage1: 0.3005  loss_box_reg_stage1: 0.39  loss_cls_stage2: 0.2187  loss_box_reg_stage2: 0.3271  loss_mask: 0.5142  loss_rpn_cls: 0.07079  loss_rpn_loc: 0.04079  validation_loss: 2.213  time: 1.5372  data_time: 0.0236  lr: 9.9652e-08  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:46:36 d2.utils.events]: \u001b[0m eta: 0:04:40  iter: 9819  total_loss: 2.58  loss_cls_stage0: 0.3396  loss_box_reg_stage0: 0.2711  loss_cls_stage1: 0.3058  loss_box_reg_stage1: 0.4026  loss_cls_stage2: 0.213  loss_box_reg_stage2: 0.3267  loss_mask: 0.5715  loss_rpn_cls: 0.04997  loss_rpn_loc: 0.03356  validation_loss: 2.213  time: 1.5373  data_time: 0.0226  lr: 8.0813e-08  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:47:07 d2.utils.events]: \u001b[0m eta: 0:04:09  iter: 9839  total_loss: 2.256  loss_cls_stage0: 0.3006  loss_box_reg_stage0: 0.2445  loss_cls_stage1: 0.2316  loss_box_reg_stage1: 0.3412  loss_cls_stage2: 0.1632  loss_box_reg_stage2: 0.2749  loss_mask: 0.5605  loss_rpn_cls: 0.06278  loss_rpn_loc: 0.03535  validation_loss: 2.213  time: 1.5373  data_time: 0.0247  lr: 6.3944e-08  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:47:38 d2.utils.events]: \u001b[0m eta: 0:03:38  iter: 9859  total_loss: 2.518  loss_cls_stage0: 0.3504  loss_box_reg_stage0: 0.2791  loss_cls_stage1: 0.2815  loss_box_reg_stage1: 0.3784  loss_cls_stage2: 0.2021  loss_box_reg_stage2: 0.2953  loss_mask: 0.5578  loss_rpn_cls: 0.06416  loss_rpn_loc: 0.03924  validation_loss: 2.213  time: 1.5374  data_time: 0.0240  lr: 4.9046e-08  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:48:10 d2.utils.events]: \u001b[0m eta: 0:03:07  iter: 9879  total_loss: 2.361  loss_cls_stage0: 0.3008  loss_box_reg_stage0: 0.2456  loss_cls_stage1: 0.2656  loss_box_reg_stage1: 0.3782  loss_cls_stage2: 0.1949  loss_box_reg_stage2: 0.3094  loss_mask: 0.5343  loss_rpn_cls: 0.05789  loss_rpn_loc: 0.03671  validation_loss: 2.213  time: 1.5374  data_time: 0.0223  lr: 3.6121e-08  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:48:41 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 9899  total_loss: 2.646  loss_cls_stage0: 0.3549  loss_box_reg_stage0: 0.2761  loss_cls_stage1: 0.2922  loss_box_reg_stage1: 0.3976  loss_cls_stage2: 0.207  loss_box_reg_stage2: 0.3378  loss_mask: 0.5674  loss_rpn_cls: 0.06631  loss_rpn_loc: 0.04181  validation_loss: 2.213  time: 1.5375  data_time: 0.0231  lr: 2.5168e-08  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:49:12 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 9919  total_loss: 2.308  loss_cls_stage0: 0.2973  loss_box_reg_stage0: 0.228  loss_cls_stage1: 0.2579  loss_box_reg_stage1: 0.358  loss_cls_stage2: 0.1953  loss_box_reg_stage2: 0.2994  loss_mask: 0.5468  loss_rpn_cls: 0.06349  loss_rpn_loc: 0.03725  validation_loss: 2.213  time: 1.5376  data_time: 0.0251  lr: 1.6188e-08  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:49:44 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 9939  total_loss: 2.589  loss_cls_stage0: 0.3901  loss_box_reg_stage0: 0.3157  loss_cls_stage1: 0.3144  loss_box_reg_stage1: 0.4109  loss_cls_stage2: 0.2148  loss_box_reg_stage2: 0.3196  loss_mask: 0.5181  loss_rpn_cls: 0.06157  loss_rpn_loc: 0.03711  validation_loss: 2.213  time: 1.5376  data_time: 0.0240  lr: 9.1809e-09  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:50:15 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 9959  total_loss: 2.476  loss_cls_stage0: 0.3371  loss_box_reg_stage0: 0.2663  loss_cls_stage1: 0.274  loss_box_reg_stage1: 0.3767  loss_cls_stage2: 0.1967  loss_box_reg_stage2: 0.3147  loss_mask: 0.5623  loss_rpn_cls: 0.065  loss_rpn_loc: 0.03582  validation_loss: 2.213  time: 1.5377  data_time: 0.0314  lr: 4.1476e-09  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:50:47 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 9979  total_loss: 2.209  loss_cls_stage0: 0.2965  loss_box_reg_stage0: 0.2434  loss_cls_stage1: 0.2491  loss_box_reg_stage1: 0.3456  loss_cls_stage2: 0.1725  loss_box_reg_stage2: 0.2954  loss_mask: 0.511  loss_rpn_cls: 0.06487  loss_rpn_loc: 0.0371  validation_loss: 2.213  time: 1.5377  data_time: 0.0247  lr: 1.0881e-09  max_mem: 12121M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/27 06:51:21 d2.data.common]: \u001b[0mSerializing 857 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/27 06:51:21 d2.data.common]: \u001b[0mSerialized dataset takes 0.89 MiB\n",
      "\u001b[32m[03/27 06:51:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 857 images\n",
      "\u001b[32m[03/27 06:51:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/857. 0.0821 s / img. ETA=0:01:51\n",
      "\u001b[32m[03/27 06:51:28 d2.evaluation.evaluator]: \u001b[0mInference done 53/857. 0.0815 s / img. ETA=0:01:37\n",
      "\u001b[32m[03/27 06:51:33 d2.evaluation.evaluator]: \u001b[0mInference done 93/857. 0.0817 s / img. ETA=0:01:34\n",
      "\u001b[32m[03/27 06:51:39 d2.evaluation.evaluator]: \u001b[0mInference done 138/857. 0.0814 s / img. ETA=0:01:26\n",
      "\u001b[32m[03/27 06:51:44 d2.evaluation.evaluator]: \u001b[0mInference done 180/857. 0.0813 s / img. ETA=0:01:21\n",
      "\u001b[32m[03/27 06:51:49 d2.evaluation.evaluator]: \u001b[0mInference done 223/857. 0.0813 s / img. ETA=0:01:15\n",
      "\u001b[32m[03/27 06:51:54 d2.evaluation.evaluator]: \u001b[0mInference done 268/857. 0.0812 s / img. ETA=0:01:09\n",
      "\u001b[32m[03/27 06:51:59 d2.evaluation.evaluator]: \u001b[0mInference done 312/857. 0.0812 s / img. ETA=0:01:04\n",
      "\u001b[32m[03/27 06:52:04 d2.evaluation.evaluator]: \u001b[0mInference done 355/857. 0.0812 s / img. ETA=0:00:59\n",
      "\u001b[32m[03/27 06:52:09 d2.evaluation.evaluator]: \u001b[0mInference done 400/857. 0.0811 s / img. ETA=0:00:53\n",
      "\u001b[32m[03/27 06:52:14 d2.evaluation.evaluator]: \u001b[0mInference done 444/857. 0.0811 s / img. ETA=0:00:48\n",
      "\u001b[32m[03/27 06:52:19 d2.evaluation.evaluator]: \u001b[0mInference done 489/857. 0.0811 s / img. ETA=0:00:43\n",
      "\u001b[32m[03/27 06:52:24 d2.evaluation.evaluator]: \u001b[0mInference done 534/857. 0.0810 s / img. ETA=0:00:37\n",
      "\u001b[32m[03/27 06:52:29 d2.evaluation.evaluator]: \u001b[0mInference done 576/857. 0.0810 s / img. ETA=0:00:32\n",
      "\u001b[32m[03/27 06:52:34 d2.evaluation.evaluator]: \u001b[0mInference done 618/857. 0.0813 s / img. ETA=0:00:27\n",
      "\u001b[32m[03/27 06:52:39 d2.evaluation.evaluator]: \u001b[0mInference done 661/857. 0.0813 s / img. ETA=0:00:22\n",
      "\u001b[32m[03/27 06:52:44 d2.evaluation.evaluator]: \u001b[0mInference done 704/857. 0.0813 s / img. ETA=0:00:17\n",
      "\u001b[32m[03/27 06:52:50 d2.evaluation.evaluator]: \u001b[0mInference done 747/857. 0.0813 s / img. ETA=0:00:12\n",
      "\u001b[32m[03/27 06:52:55 d2.evaluation.evaluator]: \u001b[0mInference done 789/857. 0.0813 s / img. ETA=0:00:07\n",
      "\u001b[32m[03/27 06:53:00 d2.evaluation.evaluator]: \u001b[0mInference done 834/857. 0.0813 s / img. ETA=0:00:02\n",
      "\u001b[32m[03/27 06:53:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:39.639423 (0.116948 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/27 06:53:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:09 (0.081230 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.089\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.150\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.164\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.036\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.096\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.131\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.052\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.202\n",
      "\u001b[32m[03/27 06:53:03 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold4 in csv format:\n",
      "\u001b[32m[03/27 06:53:03 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/27 06:53:03 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/27 06:53:03 d2.evaluation.testing]: \u001b[0mcopypaste: 8.9484,14.9611,16.4081,1.0002,3.6308,9.6039\n",
      "validation do loss eval 2.4117944366151907\n",
      "\u001b[32m[03/27 06:54:32 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 2.504  loss_cls_stage0: 0.349  loss_box_reg_stage0: 0.2752  loss_cls_stage1: 0.2941  loss_box_reg_stage1: 0.3785  loss_cls_stage2: 0.2055  loss_box_reg_stage2: 0.3227  loss_mask: 0.5567  loss_rpn_cls: 0.06423  loss_rpn_loc: 0.03857  validation_loss: 2.278  time: 1.5378  data_time: 0.0247  lr: 2.4674e-12  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:54:32 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 4:16:15 (1.5378 s / it)\n",
      "\u001b[32m[03/27 06:54:32 d2.engine.hooks]: \u001b[0mTotal training time: 4:46:40 (0:30:25 on hooks)\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/27 06:54:32 d2.data.common]: \u001b[0mSerializing 857 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/27 06:54:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.89 MiB\n",
      "\u001b[32m[03/27 06:54:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 857 images\n",
      "\u001b[32m[03/27 06:54:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/857. 0.0818 s / img. ETA=0:02:02\n",
      "\u001b[32m[03/27 06:54:40 d2.evaluation.evaluator]: \u001b[0mInference done 49/857. 0.0814 s / img. ETA=0:01:49\n",
      "\u001b[32m[03/27 06:54:45 d2.evaluation.evaluator]: \u001b[0mInference done 87/857. 0.0813 s / img. ETA=0:01:43\n",
      "\u001b[32m[03/27 06:54:50 d2.evaluation.evaluator]: \u001b[0mInference done 127/857. 0.0812 s / img. ETA=0:01:36\n",
      "\u001b[32m[03/27 06:54:55 d2.evaluation.evaluator]: \u001b[0mInference done 168/857. 0.0811 s / img. ETA=0:01:30\n",
      "\u001b[32m[03/27 06:55:00 d2.evaluation.evaluator]: \u001b[0mInference done 208/857. 0.0811 s / img. ETA=0:01:24\n",
      "\u001b[32m[03/27 06:55:05 d2.evaluation.evaluator]: \u001b[0mInference done 249/857. 0.0811 s / img. ETA=0:01:18\n",
      "\u001b[32m[03/27 06:55:10 d2.evaluation.evaluator]: \u001b[0mInference done 293/857. 0.0810 s / img. ETA=0:01:11\n",
      "\u001b[32m[03/27 06:55:15 d2.evaluation.evaluator]: \u001b[0mInference done 334/857. 0.0810 s / img. ETA=0:01:06\n",
      "\u001b[32m[03/27 06:55:21 d2.evaluation.evaluator]: \u001b[0mInference done 377/857. 0.0809 s / img. ETA=0:01:00\n",
      "\u001b[32m[03/27 06:55:26 d2.evaluation.evaluator]: \u001b[0mInference done 419/857. 0.0809 s / img. ETA=0:00:54\n",
      "\u001b[32m[03/27 06:55:31 d2.evaluation.evaluator]: \u001b[0mInference done 462/857. 0.0809 s / img. ETA=0:00:49\n",
      "\u001b[32m[03/27 06:55:36 d2.evaluation.evaluator]: \u001b[0mInference done 504/857. 0.0809 s / img. ETA=0:00:43\n",
      "\u001b[32m[03/27 06:55:41 d2.evaluation.evaluator]: \u001b[0mInference done 545/857. 0.0809 s / img. ETA=0:00:38\n",
      "\u001b[32m[03/27 06:55:46 d2.evaluation.evaluator]: \u001b[0mInference done 586/857. 0.0809 s / img. ETA=0:00:33\n",
      "\u001b[32m[03/27 06:55:51 d2.evaluation.evaluator]: \u001b[0mInference done 626/857. 0.0809 s / img. ETA=0:00:28\n",
      "\u001b[32m[03/27 06:55:56 d2.evaluation.evaluator]: \u001b[0mInference done 666/857. 0.0809 s / img. ETA=0:00:23\n",
      "\u001b[32m[03/27 06:56:01 d2.evaluation.evaluator]: \u001b[0mInference done 707/857. 0.0810 s / img. ETA=0:00:18\n",
      "\u001b[32m[03/27 06:56:06 d2.evaluation.evaluator]: \u001b[0mInference done 747/857. 0.0810 s / img. ETA=0:00:13\n",
      "\u001b[32m[03/27 06:56:11 d2.evaluation.evaluator]: \u001b[0mInference done 788/857. 0.0810 s / img. ETA=0:00:08\n",
      "\u001b[32m[03/27 06:56:16 d2.evaluation.evaluator]: \u001b[0mInference done 832/857. 0.0810 s / img. ETA=0:00:03\n",
      "\u001b[32m[03/27 06:56:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:45.319314 (0.123614 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/27 06:56:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:08 (0.080937 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.50 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.089\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.150\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.164\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.036\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.096\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.131\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.052\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.202\n",
      "\u001b[32m[03/27 06:56:20 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold4 in csv format:\n",
      "\u001b[32m[03/27 06:56:20 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/27 06:56:20 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/27 06:56:20 d2.evaluation.testing]: \u001b[0mcopypaste: 8.9484,14.9611,16.4081,1.0002,3.6308,9.6039\n",
      "cfg.OUTPUT_DIR ./output -> /home/yamaguchi-milkcocholate/VinBigData/src/VinBigData-ObjectDetection/detectron2_results/results01/fold-5\n",
      "\u001b[32m[03/27 06:56:22 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): CascadeROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): ModuleList(\n",
      "      (0): FastRCNNConvFCHead(\n",
      "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "        (fc_relu1): ReLU()\n",
      "        (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (fc_relu2): ReLU()\n",
      "      )\n",
      "      (1): FastRCNNConvFCHead(\n",
      "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "        (fc_relu1): ReLU()\n",
      "        (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (fc_relu2): ReLU()\n",
      "      )\n",
      "      (2): FastRCNNConvFCHead(\n",
      "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "        (fc_relu1): ReLU()\n",
      "        (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (fc_relu2): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (box_predictor): ModuleList(\n",
      "      (0): FastRCNNOutputLayers(\n",
      "        (cls_score): Linear(in_features=1024, out_features=15, bias=True)\n",
      "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      )\n",
      "      (1): FastRCNNOutputLayers(\n",
      "        (cls_score): Linear(in_features=1024, out_features=15, bias=True)\n",
      "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      )\n",
      "      (2): FastRCNNOutputLayers(\n",
      "        (cls_score): Linear(in_features=1024, out_features=15, bias=True)\n",
      "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 14, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[AlbumentationsMapper] Augmentations used in training: Compose([\n",
      "  HorizontalFlip(always_apply=False, p=0.5),\n",
      "  ShiftScaleRotate(always_apply=False, p=0.5, shift_limit_x=(-0.0625, 0.0625), shift_limit_y=(-0.0625, 0.0625), scale_limit=(-0.15000000000000002, 0.1499999999999999), rotate_limit=(-10, 10), interpolation=1, border_mode=4, value=None, mask_value=None),\n",
      "  RandomBrightnessContrast(always_apply=False, p=0.5, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), brightness_by_max=True),\n",
      "  Blur(always_apply=False, p=0.4, blur_limit=(3, 10)),\n",
      "  IAAAffine(always_apply=False, p=0.5, scale=(1.0, 1.0), translate_percent=None, translate_px=None, rotate=(-0.0, 0.0), shear=(-0.0, 0.0), order=1, cval=0, mode='reflect'),\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/27 06:56:22 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 3495 images left.\n",
      "\u001b[32m[03/27 06:56:22 d2.data.build]: \u001b[0mDistribution of instances among all 14 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "| Aortic enla.. | 2703         |  Atelectasis  | 187          | Calcification | 583          |\n",
      "| Cardiomegaly  | 1912         | Consolidation | 339          |      ILD      | 576          |\n",
      "| Infiltration  | 749          | Lung Opacity  | 1586         |  Nodule/Mass  | 1529         |\n",
      "| Other lesion  | 1384         | Pleural eff.. | 1396         | Pleural thi.. | 3215         |\n",
      "| Pneumothorax  | 100          | Pulmonary f.. | 2689         |               |              |\n",
      "|     total     | 18948        |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/27 06:56:22 d2.data.common]: \u001b[0mSerializing 3495 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/27 06:56:22 d2.data.common]: \u001b[0mSerialized dataset takes 3.61 MiB\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/27 06:56:22 d2.data.build]: \u001b[0mDistribution of instances among all 14 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "| Aortic enla.. | 672          |  Atelectasis  | 45           | Calcification | 160          |\n",
      "| Cardiomegaly  | 471          | Consolidation | 84           |      ILD      | 145          |\n",
      "| Infiltration  | 194          | Lung Opacity  | 393          |  Nodule/Mass  | 323          |\n",
      "| Other lesion  | 423          | Pleural eff.. | 352          | Pleural thi.. | 810          |\n",
      "| Pneumothorax  | 29           | Pulmonary f.. | 665          |               |              |\n",
      "|     total     | 4766         |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/27 06:56:22 d2.data.common]: \u001b[0mSerializing 883 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/27 06:56:22 d2.data.common]: \u001b[0mSerialized dataset takes 0.91 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'proposal_generator.anchor_generator.cell_anchors.0' to the model due to incompatible shapes: (3, 4) in the checkpoint but (5, 4) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.anchor_generator.cell_anchors.1' to the model due to incompatible shapes: (3, 4) in the checkpoint but (5, 4) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.anchor_generator.cell_anchors.2' to the model due to incompatible shapes: (3, 4) in the checkpoint but (5, 4) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.anchor_generator.cell_anchors.3' to the model due to incompatible shapes: (3, 4) in the checkpoint but (5, 4) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.anchor_generator.cell_anchors.4' to the model due to incompatible shapes: (3, 4) in the checkpoint but (5, 4) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.objectness_logits.weight' to the model due to incompatible shapes: (3, 256, 1, 1) in the checkpoint but (5, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.objectness_logits.bias' to the model due to incompatible shapes: (3,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.anchor_deltas.weight' to the model due to incompatible shapes: (12, 256, 1, 1) in the checkpoint but (20, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.anchor_deltas.bias' to the model due to incompatible shapes: (12,) in the checkpoint but (20,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.0.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (15, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.0.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (15,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.1.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (15, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.1.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (15,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.2.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (15, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.2.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (15,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (14, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (14,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/27 06:56:23 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/27 06:56:49 d2.utils.events]: \u001b[0m eta: 3:43:09  iter: 19  total_loss: 10.07  loss_cls_stage0: 2.787  loss_box_reg_stage0: 0.02193  loss_cls_stage1: 2.977  loss_box_reg_stage1: 0.04863  loss_cls_stage2: 2.668  loss_box_reg_stage2: 0.02998  loss_mask: 0.693  loss_rpn_cls: 0.8015  loss_rpn_loc: 0.04453  time: 1.3411  data_time: 0.0492  lr: 1.9981e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:57:16 d2.utils.events]: \u001b[0m eta: 3:42:41  iter: 39  total_loss: 9.466  loss_cls_stage0: 2.604  loss_box_reg_stage0: 0.02028  loss_cls_stage1: 2.742  loss_box_reg_stage1: 0.04573  loss_cls_stage2: 2.46  loss_box_reg_stage2: 0.03316  loss_mask: 0.6928  loss_rpn_cls: 0.7915  loss_rpn_loc: 0.05012  time: 1.3413  data_time: 0.0255  lr: 3.996e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:57:43 d2.utils.events]: \u001b[0m eta: 3:42:20  iter: 59  total_loss: 8.238  loss_cls_stage0: 2.218  loss_box_reg_stage0: 0.02088  loss_cls_stage1: 2.339  loss_box_reg_stage1: 0.04973  loss_cls_stage2: 2.074  loss_box_reg_stage2: 0.03646  loss_mask: 0.6924  loss_rpn_cls: 0.7664  loss_rpn_loc: 0.04948  time: 1.3454  data_time: 0.0236  lr: 5.9936e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:58:10 d2.utils.events]: \u001b[0m eta: 3:41:55  iter: 79  total_loss: 6.568  loss_cls_stage0: 1.673  loss_box_reg_stage0: 0.02173  loss_cls_stage1: 1.75  loss_box_reg_stage1: 0.04767  loss_cls_stage2: 1.524  loss_box_reg_stage2: 0.03088  loss_mask: 0.6926  loss_rpn_cls: 0.736  loss_rpn_loc: 0.05249  time: 1.3453  data_time: 0.0238  lr: 7.9909e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:58:37 d2.utils.events]: \u001b[0m eta: 3:41:40  iter: 99  total_loss: 4.645  loss_cls_stage0: 1.076  loss_box_reg_stage0: 0.02627  loss_cls_stage1: 1.085  loss_box_reg_stage1: 0.05296  loss_cls_stage2: 0.9038  loss_box_reg_stage2: 0.03483  loss_mask: 0.6921  loss_rpn_cls: 0.7006  loss_rpn_loc: 0.05328  time: 1.3474  data_time: 0.0243  lr: 9.9877e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:59:05 d2.utils.events]: \u001b[0m eta: 3:41:26  iter: 119  total_loss: 3.147  loss_cls_stage0: 0.5893  loss_box_reg_stage0: 0.02732  loss_cls_stage1: 0.5708  loss_box_reg_stage1: 0.05501  loss_cls_stage2: 0.4696  loss_box_reg_stage2: 0.03845  loss_mask: 0.6913  loss_rpn_cls: 0.6477  loss_rpn_loc: 0.05954  time: 1.3489  data_time: 0.0235  lr: 1.1984e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 06:59:32 d2.utils.events]: \u001b[0m eta: 3:41:31  iter: 139  total_loss: 2.524  loss_cls_stage0: 0.3587  loss_box_reg_stage0: 0.02714  loss_cls_stage1: 0.3749  loss_box_reg_stage1: 0.05529  loss_cls_stage2: 0.3081  loss_box_reg_stage2: 0.03468  loss_mask: 0.6912  loss_rpn_cls: 0.5912  loss_rpn_loc: 0.05961  time: 1.3525  data_time: 0.0240  lr: 1.3979e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:00:00 d2.utils.events]: \u001b[0m eta: 3:41:23  iter: 159  total_loss: 2.415  loss_cls_stage0: 0.318  loss_box_reg_stage0: 0.03752  loss_cls_stage1: 0.3691  loss_box_reg_stage1: 0.06299  loss_cls_stage2: 0.3034  loss_box_reg_stage2: 0.04098  loss_mask: 0.6904  loss_rpn_cls: 0.526  loss_rpn_loc: 0.064  time: 1.3593  data_time: 0.0242  lr: 1.5974e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:00:29 d2.utils.events]: \u001b[0m eta: 3:41:18  iter: 179  total_loss: 2.45  loss_cls_stage0: 0.3358  loss_box_reg_stage0: 0.05863  loss_cls_stage1: 0.392  loss_box_reg_stage1: 0.06812  loss_cls_stage2: 0.3463  loss_box_reg_stage2: 0.04275  loss_mask: 0.6887  loss_rpn_cls: 0.4616  loss_rpn_loc: 0.05626  time: 1.3689  data_time: 0.0251  lr: 1.7968e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:00:58 d2.utils.events]: \u001b[0m eta: 3:41:23  iter: 199  total_loss: 2.434  loss_cls_stage0: 0.3405  loss_box_reg_stage0: 0.09813  loss_cls_stage1: 0.3726  loss_box_reg_stage1: 0.08822  loss_cls_stage2: 0.3375  loss_box_reg_stage2: 0.04631  loss_mask: 0.6877  loss_rpn_cls: 0.393  loss_rpn_loc: 0.04625  time: 1.3787  data_time: 0.0241  lr: 1.9961e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:01:28 d2.utils.events]: \u001b[0m eta: 3:41:35  iter: 219  total_loss: 2.305  loss_cls_stage0: 0.3229  loss_box_reg_stage0: 0.1248  loss_cls_stage1: 0.3166  loss_box_reg_stage1: 0.1086  loss_cls_stage2: 0.2875  loss_box_reg_stage2: 0.05447  loss_mask: 0.6876  loss_rpn_cls: 0.3381  loss_rpn_loc: 0.05735  time: 1.3880  data_time: 0.0247  lr: 2.1952e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:01:58 d2.utils.events]: \u001b[0m eta: 3:42:06  iter: 239  total_loss: 2.015  loss_cls_stage0: 0.266  loss_box_reg_stage0: 0.1042  loss_cls_stage1: 0.2444  loss_box_reg_stage1: 0.09112  loss_cls_stage2: 0.224  loss_box_reg_stage2: 0.05707  loss_mask: 0.6879  loss_rpn_cls: 0.291  loss_rpn_loc: 0.05819  time: 1.3962  data_time: 0.0225  lr: 2.3942e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:02:27 d2.utils.events]: \u001b[0m eta: 3:43:28  iter: 259  total_loss: 1.816  loss_cls_stage0: 0.2295  loss_box_reg_stage0: 0.09006  loss_cls_stage1: 0.1898  loss_box_reg_stage1: 0.08455  loss_cls_stage2: 0.1627  loss_box_reg_stage2: 0.0488  loss_mask: 0.6867  loss_rpn_cls: 0.2459  loss_rpn_loc: 0.04714  time: 1.4025  data_time: 0.0239  lr: 2.5931e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:02:57 d2.utils.events]: \u001b[0m eta: 3:46:02  iter: 279  total_loss: 1.798  loss_cls_stage0: 0.2378  loss_box_reg_stage0: 0.1063  loss_cls_stage1: 0.1904  loss_box_reg_stage1: 0.09966  loss_cls_stage2: 0.1539  loss_box_reg_stage2: 0.05757  loss_mask: 0.6767  loss_rpn_cls: 0.2261  loss_rpn_loc: 0.04805  time: 1.4089  data_time: 0.0242  lr: 2.7918e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:03:27 d2.utils.events]: \u001b[0m eta: 3:47:53  iter: 299  total_loss: 1.798  loss_cls_stage0: 0.2572  loss_box_reg_stage0: 0.1275  loss_cls_stage1: 0.1832  loss_box_reg_stage1: 0.1029  loss_cls_stage2: 0.1393  loss_box_reg_stage2: 0.0585  loss_mask: 0.6837  loss_rpn_cls: 0.2104  loss_rpn_loc: 0.04894  time: 1.4141  data_time: 0.0242  lr: 2.9904e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:03:57 d2.utils.events]: \u001b[0m eta: 3:50:19  iter: 319  total_loss: 1.865  loss_cls_stage0: 0.2721  loss_box_reg_stage0: 0.1244  loss_cls_stage1: 0.1975  loss_box_reg_stage1: 0.1082  loss_cls_stage2: 0.1383  loss_box_reg_stage2: 0.06456  loss_mask: 0.6725  loss_rpn_cls: 0.2013  loss_rpn_loc: 0.05366  time: 1.4189  data_time: 0.0239  lr: 3.1888e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:04:27 d2.utils.events]: \u001b[0m eta: 3:52:11  iter: 339  total_loss: 1.724  loss_cls_stage0: 0.2508  loss_box_reg_stage0: 0.1146  loss_cls_stage1: 0.1872  loss_box_reg_stage1: 0.08857  loss_cls_stage2: 0.1322  loss_box_reg_stage2: 0.0625  loss_mask: 0.6645  loss_rpn_cls: 0.1919  loss_rpn_loc: 0.05047  time: 1.4232  data_time: 0.0249  lr: 3.387e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:04:56 d2.utils.events]: \u001b[0m eta: 3:54:14  iter: 359  total_loss: 1.825  loss_cls_stage0: 0.2584  loss_box_reg_stage0: 0.1157  loss_cls_stage1: 0.191  loss_box_reg_stage1: 0.1111  loss_cls_stage2: 0.1278  loss_box_reg_stage2: 0.0589  loss_mask: 0.6819  loss_rpn_cls: 0.1798  loss_rpn_loc: 0.04514  time: 1.4273  data_time: 0.0262  lr: 3.585e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:05:26 d2.utils.events]: \u001b[0m eta: 3:54:39  iter: 379  total_loss: 1.695  loss_cls_stage0: 0.2507  loss_box_reg_stage0: 0.1064  loss_cls_stage1: 0.1735  loss_box_reg_stage1: 0.09038  loss_cls_stage2: 0.1351  loss_box_reg_stage2: 0.06021  loss_mask: 0.6739  loss_rpn_cls: 0.1788  loss_rpn_loc: 0.04751  time: 1.4307  data_time: 0.0241  lr: 3.7828e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:05:56 d2.utils.events]: \u001b[0m eta: 3:54:56  iter: 399  total_loss: 1.664  loss_cls_stage0: 0.238  loss_box_reg_stage0: 0.1026  loss_cls_stage1: 0.1725  loss_box_reg_stage1: 0.0934  loss_cls_stage2: 0.1296  loss_box_reg_stage2: 0.06009  loss_mask: 0.6742  loss_rpn_cls: 0.1779  loss_rpn_loc: 0.04334  time: 1.4337  data_time: 0.0236  lr: 3.9803e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:06:26 d2.utils.events]: \u001b[0m eta: 3:54:45  iter: 419  total_loss: 1.702  loss_cls_stage0: 0.2567  loss_box_reg_stage0: 0.1125  loss_cls_stage1: 0.1728  loss_box_reg_stage1: 0.09493  loss_cls_stage2: 0.1146  loss_box_reg_stage2: 0.05929  loss_mask: 0.6666  loss_rpn_cls: 0.1645  loss_rpn_loc: 0.04401  time: 1.4370  data_time: 0.0246  lr: 4.1777e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:06:56 d2.utils.events]: \u001b[0m eta: 3:54:35  iter: 439  total_loss: 1.724  loss_cls_stage0: 0.2747  loss_box_reg_stage0: 0.1321  loss_cls_stage1: 0.1802  loss_box_reg_stage1: 0.1037  loss_cls_stage2: 0.1272  loss_box_reg_stage2: 0.06403  loss_mask: 0.6566  loss_rpn_cls: 0.1636  loss_rpn_loc: 0.0454  time: 1.4398  data_time: 0.0244  lr: 4.3747e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:07:26 d2.utils.events]: \u001b[0m eta: 3:54:28  iter: 459  total_loss: 1.716  loss_cls_stage0: 0.2603  loss_box_reg_stage0: 0.118  loss_cls_stage1: 0.1875  loss_box_reg_stage1: 0.1101  loss_cls_stage2: 0.1334  loss_box_reg_stage2: 0.06444  loss_mask: 0.6873  loss_rpn_cls: 0.1559  loss_rpn_loc: 0.04253  time: 1.4427  data_time: 0.0226  lr: 4.5716e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:07:56 d2.utils.events]: \u001b[0m eta: 3:54:15  iter: 479  total_loss: 1.813  loss_cls_stage0: 0.3018  loss_box_reg_stage0: 0.1368  loss_cls_stage1: 0.2034  loss_box_reg_stage1: 0.1246  loss_cls_stage2: 0.1328  loss_box_reg_stage2: 0.07073  loss_mask: 0.6569  loss_rpn_cls: 0.1545  loss_rpn_loc: 0.04385  time: 1.4454  data_time: 0.0238  lr: 4.7681e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:08:27 d2.utils.events]: \u001b[0m eta: 3:53:57  iter: 499  total_loss: 1.901  loss_cls_stage0: 0.3207  loss_box_reg_stage0: 0.154  loss_cls_stage1: 0.2144  loss_box_reg_stage1: 0.1308  loss_cls_stage2: 0.1391  loss_box_reg_stage2: 0.0731  loss_mask: 0.6486  loss_rpn_cls: 0.1606  loss_rpn_loc: 0.04682  time: 1.4478  data_time: 0.0237  lr: 4.9644e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:08:57 d2.utils.events]: \u001b[0m eta: 3:53:38  iter: 519  total_loss: 1.82  loss_cls_stage0: 0.3071  loss_box_reg_stage0: 0.1479  loss_cls_stage1: 0.2017  loss_box_reg_stage1: 0.1228  loss_cls_stage2: 0.1325  loss_box_reg_stage2: 0.06807  loss_mask: 0.6416  loss_rpn_cls: 0.1582  loss_rpn_loc: 0.04689  time: 1.4503  data_time: 0.0251  lr: 5.1604e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:09:27 d2.utils.events]: \u001b[0m eta: 3:53:27  iter: 539  total_loss: 1.839  loss_cls_stage0: 0.2988  loss_box_reg_stage0: 0.1429  loss_cls_stage1: 0.2043  loss_box_reg_stage1: 0.1272  loss_cls_stage2: 0.1379  loss_box_reg_stage2: 0.07994  loss_mask: 0.6722  loss_rpn_cls: 0.1543  loss_rpn_loc: 0.04448  time: 1.4523  data_time: 0.0239  lr: 5.356e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:09:57 d2.utils.events]: \u001b[0m eta: 3:53:11  iter: 559  total_loss: 1.863  loss_cls_stage0: 0.3126  loss_box_reg_stage0: 0.1603  loss_cls_stage1: 0.2043  loss_box_reg_stage1: 0.1279  loss_cls_stage2: 0.1353  loss_box_reg_stage2: 0.07502  loss_mask: 0.6653  loss_rpn_cls: 0.1538  loss_rpn_loc: 0.04529  time: 1.4542  data_time: 0.0237  lr: 5.5514e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:10:27 d2.utils.events]: \u001b[0m eta: 3:52:49  iter: 579  total_loss: 1.877  loss_cls_stage0: 0.3141  loss_box_reg_stage0: 0.1542  loss_cls_stage1: 0.2152  loss_box_reg_stage1: 0.1256  loss_cls_stage2: 0.1396  loss_box_reg_stage2: 0.07346  loss_mask: 0.6645  loss_rpn_cls: 0.1559  loss_rpn_loc: 0.04728  time: 1.4561  data_time: 0.0255  lr: 5.7464e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:10:57 d2.utils.events]: \u001b[0m eta: 3:52:29  iter: 599  total_loss: 1.758  loss_cls_stage0: 0.2961  loss_box_reg_stage0: 0.1479  loss_cls_stage1: 0.195  loss_box_reg_stage1: 0.1229  loss_cls_stage2: 0.1242  loss_box_reg_stage2: 0.06829  loss_mask: 0.6331  loss_rpn_cls: 0.1442  loss_rpn_loc: 0.04127  time: 1.4575  data_time: 0.0242  lr: 5.9411e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:11:27 d2.utils.events]: \u001b[0m eta: 3:52:03  iter: 619  total_loss: 1.906  loss_cls_stage0: 0.3285  loss_box_reg_stage0: 0.1551  loss_cls_stage1: 0.2105  loss_box_reg_stage1: 0.1275  loss_cls_stage2: 0.1419  loss_box_reg_stage2: 0.07407  loss_mask: 0.697  loss_rpn_cls: 0.1595  loss_rpn_loc: 0.04695  time: 1.4590  data_time: 0.0241  lr: 6.1354e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:11:57 d2.utils.events]: \u001b[0m eta: 3:51:36  iter: 639  total_loss: 1.827  loss_cls_stage0: 0.3042  loss_box_reg_stage0: 0.1467  loss_cls_stage1: 0.2011  loss_box_reg_stage1: 0.1211  loss_cls_stage2: 0.1361  loss_box_reg_stage2: 0.07516  loss_mask: 0.6516  loss_rpn_cls: 0.1358  loss_rpn_loc: 0.037  time: 1.4602  data_time: 0.0260  lr: 6.3294e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:12:27 d2.utils.events]: \u001b[0m eta: 3:51:08  iter: 659  total_loss: 1.934  loss_cls_stage0: 0.3165  loss_box_reg_stage0: 0.1523  loss_cls_stage1: 0.2203  loss_box_reg_stage1: 0.1266  loss_cls_stage2: 0.1403  loss_box_reg_stage2: 0.07609  loss_mask: 0.682  loss_rpn_cls: 0.1414  loss_rpn_loc: 0.04185  time: 1.4615  data_time: 0.0244  lr: 6.523e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:12:57 d2.utils.events]: \u001b[0m eta: 3:50:43  iter: 679  total_loss: 1.897  loss_cls_stage0: 0.3007  loss_box_reg_stage0: 0.1478  loss_cls_stage1: 0.2088  loss_box_reg_stage1: 0.1218  loss_cls_stage2: 0.1379  loss_box_reg_stage2: 0.07538  loss_mask: 0.6626  loss_rpn_cls: 0.1691  loss_rpn_loc: 0.04726  time: 1.4626  data_time: 0.0253  lr: 6.7162e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:13:27 d2.utils.events]: \u001b[0m eta: 3:50:20  iter: 699  total_loss: 1.967  loss_cls_stage0: 0.3285  loss_box_reg_stage0: 0.1627  loss_cls_stage1: 0.2332  loss_box_reg_stage1: 0.1414  loss_cls_stage2: 0.1498  loss_box_reg_stage2: 0.08449  loss_mask: 0.6673  loss_rpn_cls: 0.1408  loss_rpn_loc: 0.04367  time: 1.4637  data_time: 0.0232  lr: 6.909e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:13:58 d2.utils.events]: \u001b[0m eta: 3:49:53  iter: 719  total_loss: 1.837  loss_cls_stage0: 0.3134  loss_box_reg_stage0: 0.1509  loss_cls_stage1: 0.2203  loss_box_reg_stage1: 0.1355  loss_cls_stage2: 0.1379  loss_box_reg_stage2: 0.07684  loss_mask: 0.6495  loss_rpn_cls: 0.1525  loss_rpn_loc: 0.0405  time: 1.4649  data_time: 0.0244  lr: 7.1015e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:14:27 d2.utils.events]: \u001b[0m eta: 3:49:25  iter: 739  total_loss: 1.796  loss_cls_stage0: 0.3013  loss_box_reg_stage0: 0.1481  loss_cls_stage1: 0.1911  loss_box_reg_stage1: 0.1177  loss_cls_stage2: 0.1267  loss_box_reg_stage2: 0.06861  loss_mask: 0.6572  loss_rpn_cls: 0.1416  loss_rpn_loc: 0.04156  time: 1.4656  data_time: 0.0251  lr: 7.2934e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:14:57 d2.utils.events]: \u001b[0m eta: 3:48:57  iter: 759  total_loss: 1.89  loss_cls_stage0: 0.3211  loss_box_reg_stage0: 0.1628  loss_cls_stage1: 0.2245  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.1393  loss_box_reg_stage2: 0.08292  loss_mask: 0.6397  loss_rpn_cls: 0.1376  loss_rpn_loc: 0.0417  time: 1.4667  data_time: 0.0239  lr: 7.485e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:15:27 d2.utils.events]: \u001b[0m eta: 3:48:32  iter: 779  total_loss: 1.946  loss_cls_stage0: 0.3221  loss_box_reg_stage0: 0.1494  loss_cls_stage1: 0.2161  loss_box_reg_stage1: 0.1403  loss_cls_stage2: 0.1352  loss_box_reg_stage2: 0.08169  loss_mask: 0.6541  loss_rpn_cls: 0.1527  loss_rpn_loc: 0.04352  time: 1.4675  data_time: 0.0237  lr: 7.6761e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:15:57 d2.utils.events]: \u001b[0m eta: 3:48:05  iter: 799  total_loss: 1.846  loss_cls_stage0: 0.3063  loss_box_reg_stage0: 0.154  loss_cls_stage1: 0.2016  loss_box_reg_stage1: 0.1308  loss_cls_stage2: 0.1338  loss_box_reg_stage2: 0.0802  loss_mask: 0.6605  loss_rpn_cls: 0.1362  loss_rpn_loc: 0.03899  time: 1.4681  data_time: 0.0241  lr: 7.8668e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:16:27 d2.utils.events]: \u001b[0m eta: 3:47:40  iter: 819  total_loss: 1.915  loss_cls_stage0: 0.3039  loss_box_reg_stage0: 0.1653  loss_cls_stage1: 0.2152  loss_box_reg_stage1: 0.1446  loss_cls_stage2: 0.1402  loss_box_reg_stage2: 0.07784  loss_mask: 0.663  loss_rpn_cls: 0.1281  loss_rpn_loc: 0.04136  time: 1.4689  data_time: 0.0231  lr: 8.057e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:16:57 d2.utils.events]: \u001b[0m eta: 3:47:11  iter: 839  total_loss: 1.896  loss_cls_stage0: 0.3101  loss_box_reg_stage0: 0.149  loss_cls_stage1: 0.2079  loss_box_reg_stage1: 0.1323  loss_cls_stage2: 0.1325  loss_box_reg_stage2: 0.08125  loss_mask: 0.6366  loss_rpn_cls: 0.1416  loss_rpn_loc: 0.04149  time: 1.4696  data_time: 0.0235  lr: 8.2467e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:17:27 d2.utils.events]: \u001b[0m eta: 3:46:44  iter: 859  total_loss: 1.999  loss_cls_stage0: 0.3224  loss_box_reg_stage0: 0.1588  loss_cls_stage1: 0.2329  loss_box_reg_stage1: 0.1445  loss_cls_stage2: 0.1455  loss_box_reg_stage2: 0.09071  loss_mask: 0.6556  loss_rpn_cls: 0.1372  loss_rpn_loc: 0.0427  time: 1.4702  data_time: 0.0251  lr: 8.4359e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:17:57 d2.utils.events]: \u001b[0m eta: 3:46:16  iter: 879  total_loss: 1.915  loss_cls_stage0: 0.3101  loss_box_reg_stage0: 0.1564  loss_cls_stage1: 0.2168  loss_box_reg_stage1: 0.1402  loss_cls_stage2: 0.1466  loss_box_reg_stage2: 0.09658  loss_mask: 0.6439  loss_rpn_cls: 0.1274  loss_rpn_loc: 0.04047  time: 1.4709  data_time: 0.0233  lr: 8.6247e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:18:27 d2.utils.events]: \u001b[0m eta: 3:45:48  iter: 899  total_loss: 1.883  loss_cls_stage0: 0.3153  loss_box_reg_stage0: 0.1524  loss_cls_stage1: 0.2227  loss_box_reg_stage1: 0.1363  loss_cls_stage2: 0.1444  loss_box_reg_stage2: 0.08428  loss_mask: 0.6411  loss_rpn_cls: 0.1435  loss_rpn_loc: 0.03953  time: 1.4713  data_time: 0.0241  lr: 8.8129e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:18:57 d2.utils.events]: \u001b[0m eta: 3:45:19  iter: 919  total_loss: 1.898  loss_cls_stage0: 0.3051  loss_box_reg_stage0: 0.1517  loss_cls_stage1: 0.216  loss_box_reg_stage1: 0.1404  loss_cls_stage2: 0.1398  loss_box_reg_stage2: 0.07959  loss_mask: 0.6563  loss_rpn_cls: 0.1285  loss_rpn_loc: 0.04008  time: 1.4717  data_time: 0.0299  lr: 9.0006e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:19:27 d2.utils.events]: \u001b[0m eta: 3:44:51  iter: 939  total_loss: 2.117  loss_cls_stage0: 0.3438  loss_box_reg_stage0: 0.1752  loss_cls_stage1: 0.2398  loss_box_reg_stage1: 0.1594  loss_cls_stage2: 0.1647  loss_box_reg_stage2: 0.1028  loss_mask: 0.6556  loss_rpn_cls: 0.1385  loss_rpn_loc: 0.04875  time: 1.4724  data_time: 0.0237  lr: 9.1878e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:19:57 d2.utils.events]: \u001b[0m eta: 3:44:22  iter: 959  total_loss: 1.857  loss_cls_stage0: 0.306  loss_box_reg_stage0: 0.1553  loss_cls_stage1: 0.2191  loss_box_reg_stage1: 0.1424  loss_cls_stage2: 0.1401  loss_box_reg_stage2: 0.08465  loss_mask: 0.6275  loss_rpn_cls: 0.1304  loss_rpn_loc: 0.0386  time: 1.4728  data_time: 0.0249  lr: 9.3744e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:20:27 d2.utils.events]: \u001b[0m eta: 3:43:51  iter: 979  total_loss: 1.642  loss_cls_stage0: 0.2692  loss_box_reg_stage0: 0.1353  loss_cls_stage1: 0.1846  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.1303  loss_box_reg_stage2: 0.08258  loss_mask: 0.6218  loss_rpn_cls: 0.1158  loss_rpn_loc: 0.03826  time: 1.4731  data_time: 0.0228  lr: 9.5605e-05  max_mem: 12121M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/27 07:20:58 d2.data.common]: \u001b[0mSerializing 883 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/27 07:20:59 d2.data.common]: \u001b[0mSerialized dataset takes 0.91 MiB\n",
      "\u001b[32m[03/27 07:20:59 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'vinbigdata_valid_fold5' to COCO format ...)\n",
      "\u001b[32m[03/27 07:20:59 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
      "\u001b[32m[03/27 07:20:59 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 883, #annotations: 4766\n",
      "\u001b[32m[03/27 07:20:59 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at '/home/yamaguchi-milkcocholate/VinBigData/src/VinBigData-ObjectDetection/detectron2_results/results01/fold-5/inference/vinbigdata_valid_fold5_coco_format.json' ...\n",
      "\u001b[32m[03/27 07:20:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 883 images\n",
      "\u001b[32m[03/27 07:21:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/883. 0.0767 s / img. ETA=0:01:08\n",
      "\u001b[32m[03/27 07:21:06 d2.evaluation.evaluator]: \u001b[0mInference done 75/883. 0.0765 s / img. ETA=0:01:03\n",
      "\u001b[32m[03/27 07:21:11 d2.evaluation.evaluator]: \u001b[0mInference done 138/883. 0.0765 s / img. ETA=0:00:59\n",
      "\u001b[32m[03/27 07:21:16 d2.evaluation.evaluator]: \u001b[0mInference done 201/883. 0.0767 s / img. ETA=0:00:54\n",
      "\u001b[32m[03/27 07:21:21 d2.evaluation.evaluator]: \u001b[0mInference done 264/883. 0.0767 s / img. ETA=0:00:49\n",
      "\u001b[32m[03/27 07:21:26 d2.evaluation.evaluator]: \u001b[0mInference done 328/883. 0.0766 s / img. ETA=0:00:44\n",
      "\u001b[32m[03/27 07:21:31 d2.evaluation.evaluator]: \u001b[0mInference done 392/883. 0.0766 s / img. ETA=0:00:38\n",
      "\u001b[32m[03/27 07:21:36 d2.evaluation.evaluator]: \u001b[0mInference done 456/883. 0.0765 s / img. ETA=0:00:33\n",
      "\u001b[32m[03/27 07:21:41 d2.evaluation.evaluator]: \u001b[0mInference done 520/883. 0.0765 s / img. ETA=0:00:28\n",
      "\u001b[32m[03/27 07:21:46 d2.evaluation.evaluator]: \u001b[0mInference done 584/883. 0.0765 s / img. ETA=0:00:23\n",
      "\u001b[32m[03/27 07:21:51 d2.evaluation.evaluator]: \u001b[0mInference done 647/883. 0.0765 s / img. ETA=0:00:18\n",
      "\u001b[32m[03/27 07:21:56 d2.evaluation.evaluator]: \u001b[0mInference done 710/883. 0.0766 s / img. ETA=0:00:13\n",
      "\u001b[32m[03/27 07:22:01 d2.evaluation.evaluator]: \u001b[0mInference done 774/883. 0.0765 s / img. ETA=0:00:08\n",
      "\u001b[32m[03/27 07:22:06 d2.evaluation.evaluator]: \u001b[0mInference done 838/883. 0.0765 s / img. ETA=0:00:03\n",
      "\u001b[32m[03/27 07:22:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:09.668895 (0.079350 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/27 07:22:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:07 (0.076494 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.32 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "\u001b[32m[03/27 07:22:10 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold5 in csv format:\n",
      "\u001b[32m[03/27 07:22:10 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/27 07:22:10 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/27 07:22:10 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n",
      "validation do loss eval 1.96785978361738\n",
      "\u001b[32m[03/27 07:23:39 d2.utils.events]: \u001b[0m eta: 3:43:23  iter: 999  total_loss: 1.984  loss_cls_stage0: 0.3055  loss_box_reg_stage0: 0.158  loss_cls_stage1: 0.2325  loss_box_reg_stage1: 0.1471  loss_cls_stage2: 0.1434  loss_box_reg_stage2: 0.08617  loss_mask: 0.6596  loss_rpn_cls: 0.1345  loss_rpn_loc: 0.04232  validation_loss: 1.968  time: 1.4736  data_time: 0.0243  lr: 9.746e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:24:08 d2.utils.events]: \u001b[0m eta: 3:42:57  iter: 1019  total_loss: 1.819  loss_cls_stage0: 0.2884  loss_box_reg_stage0: 0.1369  loss_cls_stage1: 0.2054  loss_box_reg_stage1: 0.1284  loss_cls_stage2: 0.1393  loss_box_reg_stage2: 0.07834  loss_mask: 0.5997  loss_rpn_cls: 0.1209  loss_rpn_loc: 0.04004  validation_loss: 1.968  time: 1.4734  data_time: 0.0242  lr: 9.746e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:24:38 d2.utils.events]: \u001b[0m eta: 3:42:31  iter: 1039  total_loss: 1.883  loss_cls_stage0: 0.3243  loss_box_reg_stage0: 0.1704  loss_cls_stage1: 0.2193  loss_box_reg_stage1: 0.1529  loss_cls_stage2: 0.1412  loss_box_reg_stage2: 0.08579  loss_mask: 0.6255  loss_rpn_cls: 0.1158  loss_rpn_loc: 0.04162  validation_loss: 1.968  time: 1.4740  data_time: 0.0241  lr: 9.736e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:25:08 d2.utils.events]: \u001b[0m eta: 3:42:06  iter: 1059  total_loss: 1.972  loss_cls_stage0: 0.3451  loss_box_reg_stage0: 0.1701  loss_cls_stage1: 0.2512  loss_box_reg_stage1: 0.1556  loss_cls_stage2: 0.1671  loss_box_reg_stage2: 0.09492  loss_mask: 0.6382  loss_rpn_cls: 0.1351  loss_rpn_loc: 0.04017  validation_loss: 1.968  time: 1.4746  data_time: 0.0227  lr: 9.7258e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:25:38 d2.utils.events]: \u001b[0m eta: 3:41:40  iter: 1079  total_loss: 1.856  loss_cls_stage0: 0.2955  loss_box_reg_stage0: 0.1433  loss_cls_stage1: 0.2154  loss_box_reg_stage1: 0.1442  loss_cls_stage2: 0.145  loss_box_reg_stage2: 0.09377  loss_mask: 0.6379  loss_rpn_cls: 0.1145  loss_rpn_loc: 0.03814  validation_loss: 1.968  time: 1.4749  data_time: 0.0244  lr: 9.7155e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:26:08 d2.utils.events]: \u001b[0m eta: 3:41:14  iter: 1099  total_loss: 1.825  loss_cls_stage0: 0.2846  loss_box_reg_stage0: 0.1465  loss_cls_stage1: 0.219  loss_box_reg_stage1: 0.1415  loss_cls_stage2: 0.147  loss_box_reg_stage2: 0.09295  loss_mask: 0.6148  loss_rpn_cls: 0.119  loss_rpn_loc: 0.04272  validation_loss: 1.968  time: 1.4754  data_time: 0.0248  lr: 9.7049e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:26:38 d2.utils.events]: \u001b[0m eta: 3:40:49  iter: 1119  total_loss: 1.902  loss_cls_stage0: 0.3058  loss_box_reg_stage0: 0.1523  loss_cls_stage1: 0.2275  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.1426  loss_box_reg_stage2: 0.0897  loss_mask: 0.6326  loss_rpn_cls: 0.1176  loss_rpn_loc: 0.04142  validation_loss: 1.968  time: 1.4758  data_time: 0.0224  lr: 9.6942e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:27:08 d2.utils.events]: \u001b[0m eta: 3:40:25  iter: 1139  total_loss: 1.89  loss_cls_stage0: 0.3194  loss_box_reg_stage0: 0.1502  loss_cls_stage1: 0.2307  loss_box_reg_stage1: 0.1555  loss_cls_stage2: 0.149  loss_box_reg_stage2: 0.0945  loss_mask: 0.6239  loss_rpn_cls: 0.1238  loss_rpn_loc: 0.04169  validation_loss: 1.968  time: 1.4762  data_time: 0.0243  lr: 9.6833e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:27:38 d2.utils.events]: \u001b[0m eta: 3:39:57  iter: 1159  total_loss: 1.847  loss_cls_stage0: 0.2744  loss_box_reg_stage0: 0.1413  loss_cls_stage1: 0.2078  loss_box_reg_stage1: 0.1377  loss_cls_stage2: 0.1381  loss_box_reg_stage2: 0.07999  loss_mask: 0.6411  loss_rpn_cls: 0.1068  loss_rpn_loc: 0.03756  validation_loss: 1.968  time: 1.4765  data_time: 0.0234  lr: 9.6722e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:28:08 d2.utils.events]: \u001b[0m eta: 3:39:33  iter: 1179  total_loss: 1.949  loss_cls_stage0: 0.3223  loss_box_reg_stage0: 0.16  loss_cls_stage1: 0.2433  loss_box_reg_stage1: 0.1665  loss_cls_stage2: 0.16  loss_box_reg_stage2: 0.1021  loss_mask: 0.6504  loss_rpn_cls: 0.1368  loss_rpn_loc: 0.04459  validation_loss: 1.968  time: 1.4768  data_time: 0.0240  lr: 9.6609e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:28:38 d2.utils.events]: \u001b[0m eta: 3:39:06  iter: 1199  total_loss: 2.06  loss_cls_stage0: 0.344  loss_box_reg_stage0: 0.1883  loss_cls_stage1: 0.2498  loss_box_reg_stage1: 0.1877  loss_cls_stage2: 0.1612  loss_box_reg_stage2: 0.1046  loss_mask: 0.6606  loss_rpn_cls: 0.1288  loss_rpn_loc: 0.03829  validation_loss: 1.968  time: 1.4773  data_time: 0.0246  lr: 9.6495e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:29:08 d2.utils.events]: \u001b[0m eta: 3:38:39  iter: 1219  total_loss: 1.845  loss_cls_stage0: 0.302  loss_box_reg_stage0: 0.1541  loss_cls_stage1: 0.2234  loss_box_reg_stage1: 0.1547  loss_cls_stage2: 0.1443  loss_box_reg_stage2: 0.09088  loss_mask: 0.6306  loss_rpn_cls: 0.135  loss_rpn_loc: 0.03986  validation_loss: 1.968  time: 1.4776  data_time: 0.0240  lr: 9.6378e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:29:38 d2.utils.events]: \u001b[0m eta: 3:38:10  iter: 1239  total_loss: 1.909  loss_cls_stage0: 0.2925  loss_box_reg_stage0: 0.1564  loss_cls_stage1: 0.2361  loss_box_reg_stage1: 0.1572  loss_cls_stage2: 0.1575  loss_box_reg_stage2: 0.1028  loss_mask: 0.6165  loss_rpn_cls: 0.1267  loss_rpn_loc: 0.04274  validation_loss: 1.968  time: 1.4780  data_time: 0.0235  lr: 9.626e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:30:08 d2.utils.events]: \u001b[0m eta: 3:37:45  iter: 1259  total_loss: 1.92  loss_cls_stage0: 0.3105  loss_box_reg_stage0: 0.1624  loss_cls_stage1: 0.2318  loss_box_reg_stage1: 0.1726  loss_cls_stage2: 0.1419  loss_box_reg_stage2: 0.09338  loss_mask: 0.6209  loss_rpn_cls: 0.111  loss_rpn_loc: 0.03866  validation_loss: 1.968  time: 1.4783  data_time: 0.0238  lr: 9.614e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:30:38 d2.utils.events]: \u001b[0m eta: 3:37:16  iter: 1279  total_loss: 1.95  loss_cls_stage0: 0.3007  loss_box_reg_stage0: 0.1554  loss_cls_stage1: 0.2301  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.1596  loss_box_reg_stage2: 0.1145  loss_mask: 0.6436  loss_rpn_cls: 0.1144  loss_rpn_loc: 0.03558  validation_loss: 1.968  time: 1.4785  data_time: 0.0265  lr: 9.6018e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:31:08 d2.utils.events]: \u001b[0m eta: 3:36:48  iter: 1299  total_loss: 1.971  loss_cls_stage0: 0.3181  loss_box_reg_stage0: 0.1664  loss_cls_stage1: 0.2407  loss_box_reg_stage1: 0.1674  loss_cls_stage2: 0.1539  loss_box_reg_stage2: 0.1041  loss_mask: 0.6523  loss_rpn_cls: 0.1187  loss_rpn_loc: 0.0447  validation_loss: 1.968  time: 1.4790  data_time: 0.0241  lr: 9.5894e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:31:38 d2.utils.events]: \u001b[0m eta: 3:36:18  iter: 1319  total_loss: 1.849  loss_cls_stage0: 0.2864  loss_box_reg_stage0: 0.1425  loss_cls_stage1: 0.2327  loss_box_reg_stage1: 0.1672  loss_cls_stage2: 0.1481  loss_box_reg_stage2: 0.09924  loss_mask: 0.6489  loss_rpn_cls: 0.1204  loss_rpn_loc: 0.03589  validation_loss: 1.968  time: 1.4792  data_time: 0.0247  lr: 9.5768e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:32:08 d2.utils.events]: \u001b[0m eta: 3:35:48  iter: 1339  total_loss: 1.899  loss_cls_stage0: 0.2906  loss_box_reg_stage0: 0.1425  loss_cls_stage1: 0.2296  loss_box_reg_stage1: 0.1557  loss_cls_stage2: 0.1571  loss_box_reg_stage2: 0.09529  loss_mask: 0.6198  loss_rpn_cls: 0.1315  loss_rpn_loc: 0.03839  validation_loss: 1.968  time: 1.4795  data_time: 0.0242  lr: 9.5641e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:32:38 d2.utils.events]: \u001b[0m eta: 3:35:18  iter: 1359  total_loss: 1.757  loss_cls_stage0: 0.2572  loss_box_reg_stage0: 0.1337  loss_cls_stage1: 0.2026  loss_box_reg_stage1: 0.1475  loss_cls_stage2: 0.1497  loss_box_reg_stage2: 0.1008  loss_mask: 0.6313  loss_rpn_cls: 0.1105  loss_rpn_loc: 0.0334  validation_loss: 1.968  time: 1.4797  data_time: 0.0233  lr: 9.5512e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:33:08 d2.utils.events]: \u001b[0m eta: 3:34:50  iter: 1379  total_loss: 1.879  loss_cls_stage0: 0.313  loss_box_reg_stage0: 0.1547  loss_cls_stage1: 0.2288  loss_box_reg_stage1: 0.1605  loss_cls_stage2: 0.1549  loss_box_reg_stage2: 0.09962  loss_mask: 0.6281  loss_rpn_cls: 0.1072  loss_rpn_loc: 0.03738  validation_loss: 1.968  time: 1.4800  data_time: 0.0228  lr: 9.5381e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:33:38 d2.utils.events]: \u001b[0m eta: 3:34:24  iter: 1399  total_loss: 1.963  loss_cls_stage0: 0.3088  loss_box_reg_stage0: 0.1613  loss_cls_stage1: 0.2371  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.1616  loss_box_reg_stage2: 0.1094  loss_mask: 0.6171  loss_rpn_cls: 0.1136  loss_rpn_loc: 0.03873  validation_loss: 1.968  time: 1.4804  data_time: 0.0228  lr: 9.5248e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:34:08 d2.utils.events]: \u001b[0m eta: 3:33:55  iter: 1419  total_loss: 1.925  loss_cls_stage0: 0.3087  loss_box_reg_stage0: 0.1568  loss_cls_stage1: 0.2323  loss_box_reg_stage1: 0.1658  loss_cls_stage2: 0.1574  loss_box_reg_stage2: 0.1013  loss_mask: 0.6315  loss_rpn_cls: 0.1212  loss_rpn_loc: 0.04323  validation_loss: 1.968  time: 1.4807  data_time: 0.0228  lr: 9.5113e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:34:38 d2.utils.events]: \u001b[0m eta: 3:33:24  iter: 1439  total_loss: 1.73  loss_cls_stage0: 0.2751  loss_box_reg_stage0: 0.1413  loss_cls_stage1: 0.2164  loss_box_reg_stage1: 0.1508  loss_cls_stage2: 0.1399  loss_box_reg_stage2: 0.09691  loss_mask: 0.6219  loss_rpn_cls: 0.09528  loss_rpn_loc: 0.03305  validation_loss: 1.968  time: 1.4809  data_time: 0.0237  lr: 9.4977e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:35:08 d2.utils.events]: \u001b[0m eta: 3:32:53  iter: 1459  total_loss: 1.905  loss_cls_stage0: 0.294  loss_box_reg_stage0: 0.1499  loss_cls_stage1: 0.2308  loss_box_reg_stage1: 0.1651  loss_cls_stage2: 0.1578  loss_box_reg_stage2: 0.1145  loss_mask: 0.6142  loss_rpn_cls: 0.1033  loss_rpn_loc: 0.03814  validation_loss: 1.968  time: 1.4811  data_time: 0.0242  lr: 9.4839e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:35:38 d2.utils.events]: \u001b[0m eta: 3:32:20  iter: 1479  total_loss: 1.889  loss_cls_stage0: 0.2977  loss_box_reg_stage0: 0.1478  loss_cls_stage1: 0.2397  loss_box_reg_stage1: 0.1606  loss_cls_stage2: 0.1761  loss_box_reg_stage2: 0.1121  loss_mask: 0.5701  loss_rpn_cls: 0.1433  loss_rpn_loc: 0.04653  validation_loss: 1.968  time: 1.4814  data_time: 0.0245  lr: 9.4699e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:36:08 d2.utils.events]: \u001b[0m eta: 3:31:49  iter: 1499  total_loss: 1.884  loss_cls_stage0: 0.2973  loss_box_reg_stage0: 0.1568  loss_cls_stage1: 0.223  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.1565  loss_box_reg_stage2: 0.1085  loss_mask: 0.6319  loss_rpn_cls: 0.1145  loss_rpn_loc: 0.03738  validation_loss: 1.968  time: 1.4817  data_time: 0.0241  lr: 9.4557e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:36:38 d2.utils.events]: \u001b[0m eta: 3:31:17  iter: 1519  total_loss: 1.989  loss_cls_stage0: 0.3274  loss_box_reg_stage0: 0.1639  loss_cls_stage1: 0.2471  loss_box_reg_stage1: 0.1655  loss_cls_stage2: 0.1667  loss_box_reg_stage2: 0.1074  loss_mask: 0.5903  loss_rpn_cls: 0.1169  loss_rpn_loc: 0.03704  validation_loss: 1.968  time: 1.4819  data_time: 0.0221  lr: 9.4414e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:37:08 d2.utils.events]: \u001b[0m eta: 3:30:46  iter: 1539  total_loss: 1.839  loss_cls_stage0: 0.2803  loss_box_reg_stage0: 0.136  loss_cls_stage1: 0.2219  loss_box_reg_stage1: 0.1527  loss_cls_stage2: 0.1548  loss_box_reg_stage2: 0.09724  loss_mask: 0.6171  loss_rpn_cls: 0.1126  loss_rpn_loc: 0.03542  validation_loss: 1.968  time: 1.4821  data_time: 0.0242  lr: 9.4269e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:37:38 d2.utils.events]: \u001b[0m eta: 3:30:15  iter: 1559  total_loss: 1.853  loss_cls_stage0: 0.2976  loss_box_reg_stage0: 0.1519  loss_cls_stage1: 0.2162  loss_box_reg_stage1: 0.1707  loss_cls_stage2: 0.1465  loss_box_reg_stage2: 0.1052  loss_mask: 0.5956  loss_rpn_cls: 0.1078  loss_rpn_loc: 0.03789  validation_loss: 1.968  time: 1.4824  data_time: 0.0231  lr: 9.4122e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:38:08 d2.utils.events]: \u001b[0m eta: 3:29:41  iter: 1579  total_loss: 1.933  loss_cls_stage0: 0.2869  loss_box_reg_stage0: 0.1458  loss_cls_stage1: 0.226  loss_box_reg_stage1: 0.1714  loss_cls_stage2: 0.1525  loss_box_reg_stage2: 0.1037  loss_mask: 0.6497  loss_rpn_cls: 0.1088  loss_rpn_loc: 0.03937  validation_loss: 1.968  time: 1.4825  data_time: 0.0222  lr: 9.3973e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:38:38 d2.utils.events]: \u001b[0m eta: 3:29:11  iter: 1599  total_loss: 1.925  loss_cls_stage0: 0.3111  loss_box_reg_stage0: 0.1588  loss_cls_stage1: 0.2376  loss_box_reg_stage1: 0.1746  loss_cls_stage2: 0.156  loss_box_reg_stage2: 0.108  loss_mask: 0.5909  loss_rpn_cls: 0.1158  loss_rpn_loc: 0.03818  validation_loss: 1.968  time: 1.4828  data_time: 0.0230  lr: 9.3823e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:39:08 d2.utils.events]: \u001b[0m eta: 3:28:40  iter: 1619  total_loss: 1.862  loss_cls_stage0: 0.2977  loss_box_reg_stage0: 0.145  loss_cls_stage1: 0.2262  loss_box_reg_stage1: 0.1586  loss_cls_stage2: 0.1561  loss_box_reg_stage2: 0.1113  loss_mask: 0.6012  loss_rpn_cls: 0.1109  loss_rpn_loc: 0.038  validation_loss: 1.968  time: 1.4830  data_time: 0.0242  lr: 9.3671e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:39:38 d2.utils.events]: \u001b[0m eta: 3:28:10  iter: 1639  total_loss: 1.856  loss_cls_stage0: 0.2937  loss_box_reg_stage0: 0.1522  loss_cls_stage1: 0.2228  loss_box_reg_stage1: 0.1595  loss_cls_stage2: 0.1613  loss_box_reg_stage2: 0.1081  loss_mask: 0.6046  loss_rpn_cls: 0.1131  loss_rpn_loc: 0.03915  validation_loss: 1.968  time: 1.4832  data_time: 0.0233  lr: 9.3517e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:40:08 d2.utils.events]: \u001b[0m eta: 3:27:40  iter: 1659  total_loss: 1.87  loss_cls_stage0: 0.2885  loss_box_reg_stage0: 0.1573  loss_cls_stage1: 0.2235  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.1591  loss_box_reg_stage2: 0.1143  loss_mask: 0.6163  loss_rpn_cls: 0.1043  loss_rpn_loc: 0.03684  validation_loss: 1.968  time: 1.4834  data_time: 0.0294  lr: 9.3361e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:40:38 d2.utils.events]: \u001b[0m eta: 3:27:11  iter: 1679  total_loss: 1.934  loss_cls_stage0: 0.2929  loss_box_reg_stage0: 0.1512  loss_cls_stage1: 0.2319  loss_box_reg_stage1: 0.1814  loss_cls_stage2: 0.1596  loss_box_reg_stage2: 0.1149  loss_mask: 0.6113  loss_rpn_cls: 0.1102  loss_rpn_loc: 0.03459  validation_loss: 1.968  time: 1.4836  data_time: 0.0234  lr: 9.3204e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:41:08 d2.utils.events]: \u001b[0m eta: 3:26:41  iter: 1699  total_loss: 1.785  loss_cls_stage0: 0.2774  loss_box_reg_stage0: 0.1363  loss_cls_stage1: 0.2179  loss_box_reg_stage1: 0.1623  loss_cls_stage2: 0.1476  loss_box_reg_stage2: 0.1059  loss_mask: 0.5934  loss_rpn_cls: 0.09673  loss_rpn_loc: 0.03048  validation_loss: 1.968  time: 1.4837  data_time: 0.0227  lr: 9.3045e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:41:38 d2.utils.events]: \u001b[0m eta: 3:26:11  iter: 1719  total_loss: 1.926  loss_cls_stage0: 0.3161  loss_box_reg_stage0: 0.1649  loss_cls_stage1: 0.2381  loss_box_reg_stage1: 0.189  loss_cls_stage2: 0.1572  loss_box_reg_stage2: 0.1138  loss_mask: 0.5663  loss_rpn_cls: 0.1055  loss_rpn_loc: 0.03988  validation_loss: 1.968  time: 1.4840  data_time: 0.0232  lr: 9.2884e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:42:08 d2.utils.events]: \u001b[0m eta: 3:25:42  iter: 1739  total_loss: 1.858  loss_cls_stage0: 0.2886  loss_box_reg_stage0: 0.148  loss_cls_stage1: 0.2158  loss_box_reg_stage1: 0.1678  loss_cls_stage2: 0.1553  loss_box_reg_stage2: 0.1143  loss_mask: 0.6302  loss_rpn_cls: 0.1011  loss_rpn_loc: 0.03431  validation_loss: 1.968  time: 1.4842  data_time: 0.0244  lr: 9.2722e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:42:38 d2.utils.events]: \u001b[0m eta: 3:25:12  iter: 1759  total_loss: 1.957  loss_cls_stage0: 0.3229  loss_box_reg_stage0: 0.1693  loss_cls_stage1: 0.2519  loss_box_reg_stage1: 0.1823  loss_cls_stage2: 0.1737  loss_box_reg_stage2: 0.1299  loss_mask: 0.5916  loss_rpn_cls: 0.1243  loss_rpn_loc: 0.04078  validation_loss: 1.968  time: 1.4844  data_time: 0.0241  lr: 9.2558e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:43:08 d2.utils.events]: \u001b[0m eta: 3:24:42  iter: 1779  total_loss: 1.737  loss_cls_stage0: 0.2609  loss_box_reg_stage0: 0.1341  loss_cls_stage1: 0.1971  loss_box_reg_stage1: 0.1464  loss_cls_stage2: 0.1404  loss_box_reg_stage2: 0.1065  loss_mask: 0.5944  loss_rpn_cls: 0.1062  loss_rpn_loc: 0.03562  validation_loss: 1.968  time: 1.4845  data_time: 0.0302  lr: 9.2392e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:43:38 d2.utils.events]: \u001b[0m eta: 3:24:12  iter: 1799  total_loss: 1.795  loss_cls_stage0: 0.2812  loss_box_reg_stage0: 0.1496  loss_cls_stage1: 0.2192  loss_box_reg_stage1: 0.1621  loss_cls_stage2: 0.16  loss_box_reg_stage2: 0.1142  loss_mask: 0.5746  loss_rpn_cls: 0.1069  loss_rpn_loc: 0.03813  validation_loss: 1.968  time: 1.4847  data_time: 0.0241  lr: 9.2225e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:44:08 d2.utils.events]: \u001b[0m eta: 3:23:42  iter: 1819  total_loss: 1.905  loss_cls_stage0: 0.2721  loss_box_reg_stage0: 0.1401  loss_cls_stage1: 0.2285  loss_box_reg_stage1: 0.1711  loss_cls_stage2: 0.1546  loss_box_reg_stage2: 0.1135  loss_mask: 0.6378  loss_rpn_cls: 0.1047  loss_rpn_loc: 0.03773  validation_loss: 1.968  time: 1.4850  data_time: 0.0235  lr: 9.2056e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:44:38 d2.utils.events]: \u001b[0m eta: 3:23:14  iter: 1839  total_loss: 1.9  loss_cls_stage0: 0.3024  loss_box_reg_stage0: 0.1635  loss_cls_stage1: 0.2369  loss_box_reg_stage1: 0.1844  loss_cls_stage2: 0.1682  loss_box_reg_stage2: 0.1228  loss_mask: 0.5522  loss_rpn_cls: 0.1063  loss_rpn_loc: 0.03818  validation_loss: 1.968  time: 1.4852  data_time: 0.0231  lr: 9.1885e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:45:08 d2.utils.events]: \u001b[0m eta: 3:22:44  iter: 1859  total_loss: 1.751  loss_cls_stage0: 0.2651  loss_box_reg_stage0: 0.1303  loss_cls_stage1: 0.2192  loss_box_reg_stage1: 0.1609  loss_cls_stage2: 0.146  loss_box_reg_stage2: 0.1013  loss_mask: 0.5944  loss_rpn_cls: 0.1152  loss_rpn_loc: 0.03891  validation_loss: 1.968  time: 1.4853  data_time: 0.0227  lr: 9.1713e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:45:39 d2.utils.events]: \u001b[0m eta: 3:22:17  iter: 1879  total_loss: 1.889  loss_cls_stage0: 0.2995  loss_box_reg_stage0: 0.1576  loss_cls_stage1: 0.2292  loss_box_reg_stage1: 0.1772  loss_cls_stage2: 0.1574  loss_box_reg_stage2: 0.1152  loss_mask: 0.5849  loss_rpn_cls: 0.1007  loss_rpn_loc: 0.03687  validation_loss: 1.968  time: 1.4855  data_time: 0.0237  lr: 9.1539e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:46:09 d2.utils.events]: \u001b[0m eta: 3:21:50  iter: 1899  total_loss: 1.847  loss_cls_stage0: 0.311  loss_box_reg_stage0: 0.1705  loss_cls_stage1: 0.2341  loss_box_reg_stage1: 0.1717  loss_cls_stage2: 0.1546  loss_box_reg_stage2: 0.1131  loss_mask: 0.607  loss_rpn_cls: 0.1013  loss_rpn_loc: 0.03762  validation_loss: 1.968  time: 1.4857  data_time: 0.0236  lr: 9.1363e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:46:39 d2.utils.events]: \u001b[0m eta: 3:21:22  iter: 1919  total_loss: 1.903  loss_cls_stage0: 0.3112  loss_box_reg_stage0: 0.1656  loss_cls_stage1: 0.2341  loss_box_reg_stage1: 0.1749  loss_cls_stage2: 0.1613  loss_box_reg_stage2: 0.1117  loss_mask: 0.5869  loss_rpn_cls: 0.1061  loss_rpn_loc: 0.04348  validation_loss: 1.968  time: 1.4859  data_time: 0.0230  lr: 9.1186e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:47:09 d2.utils.events]: \u001b[0m eta: 3:20:52  iter: 1939  total_loss: 1.816  loss_cls_stage0: 0.2856  loss_box_reg_stage0: 0.1447  loss_cls_stage1: 0.2364  loss_box_reg_stage1: 0.1827  loss_cls_stage2: 0.1578  loss_box_reg_stage2: 0.1213  loss_mask: 0.5698  loss_rpn_cls: 0.1105  loss_rpn_loc: 0.03736  validation_loss: 1.968  time: 1.4861  data_time: 0.0232  lr: 9.1007e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:47:39 d2.utils.events]: \u001b[0m eta: 3:20:25  iter: 1959  total_loss: 1.959  loss_cls_stage0: 0.3019  loss_box_reg_stage0: 0.1581  loss_cls_stage1: 0.2334  loss_box_reg_stage1: 0.1826  loss_cls_stage2: 0.1687  loss_box_reg_stage2: 0.1264  loss_mask: 0.5742  loss_rpn_cls: 0.09611  loss_rpn_loc: 0.04202  validation_loss: 1.968  time: 1.4863  data_time: 0.0226  lr: 9.0826e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:48:09 d2.utils.events]: \u001b[0m eta: 3:19:58  iter: 1979  total_loss: 2.007  loss_cls_stage0: 0.3355  loss_box_reg_stage0: 0.1925  loss_cls_stage1: 0.259  loss_box_reg_stage1: 0.222  loss_cls_stage2: 0.1626  loss_box_reg_stage2: 0.1483  loss_mask: 0.6145  loss_rpn_cls: 0.103  loss_rpn_loc: 0.03768  validation_loss: 1.968  time: 1.4866  data_time: 0.0227  lr: 9.0644e-05  max_mem: 12121M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/27 07:48:41 d2.data.common]: \u001b[0mSerializing 883 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/27 07:48:41 d2.data.common]: \u001b[0mSerialized dataset takes 0.91 MiB\n",
      "\u001b[32m[03/27 07:48:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 883 images\n",
      "\u001b[32m[03/27 07:48:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/883. 0.0782 s / img. ETA=0:01:15\n",
      "\u001b[32m[03/27 07:48:48 d2.evaluation.evaluator]: \u001b[0mInference done 69/883. 0.0782 s / img. ETA=0:01:10\n",
      "\u001b[32m[03/27 07:48:53 d2.evaluation.evaluator]: \u001b[0mInference done 128/883. 0.0781 s / img. ETA=0:01:05\n",
      "\u001b[32m[03/27 07:48:58 d2.evaluation.evaluator]: \u001b[0mInference done 186/883. 0.0782 s / img. ETA=0:01:00\n",
      "\u001b[32m[03/27 07:49:03 d2.evaluation.evaluator]: \u001b[0mInference done 244/883. 0.0782 s / img. ETA=0:00:55\n",
      "\u001b[32m[03/27 07:49:08 d2.evaluation.evaluator]: \u001b[0mInference done 303/883. 0.0782 s / img. ETA=0:00:50\n",
      "\u001b[32m[03/27 07:49:13 d2.evaluation.evaluator]: \u001b[0mInference done 361/883. 0.0782 s / img. ETA=0:00:45\n",
      "\u001b[32m[03/27 07:49:18 d2.evaluation.evaluator]: \u001b[0mInference done 419/883. 0.0782 s / img. ETA=0:00:40\n",
      "\u001b[32m[03/27 07:49:23 d2.evaluation.evaluator]: \u001b[0mInference done 478/883. 0.0782 s / img. ETA=0:00:35\n",
      "\u001b[32m[03/27 07:49:28 d2.evaluation.evaluator]: \u001b[0mInference done 535/883. 0.0783 s / img. ETA=0:00:30\n",
      "\u001b[32m[03/27 07:49:33 d2.evaluation.evaluator]: \u001b[0mInference done 593/883. 0.0783 s / img. ETA=0:00:25\n",
      "\u001b[32m[03/27 07:49:38 d2.evaluation.evaluator]: \u001b[0mInference done 650/883. 0.0783 s / img. ETA=0:00:20\n",
      "\u001b[32m[03/27 07:49:43 d2.evaluation.evaluator]: \u001b[0mInference done 708/883. 0.0784 s / img. ETA=0:00:15\n",
      "\u001b[32m[03/27 07:49:48 d2.evaluation.evaluator]: \u001b[0mInference done 766/883. 0.0784 s / img. ETA=0:00:10\n",
      "\u001b[32m[03/27 07:49:54 d2.evaluation.evaluator]: \u001b[0mInference done 823/883. 0.0784 s / img. ETA=0:00:05\n",
      "\u001b[32m[03/27 07:49:59 d2.evaluation.evaluator]: \u001b[0mInference done 880/883. 0.0785 s / img. ETA=0:00:00\n",
      "\u001b[32m[03/27 07:49:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:16.569874 (0.087209 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/27 07:49:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:08 (0.078503 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.37 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.050\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.056\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.015\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.027\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.047\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.047\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.027\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.048\n",
      "\u001b[32m[03/27 07:50:00 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold5 in csv format:\n",
      "\u001b[32m[03/27 07:50:00 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/27 07:50:00 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/27 07:50:00 d2.evaluation.testing]: \u001b[0mcopypaste: 2.5410,5.0308,5.5919,0.0000,1.4576,2.6982\n",
      "validation do loss eval 1.9406433891981476\n",
      "\u001b[32m[03/27 07:51:29 d2.utils.events]: \u001b[0m eta: 3:19:28  iter: 1999  total_loss: 1.961  loss_cls_stage0: 0.2855  loss_box_reg_stage0: 0.1472  loss_cls_stage1: 0.2321  loss_box_reg_stage1: 0.1982  loss_cls_stage2: 0.1674  loss_box_reg_stage2: 0.1307  loss_mask: 0.6323  loss_rpn_cls: 0.1114  loss_rpn_loc: 0.04182  validation_loss: 1.954  time: 1.4868  data_time: 0.0227  lr: 9.046e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:51:58 d2.utils.events]: \u001b[0m eta: 3:19:01  iter: 2019  total_loss: 1.835  loss_cls_stage0: 0.2906  loss_box_reg_stage0: 0.1562  loss_cls_stage1: 0.2291  loss_box_reg_stage1: 0.1862  loss_cls_stage2: 0.1669  loss_box_reg_stage2: 0.1297  loss_mask: 0.5665  loss_rpn_cls: 0.108  loss_rpn_loc: 0.039  validation_loss: 1.954  time: 1.4868  data_time: 0.0249  lr: 9.0275e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:52:29 d2.utils.events]: \u001b[0m eta: 3:18:32  iter: 2039  total_loss: 1.872  loss_cls_stage0: 0.3114  loss_box_reg_stage0: 0.1693  loss_cls_stage1: 0.2321  loss_box_reg_stage1: 0.1804  loss_cls_stage2: 0.1571  loss_box_reg_stage2: 0.1183  loss_mask: 0.5774  loss_rpn_cls: 0.1005  loss_rpn_loc: 0.03885  validation_loss: 1.954  time: 1.4870  data_time: 0.0230  lr: 9.0088e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:52:59 d2.utils.events]: \u001b[0m eta: 3:18:02  iter: 2059  total_loss: 1.888  loss_cls_stage0: 0.2732  loss_box_reg_stage0: 0.1375  loss_cls_stage1: 0.2269  loss_box_reg_stage1: 0.1749  loss_cls_stage2: 0.156  loss_box_reg_stage2: 0.1207  loss_mask: 0.5815  loss_rpn_cls: 0.1001  loss_rpn_loc: 0.03402  validation_loss: 1.954  time: 1.4872  data_time: 0.0231  lr: 8.9899e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:53:29 d2.utils.events]: \u001b[0m eta: 3:17:34  iter: 2079  total_loss: 2.131  loss_cls_stage0: 0.3255  loss_box_reg_stage0: 0.1725  loss_cls_stage1: 0.2598  loss_box_reg_stage1: 0.2052  loss_cls_stage2: 0.1786  loss_box_reg_stage2: 0.1384  loss_mask: 0.6005  loss_rpn_cls: 0.102  loss_rpn_loc: 0.03725  validation_loss: 1.954  time: 1.4875  data_time: 0.0234  lr: 8.9709e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:53:59 d2.utils.events]: \u001b[0m eta: 3:17:06  iter: 2099  total_loss: 1.965  loss_cls_stage0: 0.2944  loss_box_reg_stage0: 0.1483  loss_cls_stage1: 0.2322  loss_box_reg_stage1: 0.1779  loss_cls_stage2: 0.1671  loss_box_reg_stage2: 0.1297  loss_mask: 0.6126  loss_rpn_cls: 0.1069  loss_rpn_loc: 0.03858  validation_loss: 1.954  time: 1.4876  data_time: 0.0237  lr: 8.9517e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:54:29 d2.utils.events]: \u001b[0m eta: 3:16:38  iter: 2119  total_loss: 1.965  loss_cls_stage0: 0.3054  loss_box_reg_stage0: 0.1649  loss_cls_stage1: 0.2444  loss_box_reg_stage1: 0.1913  loss_cls_stage2: 0.1805  loss_box_reg_stage2: 0.1453  loss_mask: 0.5774  loss_rpn_cls: 0.1092  loss_rpn_loc: 0.04317  validation_loss: 1.954  time: 1.4879  data_time: 0.0245  lr: 8.9324e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:54:59 d2.utils.events]: \u001b[0m eta: 3:16:11  iter: 2139  total_loss: 1.893  loss_cls_stage0: 0.2892  loss_box_reg_stage0: 0.1582  loss_cls_stage1: 0.2343  loss_box_reg_stage1: 0.1852  loss_cls_stage2: 0.1582  loss_box_reg_stage2: 0.1206  loss_mask: 0.5964  loss_rpn_cls: 0.09799  loss_rpn_loc: 0.03634  validation_loss: 1.954  time: 1.4880  data_time: 0.0235  lr: 8.9129e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:55:30 d2.utils.events]: \u001b[0m eta: 3:15:43  iter: 2159  total_loss: 1.994  loss_cls_stage0: 0.3028  loss_box_reg_stage0: 0.168  loss_cls_stage1: 0.2558  loss_box_reg_stage1: 0.2026  loss_cls_stage2: 0.1756  loss_box_reg_stage2: 0.14  loss_mask: 0.5781  loss_rpn_cls: 0.09243  loss_rpn_loc: 0.04031  validation_loss: 1.954  time: 1.4883  data_time: 0.0238  lr: 8.8933e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:56:00 d2.utils.events]: \u001b[0m eta: 3:15:14  iter: 2179  total_loss: 1.865  loss_cls_stage0: 0.3055  loss_box_reg_stage0: 0.1601  loss_cls_stage1: 0.2225  loss_box_reg_stage1: 0.1763  loss_cls_stage2: 0.1651  loss_box_reg_stage2: 0.128  loss_mask: 0.565  loss_rpn_cls: 0.1035  loss_rpn_loc: 0.03684  validation_loss: 1.954  time: 1.4884  data_time: 0.0237  lr: 8.8735e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:56:30 d2.utils.events]: \u001b[0m eta: 3:14:44  iter: 2199  total_loss: 1.932  loss_cls_stage0: 0.3014  loss_box_reg_stage0: 0.1681  loss_cls_stage1: 0.2308  loss_box_reg_stage1: 0.1897  loss_cls_stage2: 0.178  loss_box_reg_stage2: 0.136  loss_mask: 0.5681  loss_rpn_cls: 0.1042  loss_rpn_loc: 0.04185  validation_loss: 1.954  time: 1.4886  data_time: 0.0227  lr: 8.8536e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:57:00 d2.utils.events]: \u001b[0m eta: 3:14:18  iter: 2219  total_loss: 1.845  loss_cls_stage0: 0.2945  loss_box_reg_stage0: 0.1574  loss_cls_stage1: 0.2383  loss_box_reg_stage1: 0.1921  loss_cls_stage2: 0.1671  loss_box_reg_stage2: 0.135  loss_mask: 0.5796  loss_rpn_cls: 0.09997  loss_rpn_loc: 0.03632  validation_loss: 1.954  time: 1.4887  data_time: 0.0256  lr: 8.8335e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:57:30 d2.utils.events]: \u001b[0m eta: 3:13:49  iter: 2239  total_loss: 1.994  loss_cls_stage0: 0.2927  loss_box_reg_stage0: 0.1563  loss_cls_stage1: 0.2375  loss_box_reg_stage1: 0.1951  loss_cls_stage2: 0.1661  loss_box_reg_stage2: 0.128  loss_mask: 0.6185  loss_rpn_cls: 0.1047  loss_rpn_loc: 0.04204  validation_loss: 1.954  time: 1.4889  data_time: 0.0242  lr: 8.8132e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:58:00 d2.utils.events]: \u001b[0m eta: 3:13:20  iter: 2259  total_loss: 1.899  loss_cls_stage0: 0.2698  loss_box_reg_stage0: 0.1526  loss_cls_stage1: 0.2274  loss_box_reg_stage1: 0.19  loss_cls_stage2: 0.1605  loss_box_reg_stage2: 0.1298  loss_mask: 0.5805  loss_rpn_cls: 0.1021  loss_rpn_loc: 0.03671  validation_loss: 1.954  time: 1.4890  data_time: 0.0245  lr: 8.7928e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:58:31 d2.utils.events]: \u001b[0m eta: 3:12:53  iter: 2279  total_loss: 1.886  loss_cls_stage0: 0.2813  loss_box_reg_stage0: 0.1549  loss_cls_stage1: 0.2287  loss_box_reg_stage1: 0.1962  loss_cls_stage2: 0.1643  loss_box_reg_stage2: 0.1384  loss_mask: 0.5935  loss_rpn_cls: 0.08998  loss_rpn_loc: 0.03611  validation_loss: 1.954  time: 1.4892  data_time: 0.0235  lr: 8.7723e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:59:01 d2.utils.events]: \u001b[0m eta: 3:12:26  iter: 2299  total_loss: 2.039  loss_cls_stage0: 0.3301  loss_box_reg_stage0: 0.1812  loss_cls_stage1: 0.2512  loss_box_reg_stage1: 0.2197  loss_cls_stage2: 0.1832  loss_box_reg_stage2: 0.1491  loss_mask: 0.5782  loss_rpn_cls: 0.1063  loss_rpn_loc: 0.04952  validation_loss: 1.954  time: 1.4894  data_time: 0.0242  lr: 8.7516e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 07:59:31 d2.utils.events]: \u001b[0m eta: 3:11:59  iter: 2319  total_loss: 1.854  loss_cls_stage0: 0.2692  loss_box_reg_stage0: 0.1507  loss_cls_stage1: 0.2103  loss_box_reg_stage1: 0.1824  loss_cls_stage2: 0.1545  loss_box_reg_stage2: 0.1358  loss_mask: 0.6077  loss_rpn_cls: 0.09981  loss_rpn_loc: 0.03622  validation_loss: 1.954  time: 1.4896  data_time: 0.0240  lr: 8.7308e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:00:01 d2.utils.events]: \u001b[0m eta: 3:11:31  iter: 2339  total_loss: 1.846  loss_cls_stage0: 0.2758  loss_box_reg_stage0: 0.1503  loss_cls_stage1: 0.225  loss_box_reg_stage1: 0.1857  loss_cls_stage2: 0.1565  loss_box_reg_stage2: 0.127  loss_mask: 0.5565  loss_rpn_cls: 0.09583  loss_rpn_loc: 0.03577  validation_loss: 1.954  time: 1.4897  data_time: 0.0241  lr: 8.7098e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:00:31 d2.utils.events]: \u001b[0m eta: 3:11:01  iter: 2359  total_loss: 1.856  loss_cls_stage0: 0.268  loss_box_reg_stage0: 0.1454  loss_cls_stage1: 0.2181  loss_box_reg_stage1: 0.1804  loss_cls_stage2: 0.1658  loss_box_reg_stage2: 0.1387  loss_mask: 0.5903  loss_rpn_cls: 0.1021  loss_rpn_loc: 0.03554  validation_loss: 1.954  time: 1.4898  data_time: 0.0242  lr: 8.6886e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:01:01 d2.utils.events]: \u001b[0m eta: 3:10:31  iter: 2379  total_loss: 1.89  loss_cls_stage0: 0.2838  loss_box_reg_stage0: 0.1597  loss_cls_stage1: 0.2169  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.1572  loss_box_reg_stage2: 0.1315  loss_mask: 0.5856  loss_rpn_cls: 0.09238  loss_rpn_loc: 0.03786  validation_loss: 1.954  time: 1.4900  data_time: 0.0236  lr: 8.6673e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:01:32 d2.utils.events]: \u001b[0m eta: 3:10:03  iter: 2399  total_loss: 1.987  loss_cls_stage0: 0.3249  loss_box_reg_stage0: 0.1939  loss_cls_stage1: 0.2451  loss_box_reg_stage1: 0.2159  loss_cls_stage2: 0.1606  loss_box_reg_stage2: 0.1454  loss_mask: 0.6016  loss_rpn_cls: 0.0976  loss_rpn_loc: 0.04172  validation_loss: 1.954  time: 1.4902  data_time: 0.0232  lr: 8.6459e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:02:02 d2.utils.events]: \u001b[0m eta: 3:09:36  iter: 2419  total_loss: 1.943  loss_cls_stage0: 0.3049  loss_box_reg_stage0: 0.1731  loss_cls_stage1: 0.2337  loss_box_reg_stage1: 0.2089  loss_cls_stage2: 0.1715  loss_box_reg_stage2: 0.1417  loss_mask: 0.579  loss_rpn_cls: 0.09178  loss_rpn_loc: 0.03556  validation_loss: 1.954  time: 1.4904  data_time: 0.0241  lr: 8.6243e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:02:32 d2.utils.events]: \u001b[0m eta: 3:09:10  iter: 2439  total_loss: 1.882  loss_cls_stage0: 0.287  loss_box_reg_stage0: 0.1588  loss_cls_stage1: 0.2247  loss_box_reg_stage1: 0.1842  loss_cls_stage2: 0.1632  loss_box_reg_stage2: 0.1303  loss_mask: 0.6071  loss_rpn_cls: 0.1  loss_rpn_loc: 0.04115  validation_loss: 1.954  time: 1.4905  data_time: 0.0235  lr: 8.6026e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:03:02 d2.utils.events]: \u001b[0m eta: 3:08:43  iter: 2459  total_loss: 1.887  loss_cls_stage0: 0.2778  loss_box_reg_stage0: 0.1558  loss_cls_stage1: 0.2295  loss_box_reg_stage1: 0.2047  loss_cls_stage2: 0.1841  loss_box_reg_stage2: 0.1539  loss_mask: 0.5607  loss_rpn_cls: 0.09539  loss_rpn_loc: 0.03972  validation_loss: 1.954  time: 1.4907  data_time: 0.0240  lr: 8.5808e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:03:33 d2.utils.events]: \u001b[0m eta: 3:08:14  iter: 2479  total_loss: 1.955  loss_cls_stage0: 0.3046  loss_box_reg_stage0: 0.1775  loss_cls_stage1: 0.2351  loss_box_reg_stage1: 0.2033  loss_cls_stage2: 0.165  loss_box_reg_stage2: 0.1526  loss_mask: 0.5897  loss_rpn_cls: 0.08891  loss_rpn_loc: 0.04243  validation_loss: 1.954  time: 1.4909  data_time: 0.0301  lr: 8.5588e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:04:03 d2.utils.events]: \u001b[0m eta: 3:07:43  iter: 2499  total_loss: 1.759  loss_cls_stage0: 0.2459  loss_box_reg_stage0: 0.1414  loss_cls_stage1: 0.2024  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.1382  loss_box_reg_stage2: 0.1288  loss_mask: 0.5437  loss_rpn_cls: 0.089  loss_rpn_loc: 0.03822  validation_loss: 1.954  time: 1.4909  data_time: 0.0237  lr: 8.5366e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:04:33 d2.utils.events]: \u001b[0m eta: 3:07:14  iter: 2519  total_loss: 1.93  loss_cls_stage0: 0.3014  loss_box_reg_stage0: 0.1662  loss_cls_stage1: 0.2402  loss_box_reg_stage1: 0.2041  loss_cls_stage2: 0.1723  loss_box_reg_stage2: 0.1414  loss_mask: 0.6006  loss_rpn_cls: 0.09458  loss_rpn_loc: 0.03576  validation_loss: 1.954  time: 1.4911  data_time: 0.0235  lr: 8.5144e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:05:03 d2.utils.events]: \u001b[0m eta: 3:06:46  iter: 2539  total_loss: 2.16  loss_cls_stage0: 0.3412  loss_box_reg_stage0: 0.2082  loss_cls_stage1: 0.2743  loss_box_reg_stage1: 0.2414  loss_cls_stage2: 0.1867  loss_box_reg_stage2: 0.1655  loss_mask: 0.6021  loss_rpn_cls: 0.09882  loss_rpn_loc: 0.04395  validation_loss: 1.954  time: 1.4913  data_time: 0.0244  lr: 8.492e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:05:34 d2.utils.events]: \u001b[0m eta: 3:06:19  iter: 2559  total_loss: 1.956  loss_cls_stage0: 0.3077  loss_box_reg_stage0: 0.1876  loss_cls_stage1: 0.2412  loss_box_reg_stage1: 0.2069  loss_cls_stage2: 0.177  loss_box_reg_stage2: 0.1534  loss_mask: 0.5906  loss_rpn_cls: 0.09618  loss_rpn_loc: 0.03752  validation_loss: 1.954  time: 1.4915  data_time: 0.0257  lr: 8.4694e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:06:04 d2.utils.events]: \u001b[0m eta: 3:05:53  iter: 2579  total_loss: 1.937  loss_cls_stage0: 0.2866  loss_box_reg_stage0: 0.1627  loss_cls_stage1: 0.2323  loss_box_reg_stage1: 0.2037  loss_cls_stage2: 0.1695  loss_box_reg_stage2: 0.136  loss_mask: 0.5597  loss_rpn_cls: 0.09664  loss_rpn_loc: 0.03813  validation_loss: 1.954  time: 1.4917  data_time: 0.0239  lr: 8.4467e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:06:34 d2.utils.events]: \u001b[0m eta: 3:05:24  iter: 2599  total_loss: 1.773  loss_cls_stage0: 0.2571  loss_box_reg_stage0: 0.1564  loss_cls_stage1: 0.2092  loss_box_reg_stage1: 0.1959  loss_cls_stage2: 0.1475  loss_box_reg_stage2: 0.1326  loss_mask: 0.5328  loss_rpn_cls: 0.07535  loss_rpn_loc: 0.03274  validation_loss: 1.954  time: 1.4918  data_time: 0.0247  lr: 8.4239e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:07:05 d2.utils.events]: \u001b[0m eta: 3:04:55  iter: 2619  total_loss: 1.955  loss_cls_stage0: 0.2872  loss_box_reg_stage0: 0.1647  loss_cls_stage1: 0.2426  loss_box_reg_stage1: 0.2026  loss_cls_stage2: 0.1724  loss_box_reg_stage2: 0.1513  loss_mask: 0.5853  loss_rpn_cls: 0.1016  loss_rpn_loc: 0.03795  validation_loss: 1.954  time: 1.4920  data_time: 0.0241  lr: 8.4009e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:07:35 d2.utils.events]: \u001b[0m eta: 3:04:25  iter: 2639  total_loss: 1.826  loss_cls_stage0: 0.2946  loss_box_reg_stage0: 0.1587  loss_cls_stage1: 0.2313  loss_box_reg_stage1: 0.1915  loss_cls_stage2: 0.1561  loss_box_reg_stage2: 0.1389  loss_mask: 0.5759  loss_rpn_cls: 0.08608  loss_rpn_loc: 0.03819  validation_loss: 1.954  time: 1.4922  data_time: 0.0225  lr: 8.3778e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:08:05 d2.utils.events]: \u001b[0m eta: 3:03:56  iter: 2659  total_loss: 1.969  loss_cls_stage0: 0.2753  loss_box_reg_stage0: 0.1597  loss_cls_stage1: 0.2353  loss_box_reg_stage1: 0.2049  loss_cls_stage2: 0.174  loss_box_reg_stage2: 0.1565  loss_mask: 0.5682  loss_rpn_cls: 0.09451  loss_rpn_loc: 0.03919  validation_loss: 1.954  time: 1.4924  data_time: 0.0235  lr: 8.3546e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:08:35 d2.utils.events]: \u001b[0m eta: 3:03:28  iter: 2679  total_loss: 1.883  loss_cls_stage0: 0.2913  loss_box_reg_stage0: 0.1734  loss_cls_stage1: 0.2265  loss_box_reg_stage1: 0.2109  loss_cls_stage2: 0.1587  loss_box_reg_stage2: 0.1541  loss_mask: 0.5888  loss_rpn_cls: 0.08279  loss_rpn_loc: 0.03266  validation_loss: 1.954  time: 1.4925  data_time: 0.0229  lr: 8.3312e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:09:06 d2.utils.events]: \u001b[0m eta: 3:03:03  iter: 2699  total_loss: 1.96  loss_cls_stage0: 0.3045  loss_box_reg_stage0: 0.1778  loss_cls_stage1: 0.2357  loss_box_reg_stage1: 0.2045  loss_cls_stage2: 0.1728  loss_box_reg_stage2: 0.162  loss_mask: 0.5779  loss_rpn_cls: 0.08156  loss_rpn_loc: 0.03389  validation_loss: 1.954  time: 1.4926  data_time: 0.0241  lr: 8.3077e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:09:36 d2.utils.events]: \u001b[0m eta: 3:02:34  iter: 2719  total_loss: 1.968  loss_cls_stage0: 0.3038  loss_box_reg_stage0: 0.1765  loss_cls_stage1: 0.2576  loss_box_reg_stage1: 0.2247  loss_cls_stage2: 0.181  loss_box_reg_stage2: 0.1705  loss_mask: 0.5387  loss_rpn_cls: 0.085  loss_rpn_loc: 0.03551  validation_loss: 1.954  time: 1.4928  data_time: 0.0232  lr: 8.2841e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:10:06 d2.utils.events]: \u001b[0m eta: 3:02:06  iter: 2739  total_loss: 1.903  loss_cls_stage0: 0.2884  loss_box_reg_stage0: 0.1609  loss_cls_stage1: 0.2363  loss_box_reg_stage1: 0.206  loss_cls_stage2: 0.1737  loss_box_reg_stage2: 0.1554  loss_mask: 0.592  loss_rpn_cls: 0.09323  loss_rpn_loc: 0.03807  validation_loss: 1.954  time: 1.4930  data_time: 0.0226  lr: 8.2604e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:10:37 d2.utils.events]: \u001b[0m eta: 3:01:37  iter: 2759  total_loss: 1.962  loss_cls_stage0: 0.3007  loss_box_reg_stage0: 0.1731  loss_cls_stage1: 0.2351  loss_box_reg_stage1: 0.2067  loss_cls_stage2: 0.1775  loss_box_reg_stage2: 0.1574  loss_mask: 0.5583  loss_rpn_cls: 0.09412  loss_rpn_loc: 0.03961  validation_loss: 1.954  time: 1.4932  data_time: 0.0232  lr: 8.2365e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:11:07 d2.utils.events]: \u001b[0m eta: 3:01:11  iter: 2779  total_loss: 1.823  loss_cls_stage0: 0.2734  loss_box_reg_stage0: 0.1529  loss_cls_stage1: 0.2076  loss_box_reg_stage1: 0.1943  loss_cls_stage2: 0.1562  loss_box_reg_stage2: 0.1549  loss_mask: 0.5913  loss_rpn_cls: 0.09273  loss_rpn_loc: 0.03463  validation_loss: 1.954  time: 1.4933  data_time: 0.0256  lr: 8.2125e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:11:37 d2.utils.events]: \u001b[0m eta: 3:00:43  iter: 2799  total_loss: 1.861  loss_cls_stage0: 0.2913  loss_box_reg_stage0: 0.1712  loss_cls_stage1: 0.2271  loss_box_reg_stage1: 0.2061  loss_cls_stage2: 0.1691  loss_box_reg_stage2: 0.1447  loss_mask: 0.541  loss_rpn_cls: 0.09172  loss_rpn_loc: 0.03717  validation_loss: 1.954  time: 1.4934  data_time: 0.0247  lr: 8.1883e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:12:08 d2.utils.events]: \u001b[0m eta: 3:00:17  iter: 2819  total_loss: 2.109  loss_cls_stage0: 0.3406  loss_box_reg_stage0: 0.1849  loss_cls_stage1: 0.2691  loss_box_reg_stage1: 0.2405  loss_cls_stage2: 0.1804  loss_box_reg_stage2: 0.166  loss_mask: 0.5632  loss_rpn_cls: 0.08636  loss_rpn_loc: 0.03776  validation_loss: 1.954  time: 1.4936  data_time: 0.0237  lr: 8.1641e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:12:38 d2.utils.events]: \u001b[0m eta: 2:59:48  iter: 2839  total_loss: 1.885  loss_cls_stage0: 0.2628  loss_box_reg_stage0: 0.1605  loss_cls_stage1: 0.2196  loss_box_reg_stage1: 0.201  loss_cls_stage2: 0.1672  loss_box_reg_stage2: 0.148  loss_mask: 0.5591  loss_rpn_cls: 0.09278  loss_rpn_loc: 0.04033  validation_loss: 1.954  time: 1.4938  data_time: 0.0247  lr: 8.1397e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:13:08 d2.utils.events]: \u001b[0m eta: 2:59:20  iter: 2859  total_loss: 1.919  loss_cls_stage0: 0.2864  loss_box_reg_stage0: 0.1691  loss_cls_stage1: 0.2402  loss_box_reg_stage1: 0.2271  loss_cls_stage2: 0.1735  loss_box_reg_stage2: 0.1616  loss_mask: 0.5596  loss_rpn_cls: 0.09678  loss_rpn_loc: 0.03574  validation_loss: 1.954  time: 1.4940  data_time: 0.0249  lr: 8.1152e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:13:38 d2.utils.events]: \u001b[0m eta: 2:58:51  iter: 2879  total_loss: 1.832  loss_cls_stage0: 0.2636  loss_box_reg_stage0: 0.1598  loss_cls_stage1: 0.1985  loss_box_reg_stage1: 0.1874  loss_cls_stage2: 0.1498  loss_box_reg_stage2: 0.1379  loss_mask: 0.5829  loss_rpn_cls: 0.08591  loss_rpn_loc: 0.03617  validation_loss: 1.954  time: 1.4941  data_time: 0.0239  lr: 8.0905e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:14:09 d2.utils.events]: \u001b[0m eta: 2:58:21  iter: 2899  total_loss: 1.73  loss_cls_stage0: 0.2464  loss_box_reg_stage0: 0.1653  loss_cls_stage1: 0.1885  loss_box_reg_stage1: 0.1914  loss_cls_stage2: 0.1501  loss_box_reg_stage2: 0.1505  loss_mask: 0.6042  loss_rpn_cls: 0.0771  loss_rpn_loc: 0.03306  validation_loss: 1.954  time: 1.4941  data_time: 0.0221  lr: 8.0658e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:14:39 d2.utils.events]: \u001b[0m eta: 2:57:52  iter: 2919  total_loss: 1.903  loss_cls_stage0: 0.3063  loss_box_reg_stage0: 0.1864  loss_cls_stage1: 0.2266  loss_box_reg_stage1: 0.2141  loss_cls_stage2: 0.1682  loss_box_reg_stage2: 0.1635  loss_mask: 0.5528  loss_rpn_cls: 0.09285  loss_rpn_loc: 0.03778  validation_loss: 1.954  time: 1.4943  data_time: 0.0286  lr: 8.0409e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:15:09 d2.utils.events]: \u001b[0m eta: 2:57:22  iter: 2939  total_loss: 1.86  loss_cls_stage0: 0.2646  loss_box_reg_stage0: 0.1608  loss_cls_stage1: 0.2047  loss_box_reg_stage1: 0.2093  loss_cls_stage2: 0.1563  loss_box_reg_stage2: 0.1529  loss_mask: 0.5696  loss_rpn_cls: 0.07496  loss_rpn_loc: 0.03289  validation_loss: 1.954  time: 1.4944  data_time: 0.0226  lr: 8.0159e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:15:40 d2.utils.events]: \u001b[0m eta: 2:56:54  iter: 2959  total_loss: 1.828  loss_cls_stage0: 0.2806  loss_box_reg_stage0: 0.1697  loss_cls_stage1: 0.2201  loss_box_reg_stage1: 0.2001  loss_cls_stage2: 0.1647  loss_box_reg_stage2: 0.1462  loss_mask: 0.5675  loss_rpn_cls: 0.08499  loss_rpn_loc: 0.03736  validation_loss: 1.954  time: 1.4946  data_time: 0.0247  lr: 7.9908e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:16:10 d2.utils.events]: \u001b[0m eta: 2:56:23  iter: 2979  total_loss: 1.838  loss_cls_stage0: 0.282  loss_box_reg_stage0: 0.1717  loss_cls_stage1: 0.2194  loss_box_reg_stage1: 0.2126  loss_cls_stage2: 0.1555  loss_box_reg_stage2: 0.1474  loss_mask: 0.5287  loss_rpn_cls: 0.08357  loss_rpn_loc: 0.03908  validation_loss: 1.954  time: 1.4947  data_time: 0.0233  lr: 7.9655e-05  max_mem: 12121M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/27 08:16:42 d2.data.common]: \u001b[0mSerializing 883 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/27 08:16:42 d2.data.common]: \u001b[0mSerialized dataset takes 0.91 MiB\n",
      "\u001b[32m[03/27 08:16:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 883 images\n",
      "\u001b[32m[03/27 08:16:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/883. 0.0798 s / img. ETA=0:01:37\n",
      "\u001b[32m[03/27 08:16:49 d2.evaluation.evaluator]: \u001b[0mInference done 56/883. 0.0798 s / img. ETA=0:01:32\n",
      "\u001b[32m[03/27 08:16:54 d2.evaluation.evaluator]: \u001b[0mInference done 99/883. 0.0803 s / img. ETA=0:01:29\n",
      "\u001b[32m[03/27 08:16:59 d2.evaluation.evaluator]: \u001b[0mInference done 142/883. 0.0803 s / img. ETA=0:01:25\n",
      "\u001b[32m[03/27 08:17:04 d2.evaluation.evaluator]: \u001b[0mInference done 186/883. 0.0803 s / img. ETA=0:01:20\n",
      "\u001b[32m[03/27 08:17:10 d2.evaluation.evaluator]: \u001b[0mInference done 230/883. 0.0803 s / img. ETA=0:01:15\n",
      "\u001b[32m[03/27 08:17:15 d2.evaluation.evaluator]: \u001b[0mInference done 275/883. 0.0803 s / img. ETA=0:01:09\n",
      "\u001b[32m[03/27 08:17:20 d2.evaluation.evaluator]: \u001b[0mInference done 318/883. 0.0803 s / img. ETA=0:01:05\n",
      "\u001b[32m[03/27 08:17:25 d2.evaluation.evaluator]: \u001b[0mInference done 362/883. 0.0803 s / img. ETA=0:01:00\n",
      "\u001b[32m[03/27 08:17:30 d2.evaluation.evaluator]: \u001b[0mInference done 405/883. 0.0803 s / img. ETA=0:00:55\n",
      "\u001b[32m[03/27 08:17:35 d2.evaluation.evaluator]: \u001b[0mInference done 450/883. 0.0803 s / img. ETA=0:00:49\n",
      "\u001b[32m[03/27 08:17:40 d2.evaluation.evaluator]: \u001b[0mInference done 496/883. 0.0803 s / img. ETA=0:00:44\n",
      "\u001b[32m[03/27 08:17:45 d2.evaluation.evaluator]: \u001b[0mInference done 539/883. 0.0803 s / img. ETA=0:00:39\n",
      "\u001b[32m[03/27 08:17:50 d2.evaluation.evaluator]: \u001b[0mInference done 584/883. 0.0803 s / img. ETA=0:00:34\n",
      "\u001b[32m[03/27 08:17:55 d2.evaluation.evaluator]: \u001b[0mInference done 627/883. 0.0803 s / img. ETA=0:00:29\n",
      "\u001b[32m[03/27 08:18:00 d2.evaluation.evaluator]: \u001b[0mInference done 670/883. 0.0803 s / img. ETA=0:00:24\n",
      "\u001b[32m[03/27 08:18:05 d2.evaluation.evaluator]: \u001b[0mInference done 713/883. 0.0804 s / img. ETA=0:00:19\n",
      "\u001b[32m[03/27 08:18:10 d2.evaluation.evaluator]: \u001b[0mInference done 758/883. 0.0803 s / img. ETA=0:00:14\n",
      "\u001b[32m[03/27 08:18:15 d2.evaluation.evaluator]: \u001b[0mInference done 802/883. 0.0803 s / img. ETA=0:00:09\n",
      "\u001b[32m[03/27 08:18:21 d2.evaluation.evaluator]: \u001b[0mInference done 845/883. 0.0803 s / img. ETA=0:00:04\n",
      "\u001b[32m[03/27 08:18:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:41.623149 (0.115744 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/27 08:18:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:10 (0.080352 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.39 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.046\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.085\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.024\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.047\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.076\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.086\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.086\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.035\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.087\n",
      "\u001b[32m[03/27 08:18:26 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold5 in csv format:\n",
      "\u001b[32m[03/27 08:18:26 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/27 08:18:26 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/27 08:18:26 d2.evaluation.testing]: \u001b[0mcopypaste: 4.6333,8.5000,9.0444,0.0000,2.4159,4.7177\n",
      "validation do loss eval 1.9945833159976882\n",
      "\u001b[32m[03/27 08:19:56 d2.utils.events]: \u001b[0m eta: 2:55:54  iter: 2999  total_loss: 2.121  loss_cls_stage0: 0.3165  loss_box_reg_stage0: 0.1985  loss_cls_stage1: 0.2623  loss_box_reg_stage1: 0.2396  loss_cls_stage2: 0.1896  loss_box_reg_stage2: 0.1881  loss_mask: 0.5665  loss_rpn_cls: 0.09399  loss_rpn_loc: 0.04052  validation_loss: 1.968  time: 1.4949  data_time: 0.0235  lr: 7.9402e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:20:25 d2.utils.events]: \u001b[0m eta: 2:55:25  iter: 3019  total_loss: 1.889  loss_cls_stage0: 0.2627  loss_box_reg_stage0: 0.1598  loss_cls_stage1: 0.2097  loss_box_reg_stage1: 0.2124  loss_cls_stage2: 0.1638  loss_box_reg_stage2: 0.1563  loss_mask: 0.6069  loss_rpn_cls: 0.08036  loss_rpn_loc: 0.03451  validation_loss: 1.968  time: 1.4948  data_time: 0.0249  lr: 7.9147e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:20:56 d2.utils.events]: \u001b[0m eta: 2:54:56  iter: 3039  total_loss: 1.985  loss_cls_stage0: 0.2823  loss_box_reg_stage0: 0.1806  loss_cls_stage1: 0.2313  loss_box_reg_stage1: 0.2428  loss_cls_stage2: 0.1638  loss_box_reg_stage2: 0.1628  loss_mask: 0.5547  loss_rpn_cls: 0.08397  loss_rpn_loc: 0.03785  validation_loss: 1.968  time: 1.4950  data_time: 0.0231  lr: 7.8891e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:21:26 d2.utils.events]: \u001b[0m eta: 2:54:28  iter: 3059  total_loss: 1.999  loss_cls_stage0: 0.2936  loss_box_reg_stage0: 0.1803  loss_cls_stage1: 0.2324  loss_box_reg_stage1: 0.2223  loss_cls_stage2: 0.1656  loss_box_reg_stage2: 0.1635  loss_mask: 0.6169  loss_rpn_cls: 0.08863  loss_rpn_loc: 0.04113  validation_loss: 1.968  time: 1.4952  data_time: 0.0235  lr: 7.8634e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:21:57 d2.utils.events]: \u001b[0m eta: 2:54:00  iter: 3079  total_loss: 1.963  loss_cls_stage0: 0.3013  loss_box_reg_stage0: 0.1931  loss_cls_stage1: 0.2293  loss_box_reg_stage1: 0.2204  loss_cls_stage2: 0.1657  loss_box_reg_stage2: 0.1835  loss_mask: 0.5651  loss_rpn_cls: 0.07739  loss_rpn_loc: 0.03252  validation_loss: 1.968  time: 1.4953  data_time: 0.0241  lr: 7.8376e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:22:27 d2.utils.events]: \u001b[0m eta: 2:53:32  iter: 3099  total_loss: 2.108  loss_cls_stage0: 0.3246  loss_box_reg_stage0: 0.1896  loss_cls_stage1: 0.2453  loss_box_reg_stage1: 0.2403  loss_cls_stage2: 0.1767  loss_box_reg_stage2: 0.1651  loss_mask: 0.6239  loss_rpn_cls: 0.0871  loss_rpn_loc: 0.03977  validation_loss: 1.968  time: 1.4955  data_time: 0.0246  lr: 7.8117e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:22:58 d2.utils.events]: \u001b[0m eta: 2:53:02  iter: 3119  total_loss: 2.027  loss_cls_stage0: 0.3044  loss_box_reg_stage0: 0.1865  loss_cls_stage1: 0.2223  loss_box_reg_stage1: 0.2308  loss_cls_stage2: 0.1686  loss_box_reg_stage2: 0.1839  loss_mask: 0.5581  loss_rpn_cls: 0.08259  loss_rpn_loc: 0.03908  validation_loss: 1.968  time: 1.4957  data_time: 0.0234  lr: 7.7857e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:23:28 d2.utils.events]: \u001b[0m eta: 2:52:32  iter: 3139  total_loss: 1.932  loss_cls_stage0: 0.2757  loss_box_reg_stage0: 0.1735  loss_cls_stage1: 0.2225  loss_box_reg_stage1: 0.2075  loss_cls_stage2: 0.1554  loss_box_reg_stage2: 0.1691  loss_mask: 0.5804  loss_rpn_cls: 0.08871  loss_rpn_loc: 0.0366  validation_loss: 1.968  time: 1.4958  data_time: 0.0295  lr: 7.7595e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:23:58 d2.utils.events]: \u001b[0m eta: 2:52:02  iter: 3159  total_loss: 1.97  loss_cls_stage0: 0.289  loss_box_reg_stage0: 0.18  loss_cls_stage1: 0.2272  loss_box_reg_stage1: 0.2438  loss_cls_stage2: 0.1607  loss_box_reg_stage2: 0.163  loss_mask: 0.5642  loss_rpn_cls: 0.09153  loss_rpn_loc: 0.04  validation_loss: 1.968  time: 1.4959  data_time: 0.0238  lr: 7.7333e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:24:29 d2.utils.events]: \u001b[0m eta: 2:51:33  iter: 3179  total_loss: 1.899  loss_cls_stage0: 0.273  loss_box_reg_stage0: 0.169  loss_cls_stage1: 0.233  loss_box_reg_stage1: 0.2143  loss_cls_stage2: 0.1627  loss_box_reg_stage2: 0.1632  loss_mask: 0.551  loss_rpn_cls: 0.0774  loss_rpn_loc: 0.03456  validation_loss: 1.968  time: 1.4961  data_time: 0.0250  lr: 7.7069e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:24:59 d2.utils.events]: \u001b[0m eta: 2:51:04  iter: 3199  total_loss: 1.937  loss_cls_stage0: 0.3108  loss_box_reg_stage0: 0.1874  loss_cls_stage1: 0.2415  loss_box_reg_stage1: 0.2315  loss_cls_stage2: 0.1699  loss_box_reg_stage2: 0.155  loss_mask: 0.5173  loss_rpn_cls: 0.08119  loss_rpn_loc: 0.03333  validation_loss: 1.968  time: 1.4963  data_time: 0.0236  lr: 7.6805e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:25:29 d2.utils.events]: \u001b[0m eta: 2:50:35  iter: 3219  total_loss: 1.898  loss_cls_stage0: 0.2785  loss_box_reg_stage0: 0.1704  loss_cls_stage1: 0.2055  loss_box_reg_stage1: 0.2111  loss_cls_stage2: 0.1492  loss_box_reg_stage2: 0.1651  loss_mask: 0.5548  loss_rpn_cls: 0.08396  loss_rpn_loc: 0.03124  validation_loss: 1.968  time: 1.4963  data_time: 0.0251  lr: 7.6539e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:26:00 d2.utils.events]: \u001b[0m eta: 2:50:06  iter: 3239  total_loss: 2.051  loss_cls_stage0: 0.3215  loss_box_reg_stage0: 0.2075  loss_cls_stage1: 0.2501  loss_box_reg_stage1: 0.2288  loss_cls_stage2: 0.1669  loss_box_reg_stage2: 0.1522  loss_mask: 0.6189  loss_rpn_cls: 0.0854  loss_rpn_loc: 0.03519  validation_loss: 1.968  time: 1.4965  data_time: 0.0300  lr: 7.6272e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:26:30 d2.utils.events]: \u001b[0m eta: 2:49:40  iter: 3259  total_loss: 2.083  loss_cls_stage0: 0.3119  loss_box_reg_stage0: 0.2055  loss_cls_stage1: 0.2529  loss_box_reg_stage1: 0.2448  loss_cls_stage2: 0.1808  loss_box_reg_stage2: 0.1827  loss_mask: 0.5706  loss_rpn_cls: 0.07925  loss_rpn_loc: 0.03753  validation_loss: 1.968  time: 1.4967  data_time: 0.0236  lr: 7.6004e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:27:01 d2.utils.events]: \u001b[0m eta: 2:49:12  iter: 3279  total_loss: 2.115  loss_cls_stage0: 0.3275  loss_box_reg_stage0: 0.204  loss_cls_stage1: 0.2566  loss_box_reg_stage1: 0.236  loss_cls_stage2: 0.1763  loss_box_reg_stage2: 0.1697  loss_mask: 0.5512  loss_rpn_cls: 0.0808  loss_rpn_loc: 0.04369  validation_loss: 1.968  time: 1.4969  data_time: 0.0243  lr: 7.5735e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:27:32 d2.utils.events]: \u001b[0m eta: 2:48:41  iter: 3299  total_loss: 2.179  loss_cls_stage0: 0.3019  loss_box_reg_stage0: 0.1972  loss_cls_stage1: 0.2535  loss_box_reg_stage1: 0.2464  loss_cls_stage2: 0.1783  loss_box_reg_stage2: 0.1939  loss_mask: 0.5825  loss_rpn_cls: 0.1017  loss_rpn_loc: 0.04437  validation_loss: 1.968  time: 1.4971  data_time: 0.0248  lr: 7.5466e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:28:02 d2.utils.events]: \u001b[0m eta: 2:48:18  iter: 3319  total_loss: 2.042  loss_cls_stage0: 0.2948  loss_box_reg_stage0: 0.1979  loss_cls_stage1: 0.2399  loss_box_reg_stage1: 0.2546  loss_cls_stage2: 0.1683  loss_box_reg_stage2: 0.1976  loss_mask: 0.5822  loss_rpn_cls: 0.07802  loss_rpn_loc: 0.03606  validation_loss: 1.968  time: 1.4972  data_time: 0.0235  lr: 7.5195e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:28:33 d2.utils.events]: \u001b[0m eta: 2:47:51  iter: 3339  total_loss: 2.149  loss_cls_stage0: 0.2943  loss_box_reg_stage0: 0.1921  loss_cls_stage1: 0.2398  loss_box_reg_stage1: 0.2669  loss_cls_stage2: 0.1855  loss_box_reg_stage2: 0.208  loss_mask: 0.5867  loss_rpn_cls: 0.09314  loss_rpn_loc: 0.04246  validation_loss: 1.968  time: 1.4974  data_time: 0.0245  lr: 7.4923e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:29:03 d2.utils.events]: \u001b[0m eta: 2:47:21  iter: 3359  total_loss: 1.833  loss_cls_stage0: 0.2721  loss_box_reg_stage0: 0.1649  loss_cls_stage1: 0.2087  loss_box_reg_stage1: 0.2194  loss_cls_stage2: 0.1568  loss_box_reg_stage2: 0.1713  loss_mask: 0.5075  loss_rpn_cls: 0.07371  loss_rpn_loc: 0.03348  validation_loss: 1.968  time: 1.4975  data_time: 0.0273  lr: 7.465e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:29:34 d2.utils.events]: \u001b[0m eta: 2:46:54  iter: 3379  total_loss: 2.123  loss_cls_stage0: 0.3217  loss_box_reg_stage0: 0.185  loss_cls_stage1: 0.2627  loss_box_reg_stage1: 0.2497  loss_cls_stage2: 0.1964  loss_box_reg_stage2: 0.2013  loss_mask: 0.5846  loss_rpn_cls: 0.08853  loss_rpn_loc: 0.04028  validation_loss: 1.968  time: 1.4977  data_time: 0.0243  lr: 7.4376e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:30:04 d2.utils.events]: \u001b[0m eta: 2:46:25  iter: 3399  total_loss: 1.974  loss_cls_stage0: 0.293  loss_box_reg_stage0: 0.2011  loss_cls_stage1: 0.2212  loss_box_reg_stage1: 0.2438  loss_cls_stage2: 0.1655  loss_box_reg_stage2: 0.1779  loss_mask: 0.5705  loss_rpn_cls: 0.08452  loss_rpn_loc: 0.03635  validation_loss: 1.968  time: 1.4979  data_time: 0.0254  lr: 7.4101e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:30:35 d2.utils.events]: \u001b[0m eta: 2:45:57  iter: 3419  total_loss: 1.98  loss_cls_stage0: 0.2871  loss_box_reg_stage0: 0.1855  loss_cls_stage1: 0.2234  loss_box_reg_stage1: 0.2279  loss_cls_stage2: 0.1626  loss_box_reg_stage2: 0.1821  loss_mask: 0.5533  loss_rpn_cls: 0.08421  loss_rpn_loc: 0.03728  validation_loss: 1.968  time: 1.4980  data_time: 0.0254  lr: 7.3826e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:31:05 d2.utils.events]: \u001b[0m eta: 2:45:29  iter: 3439  total_loss: 2.001  loss_cls_stage0: 0.2926  loss_box_reg_stage0: 0.183  loss_cls_stage1: 0.2227  loss_box_reg_stage1: 0.2326  loss_cls_stage2: 0.1581  loss_box_reg_stage2: 0.1757  loss_mask: 0.5721  loss_rpn_cls: 0.07701  loss_rpn_loc: 0.0389  validation_loss: 1.968  time: 1.4982  data_time: 0.0241  lr: 7.3549e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:31:35 d2.utils.events]: \u001b[0m eta: 2:45:02  iter: 3459  total_loss: 2.033  loss_cls_stage0: 0.2841  loss_box_reg_stage0: 0.1633  loss_cls_stage1: 0.2467  loss_box_reg_stage1: 0.216  loss_cls_stage2: 0.1775  loss_box_reg_stage2: 0.1842  loss_mask: 0.597  loss_rpn_cls: 0.07738  loss_rpn_loc: 0.03302  validation_loss: 1.968  time: 1.4983  data_time: 0.0253  lr: 7.3271e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:32:06 d2.utils.events]: \u001b[0m eta: 2:44:34  iter: 3479  total_loss: 2.165  loss_cls_stage0: 0.3109  loss_box_reg_stage0: 0.1952  loss_cls_stage1: 0.2521  loss_box_reg_stage1: 0.2662  loss_cls_stage2: 0.1867  loss_box_reg_stage2: 0.2142  loss_mask: 0.5869  loss_rpn_cls: 0.08047  loss_rpn_loc: 0.04214  validation_loss: 1.968  time: 1.4985  data_time: 0.0302  lr: 7.2993e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:32:37 d2.utils.events]: \u001b[0m eta: 2:44:09  iter: 3499  total_loss: 2.124  loss_cls_stage0: 0.3012  loss_box_reg_stage0: 0.1983  loss_cls_stage1: 0.2486  loss_box_reg_stage1: 0.2723  loss_cls_stage2: 0.1827  loss_box_reg_stage2: 0.2028  loss_mask: 0.5661  loss_rpn_cls: 0.07727  loss_rpn_loc: 0.0392  validation_loss: 1.968  time: 1.4987  data_time: 0.0233  lr: 7.2714e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:33:07 d2.utils.events]: \u001b[0m eta: 2:43:40  iter: 3519  total_loss: 2.079  loss_cls_stage0: 0.3098  loss_box_reg_stage0: 0.1952  loss_cls_stage1: 0.2465  loss_box_reg_stage1: 0.255  loss_cls_stage2: 0.1652  loss_box_reg_stage2: 0.1822  loss_mask: 0.599  loss_rpn_cls: 0.0778  loss_rpn_loc: 0.03767  validation_loss: 1.968  time: 1.4988  data_time: 0.0239  lr: 7.2433e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:33:38 d2.utils.events]: \u001b[0m eta: 2:43:11  iter: 3539  total_loss: 2.034  loss_cls_stage0: 0.3036  loss_box_reg_stage0: 0.1976  loss_cls_stage1: 0.2406  loss_box_reg_stage1: 0.2409  loss_cls_stage2: 0.1749  loss_box_reg_stage2: 0.2007  loss_mask: 0.5618  loss_rpn_cls: 0.08822  loss_rpn_loc: 0.03796  validation_loss: 1.968  time: 1.4990  data_time: 0.0238  lr: 7.2152e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:34:08 d2.utils.events]: \u001b[0m eta: 2:42:41  iter: 3559  total_loss: 1.804  loss_cls_stage0: 0.2799  loss_box_reg_stage0: 0.1783  loss_cls_stage1: 0.2114  loss_box_reg_stage1: 0.245  loss_cls_stage2: 0.1483  loss_box_reg_stage2: 0.1844  loss_mask: 0.5666  loss_rpn_cls: 0.07172  loss_rpn_loc: 0.02912  validation_loss: 1.968  time: 1.4991  data_time: 0.0251  lr: 7.187e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:34:39 d2.utils.events]: \u001b[0m eta: 2:42:13  iter: 3579  total_loss: 1.98  loss_cls_stage0: 0.2691  loss_box_reg_stage0: 0.1897  loss_cls_stage1: 0.2259  loss_box_reg_stage1: 0.2535  loss_cls_stage2: 0.1555  loss_box_reg_stage2: 0.1778  loss_mask: 0.553  loss_rpn_cls: 0.08665  loss_rpn_loc: 0.03651  validation_loss: 1.968  time: 1.4992  data_time: 0.0234  lr: 7.1587e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:35:09 d2.utils.events]: \u001b[0m eta: 2:41:46  iter: 3599  total_loss: 2.019  loss_cls_stage0: 0.2937  loss_box_reg_stage0: 0.2013  loss_cls_stage1: 0.2299  loss_box_reg_stage1: 0.2546  loss_cls_stage2: 0.1629  loss_box_reg_stage2: 0.1905  loss_mask: 0.5821  loss_rpn_cls: 0.08444  loss_rpn_loc: 0.03825  validation_loss: 1.968  time: 1.4994  data_time: 0.0223  lr: 7.1303e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:35:40 d2.utils.events]: \u001b[0m eta: 2:41:20  iter: 3619  total_loss: 2.197  loss_cls_stage0: 0.3242  loss_box_reg_stage0: 0.217  loss_cls_stage1: 0.2571  loss_box_reg_stage1: 0.2758  loss_cls_stage2: 0.1865  loss_box_reg_stage2: 0.1977  loss_mask: 0.6188  loss_rpn_cls: 0.08036  loss_rpn_loc: 0.03694  validation_loss: 1.968  time: 1.4996  data_time: 0.0232  lr: 7.1019e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:36:11 d2.utils.events]: \u001b[0m eta: 2:40:53  iter: 3639  total_loss: 2.176  loss_cls_stage0: 0.3252  loss_box_reg_stage0: 0.2119  loss_cls_stage1: 0.2554  loss_box_reg_stage1: 0.2802  loss_cls_stage2: 0.1897  loss_box_reg_stage2: 0.2207  loss_mask: 0.5818  loss_rpn_cls: 0.07369  loss_rpn_loc: 0.03893  validation_loss: 1.968  time: 1.4999  data_time: 0.0227  lr: 7.0733e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:36:42 d2.utils.events]: \u001b[0m eta: 2:40:24  iter: 3659  total_loss: 2.016  loss_cls_stage0: 0.314  loss_box_reg_stage0: 0.2173  loss_cls_stage1: 0.2438  loss_box_reg_stage1: 0.237  loss_cls_stage2: 0.1716  loss_box_reg_stage2: 0.2036  loss_mask: 0.5584  loss_rpn_cls: 0.086  loss_rpn_loc: 0.03683  validation_loss: 1.968  time: 1.5000  data_time: 0.0233  lr: 7.0447e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:37:12 d2.utils.events]: \u001b[0m eta: 2:39:59  iter: 3679  total_loss: 2.219  loss_cls_stage0: 0.3288  loss_box_reg_stage0: 0.2166  loss_cls_stage1: 0.2695  loss_box_reg_stage1: 0.293  loss_cls_stage2: 0.1866  loss_box_reg_stage2: 0.2283  loss_mask: 0.5431  loss_rpn_cls: 0.08455  loss_rpn_loc: 0.04133  validation_loss: 1.968  time: 1.5003  data_time: 0.0239  lr: 7.016e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:37:43 d2.utils.events]: \u001b[0m eta: 2:39:30  iter: 3699  total_loss: 1.923  loss_cls_stage0: 0.2881  loss_box_reg_stage0: 0.1967  loss_cls_stage1: 0.2134  loss_box_reg_stage1: 0.248  loss_cls_stage2: 0.1556  loss_box_reg_stage2: 0.2098  loss_mask: 0.5465  loss_rpn_cls: 0.07374  loss_rpn_loc: 0.03554  validation_loss: 1.968  time: 1.5004  data_time: 0.0236  lr: 6.9872e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:38:14 d2.utils.events]: \u001b[0m eta: 2:39:01  iter: 3719  total_loss: 2.059  loss_cls_stage0: 0.316  loss_box_reg_stage0: 0.2231  loss_cls_stage1: 0.2532  loss_box_reg_stage1: 0.2746  loss_cls_stage2: 0.1832  loss_box_reg_stage2: 0.2023  loss_mask: 0.5074  loss_rpn_cls: 0.08584  loss_rpn_loc: 0.03783  validation_loss: 1.968  time: 1.5006  data_time: 0.0229  lr: 6.9583e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:38:44 d2.utils.events]: \u001b[0m eta: 2:38:33  iter: 3739  total_loss: 2.033  loss_cls_stage0: 0.3022  loss_box_reg_stage0: 0.2  loss_cls_stage1: 0.2298  loss_box_reg_stage1: 0.253  loss_cls_stage2: 0.1617  loss_box_reg_stage2: 0.2047  loss_mask: 0.5944  loss_rpn_cls: 0.06904  loss_rpn_loc: 0.03259  validation_loss: 1.968  time: 1.5007  data_time: 0.0315  lr: 6.9294e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:39:15 d2.utils.events]: \u001b[0m eta: 2:38:08  iter: 3759  total_loss: 2.224  loss_cls_stage0: 0.3403  loss_box_reg_stage0: 0.2271  loss_cls_stage1: 0.2598  loss_box_reg_stage1: 0.2932  loss_cls_stage2: 0.1854  loss_box_reg_stage2: 0.2113  loss_mask: 0.575  loss_rpn_cls: 0.0838  loss_rpn_loc: 0.03913  validation_loss: 1.968  time: 1.5010  data_time: 0.0233  lr: 6.9003e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:39:46 d2.utils.events]: \u001b[0m eta: 2:37:43  iter: 3779  total_loss: 2.071  loss_cls_stage0: 0.291  loss_box_reg_stage0: 0.1921  loss_cls_stage1: 0.2403  loss_box_reg_stage1: 0.2557  loss_cls_stage2: 0.1805  loss_box_reg_stage2: 0.2034  loss_mask: 0.5275  loss_rpn_cls: 0.07843  loss_rpn_loc: 0.03896  validation_loss: 1.968  time: 1.5012  data_time: 0.0230  lr: 6.8713e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:40:17 d2.utils.events]: \u001b[0m eta: 2:37:15  iter: 3799  total_loss: 1.924  loss_cls_stage0: 0.2596  loss_box_reg_stage0: 0.1812  loss_cls_stage1: 0.2159  loss_box_reg_stage1: 0.2526  loss_cls_stage2: 0.1548  loss_box_reg_stage2: 0.1967  loss_mask: 0.5583  loss_rpn_cls: 0.08478  loss_rpn_loc: 0.03297  validation_loss: 1.968  time: 1.5013  data_time: 0.0235  lr: 6.8421e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:40:47 d2.utils.events]: \u001b[0m eta: 2:36:43  iter: 3819  total_loss: 1.879  loss_cls_stage0: 0.2584  loss_box_reg_stage0: 0.1787  loss_cls_stage1: 0.2029  loss_box_reg_stage1: 0.2235  loss_cls_stage2: 0.1489  loss_box_reg_stage2: 0.1913  loss_mask: 0.5474  loss_rpn_cls: 0.07353  loss_rpn_loc: 0.03036  validation_loss: 1.968  time: 1.5015  data_time: 0.0232  lr: 6.8128e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:41:18 d2.utils.events]: \u001b[0m eta: 2:36:15  iter: 3839  total_loss: 2.111  loss_cls_stage0: 0.2998  loss_box_reg_stage0: 0.1987  loss_cls_stage1: 0.2484  loss_box_reg_stage1: 0.259  loss_cls_stage2: 0.1796  loss_box_reg_stage2: 0.1927  loss_mask: 0.5733  loss_rpn_cls: 0.07974  loss_rpn_loc: 0.0402  validation_loss: 1.968  time: 1.5016  data_time: 0.0240  lr: 6.7835e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:41:49 d2.utils.events]: \u001b[0m eta: 2:35:46  iter: 3859  total_loss: 2.118  loss_cls_stage0: 0.2913  loss_box_reg_stage0: 0.1921  loss_cls_stage1: 0.2443  loss_box_reg_stage1: 0.2681  loss_cls_stage2: 0.1912  loss_box_reg_stage2: 0.2222  loss_mask: 0.5428  loss_rpn_cls: 0.08007  loss_rpn_loc: 0.04236  validation_loss: 1.968  time: 1.5018  data_time: 0.0242  lr: 6.7541e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:42:19 d2.utils.events]: \u001b[0m eta: 2:35:22  iter: 3879  total_loss: 2.151  loss_cls_stage0: 0.296  loss_box_reg_stage0: 0.1975  loss_cls_stage1: 0.2365  loss_box_reg_stage1: 0.2819  loss_cls_stage2: 0.1658  loss_box_reg_stage2: 0.227  loss_mask: 0.5531  loss_rpn_cls: 0.07558  loss_rpn_loc: 0.03622  validation_loss: 1.968  time: 1.5020  data_time: 0.0237  lr: 6.7247e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:42:50 d2.utils.events]: \u001b[0m eta: 2:34:54  iter: 3899  total_loss: 2.313  loss_cls_stage0: 0.3515  loss_box_reg_stage0: 0.2375  loss_cls_stage1: 0.267  loss_box_reg_stage1: 0.3002  loss_cls_stage2: 0.1953  loss_box_reg_stage2: 0.224  loss_mask: 0.5739  loss_rpn_cls: 0.08566  loss_rpn_loc: 0.04293  validation_loss: 1.968  time: 1.5022  data_time: 0.0235  lr: 6.6952e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:43:21 d2.utils.events]: \u001b[0m eta: 2:34:25  iter: 3919  total_loss: 2.177  loss_cls_stage0: 0.3114  loss_box_reg_stage0: 0.236  loss_cls_stage1: 0.2505  loss_box_reg_stage1: 0.3054  loss_cls_stage2: 0.1798  loss_box_reg_stage2: 0.223  loss_mask: 0.5562  loss_rpn_cls: 0.0794  loss_rpn_loc: 0.04217  validation_loss: 1.968  time: 1.5024  data_time: 0.0234  lr: 6.6656e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:43:52 d2.utils.events]: \u001b[0m eta: 2:33:56  iter: 3939  total_loss: 2.102  loss_cls_stage0: 0.3102  loss_box_reg_stage0: 0.2274  loss_cls_stage1: 0.2396  loss_box_reg_stage1: 0.2832  loss_cls_stage2: 0.1638  loss_box_reg_stage2: 0.2118  loss_mask: 0.5463  loss_rpn_cls: 0.07386  loss_rpn_loc: 0.03309  validation_loss: 1.968  time: 1.5026  data_time: 0.0223  lr: 6.6359e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:44:23 d2.utils.events]: \u001b[0m eta: 2:33:28  iter: 3959  total_loss: 2.201  loss_cls_stage0: 0.3221  loss_box_reg_stage0: 0.2181  loss_cls_stage1: 0.2714  loss_box_reg_stage1: 0.2872  loss_cls_stage2: 0.187  loss_box_reg_stage2: 0.2187  loss_mask: 0.5378  loss_rpn_cls: 0.08247  loss_rpn_loc: 0.04216  validation_loss: 1.968  time: 1.5028  data_time: 0.0252  lr: 6.6062e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:44:54 d2.utils.events]: \u001b[0m eta: 2:33:01  iter: 3979  total_loss: 2.248  loss_cls_stage0: 0.3166  loss_box_reg_stage0: 0.2214  loss_cls_stage1: 0.2615  loss_box_reg_stage1: 0.2881  loss_cls_stage2: 0.1953  loss_box_reg_stage2: 0.2284  loss_mask: 0.5511  loss_rpn_cls: 0.08012  loss_rpn_loc: 0.04127  validation_loss: 1.968  time: 1.5030  data_time: 0.0237  lr: 6.5764e-05  max_mem: 12121M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/27 08:45:27 d2.data.common]: \u001b[0mSerializing 883 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/27 08:45:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.91 MiB\n",
      "\u001b[32m[03/27 08:45:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 883 images\n",
      "\u001b[32m[03/27 08:45:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/883. 0.0795 s / img. ETA=0:01:33\n",
      "\u001b[32m[03/27 08:45:33 d2.evaluation.evaluator]: \u001b[0mInference done 60/883. 0.0803 s / img. ETA=0:01:25\n",
      "\u001b[32m[03/27 08:45:39 d2.evaluation.evaluator]: \u001b[0mInference done 109/883. 0.0800 s / img. ETA=0:01:20\n",
      "\u001b[32m[03/27 08:45:44 d2.evaluation.evaluator]: \u001b[0mInference done 155/883. 0.0800 s / img. ETA=0:01:16\n",
      "\u001b[32m[03/27 08:45:49 d2.evaluation.evaluator]: \u001b[0mInference done 204/883. 0.0800 s / img. ETA=0:01:11\n",
      "\u001b[32m[03/27 08:45:54 d2.evaluation.evaluator]: \u001b[0mInference done 253/883. 0.0800 s / img. ETA=0:01:06\n",
      "\u001b[32m[03/27 08:45:59 d2.evaluation.evaluator]: \u001b[0mInference done 302/883. 0.0799 s / img. ETA=0:01:00\n",
      "\u001b[32m[03/27 08:46:04 d2.evaluation.evaluator]: \u001b[0mInference done 351/883. 0.0799 s / img. ETA=0:00:55\n",
      "\u001b[32m[03/27 08:46:09 d2.evaluation.evaluator]: \u001b[0mInference done 400/883. 0.0799 s / img. ETA=0:00:50\n",
      "\u001b[32m[03/27 08:46:14 d2.evaluation.evaluator]: \u001b[0mInference done 449/883. 0.0799 s / img. ETA=0:00:45\n",
      "\u001b[32m[03/27 08:46:19 d2.evaluation.evaluator]: \u001b[0mInference done 498/883. 0.0799 s / img. ETA=0:00:40\n",
      "\u001b[32m[03/27 08:46:24 d2.evaluation.evaluator]: \u001b[0mInference done 547/883. 0.0799 s / img. ETA=0:00:34\n",
      "\u001b[32m[03/27 08:46:29 d2.evaluation.evaluator]: \u001b[0mInference done 596/883. 0.0799 s / img. ETA=0:00:29\n",
      "\u001b[32m[03/27 08:46:34 d2.evaluation.evaluator]: \u001b[0mInference done 645/883. 0.0799 s / img. ETA=0:00:24\n",
      "\u001b[32m[03/27 08:46:39 d2.evaluation.evaluator]: \u001b[0mInference done 693/883. 0.0799 s / img. ETA=0:00:19\n",
      "\u001b[32m[03/27 08:46:44 d2.evaluation.evaluator]: \u001b[0mInference done 742/883. 0.0799 s / img. ETA=0:00:14\n",
      "\u001b[32m[03/27 08:46:49 d2.evaluation.evaluator]: \u001b[0mInference done 791/883. 0.0799 s / img. ETA=0:00:09\n",
      "\u001b[32m[03/27 08:46:54 d2.evaluation.evaluator]: \u001b[0mInference done 839/883. 0.0799 s / img. ETA=0:00:04\n",
      "\u001b[32m[03/27 08:46:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:31.258031 (0.103939 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/27 08:46:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:10 (0.079888 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.28 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.059\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.102\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.113\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.027\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.061\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.095\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.111\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.111\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.036\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.116\n",
      "\u001b[32m[03/27 08:47:00 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold5 in csv format:\n",
      "\u001b[32m[03/27 08:47:00 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/27 08:47:00 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/27 08:47:00 d2.evaluation.testing]: \u001b[0mcopypaste: 5.9487,10.1619,11.2590,0.0000,2.7451,6.1288\n",
      "validation do loss eval 2.10964555552995\n",
      "\u001b[32m[03/27 08:48:31 d2.utils.events]: \u001b[0m eta: 2:32:31  iter: 3999  total_loss: 2.283  loss_cls_stage0: 0.329  loss_box_reg_stage0: 0.228  loss_cls_stage1: 0.2619  loss_box_reg_stage1: 0.2826  loss_cls_stage2: 0.1852  loss_box_reg_stage2: 0.2149  loss_mask: 0.6006  loss_rpn_cls: 0.07192  loss_rpn_loc: 0.03625  validation_loss: 1.981  time: 1.5031  data_time: 0.0236  lr: 6.5466e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:49:01 d2.utils.events]: \u001b[0m eta: 2:32:02  iter: 4019  total_loss: 2.005  loss_cls_stage0: 0.286  loss_box_reg_stage0: 0.2016  loss_cls_stage1: 0.2343  loss_box_reg_stage1: 0.2616  loss_cls_stage2: 0.1696  loss_box_reg_stage2: 0.2069  loss_mask: 0.5639  loss_rpn_cls: 0.07123  loss_rpn_loc: 0.03512  validation_loss: 1.981  time: 1.5031  data_time: 0.0244  lr: 6.5167e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:49:31 d2.utils.events]: \u001b[0m eta: 2:31:32  iter: 4039  total_loss: 2.04  loss_cls_stage0: 0.2893  loss_box_reg_stage0: 0.2043  loss_cls_stage1: 0.2185  loss_box_reg_stage1: 0.2551  loss_cls_stage2: 0.1619  loss_box_reg_stage2: 0.1966  loss_mask: 0.5573  loss_rpn_cls: 0.07782  loss_rpn_loc: 0.03482  validation_loss: 1.981  time: 1.5033  data_time: 0.0221  lr: 6.4867e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:50:02 d2.utils.events]: \u001b[0m eta: 2:31:02  iter: 4059  total_loss: 2.046  loss_cls_stage0: 0.2944  loss_box_reg_stage0: 0.2066  loss_cls_stage1: 0.2365  loss_box_reg_stage1: 0.2666  loss_cls_stage2: 0.1656  loss_box_reg_stage2: 0.2059  loss_mask: 0.5556  loss_rpn_cls: 0.07235  loss_rpn_loc: 0.03409  validation_loss: 1.981  time: 1.5035  data_time: 0.0219  lr: 6.4567e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:50:33 d2.utils.events]: \u001b[0m eta: 2:30:33  iter: 4079  total_loss: 2.077  loss_cls_stage0: 0.2936  loss_box_reg_stage0: 0.2131  loss_cls_stage1: 0.2345  loss_box_reg_stage1: 0.2707  loss_cls_stage2: 0.1712  loss_box_reg_stage2: 0.2299  loss_mask: 0.5656  loss_rpn_cls: 0.06953  loss_rpn_loc: 0.03446  validation_loss: 1.981  time: 1.5036  data_time: 0.0245  lr: 6.4266e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:51:04 d2.utils.events]: \u001b[0m eta: 2:30:04  iter: 4099  total_loss: 2.043  loss_cls_stage0: 0.3041  loss_box_reg_stage0: 0.2204  loss_cls_stage1: 0.2431  loss_box_reg_stage1: 0.266  loss_cls_stage2: 0.1692  loss_box_reg_stage2: 0.2018  loss_mask: 0.5229  loss_rpn_cls: 0.07952  loss_rpn_loc: 0.03939  validation_loss: 1.981  time: 1.5038  data_time: 0.0231  lr: 6.3965e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:51:34 d2.utils.events]: \u001b[0m eta: 2:29:33  iter: 4119  total_loss: 1.87  loss_cls_stage0: 0.2632  loss_box_reg_stage0: 0.1863  loss_cls_stage1: 0.2111  loss_box_reg_stage1: 0.2621  loss_cls_stage2: 0.1545  loss_box_reg_stage2: 0.2189  loss_mask: 0.5799  loss_rpn_cls: 0.07663  loss_rpn_loc: 0.03119  validation_loss: 1.981  time: 1.5039  data_time: 0.0257  lr: 6.3663e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:52:05 d2.utils.events]: \u001b[0m eta: 2:29:03  iter: 4139  total_loss: 2.205  loss_cls_stage0: 0.331  loss_box_reg_stage0: 0.2344  loss_cls_stage1: 0.2662  loss_box_reg_stage1: 0.3015  loss_cls_stage2: 0.1814  loss_box_reg_stage2: 0.2171  loss_mask: 0.5772  loss_rpn_cls: 0.07596  loss_rpn_loc: 0.03634  validation_loss: 1.981  time: 1.5042  data_time: 0.0233  lr: 6.336e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:52:36 d2.utils.events]: \u001b[0m eta: 2:28:34  iter: 4159  total_loss: 2.387  loss_cls_stage0: 0.3524  loss_box_reg_stage0: 0.2503  loss_cls_stage1: 0.2888  loss_box_reg_stage1: 0.3114  loss_cls_stage2: 0.1938  loss_box_reg_stage2: 0.2452  loss_mask: 0.6028  loss_rpn_cls: 0.07324  loss_rpn_loc: 0.03898  validation_loss: 1.981  time: 1.5044  data_time: 0.0246  lr: 6.3057e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:53:07 d2.utils.events]: \u001b[0m eta: 2:28:07  iter: 4179  total_loss: 2.144  loss_cls_stage0: 0.3115  loss_box_reg_stage0: 0.2363  loss_cls_stage1: 0.2502  loss_box_reg_stage1: 0.297  loss_cls_stage2: 0.1799  loss_box_reg_stage2: 0.2201  loss_mask: 0.5485  loss_rpn_cls: 0.07813  loss_rpn_loc: 0.03684  validation_loss: 1.981  time: 1.5046  data_time: 0.0234  lr: 6.2754e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:53:38 d2.utils.events]: \u001b[0m eta: 2:27:37  iter: 4199  total_loss: 2.138  loss_cls_stage0: 0.3294  loss_box_reg_stage0: 0.2166  loss_cls_stage1: 0.257  loss_box_reg_stage1: 0.2911  loss_cls_stage2: 0.1702  loss_box_reg_stage2: 0.2084  loss_mask: 0.5382  loss_rpn_cls: 0.07587  loss_rpn_loc: 0.03999  validation_loss: 1.981  time: 1.5047  data_time: 0.0235  lr: 6.245e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:54:09 d2.utils.events]: \u001b[0m eta: 2:27:09  iter: 4219  total_loss: 2.142  loss_cls_stage0: 0.3123  loss_box_reg_stage0: 0.2197  loss_cls_stage1: 0.2583  loss_box_reg_stage1: 0.2782  loss_cls_stage2: 0.1843  loss_box_reg_stage2: 0.2179  loss_mask: 0.5787  loss_rpn_cls: 0.06838  loss_rpn_loc: 0.03568  validation_loss: 1.981  time: 1.5049  data_time: 0.0237  lr: 6.2145e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:54:39 d2.utils.events]: \u001b[0m eta: 2:26:38  iter: 4239  total_loss: 2.208  loss_cls_stage0: 0.3276  loss_box_reg_stage0: 0.2258  loss_cls_stage1: 0.2633  loss_box_reg_stage1: 0.2867  loss_cls_stage2: 0.1816  loss_box_reg_stage2: 0.2266  loss_mask: 0.5599  loss_rpn_cls: 0.06872  loss_rpn_loc: 0.03371  validation_loss: 1.981  time: 1.5050  data_time: 0.0301  lr: 6.184e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:55:10 d2.utils.events]: \u001b[0m eta: 2:26:08  iter: 4259  total_loss: 2.077  loss_cls_stage0: 0.2934  loss_box_reg_stage0: 0.2024  loss_cls_stage1: 0.2389  loss_box_reg_stage1: 0.2656  loss_cls_stage2: 0.1652  loss_box_reg_stage2: 0.221  loss_mask: 0.574  loss_rpn_cls: 0.07147  loss_rpn_loc: 0.0341  validation_loss: 1.981  time: 1.5051  data_time: 0.0239  lr: 6.1535e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:55:41 d2.utils.events]: \u001b[0m eta: 2:25:39  iter: 4279  total_loss: 2.047  loss_cls_stage0: 0.293  loss_box_reg_stage0: 0.1999  loss_cls_stage1: 0.2309  loss_box_reg_stage1: 0.2852  loss_cls_stage2: 0.1778  loss_box_reg_stage2: 0.2332  loss_mask: 0.5415  loss_rpn_cls: 0.0671  loss_rpn_loc: 0.03268  validation_loss: 1.981  time: 1.5052  data_time: 0.0237  lr: 6.1229e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:56:12 d2.utils.events]: \u001b[0m eta: 2:25:11  iter: 4299  total_loss: 2.359  loss_cls_stage0: 0.3389  loss_box_reg_stage0: 0.2495  loss_cls_stage1: 0.2804  loss_box_reg_stage1: 0.3144  loss_cls_stage2: 0.1967  loss_box_reg_stage2: 0.2473  loss_mask: 0.5964  loss_rpn_cls: 0.0705  loss_rpn_loc: 0.03766  validation_loss: 1.981  time: 1.5055  data_time: 0.0231  lr: 6.0922e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:56:42 d2.utils.events]: \u001b[0m eta: 2:24:41  iter: 4319  total_loss: 2.056  loss_cls_stage0: 0.2939  loss_box_reg_stage0: 0.2078  loss_cls_stage1: 0.2399  loss_box_reg_stage1: 0.272  loss_cls_stage2: 0.1712  loss_box_reg_stage2: 0.2014  loss_mask: 0.5652  loss_rpn_cls: 0.07205  loss_rpn_loc: 0.03613  validation_loss: 1.981  time: 1.5056  data_time: 0.0238  lr: 6.0616e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:57:13 d2.utils.events]: \u001b[0m eta: 2:24:13  iter: 4339  total_loss: 2.251  loss_cls_stage0: 0.3287  loss_box_reg_stage0: 0.2346  loss_cls_stage1: 0.2793  loss_box_reg_stage1: 0.3131  loss_cls_stage2: 0.1957  loss_box_reg_stage2: 0.2319  loss_mask: 0.5776  loss_rpn_cls: 0.07901  loss_rpn_loc: 0.03787  validation_loss: 1.981  time: 1.5058  data_time: 0.0230  lr: 6.0309e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:57:44 d2.utils.events]: \u001b[0m eta: 2:23:46  iter: 4359  total_loss: 2.285  loss_cls_stage0: 0.3318  loss_box_reg_stage0: 0.232  loss_cls_stage1: 0.2656  loss_box_reg_stage1: 0.3094  loss_cls_stage2: 0.1917  loss_box_reg_stage2: 0.2407  loss_mask: 0.5363  loss_rpn_cls: 0.0786  loss_rpn_loc: 0.03915  validation_loss: 1.981  time: 1.5060  data_time: 0.0249  lr: 6.0001e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:58:15 d2.utils.events]: \u001b[0m eta: 2:23:17  iter: 4379  total_loss: 2.131  loss_cls_stage0: 0.2923  loss_box_reg_stage0: 0.2109  loss_cls_stage1: 0.2414  loss_box_reg_stage1: 0.3029  loss_cls_stage2: 0.1809  loss_box_reg_stage2: 0.2441  loss_mask: 0.5085  loss_rpn_cls: 0.06862  loss_rpn_loc: 0.03411  validation_loss: 1.981  time: 1.5062  data_time: 0.0249  lr: 5.9693e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:58:46 d2.utils.events]: \u001b[0m eta: 2:22:49  iter: 4399  total_loss: 2.398  loss_cls_stage0: 0.3553  loss_box_reg_stage0: 0.2417  loss_cls_stage1: 0.2934  loss_box_reg_stage1: 0.3455  loss_cls_stage2: 0.2  loss_box_reg_stage2: 0.2531  loss_mask: 0.578  loss_rpn_cls: 0.07357  loss_rpn_loc: 0.03886  validation_loss: 1.981  time: 1.5064  data_time: 0.0238  lr: 5.9384e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:59:17 d2.utils.events]: \u001b[0m eta: 2:22:21  iter: 4419  total_loss: 2.14  loss_cls_stage0: 0.2917  loss_box_reg_stage0: 0.2224  loss_cls_stage1: 0.2474  loss_box_reg_stage1: 0.3038  loss_cls_stage2: 0.1806  loss_box_reg_stage2: 0.2273  loss_mask: 0.628  loss_rpn_cls: 0.06599  loss_rpn_loc: 0.03331  validation_loss: 1.981  time: 1.5065  data_time: 0.0241  lr: 5.9076e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 08:59:48 d2.utils.events]: \u001b[0m eta: 2:21:51  iter: 4439  total_loss: 2.167  loss_cls_stage0: 0.2963  loss_box_reg_stage0: 0.2131  loss_cls_stage1: 0.2403  loss_box_reg_stage1: 0.2976  loss_cls_stage2: 0.1734  loss_box_reg_stage2: 0.2329  loss_mask: 0.5409  loss_rpn_cls: 0.07211  loss_rpn_loc: 0.03567  validation_loss: 1.981  time: 1.5067  data_time: 0.0243  lr: 5.8767e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:00:19 d2.utils.events]: \u001b[0m eta: 2:21:26  iter: 4459  total_loss: 2.111  loss_cls_stage0: 0.3059  loss_box_reg_stage0: 0.2189  loss_cls_stage1: 0.2378  loss_box_reg_stage1: 0.2957  loss_cls_stage2: 0.1622  loss_box_reg_stage2: 0.2314  loss_mask: 0.5708  loss_rpn_cls: 0.07054  loss_rpn_loc: 0.03318  validation_loss: 1.981  time: 1.5068  data_time: 0.0232  lr: 5.8457e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:00:50 d2.utils.events]: \u001b[0m eta: 2:20:57  iter: 4479  total_loss: 2.288  loss_cls_stage0: 0.3564  loss_box_reg_stage0: 0.2421  loss_cls_stage1: 0.2876  loss_box_reg_stage1: 0.3224  loss_cls_stage2: 0.1928  loss_box_reg_stage2: 0.2445  loss_mask: 0.5549  loss_rpn_cls: 0.07663  loss_rpn_loc: 0.03977  validation_loss: 1.981  time: 1.5071  data_time: 0.0235  lr: 5.8147e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:01:21 d2.utils.events]: \u001b[0m eta: 2:20:27  iter: 4499  total_loss: 2.083  loss_cls_stage0: 0.3105  loss_box_reg_stage0: 0.217  loss_cls_stage1: 0.2475  loss_box_reg_stage1: 0.2827  loss_cls_stage2: 0.1798  loss_box_reg_stage2: 0.2376  loss_mask: 0.5414  loss_rpn_cls: 0.07689  loss_rpn_loc: 0.03513  validation_loss: 1.981  time: 1.5072  data_time: 0.0236  lr: 5.7837e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:01:52 d2.utils.events]: \u001b[0m eta: 2:20:01  iter: 4519  total_loss: 2.192  loss_cls_stage0: 0.3143  loss_box_reg_stage0: 0.2225  loss_cls_stage1: 0.2524  loss_box_reg_stage1: 0.2875  loss_cls_stage2: 0.1851  loss_box_reg_stage2: 0.2267  loss_mask: 0.5432  loss_rpn_cls: 0.08073  loss_rpn_loc: 0.03983  validation_loss: 1.981  time: 1.5074  data_time: 0.0246  lr: 5.7527e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:02:23 d2.utils.events]: \u001b[0m eta: 2:19:32  iter: 4539  total_loss: 2.207  loss_cls_stage0: 0.3083  loss_box_reg_stage0: 0.2237  loss_cls_stage1: 0.2449  loss_box_reg_stage1: 0.2943  loss_cls_stage2: 0.1805  loss_box_reg_stage2: 0.2538  loss_mask: 0.5723  loss_rpn_cls: 0.07593  loss_rpn_loc: 0.03874  validation_loss: 1.981  time: 1.5076  data_time: 0.0246  lr: 5.7216e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:02:53 d2.utils.events]: \u001b[0m eta: 2:19:02  iter: 4559  total_loss: 2.065  loss_cls_stage0: 0.2958  loss_box_reg_stage0: 0.2187  loss_cls_stage1: 0.2224  loss_box_reg_stage1: 0.2798  loss_cls_stage2: 0.1747  loss_box_reg_stage2: 0.2165  loss_mask: 0.5637  loss_rpn_cls: 0.07315  loss_rpn_loc: 0.03344  validation_loss: 1.981  time: 1.5077  data_time: 0.0246  lr: 5.6905e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:03:24 d2.utils.events]: \u001b[0m eta: 2:18:33  iter: 4579  total_loss: 2.075  loss_cls_stage0: 0.3019  loss_box_reg_stage0: 0.2098  loss_cls_stage1: 0.2409  loss_box_reg_stage1: 0.2922  loss_cls_stage2: 0.1815  loss_box_reg_stage2: 0.2357  loss_mask: 0.4976  loss_rpn_cls: 0.076  loss_rpn_loc: 0.03986  validation_loss: 1.981  time: 1.5079  data_time: 0.0243  lr: 5.6594e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:03:55 d2.utils.events]: \u001b[0m eta: 2:18:03  iter: 4599  total_loss: 2.178  loss_cls_stage0: 0.296  loss_box_reg_stage0: 0.2203  loss_cls_stage1: 0.2344  loss_box_reg_stage1: 0.3054  loss_cls_stage2: 0.182  loss_box_reg_stage2: 0.2351  loss_mask: 0.5606  loss_rpn_cls: 0.0703  loss_rpn_loc: 0.03358  validation_loss: 1.981  time: 1.5080  data_time: 0.0239  lr: 5.6282e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:04:26 d2.utils.events]: \u001b[0m eta: 2:17:33  iter: 4619  total_loss: 2.18  loss_cls_stage0: 0.3285  loss_box_reg_stage0: 0.225  loss_cls_stage1: 0.2568  loss_box_reg_stage1: 0.2952  loss_cls_stage2: 0.1892  loss_box_reg_stage2: 0.2473  loss_mask: 0.5382  loss_rpn_cls: 0.07512  loss_rpn_loc: 0.03599  validation_loss: 1.981  time: 1.5082  data_time: 0.0313  lr: 5.597e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:04:57 d2.utils.events]: \u001b[0m eta: 2:17:03  iter: 4639  total_loss: 2.19  loss_cls_stage0: 0.3223  loss_box_reg_stage0: 0.2324  loss_cls_stage1: 0.2546  loss_box_reg_stage1: 0.3224  loss_cls_stage2: 0.1868  loss_box_reg_stage2: 0.2507  loss_mask: 0.5194  loss_rpn_cls: 0.06957  loss_rpn_loc: 0.03845  validation_loss: 1.981  time: 1.5083  data_time: 0.0228  lr: 5.5658e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:05:28 d2.utils.events]: \u001b[0m eta: 2:16:37  iter: 4659  total_loss: 2.084  loss_cls_stage0: 0.3059  loss_box_reg_stage0: 0.2188  loss_cls_stage1: 0.2359  loss_box_reg_stage1: 0.318  loss_cls_stage2: 0.1721  loss_box_reg_stage2: 0.275  loss_mask: 0.5317  loss_rpn_cls: 0.06792  loss_rpn_loc: 0.03086  validation_loss: 1.981  time: 1.5085  data_time: 0.0234  lr: 5.5346e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:05:59 d2.utils.events]: \u001b[0m eta: 2:16:09  iter: 4679  total_loss: 2.233  loss_cls_stage0: 0.34  loss_box_reg_stage0: 0.2654  loss_cls_stage1: 0.275  loss_box_reg_stage1: 0.3322  loss_cls_stage2: 0.2032  loss_box_reg_stage2: 0.2619  loss_mask: 0.5505  loss_rpn_cls: 0.07068  loss_rpn_loc: 0.03789  validation_loss: 1.981  time: 1.5087  data_time: 0.0240  lr: 5.5034e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:06:30 d2.utils.events]: \u001b[0m eta: 2:15:43  iter: 4699  total_loss: 2.296  loss_cls_stage0: 0.3364  loss_box_reg_stage0: 0.2403  loss_cls_stage1: 0.2631  loss_box_reg_stage1: 0.315  loss_cls_stage2: 0.1864  loss_box_reg_stage2: 0.2449  loss_mask: 0.5592  loss_rpn_cls: 0.06681  loss_rpn_loc: 0.03684  validation_loss: 1.981  time: 1.5089  data_time: 0.0238  lr: 5.4721e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:07:01 d2.utils.events]: \u001b[0m eta: 2:15:14  iter: 4719  total_loss: 2.215  loss_cls_stage0: 0.3077  loss_box_reg_stage0: 0.2353  loss_cls_stage1: 0.2629  loss_box_reg_stage1: 0.3195  loss_cls_stage2: 0.1886  loss_box_reg_stage2: 0.2532  loss_mask: 0.5257  loss_rpn_cls: 0.0652  loss_rpn_loc: 0.031  validation_loss: 1.981  time: 1.5091  data_time: 0.0237  lr: 5.4408e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:07:32 d2.utils.events]: \u001b[0m eta: 2:14:45  iter: 4739  total_loss: 2.143  loss_cls_stage0: 0.3074  loss_box_reg_stage0: 0.2107  loss_cls_stage1: 0.2546  loss_box_reg_stage1: 0.2884  loss_cls_stage2: 0.1855  loss_box_reg_stage2: 0.2465  loss_mask: 0.5375  loss_rpn_cls: 0.06472  loss_rpn_loc: 0.03448  validation_loss: 1.981  time: 1.5092  data_time: 0.0241  lr: 5.4095e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:08:03 d2.utils.events]: \u001b[0m eta: 2:14:14  iter: 4759  total_loss: 2.255  loss_cls_stage0: 0.3463  loss_box_reg_stage0: 0.2403  loss_cls_stage1: 0.2832  loss_box_reg_stage1: 0.3093  loss_cls_stage2: 0.1971  loss_box_reg_stage2: 0.239  loss_mask: 0.4954  loss_rpn_cls: 0.06626  loss_rpn_loc: 0.03574  validation_loss: 1.981  time: 1.5094  data_time: 0.0238  lr: 5.3782e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:08:34 d2.utils.events]: \u001b[0m eta: 2:13:44  iter: 4779  total_loss: 2.167  loss_cls_stage0: 0.3229  loss_box_reg_stage0: 0.2285  loss_cls_stage1: 0.2577  loss_box_reg_stage1: 0.3064  loss_cls_stage2: 0.1872  loss_box_reg_stage2: 0.2435  loss_mask: 0.5703  loss_rpn_cls: 0.0715  loss_rpn_loc: 0.03898  validation_loss: 1.981  time: 1.5096  data_time: 0.0225  lr: 5.3469e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:09:05 d2.utils.events]: \u001b[0m eta: 2:13:15  iter: 4799  total_loss: 2.149  loss_cls_stage0: 0.3046  loss_box_reg_stage0: 0.2123  loss_cls_stage1: 0.2508  loss_box_reg_stage1: 0.2926  loss_cls_stage2: 0.1862  loss_box_reg_stage2: 0.253  loss_mask: 0.5697  loss_rpn_cls: 0.07283  loss_rpn_loc: 0.0357  validation_loss: 1.981  time: 1.5097  data_time: 0.0225  lr: 5.3155e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:09:36 d2.utils.events]: \u001b[0m eta: 2:12:46  iter: 4819  total_loss: 2.081  loss_cls_stage0: 0.2843  loss_box_reg_stage0: 0.2163  loss_cls_stage1: 0.2467  loss_box_reg_stage1: 0.3005  loss_cls_stage2: 0.1706  loss_box_reg_stage2: 0.2604  loss_mask: 0.5379  loss_rpn_cls: 0.05684  loss_rpn_loc: 0.03332  validation_loss: 1.981  time: 1.5099  data_time: 0.0236  lr: 5.2842e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:10:07 d2.utils.events]: \u001b[0m eta: 2:12:18  iter: 4839  total_loss: 2.347  loss_cls_stage0: 0.3236  loss_box_reg_stage0: 0.2311  loss_cls_stage1: 0.2852  loss_box_reg_stage1: 0.3029  loss_cls_stage2: 0.2056  loss_box_reg_stage2: 0.2595  loss_mask: 0.5667  loss_rpn_cls: 0.07757  loss_rpn_loc: 0.0372  validation_loss: 1.981  time: 1.5100  data_time: 0.0231  lr: 5.2528e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:10:38 d2.utils.events]: \u001b[0m eta: 2:11:50  iter: 4859  total_loss: 2.345  loss_cls_stage0: 0.333  loss_box_reg_stage0: 0.2599  loss_cls_stage1: 0.2759  loss_box_reg_stage1: 0.3277  loss_cls_stage2: 0.1924  loss_box_reg_stage2: 0.2495  loss_mask: 0.5953  loss_rpn_cls: 0.07671  loss_rpn_loc: 0.03588  validation_loss: 1.981  time: 1.5102  data_time: 0.0228  lr: 5.2214e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:11:09 d2.utils.events]: \u001b[0m eta: 2:11:19  iter: 4879  total_loss: 2.001  loss_cls_stage0: 0.2628  loss_box_reg_stage0: 0.1954  loss_cls_stage1: 0.2221  loss_box_reg_stage1: 0.2882  loss_cls_stage2: 0.1669  loss_box_reg_stage2: 0.2308  loss_mask: 0.5189  loss_rpn_cls: 0.06428  loss_rpn_loc: 0.03081  validation_loss: 1.981  time: 1.5103  data_time: 0.0237  lr: 5.19e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:11:40 d2.utils.events]: \u001b[0m eta: 2:10:50  iter: 4899  total_loss: 2.242  loss_cls_stage0: 0.3106  loss_box_reg_stage0: 0.2173  loss_cls_stage1: 0.2576  loss_box_reg_stage1: 0.3265  loss_cls_stage2: 0.1926  loss_box_reg_stage2: 0.2352  loss_mask: 0.5679  loss_rpn_cls: 0.06693  loss_rpn_loc: 0.03115  validation_loss: 1.981  time: 1.5104  data_time: 0.0237  lr: 5.1586e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:12:11 d2.utils.events]: \u001b[0m eta: 2:10:18  iter: 4919  total_loss: 2.282  loss_cls_stage0: 0.2994  loss_box_reg_stage0: 0.2416  loss_cls_stage1: 0.2671  loss_box_reg_stage1: 0.3145  loss_cls_stage2: 0.1769  loss_box_reg_stage2: 0.2459  loss_mask: 0.5298  loss_rpn_cls: 0.06941  loss_rpn_loc: 0.03633  validation_loss: 1.981  time: 1.5106  data_time: 0.0238  lr: 5.1272e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:12:42 d2.utils.events]: \u001b[0m eta: 2:09:49  iter: 4939  total_loss: 2.074  loss_cls_stage0: 0.2893  loss_box_reg_stage0: 0.2169  loss_cls_stage1: 0.2425  loss_box_reg_stage1: 0.2998  loss_cls_stage2: 0.1751  loss_box_reg_stage2: 0.2405  loss_mask: 0.568  loss_rpn_cls: 0.06923  loss_rpn_loc: 0.03583  validation_loss: 1.981  time: 1.5107  data_time: 0.0233  lr: 5.0958e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:13:13 d2.utils.events]: \u001b[0m eta: 2:09:20  iter: 4959  total_loss: 2.242  loss_cls_stage0: 0.3212  loss_box_reg_stage0: 0.24  loss_cls_stage1: 0.267  loss_box_reg_stage1: 0.3262  loss_cls_stage2: 0.1831  loss_box_reg_stage2: 0.2613  loss_mask: 0.5265  loss_rpn_cls: 0.07153  loss_rpn_loc: 0.03863  validation_loss: 1.981  time: 1.5109  data_time: 0.0234  lr: 5.0644e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:13:44 d2.utils.events]: \u001b[0m eta: 2:08:49  iter: 4979  total_loss: 2.306  loss_cls_stage0: 0.3131  loss_box_reg_stage0: 0.2339  loss_cls_stage1: 0.2595  loss_box_reg_stage1: 0.327  loss_cls_stage2: 0.1933  loss_box_reg_stage2: 0.2526  loss_mask: 0.5365  loss_rpn_cls: 0.06816  loss_rpn_loc: 0.0366  validation_loss: 1.981  time: 1.5111  data_time: 0.0246  lr: 5.033e-05  max_mem: 12121M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/27 09:14:17 d2.data.common]: \u001b[0mSerializing 883 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/27 09:14:17 d2.data.common]: \u001b[0mSerialized dataset takes 0.91 MiB\n",
      "\u001b[32m[03/27 09:14:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 883 images\n",
      "\u001b[32m[03/27 09:14:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/883. 0.0797 s / img. ETA=0:01:51\n",
      "\u001b[32m[03/27 09:14:24 d2.evaluation.evaluator]: \u001b[0mInference done 55/883. 0.0796 s / img. ETA=0:01:36\n",
      "\u001b[32m[03/27 09:14:29 d2.evaluation.evaluator]: \u001b[0mInference done 98/883. 0.0798 s / img. ETA=0:01:32\n",
      "\u001b[32m[03/27 09:14:34 d2.evaluation.evaluator]: \u001b[0mInference done 138/883. 0.0800 s / img. ETA=0:01:29\n",
      "\u001b[32m[03/27 09:14:39 d2.evaluation.evaluator]: \u001b[0mInference done 186/883. 0.0799 s / img. ETA=0:01:21\n",
      "\u001b[32m[03/27 09:14:44 d2.evaluation.evaluator]: \u001b[0mInference done 233/883. 0.0800 s / img. ETA=0:01:14\n",
      "\u001b[32m[03/27 09:14:49 d2.evaluation.evaluator]: \u001b[0mInference done 280/883. 0.0801 s / img. ETA=0:01:08\n",
      "\u001b[32m[03/27 09:14:54 d2.evaluation.evaluator]: \u001b[0mInference done 326/883. 0.0801 s / img. ETA=0:01:02\n",
      "\u001b[32m[03/27 09:15:00 d2.evaluation.evaluator]: \u001b[0mInference done 373/883. 0.0801 s / img. ETA=0:00:57\n",
      "\u001b[32m[03/27 09:15:05 d2.evaluation.evaluator]: \u001b[0mInference done 419/883. 0.0801 s / img. ETA=0:00:51\n",
      "\u001b[32m[03/27 09:15:10 d2.evaluation.evaluator]: \u001b[0mInference done 467/883. 0.0800 s / img. ETA=0:00:46\n",
      "\u001b[32m[03/27 09:15:15 d2.evaluation.evaluator]: \u001b[0mInference done 515/883. 0.0800 s / img. ETA=0:00:40\n",
      "\u001b[32m[03/27 09:15:20 d2.evaluation.evaluator]: \u001b[0mInference done 563/883. 0.0800 s / img. ETA=0:00:35\n",
      "\u001b[32m[03/27 09:15:25 d2.evaluation.evaluator]: \u001b[0mInference done 611/883. 0.0800 s / img. ETA=0:00:29\n",
      "\u001b[32m[03/27 09:15:30 d2.evaluation.evaluator]: \u001b[0mInference done 659/883. 0.0800 s / img. ETA=0:00:24\n",
      "\u001b[32m[03/27 09:15:35 d2.evaluation.evaluator]: \u001b[0mInference done 706/883. 0.0800 s / img. ETA=0:00:19\n",
      "\u001b[32m[03/27 09:15:40 d2.evaluation.evaluator]: \u001b[0mInference done 753/883. 0.0800 s / img. ETA=0:00:14\n",
      "\u001b[32m[03/27 09:15:45 d2.evaluation.evaluator]: \u001b[0mInference done 800/883. 0.0800 s / img. ETA=0:00:09\n",
      "\u001b[32m[03/27 09:15:50 d2.evaluation.evaluator]: \u001b[0mInference done 846/883. 0.0800 s / img. ETA=0:00:04\n",
      "\u001b[32m[03/27 09:15:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:35.909680 (0.109237 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/27 09:15:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:10 (0.080016 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.44 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.070\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.119\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.130\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.032\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.073\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.106\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.128\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.128\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.042\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.135\n",
      "\u001b[32m[03/27 09:15:55 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold5 in csv format:\n",
      "\u001b[32m[03/27 09:15:55 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/27 09:15:55 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/27 09:15:55 d2.evaluation.testing]: \u001b[0mcopypaste: 7.0228,11.8920,12.9683,0.0755,3.2280,7.3347\n",
      "validation do loss eval 2.2839520242019575\n",
      "\u001b[32m[03/27 09:17:26 d2.utils.events]: \u001b[0m eta: 2:08:19  iter: 4999  total_loss: 2.103  loss_cls_stage0: 0.276  loss_box_reg_stage0: 0.2097  loss_cls_stage1: 0.2356  loss_box_reg_stage1: 0.3048  loss_cls_stage2: 0.1694  loss_box_reg_stage2: 0.2361  loss_mask: 0.5286  loss_rpn_cls: 0.06624  loss_rpn_loc: 0.0305  validation_loss: 1.995  time: 1.5112  data_time: 0.0245  lr: 5.0016e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:17:57 d2.utils.events]: \u001b[0m eta: 2:07:51  iter: 5019  total_loss: 2.424  loss_cls_stage0: 0.3507  loss_box_reg_stage0: 0.257  loss_cls_stage1: 0.2796  loss_box_reg_stage1: 0.3646  loss_cls_stage2: 0.1971  loss_box_reg_stage2: 0.3008  loss_mask: 0.5349  loss_rpn_cls: 0.08101  loss_rpn_loc: 0.04199  validation_loss: 1.995  time: 1.5113  data_time: 0.0258  lr: 4.9702e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:18:28 d2.utils.events]: \u001b[0m eta: 2:07:21  iter: 5039  total_loss: 2.069  loss_cls_stage0: 0.31  loss_box_reg_stage0: 0.2097  loss_cls_stage1: 0.232  loss_box_reg_stage1: 0.2787  loss_cls_stage2: 0.1719  loss_box_reg_stage2: 0.2445  loss_mask: 0.5712  loss_rpn_cls: 0.0731  loss_rpn_loc: 0.03558  validation_loss: 1.995  time: 1.5114  data_time: 0.0241  lr: 4.9387e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:18:59 d2.utils.events]: \u001b[0m eta: 2:06:53  iter: 5059  total_loss: 2.414  loss_cls_stage0: 0.3665  loss_box_reg_stage0: 0.2571  loss_cls_stage1: 0.2951  loss_box_reg_stage1: 0.3577  loss_cls_stage2: 0.193  loss_box_reg_stage2: 0.2762  loss_mask: 0.5357  loss_rpn_cls: 0.06798  loss_rpn_loc: 0.04129  validation_loss: 1.995  time: 1.5116  data_time: 0.0240  lr: 4.9073e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:19:30 d2.utils.events]: \u001b[0m eta: 2:06:24  iter: 5079  total_loss: 2.24  loss_cls_stage0: 0.3078  loss_box_reg_stage0: 0.2399  loss_cls_stage1: 0.2545  loss_box_reg_stage1: 0.3357  loss_cls_stage2: 0.1883  loss_box_reg_stage2: 0.2684  loss_mask: 0.5591  loss_rpn_cls: 0.06425  loss_rpn_loc: 0.03638  validation_loss: 1.995  time: 1.5118  data_time: 0.0234  lr: 4.8759e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:20:01 d2.utils.events]: \u001b[0m eta: 2:05:54  iter: 5099  total_loss: 2.165  loss_cls_stage0: 0.2758  loss_box_reg_stage0: 0.2237  loss_cls_stage1: 0.2268  loss_box_reg_stage1: 0.3215  loss_cls_stage2: 0.1587  loss_box_reg_stage2: 0.2673  loss_mask: 0.5511  loss_rpn_cls: 0.06239  loss_rpn_loc: 0.03421  validation_loss: 1.995  time: 1.5119  data_time: 0.0239  lr: 4.8445e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:20:32 d2.utils.events]: \u001b[0m eta: 2:05:25  iter: 5119  total_loss: 2.134  loss_cls_stage0: 0.3114  loss_box_reg_stage0: 0.2294  loss_cls_stage1: 0.2494  loss_box_reg_stage1: 0.3227  loss_cls_stage2: 0.1756  loss_box_reg_stage2: 0.2536  loss_mask: 0.5362  loss_rpn_cls: 0.07138  loss_rpn_loc: 0.03465  validation_loss: 1.995  time: 1.5121  data_time: 0.0227  lr: 4.8131e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:21:03 d2.utils.events]: \u001b[0m eta: 2:04:56  iter: 5139  total_loss: 2.242  loss_cls_stage0: 0.2919  loss_box_reg_stage0: 0.2333  loss_cls_stage1: 0.2545  loss_box_reg_stage1: 0.3261  loss_cls_stage2: 0.1796  loss_box_reg_stage2: 0.2845  loss_mask: 0.5451  loss_rpn_cls: 0.06659  loss_rpn_loc: 0.03318  validation_loss: 1.995  time: 1.5123  data_time: 0.0249  lr: 4.7817e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:21:34 d2.utils.events]: \u001b[0m eta: 2:04:23  iter: 5159  total_loss: 2.022  loss_cls_stage0: 0.293  loss_box_reg_stage0: 0.2103  loss_cls_stage1: 0.2379  loss_box_reg_stage1: 0.282  loss_cls_stage2: 0.1599  loss_box_reg_stage2: 0.2376  loss_mask: 0.51  loss_rpn_cls: 0.06923  loss_rpn_loc: 0.0357  validation_loss: 1.995  time: 1.5124  data_time: 0.0246  lr: 4.7503e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:22:06 d2.utils.events]: \u001b[0m eta: 2:03:54  iter: 5179  total_loss: 2.374  loss_cls_stage0: 0.342  loss_box_reg_stage0: 0.2595  loss_cls_stage1: 0.2638  loss_box_reg_stage1: 0.3282  loss_cls_stage2: 0.1884  loss_box_reg_stage2: 0.256  loss_mask: 0.5289  loss_rpn_cls: 0.07539  loss_rpn_loc: 0.03893  validation_loss: 1.995  time: 1.5126  data_time: 0.0251  lr: 4.719e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:22:36 d2.utils.events]: \u001b[0m eta: 2:03:22  iter: 5199  total_loss: 2.08  loss_cls_stage0: 0.2919  loss_box_reg_stage0: 0.2148  loss_cls_stage1: 0.2327  loss_box_reg_stage1: 0.2873  loss_cls_stage2: 0.1803  loss_box_reg_stage2: 0.2353  loss_mask: 0.5304  loss_rpn_cls: 0.07276  loss_rpn_loc: 0.03264  validation_loss: 1.995  time: 1.5127  data_time: 0.0253  lr: 4.6876e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:23:07 d2.utils.events]: \u001b[0m eta: 2:02:52  iter: 5219  total_loss: 2.227  loss_cls_stage0: 0.293  loss_box_reg_stage0: 0.2141  loss_cls_stage1: 0.2475  loss_box_reg_stage1: 0.2972  loss_cls_stage2: 0.1927  loss_box_reg_stage2: 0.2561  loss_mask: 0.5432  loss_rpn_cls: 0.07514  loss_rpn_loc: 0.03464  validation_loss: 1.995  time: 1.5128  data_time: 0.0241  lr: 4.6563e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:23:39 d2.utils.events]: \u001b[0m eta: 2:02:25  iter: 5239  total_loss: 2.443  loss_cls_stage0: 0.3536  loss_box_reg_stage0: 0.2663  loss_cls_stage1: 0.288  loss_box_reg_stage1: 0.3465  loss_cls_stage2: 0.1998  loss_box_reg_stage2: 0.2545  loss_mask: 0.5677  loss_rpn_cls: 0.07469  loss_rpn_loc: 0.03943  validation_loss: 1.995  time: 1.5130  data_time: 0.0235  lr: 4.6249e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:24:10 d2.utils.events]: \u001b[0m eta: 2:01:57  iter: 5259  total_loss: 2.261  loss_cls_stage0: 0.3286  loss_box_reg_stage0: 0.2339  loss_cls_stage1: 0.2577  loss_box_reg_stage1: 0.3155  loss_cls_stage2: 0.1796  loss_box_reg_stage2: 0.2622  loss_mask: 0.5627  loss_rpn_cls: 0.06322  loss_rpn_loc: 0.03404  validation_loss: 1.995  time: 1.5132  data_time: 0.0239  lr: 4.5936e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:24:41 d2.utils.events]: \u001b[0m eta: 2:01:28  iter: 5279  total_loss: 2.284  loss_cls_stage0: 0.3209  loss_box_reg_stage0: 0.2368  loss_cls_stage1: 0.2697  loss_box_reg_stage1: 0.3384  loss_cls_stage2: 0.1841  loss_box_reg_stage2: 0.2747  loss_mask: 0.5187  loss_rpn_cls: 0.07171  loss_rpn_loc: 0.04255  validation_loss: 1.995  time: 1.5134  data_time: 0.0245  lr: 4.5623e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:25:12 d2.utils.events]: \u001b[0m eta: 2:00:57  iter: 5299  total_loss: 2.152  loss_cls_stage0: 0.2999  loss_box_reg_stage0: 0.2211  loss_cls_stage1: 0.2465  loss_box_reg_stage1: 0.3226  loss_cls_stage2: 0.1731  loss_box_reg_stage2: 0.2643  loss_mask: 0.5422  loss_rpn_cls: 0.07778  loss_rpn_loc: 0.03402  validation_loss: 1.995  time: 1.5135  data_time: 0.0237  lr: 4.531e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:25:43 d2.utils.events]: \u001b[0m eta: 2:00:28  iter: 5319  total_loss: 2.158  loss_cls_stage0: 0.3043  loss_box_reg_stage0: 0.2238  loss_cls_stage1: 0.2485  loss_box_reg_stage1: 0.3208  loss_cls_stage2: 0.1896  loss_box_reg_stage2: 0.2704  loss_mask: 0.5536  loss_rpn_cls: 0.06144  loss_rpn_loc: 0.03202  validation_loss: 1.995  time: 1.5136  data_time: 0.0239  lr: 4.4998e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:26:14 d2.utils.events]: \u001b[0m eta: 1:59:57  iter: 5339  total_loss: 2.085  loss_cls_stage0: 0.2772  loss_box_reg_stage0: 0.2028  loss_cls_stage1: 0.2344  loss_box_reg_stage1: 0.3307  loss_cls_stage2: 0.1791  loss_box_reg_stage2: 0.2551  loss_mask: 0.5398  loss_rpn_cls: 0.06496  loss_rpn_loc: 0.03052  validation_loss: 1.995  time: 1.5138  data_time: 0.0245  lr: 4.4685e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:26:45 d2.utils.events]: \u001b[0m eta: 1:59:26  iter: 5359  total_loss: 2.24  loss_cls_stage0: 0.304  loss_box_reg_stage0: 0.2429  loss_cls_stage1: 0.2439  loss_box_reg_stage1: 0.3171  loss_cls_stage2: 0.1802  loss_box_reg_stage2: 0.2545  loss_mask: 0.5451  loss_rpn_cls: 0.0669  loss_rpn_loc: 0.03803  validation_loss: 1.995  time: 1.5139  data_time: 0.0236  lr: 4.4373e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:27:16 d2.utils.events]: \u001b[0m eta: 1:58:57  iter: 5379  total_loss: 2.318  loss_cls_stage0: 0.3342  loss_box_reg_stage0: 0.2581  loss_cls_stage1: 0.2827  loss_box_reg_stage1: 0.3498  loss_cls_stage2: 0.1856  loss_box_reg_stage2: 0.2763  loss_mask: 0.5638  loss_rpn_cls: 0.06518  loss_rpn_loc: 0.03321  validation_loss: 1.995  time: 1.5141  data_time: 0.0238  lr: 4.4061e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:27:47 d2.utils.events]: \u001b[0m eta: 1:58:26  iter: 5399  total_loss: 2.191  loss_cls_stage0: 0.2926  loss_box_reg_stage0: 0.2365  loss_cls_stage1: 0.2446  loss_box_reg_stage1: 0.333  loss_cls_stage2: 0.1899  loss_box_reg_stage2: 0.2642  loss_mask: 0.5503  loss_rpn_cls: 0.06842  loss_rpn_loc: 0.03379  validation_loss: 1.995  time: 1.5142  data_time: 0.0260  lr: 4.3749e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:28:19 d2.utils.events]: \u001b[0m eta: 1:57:57  iter: 5419  total_loss: 2.265  loss_cls_stage0: 0.325  loss_box_reg_stage0: 0.2395  loss_cls_stage1: 0.2608  loss_box_reg_stage1: 0.3282  loss_cls_stage2: 0.1847  loss_box_reg_stage2: 0.2455  loss_mask: 0.5857  loss_rpn_cls: 0.06481  loss_rpn_loc: 0.0366  validation_loss: 1.995  time: 1.5144  data_time: 0.0247  lr: 4.3437e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:28:50 d2.utils.events]: \u001b[0m eta: 1:57:28  iter: 5439  total_loss: 2.454  loss_cls_stage0: 0.3484  loss_box_reg_stage0: 0.2705  loss_cls_stage1: 0.2833  loss_box_reg_stage1: 0.3658  loss_cls_stage2: 0.2083  loss_box_reg_stage2: 0.2951  loss_mask: 0.557  loss_rpn_cls: 0.08167  loss_rpn_loc: 0.04515  validation_loss: 1.995  time: 1.5146  data_time: 0.0256  lr: 4.3126e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:29:21 d2.utils.events]: \u001b[0m eta: 1:56:58  iter: 5459  total_loss: 2.382  loss_cls_stage0: 0.3222  loss_box_reg_stage0: 0.2435  loss_cls_stage1: 0.2645  loss_box_reg_stage1: 0.3598  loss_cls_stage2: 0.1822  loss_box_reg_stage2: 0.2643  loss_mask: 0.5881  loss_rpn_cls: 0.06662  loss_rpn_loc: 0.03631  validation_loss: 1.995  time: 1.5148  data_time: 0.0258  lr: 4.2815e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:29:53 d2.utils.events]: \u001b[0m eta: 1:56:29  iter: 5479  total_loss: 2.526  loss_cls_stage0: 0.3732  loss_box_reg_stage0: 0.2808  loss_cls_stage1: 0.2987  loss_box_reg_stage1: 0.3543  loss_cls_stage2: 0.2152  loss_box_reg_stage2: 0.27  loss_mask: 0.5272  loss_rpn_cls: 0.07443  loss_rpn_loc: 0.03968  validation_loss: 1.995  time: 1.5150  data_time: 0.0246  lr: 4.2504e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:30:24 d2.utils.events]: \u001b[0m eta: 1:55:59  iter: 5499  total_loss: 2.353  loss_cls_stage0: 0.3443  loss_box_reg_stage0: 0.25  loss_cls_stage1: 0.2797  loss_box_reg_stage1: 0.3288  loss_cls_stage2: 0.1908  loss_box_reg_stage2: 0.2475  loss_mask: 0.5587  loss_rpn_cls: 0.06688  loss_rpn_loc: 0.03843  validation_loss: 1.995  time: 1.5151  data_time: 0.0254  lr: 4.2194e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:30:55 d2.utils.events]: \u001b[0m eta: 1:55:32  iter: 5519  total_loss: 2.379  loss_cls_stage0: 0.3597  loss_box_reg_stage0: 0.2731  loss_cls_stage1: 0.2899  loss_box_reg_stage1: 0.3465  loss_cls_stage2: 0.2064  loss_box_reg_stage2: 0.2709  loss_mask: 0.5342  loss_rpn_cls: 0.07469  loss_rpn_loc: 0.03821  validation_loss: 1.995  time: 1.5154  data_time: 0.0242  lr: 4.1884e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:31:26 d2.utils.events]: \u001b[0m eta: 1:55:02  iter: 5539  total_loss: 2.219  loss_cls_stage0: 0.2947  loss_box_reg_stage0: 0.2328  loss_cls_stage1: 0.2473  loss_box_reg_stage1: 0.3285  loss_cls_stage2: 0.1811  loss_box_reg_stage2: 0.2504  loss_mask: 0.5794  loss_rpn_cls: 0.06894  loss_rpn_loc: 0.03706  validation_loss: 1.995  time: 1.5155  data_time: 0.0240  lr: 4.1574e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:31:58 d2.utils.events]: \u001b[0m eta: 1:54:34  iter: 5559  total_loss: 2.27  loss_cls_stage0: 0.3246  loss_box_reg_stage0: 0.2388  loss_cls_stage1: 0.265  loss_box_reg_stage1: 0.3286  loss_cls_stage2: 0.1928  loss_box_reg_stage2: 0.2835  loss_mask: 0.5601  loss_rpn_cls: 0.06821  loss_rpn_loc: 0.03652  validation_loss: 1.995  time: 1.5156  data_time: 0.0240  lr: 4.1264e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:32:29 d2.utils.events]: \u001b[0m eta: 1:54:03  iter: 5579  total_loss: 2.294  loss_cls_stage0: 0.3211  loss_box_reg_stage0: 0.2553  loss_cls_stage1: 0.264  loss_box_reg_stage1: 0.3442  loss_cls_stage2: 0.1923  loss_box_reg_stage2: 0.2726  loss_mask: 0.52  loss_rpn_cls: 0.07211  loss_rpn_loc: 0.0402  validation_loss: 1.995  time: 1.5158  data_time: 0.0247  lr: 4.0955e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:33:00 d2.utils.events]: \u001b[0m eta: 1:53:33  iter: 5599  total_loss: 2.23  loss_cls_stage0: 0.3204  loss_box_reg_stage0: 0.2513  loss_cls_stage1: 0.2584  loss_box_reg_stage1: 0.3134  loss_cls_stage2: 0.1785  loss_box_reg_stage2: 0.2656  loss_mask: 0.5701  loss_rpn_cls: 0.06966  loss_rpn_loc: 0.03717  validation_loss: 1.995  time: 1.5159  data_time: 0.0241  lr: 4.0646e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:33:31 d2.utils.events]: \u001b[0m eta: 1:53:02  iter: 5619  total_loss: 2.139  loss_cls_stage0: 0.2966  loss_box_reg_stage0: 0.2221  loss_cls_stage1: 0.2541  loss_box_reg_stage1: 0.3201  loss_cls_stage2: 0.1866  loss_box_reg_stage2: 0.2504  loss_mask: 0.5326  loss_rpn_cls: 0.07073  loss_rpn_loc: 0.03614  validation_loss: 1.995  time: 1.5161  data_time: 0.0256  lr: 4.0338e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:34:02 d2.utils.events]: \u001b[0m eta: 1:52:30  iter: 5639  total_loss: 2.172  loss_cls_stage0: 0.3073  loss_box_reg_stage0: 0.2301  loss_cls_stage1: 0.2492  loss_box_reg_stage1: 0.3108  loss_cls_stage2: 0.1698  loss_box_reg_stage2: 0.2474  loss_mask: 0.5777  loss_rpn_cls: 0.08141  loss_rpn_loc: 0.03976  validation_loss: 1.995  time: 1.5162  data_time: 0.0240  lr: 4.003e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:34:33 d2.utils.events]: \u001b[0m eta: 1:52:00  iter: 5659  total_loss: 2.407  loss_cls_stage0: 0.3433  loss_box_reg_stage0: 0.2595  loss_cls_stage1: 0.2783  loss_box_reg_stage1: 0.338  loss_cls_stage2: 0.1912  loss_box_reg_stage2: 0.2671  loss_mask: 0.588  loss_rpn_cls: 0.07088  loss_rpn_loc: 0.03648  validation_loss: 1.995  time: 1.5163  data_time: 0.0231  lr: 3.9722e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:35:04 d2.utils.events]: \u001b[0m eta: 1:51:29  iter: 5679  total_loss: 2.327  loss_cls_stage0: 0.3221  loss_box_reg_stage0: 0.235  loss_cls_stage1: 0.2638  loss_box_reg_stage1: 0.3469  loss_cls_stage2: 0.1957  loss_box_reg_stage2: 0.2662  loss_mask: 0.5393  loss_rpn_cls: 0.06405  loss_rpn_loc: 0.03529  validation_loss: 1.995  time: 1.5164  data_time: 0.0244  lr: 3.9415e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:35:35 d2.utils.events]: \u001b[0m eta: 1:51:00  iter: 5699  total_loss: 2.456  loss_cls_stage0: 0.3481  loss_box_reg_stage0: 0.261  loss_cls_stage1: 0.2967  loss_box_reg_stage1: 0.3548  loss_cls_stage2: 0.2052  loss_box_reg_stage2: 0.2836  loss_mask: 0.5055  loss_rpn_cls: 0.08176  loss_rpn_loc: 0.0435  validation_loss: 1.995  time: 1.5166  data_time: 0.0246  lr: 3.9108e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:36:07 d2.utils.events]: \u001b[0m eta: 1:50:29  iter: 5719  total_loss: 2.375  loss_cls_stage0: 0.3543  loss_box_reg_stage0: 0.2548  loss_cls_stage1: 0.2824  loss_box_reg_stage1: 0.3381  loss_cls_stage2: 0.1838  loss_box_reg_stage2: 0.2534  loss_mask: 0.5807  loss_rpn_cls: 0.06097  loss_rpn_loc: 0.03882  validation_loss: 1.995  time: 1.5168  data_time: 0.0233  lr: 3.8802e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:36:38 d2.utils.events]: \u001b[0m eta: 1:50:00  iter: 5739  total_loss: 2.305  loss_cls_stage0: 0.3321  loss_box_reg_stage0: 0.2497  loss_cls_stage1: 0.2645  loss_box_reg_stage1: 0.3426  loss_cls_stage2: 0.1878  loss_box_reg_stage2: 0.2754  loss_mask: 0.5467  loss_rpn_cls: 0.06183  loss_rpn_loc: 0.03785  validation_loss: 1.995  time: 1.5169  data_time: 0.0234  lr: 3.8496e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:37:09 d2.utils.events]: \u001b[0m eta: 1:49:31  iter: 5759  total_loss: 2.212  loss_cls_stage0: 0.324  loss_box_reg_stage0: 0.2493  loss_cls_stage1: 0.2536  loss_box_reg_stage1: 0.342  loss_cls_stage2: 0.1734  loss_box_reg_stage2: 0.2737  loss_mask: 0.5182  loss_rpn_cls: 0.05885  loss_rpn_loc: 0.03064  validation_loss: 1.995  time: 1.5171  data_time: 0.0250  lr: 3.819e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:37:40 d2.utils.events]: \u001b[0m eta: 1:49:00  iter: 5779  total_loss: 2.187  loss_cls_stage0: 0.3017  loss_box_reg_stage0: 0.2173  loss_cls_stage1: 0.2544  loss_box_reg_stage1: 0.3213  loss_cls_stage2: 0.1856  loss_box_reg_stage2: 0.2788  loss_mask: 0.5459  loss_rpn_cls: 0.06481  loss_rpn_loc: 0.03217  validation_loss: 1.995  time: 1.5172  data_time: 0.0253  lr: 3.7885e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:38:11 d2.utils.events]: \u001b[0m eta: 1:48:31  iter: 5799  total_loss: 2.194  loss_cls_stage0: 0.2927  loss_box_reg_stage0: 0.2403  loss_cls_stage1: 0.2476  loss_box_reg_stage1: 0.3223  loss_cls_stage2: 0.1758  loss_box_reg_stage2: 0.2556  loss_mask: 0.5392  loss_rpn_cls: 0.06569  loss_rpn_loc: 0.03504  validation_loss: 1.995  time: 1.5174  data_time: 0.0241  lr: 3.7581e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:38:42 d2.utils.events]: \u001b[0m eta: 1:48:00  iter: 5819  total_loss: 2.244  loss_cls_stage0: 0.3218  loss_box_reg_stage0: 0.2396  loss_cls_stage1: 0.2639  loss_box_reg_stage1: 0.3346  loss_cls_stage2: 0.1784  loss_box_reg_stage2: 0.2583  loss_mask: 0.5085  loss_rpn_cls: 0.06348  loss_rpn_loc: 0.03938  validation_loss: 1.995  time: 1.5175  data_time: 0.0231  lr: 3.7277e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:39:14 d2.utils.events]: \u001b[0m eta: 1:47:31  iter: 5839  total_loss: 2.215  loss_cls_stage0: 0.3033  loss_box_reg_stage0: 0.2408  loss_cls_stage1: 0.2588  loss_box_reg_stage1: 0.3289  loss_cls_stage2: 0.1825  loss_box_reg_stage2: 0.2734  loss_mask: 0.598  loss_rpn_cls: 0.06721  loss_rpn_loc: 0.04569  validation_loss: 1.995  time: 1.5176  data_time: 0.0246  lr: 3.6973e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:39:45 d2.utils.events]: \u001b[0m eta: 1:47:00  iter: 5859  total_loss: 2.489  loss_cls_stage0: 0.3709  loss_box_reg_stage0: 0.278  loss_cls_stage1: 0.3004  loss_box_reg_stage1: 0.3704  loss_cls_stage2: 0.2119  loss_box_reg_stage2: 0.3023  loss_mask: 0.5399  loss_rpn_cls: 0.07843  loss_rpn_loc: 0.04214  validation_loss: 1.995  time: 1.5178  data_time: 0.0250  lr: 3.667e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:40:16 d2.utils.events]: \u001b[0m eta: 1:46:33  iter: 5879  total_loss: 2.324  loss_cls_stage0: 0.2974  loss_box_reg_stage0: 0.2449  loss_cls_stage1: 0.2499  loss_box_reg_stage1: 0.3566  loss_cls_stage2: 0.1909  loss_box_reg_stage2: 0.2789  loss_mask: 0.5711  loss_rpn_cls: 0.0637  loss_rpn_loc: 0.03548  validation_loss: 1.995  time: 1.5179  data_time: 0.0241  lr: 3.6368e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:40:48 d2.utils.events]: \u001b[0m eta: 1:46:04  iter: 5899  total_loss: 2.387  loss_cls_stage0: 0.345  loss_box_reg_stage0: 0.2607  loss_cls_stage1: 0.2715  loss_box_reg_stage1: 0.3472  loss_cls_stage2: 0.1991  loss_box_reg_stage2: 0.267  loss_mask: 0.5958  loss_rpn_cls: 0.05845  loss_rpn_loc: 0.03194  validation_loss: 1.995  time: 1.5181  data_time: 0.0260  lr: 3.6066e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:41:19 d2.utils.events]: \u001b[0m eta: 1:45:35  iter: 5919  total_loss: 2.46  loss_cls_stage0: 0.3523  loss_box_reg_stage0: 0.2735  loss_cls_stage1: 0.2946  loss_box_reg_stage1: 0.3799  loss_cls_stage2: 0.2212  loss_box_reg_stage2: 0.3146  loss_mask: 0.5293  loss_rpn_cls: 0.0732  loss_rpn_loc: 0.03748  validation_loss: 1.995  time: 1.5183  data_time: 0.0241  lr: 3.5764e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:41:50 d2.utils.events]: \u001b[0m eta: 1:45:04  iter: 5939  total_loss: 2.178  loss_cls_stage0: 0.3051  loss_box_reg_stage0: 0.2246  loss_cls_stage1: 0.2465  loss_box_reg_stage1: 0.3098  loss_cls_stage2: 0.1752  loss_box_reg_stage2: 0.268  loss_mask: 0.5653  loss_rpn_cls: 0.05744  loss_rpn_loc: 0.03669  validation_loss: 1.995  time: 1.5184  data_time: 0.0241  lr: 3.5463e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:42:21 d2.utils.events]: \u001b[0m eta: 1:44:34  iter: 5959  total_loss: 2.47  loss_cls_stage0: 0.3696  loss_box_reg_stage0: 0.2752  loss_cls_stage1: 0.3024  loss_box_reg_stage1: 0.375  loss_cls_stage2: 0.2103  loss_box_reg_stage2: 0.2923  loss_mask: 0.5352  loss_rpn_cls: 0.06934  loss_rpn_loc: 0.04127  validation_loss: 1.995  time: 1.5185  data_time: 0.0245  lr: 3.5163e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:42:52 d2.utils.events]: \u001b[0m eta: 1:44:04  iter: 5979  total_loss: 2.276  loss_cls_stage0: 0.3124  loss_box_reg_stage0: 0.2332  loss_cls_stage1: 0.2728  loss_box_reg_stage1: 0.3209  loss_cls_stage2: 0.1991  loss_box_reg_stage2: 0.2677  loss_mask: 0.5666  loss_rpn_cls: 0.05895  loss_rpn_loc: 0.03462  validation_loss: 1.995  time: 1.5187  data_time: 0.0247  lr: 3.4863e-05  max_mem: 12121M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/27 09:43:26 d2.data.common]: \u001b[0mSerializing 883 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/27 09:43:26 d2.data.common]: \u001b[0mSerialized dataset takes 0.91 MiB\n",
      "\u001b[32m[03/27 09:43:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 883 images\n",
      "\u001b[32m[03/27 09:43:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/883. 0.0820 s / img. ETA=0:02:02\n",
      "\u001b[32m[03/27 09:43:33 d2.evaluation.evaluator]: \u001b[0mInference done 54/883. 0.0808 s / img. ETA=0:01:39\n",
      "\u001b[32m[03/27 09:43:38 d2.evaluation.evaluator]: \u001b[0mInference done 93/883. 0.0811 s / img. ETA=0:01:37\n",
      "\u001b[32m[03/27 09:43:43 d2.evaluation.evaluator]: \u001b[0mInference done 132/883. 0.0813 s / img. ETA=0:01:34\n",
      "\u001b[32m[03/27 09:43:48 d2.evaluation.evaluator]: \u001b[0mInference done 173/883. 0.0812 s / img. ETA=0:01:28\n",
      "\u001b[32m[03/27 09:43:53 d2.evaluation.evaluator]: \u001b[0mInference done 216/883. 0.0811 s / img. ETA=0:01:22\n",
      "\u001b[32m[03/27 09:43:58 d2.evaluation.evaluator]: \u001b[0mInference done 257/883. 0.0811 s / img. ETA=0:01:17\n",
      "\u001b[32m[03/27 09:44:03 d2.evaluation.evaluator]: \u001b[0mInference done 299/883. 0.0811 s / img. ETA=0:01:12\n",
      "\u001b[32m[03/27 09:44:09 d2.evaluation.evaluator]: \u001b[0mInference done 341/883. 0.0810 s / img. ETA=0:01:06\n",
      "\u001b[32m[03/27 09:44:14 d2.evaluation.evaluator]: \u001b[0mInference done 381/883. 0.0810 s / img. ETA=0:01:02\n",
      "\u001b[32m[03/27 09:44:19 d2.evaluation.evaluator]: \u001b[0mInference done 419/883. 0.0811 s / img. ETA=0:00:57\n",
      "\u001b[32m[03/27 09:44:24 d2.evaluation.evaluator]: \u001b[0mInference done 460/883. 0.0811 s / img. ETA=0:00:52\n",
      "\u001b[32m[03/27 09:44:29 d2.evaluation.evaluator]: \u001b[0mInference done 502/883. 0.0811 s / img. ETA=0:00:47\n",
      "\u001b[32m[03/27 09:44:34 d2.evaluation.evaluator]: \u001b[0mInference done 543/883. 0.0813 s / img. ETA=0:00:42\n",
      "\u001b[32m[03/27 09:44:39 d2.evaluation.evaluator]: \u001b[0mInference done 587/883. 0.0813 s / img. ETA=0:00:36\n",
      "\u001b[32m[03/27 09:44:44 d2.evaluation.evaluator]: \u001b[0mInference done 629/883. 0.0813 s / img. ETA=0:00:31\n",
      "\u001b[32m[03/27 09:44:49 d2.evaluation.evaluator]: \u001b[0mInference done 672/883. 0.0812 s / img. ETA=0:00:25\n",
      "\u001b[32m[03/27 09:44:54 d2.evaluation.evaluator]: \u001b[0mInference done 713/883. 0.0812 s / img. ETA=0:00:20\n",
      "\u001b[32m[03/27 09:44:59 d2.evaluation.evaluator]: \u001b[0mInference done 754/883. 0.0812 s / img. ETA=0:00:15\n",
      "\u001b[32m[03/27 09:45:04 d2.evaluation.evaluator]: \u001b[0mInference done 797/883. 0.0812 s / img. ETA=0:00:10\n",
      "\u001b[32m[03/27 09:45:09 d2.evaluation.evaluator]: \u001b[0mInference done 836/883. 0.0812 s / img. ETA=0:00:05\n",
      "\u001b[32m[03/27 09:45:14 d2.evaluation.evaluator]: \u001b[0mInference done 879/883. 0.0811 s / img. ETA=0:00:00\n",
      "\u001b[32m[03/27 09:45:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:47.711103 (0.122678 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/27 09:45:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:11 (0.081139 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.078\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.133\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.148\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.034\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.084\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.122\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.160\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.161\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.045\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.181\n",
      "\u001b[32m[03/27 09:45:16 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold5 in csv format:\n",
      "\u001b[32m[03/27 09:45:16 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/27 09:45:16 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/27 09:45:16 d2.evaluation.testing]: \u001b[0mcopypaste: 7.8291,13.2553,14.8393,0.1402,3.4295,8.4241\n",
      "validation do loss eval 2.3145507508840057\n",
      "\u001b[32m[03/27 09:46:48 d2.utils.events]: \u001b[0m eta: 1:43:33  iter: 5999  total_loss: 2.269  loss_cls_stage0: 0.3265  loss_box_reg_stage0: 0.2375  loss_cls_stage1: 0.257  loss_box_reg_stage1: 0.3241  loss_cls_stage2: 0.1856  loss_box_reg_stage2: 0.2647  loss_mask: 0.5668  loss_rpn_cls: 0.05854  loss_rpn_loc: 0.03163  validation_loss: 2.052  time: 1.5188  data_time: 0.0241  lr: 3.4564e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:47:18 d2.utils.events]: \u001b[0m eta: 1:43:01  iter: 6019  total_loss: 2.251  loss_cls_stage0: 0.299  loss_box_reg_stage0: 0.2252  loss_cls_stage1: 0.2486  loss_box_reg_stage1: 0.3202  loss_cls_stage2: 0.1757  loss_box_reg_stage2: 0.2625  loss_mask: 0.5777  loss_rpn_cls: 0.06554  loss_rpn_loc: 0.03178  validation_loss: 2.052  time: 1.5188  data_time: 0.0251  lr: 3.4266e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:47:49 d2.utils.events]: \u001b[0m eta: 1:42:31  iter: 6039  total_loss: 2.395  loss_cls_stage0: 0.3209  loss_box_reg_stage0: 0.2516  loss_cls_stage1: 0.2729  loss_box_reg_stage1: 0.3535  loss_cls_stage2: 0.1909  loss_box_reg_stage2: 0.2807  loss_mask: 0.5621  loss_rpn_cls: 0.06836  loss_rpn_loc: 0.0359  validation_loss: 2.052  time: 1.5190  data_time: 0.0250  lr: 3.3968e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:48:20 d2.utils.events]: \u001b[0m eta: 1:41:59  iter: 6059  total_loss: 2.175  loss_cls_stage0: 0.3232  loss_box_reg_stage0: 0.2362  loss_cls_stage1: 0.2655  loss_box_reg_stage1: 0.3249  loss_cls_stage2: 0.1934  loss_box_reg_stage2: 0.2613  loss_mask: 0.5391  loss_rpn_cls: 0.06468  loss_rpn_loc: 0.03677  validation_loss: 2.052  time: 1.5191  data_time: 0.0251  lr: 3.367e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:48:51 d2.utils.events]: \u001b[0m eta: 1:41:28  iter: 6079  total_loss: 2.164  loss_cls_stage0: 0.3103  loss_box_reg_stage0: 0.2275  loss_cls_stage1: 0.2588  loss_box_reg_stage1: 0.3268  loss_cls_stage2: 0.1817  loss_box_reg_stage2: 0.2723  loss_mask: 0.5119  loss_rpn_cls: 0.06253  loss_rpn_loc: 0.02979  validation_loss: 2.052  time: 1.5192  data_time: 0.0248  lr: 3.3374e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:49:23 d2.utils.events]: \u001b[0m eta: 1:40:58  iter: 6099  total_loss: 2.331  loss_cls_stage0: 0.3274  loss_box_reg_stage0: 0.26  loss_cls_stage1: 0.2599  loss_box_reg_stage1: 0.358  loss_cls_stage2: 0.1902  loss_box_reg_stage2: 0.3026  loss_mask: 0.5697  loss_rpn_cls: 0.07311  loss_rpn_loc: 0.0385  validation_loss: 2.052  time: 1.5194  data_time: 0.0248  lr: 3.3078e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:49:54 d2.utils.events]: \u001b[0m eta: 1:40:27  iter: 6119  total_loss: 2.376  loss_cls_stage0: 0.3427  loss_box_reg_stage0: 0.2617  loss_cls_stage1: 0.2857  loss_box_reg_stage1: 0.3555  loss_cls_stage2: 0.2055  loss_box_reg_stage2: 0.2967  loss_mask: 0.5336  loss_rpn_cls: 0.06605  loss_rpn_loc: 0.03545  validation_loss: 2.052  time: 1.5195  data_time: 0.0239  lr: 3.2783e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:50:25 d2.utils.events]: \u001b[0m eta: 1:39:56  iter: 6139  total_loss: 2.272  loss_cls_stage0: 0.3376  loss_box_reg_stage0: 0.2481  loss_cls_stage1: 0.2724  loss_box_reg_stage1: 0.3352  loss_cls_stage2: 0.1857  loss_box_reg_stage2: 0.2633  loss_mask: 0.5804  loss_rpn_cls: 0.06952  loss_rpn_loc: 0.03968  validation_loss: 2.052  time: 1.5197  data_time: 0.0257  lr: 3.2488e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:50:57 d2.utils.events]: \u001b[0m eta: 1:39:26  iter: 6159  total_loss: 2.349  loss_cls_stage0: 0.3362  loss_box_reg_stage0: 0.2643  loss_cls_stage1: 0.2622  loss_box_reg_stage1: 0.33  loss_cls_stage2: 0.1933  loss_box_reg_stage2: 0.2861  loss_mask: 0.5647  loss_rpn_cls: 0.0603  loss_rpn_loc: 0.03631  validation_loss: 2.052  time: 1.5198  data_time: 0.0248  lr: 3.2194e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:51:28 d2.utils.events]: \u001b[0m eta: 1:38:56  iter: 6179  total_loss: 2.374  loss_cls_stage0: 0.3304  loss_box_reg_stage0: 0.2766  loss_cls_stage1: 0.2801  loss_box_reg_stage1: 0.3663  loss_cls_stage2: 0.1966  loss_box_reg_stage2: 0.2945  loss_mask: 0.5684  loss_rpn_cls: 0.07017  loss_rpn_loc: 0.03945  validation_loss: 2.052  time: 1.5200  data_time: 0.0249  lr: 3.1901e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:52:00 d2.utils.events]: \u001b[0m eta: 1:38:26  iter: 6199  total_loss: 2.296  loss_cls_stage0: 0.3166  loss_box_reg_stage0: 0.2407  loss_cls_stage1: 0.2608  loss_box_reg_stage1: 0.3481  loss_cls_stage2: 0.1919  loss_box_reg_stage2: 0.2882  loss_mask: 0.577  loss_rpn_cls: 0.06203  loss_rpn_loc: 0.03445  validation_loss: 2.052  time: 1.5201  data_time: 0.0267  lr: 3.1608e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:52:31 d2.utils.events]: \u001b[0m eta: 1:37:55  iter: 6219  total_loss: 2.231  loss_cls_stage0: 0.3185  loss_box_reg_stage0: 0.2291  loss_cls_stage1: 0.2767  loss_box_reg_stage1: 0.3361  loss_cls_stage2: 0.1892  loss_box_reg_stage2: 0.2932  loss_mask: 0.5125  loss_rpn_cls: 0.05125  loss_rpn_loc: 0.02781  validation_loss: 2.052  time: 1.5202  data_time: 0.0231  lr: 3.1317e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:53:02 d2.utils.events]: \u001b[0m eta: 1:37:23  iter: 6239  total_loss: 2.292  loss_cls_stage0: 0.3386  loss_box_reg_stage0: 0.2542  loss_cls_stage1: 0.2756  loss_box_reg_stage1: 0.3486  loss_cls_stage2: 0.1973  loss_box_reg_stage2: 0.2836  loss_mask: 0.5007  loss_rpn_cls: 0.06418  loss_rpn_loc: 0.0401  validation_loss: 2.052  time: 1.5204  data_time: 0.0239  lr: 3.1026e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:53:33 d2.utils.events]: \u001b[0m eta: 1:36:53  iter: 6259  total_loss: 2.271  loss_cls_stage0: 0.3223  loss_box_reg_stage0: 0.2419  loss_cls_stage1: 0.2612  loss_box_reg_stage1: 0.3104  loss_cls_stage2: 0.1734  loss_box_reg_stage2: 0.2497  loss_mask: 0.5576  loss_rpn_cls: 0.06702  loss_rpn_loc: 0.03451  validation_loss: 2.052  time: 1.5205  data_time: 0.0247  lr: 3.0735e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:54:05 d2.utils.events]: \u001b[0m eta: 1:36:22  iter: 6279  total_loss: 2.239  loss_cls_stage0: 0.3153  loss_box_reg_stage0: 0.2407  loss_cls_stage1: 0.2651  loss_box_reg_stage1: 0.3273  loss_cls_stage2: 0.1845  loss_box_reg_stage2: 0.259  loss_mask: 0.545  loss_rpn_cls: 0.06291  loss_rpn_loc: 0.03574  validation_loss: 2.052  time: 1.5207  data_time: 0.0239  lr: 3.0446e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:54:36 d2.utils.events]: \u001b[0m eta: 1:35:53  iter: 6299  total_loss: 2.392  loss_cls_stage0: 0.3438  loss_box_reg_stage0: 0.2801  loss_cls_stage1: 0.2778  loss_box_reg_stage1: 0.3709  loss_cls_stage2: 0.1931  loss_box_reg_stage2: 0.2742  loss_mask: 0.5564  loss_rpn_cls: 0.06482  loss_rpn_loc: 0.03877  validation_loss: 2.052  time: 1.5208  data_time: 0.0245  lr: 3.0157e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:55:07 d2.utils.events]: \u001b[0m eta: 1:35:22  iter: 6319  total_loss: 2.279  loss_cls_stage0: 0.3523  loss_box_reg_stage0: 0.241  loss_cls_stage1: 0.281  loss_box_reg_stage1: 0.3306  loss_cls_stage2: 0.1857  loss_box_reg_stage2: 0.255  loss_mask: 0.5072  loss_rpn_cls: 0.05571  loss_rpn_loc: 0.03731  validation_loss: 2.052  time: 1.5209  data_time: 0.0244  lr: 2.9869e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:55:38 d2.utils.events]: \u001b[0m eta: 1:34:52  iter: 6339  total_loss: 2.313  loss_cls_stage0: 0.3331  loss_box_reg_stage0: 0.2436  loss_cls_stage1: 0.264  loss_box_reg_stage1: 0.3428  loss_cls_stage2: 0.188  loss_box_reg_stage2: 0.2988  loss_mask: 0.5431  loss_rpn_cls: 0.06905  loss_rpn_loc: 0.03785  validation_loss: 2.052  time: 1.5211  data_time: 0.0242  lr: 2.9582e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:56:10 d2.utils.events]: \u001b[0m eta: 1:34:24  iter: 6359  total_loss: 2.344  loss_cls_stage0: 0.3304  loss_box_reg_stage0: 0.2557  loss_cls_stage1: 0.2731  loss_box_reg_stage1: 0.3537  loss_cls_stage2: 0.1998  loss_box_reg_stage2: 0.3083  loss_mask: 0.5591  loss_rpn_cls: 0.06726  loss_rpn_loc: 0.03875  validation_loss: 2.052  time: 1.5212  data_time: 0.0246  lr: 2.9296e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:56:41 d2.utils.events]: \u001b[0m eta: 1:33:54  iter: 6379  total_loss: 2.288  loss_cls_stage0: 0.3216  loss_box_reg_stage0: 0.2525  loss_cls_stage1: 0.2662  loss_box_reg_stage1: 0.3498  loss_cls_stage2: 0.1963  loss_box_reg_stage2: 0.2907  loss_mask: 0.5365  loss_rpn_cls: 0.07483  loss_rpn_loc: 0.03959  validation_loss: 2.052  time: 1.5214  data_time: 0.0241  lr: 2.901e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:57:12 d2.utils.events]: \u001b[0m eta: 1:33:23  iter: 6399  total_loss: 2.328  loss_cls_stage0: 0.3331  loss_box_reg_stage0: 0.2582  loss_cls_stage1: 0.2659  loss_box_reg_stage1: 0.3504  loss_cls_stage2: 0.1922  loss_box_reg_stage2: 0.2953  loss_mask: 0.5431  loss_rpn_cls: 0.0729  loss_rpn_loc: 0.03839  validation_loss: 2.052  time: 1.5215  data_time: 0.0234  lr: 2.8725e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:57:44 d2.utils.events]: \u001b[0m eta: 1:32:52  iter: 6419  total_loss: 2.328  loss_cls_stage0: 0.3223  loss_box_reg_stage0: 0.2278  loss_cls_stage1: 0.2774  loss_box_reg_stage1: 0.3446  loss_cls_stage2: 0.2041  loss_box_reg_stage2: 0.2754  loss_mask: 0.5607  loss_rpn_cls: 0.06452  loss_rpn_loc: 0.03665  validation_loss: 2.052  time: 1.5216  data_time: 0.0231  lr: 2.8441e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:58:15 d2.utils.events]: \u001b[0m eta: 1:32:19  iter: 6439  total_loss: 2.307  loss_cls_stage0: 0.3158  loss_box_reg_stage0: 0.2331  loss_cls_stage1: 0.2541  loss_box_reg_stage1: 0.315  loss_cls_stage2: 0.1851  loss_box_reg_stage2: 0.266  loss_mask: 0.5804  loss_rpn_cls: 0.0747  loss_rpn_loc: 0.03411  validation_loss: 2.052  time: 1.5217  data_time: 0.0317  lr: 2.8158e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:58:46 d2.utils.events]: \u001b[0m eta: 1:31:49  iter: 6459  total_loss: 2.298  loss_cls_stage0: 0.322  loss_box_reg_stage0: 0.2547  loss_cls_stage1: 0.2684  loss_box_reg_stage1: 0.3543  loss_cls_stage2: 0.1895  loss_box_reg_stage2: 0.2659  loss_mask: 0.5348  loss_rpn_cls: 0.06542  loss_rpn_loc: 0.0393  validation_loss: 2.052  time: 1.5218  data_time: 0.0249  lr: 2.7876e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:59:17 d2.utils.events]: \u001b[0m eta: 1:31:17  iter: 6479  total_loss: 2.386  loss_cls_stage0: 0.3169  loss_box_reg_stage0: 0.2503  loss_cls_stage1: 0.2625  loss_box_reg_stage1: 0.3464  loss_cls_stage2: 0.1862  loss_box_reg_stage2: 0.277  loss_mask: 0.5457  loss_rpn_cls: 0.06134  loss_rpn_loc: 0.03453  validation_loss: 2.052  time: 1.5220  data_time: 0.0256  lr: 2.7595e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 09:59:48 d2.utils.events]: \u001b[0m eta: 1:30:46  iter: 6499  total_loss: 2.277  loss_cls_stage0: 0.3034  loss_box_reg_stage0: 0.2406  loss_cls_stage1: 0.2629  loss_box_reg_stage1: 0.3401  loss_cls_stage2: 0.1935  loss_box_reg_stage2: 0.271  loss_mask: 0.5639  loss_rpn_cls: 0.06831  loss_rpn_loc: 0.03729  validation_loss: 2.052  time: 1.5221  data_time: 0.0233  lr: 2.7314e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:00:20 d2.utils.events]: \u001b[0m eta: 1:30:13  iter: 6519  total_loss: 2.406  loss_cls_stage0: 0.353  loss_box_reg_stage0: 0.28  loss_cls_stage1: 0.2873  loss_box_reg_stage1: 0.3546  loss_cls_stage2: 0.1914  loss_box_reg_stage2: 0.2629  loss_mask: 0.5749  loss_rpn_cls: 0.06551  loss_rpn_loc: 0.03874  validation_loss: 2.052  time: 1.5222  data_time: 0.0235  lr: 2.7035e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:00:51 d2.utils.events]: \u001b[0m eta: 1:29:44  iter: 6539  total_loss: 2.595  loss_cls_stage0: 0.3559  loss_box_reg_stage0: 0.2699  loss_cls_stage1: 0.2897  loss_box_reg_stage1: 0.3863  loss_cls_stage2: 0.2009  loss_box_reg_stage2: 0.2929  loss_mask: 0.5641  loss_rpn_cls: 0.07354  loss_rpn_loc: 0.03876  validation_loss: 2.052  time: 1.5224  data_time: 0.0232  lr: 2.6756e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:01:23 d2.utils.events]: \u001b[0m eta: 1:29:13  iter: 6559  total_loss: 2.414  loss_cls_stage0: 0.3483  loss_box_reg_stage0: 0.2708  loss_cls_stage1: 0.2998  loss_box_reg_stage1: 0.3756  loss_cls_stage2: 0.2135  loss_box_reg_stage2: 0.294  loss_mask: 0.5685  loss_rpn_cls: 0.06392  loss_rpn_loc: 0.04028  validation_loss: 2.052  time: 1.5225  data_time: 0.0242  lr: 2.6479e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:01:54 d2.utils.events]: \u001b[0m eta: 1:28:41  iter: 6579  total_loss: 2.258  loss_cls_stage0: 0.3304  loss_box_reg_stage0: 0.2256  loss_cls_stage1: 0.2867  loss_box_reg_stage1: 0.3429  loss_cls_stage2: 0.2078  loss_box_reg_stage2: 0.2768  loss_mask: 0.5403  loss_rpn_cls: 0.0576  loss_rpn_loc: 0.03376  validation_loss: 2.052  time: 1.5226  data_time: 0.0235  lr: 2.6202e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:02:25 d2.utils.events]: \u001b[0m eta: 1:28:10  iter: 6599  total_loss: 2.403  loss_cls_stage0: 0.3518  loss_box_reg_stage0: 0.2583  loss_cls_stage1: 0.2913  loss_box_reg_stage1: 0.3676  loss_cls_stage2: 0.1923  loss_box_reg_stage2: 0.2849  loss_mask: 0.5807  loss_rpn_cls: 0.05684  loss_rpn_loc: 0.03422  validation_loss: 2.052  time: 1.5227  data_time: 0.0255  lr: 2.5926e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:02:56 d2.utils.events]: \u001b[0m eta: 1:27:40  iter: 6619  total_loss: 2.338  loss_cls_stage0: 0.3267  loss_box_reg_stage0: 0.2402  loss_cls_stage1: 0.2617  loss_box_reg_stage1: 0.3495  loss_cls_stage2: 0.1977  loss_box_reg_stage2: 0.301  loss_mask: 0.6028  loss_rpn_cls: 0.0633  loss_rpn_loc: 0.03642  validation_loss: 2.052  time: 1.5229  data_time: 0.0238  lr: 2.5651e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:03:28 d2.utils.events]: \u001b[0m eta: 1:27:10  iter: 6639  total_loss: 2.445  loss_cls_stage0: 0.3413  loss_box_reg_stage0: 0.2611  loss_cls_stage1: 0.2869  loss_box_reg_stage1: 0.3712  loss_cls_stage2: 0.2047  loss_box_reg_stage2: 0.3084  loss_mask: 0.5289  loss_rpn_cls: 0.0653  loss_rpn_loc: 0.03579  validation_loss: 2.052  time: 1.5230  data_time: 0.0232  lr: 2.5377e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:03:59 d2.utils.events]: \u001b[0m eta: 1:26:39  iter: 6659  total_loss: 2.266  loss_cls_stage0: 0.3134  loss_box_reg_stage0: 0.2511  loss_cls_stage1: 0.252  loss_box_reg_stage1: 0.341  loss_cls_stage2: 0.18  loss_box_reg_stage2: 0.2852  loss_mask: 0.5353  loss_rpn_cls: 0.05986  loss_rpn_loc: 0.03344  validation_loss: 2.052  time: 1.5231  data_time: 0.0239  lr: 2.5104e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:04:30 d2.utils.events]: \u001b[0m eta: 1:26:08  iter: 6679  total_loss: 2.252  loss_cls_stage0: 0.3142  loss_box_reg_stage0: 0.257  loss_cls_stage1: 0.2649  loss_box_reg_stage1: 0.3326  loss_cls_stage2: 0.1937  loss_box_reg_stage2: 0.2902  loss_mask: 0.5023  loss_rpn_cls: 0.06322  loss_rpn_loc: 0.03448  validation_loss: 2.052  time: 1.5232  data_time: 0.0235  lr: 2.4832e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:05:01 d2.utils.events]: \u001b[0m eta: 1:25:36  iter: 6699  total_loss: 2.199  loss_cls_stage0: 0.2962  loss_box_reg_stage0: 0.2309  loss_cls_stage1: 0.2407  loss_box_reg_stage1: 0.3327  loss_cls_stage2: 0.17  loss_box_reg_stage2: 0.2855  loss_mask: 0.536  loss_rpn_cls: 0.05117  loss_rpn_loc: 0.02984  validation_loss: 2.052  time: 1.5233  data_time: 0.0239  lr: 2.4561e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:05:33 d2.utils.events]: \u001b[0m eta: 1:25:05  iter: 6719  total_loss: 2.355  loss_cls_stage0: 0.3181  loss_box_reg_stage0: 0.2576  loss_cls_stage1: 0.2722  loss_box_reg_stage1: 0.356  loss_cls_stage2: 0.1919  loss_box_reg_stage2: 0.3124  loss_mask: 0.5679  loss_rpn_cls: 0.06618  loss_rpn_loc: 0.03856  validation_loss: 2.052  time: 1.5235  data_time: 0.0237  lr: 2.4291e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:06:04 d2.utils.events]: \u001b[0m eta: 1:24:33  iter: 6739  total_loss: 2.299  loss_cls_stage0: 0.3152  loss_box_reg_stage0: 0.2366  loss_cls_stage1: 0.2683  loss_box_reg_stage1: 0.3439  loss_cls_stage2: 0.1818  loss_box_reg_stage2: 0.2792  loss_mask: 0.5873  loss_rpn_cls: 0.0608  loss_rpn_loc: 0.03058  validation_loss: 2.052  time: 1.5236  data_time: 0.0244  lr: 2.4023e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:06:36 d2.utils.events]: \u001b[0m eta: 1:24:04  iter: 6759  total_loss: 2.498  loss_cls_stage0: 0.3389  loss_box_reg_stage0: 0.2784  loss_cls_stage1: 0.2971  loss_box_reg_stage1: 0.3927  loss_cls_stage2: 0.2155  loss_box_reg_stage2: 0.3122  loss_mask: 0.5627  loss_rpn_cls: 0.05936  loss_rpn_loc: 0.03849  validation_loss: 2.052  time: 1.5237  data_time: 0.0242  lr: 2.3755e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:07:07 d2.utils.events]: \u001b[0m eta: 1:23:35  iter: 6779  total_loss: 2.31  loss_cls_stage0: 0.3132  loss_box_reg_stage0: 0.2638  loss_cls_stage1: 0.2579  loss_box_reg_stage1: 0.3611  loss_cls_stage2: 0.1916  loss_box_reg_stage2: 0.3149  loss_mask: 0.56  loss_rpn_cls: 0.05597  loss_rpn_loc: 0.03369  validation_loss: 2.052  time: 1.5238  data_time: 0.0230  lr: 2.3488e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:07:38 d2.utils.events]: \u001b[0m eta: 1:23:05  iter: 6799  total_loss: 2.424  loss_cls_stage0: 0.3453  loss_box_reg_stage0: 0.2418  loss_cls_stage1: 0.2792  loss_box_reg_stage1: 0.3444  loss_cls_stage2: 0.1967  loss_box_reg_stage2: 0.2898  loss_mask: 0.5628  loss_rpn_cls: 0.06989  loss_rpn_loc: 0.03138  validation_loss: 2.052  time: 1.5240  data_time: 0.0235  lr: 2.3222e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:08:10 d2.utils.events]: \u001b[0m eta: 1:22:34  iter: 6819  total_loss: 2.426  loss_cls_stage0: 0.3424  loss_box_reg_stage0: 0.2698  loss_cls_stage1: 0.2824  loss_box_reg_stage1: 0.3658  loss_cls_stage2: 0.2092  loss_box_reg_stage2: 0.3003  loss_mask: 0.5416  loss_rpn_cls: 0.05919  loss_rpn_loc: 0.03837  validation_loss: 2.052  time: 1.5241  data_time: 0.0241  lr: 2.2957e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:08:41 d2.utils.events]: \u001b[0m eta: 1:22:03  iter: 6839  total_loss: 2.17  loss_cls_stage0: 0.268  loss_box_reg_stage0: 0.2309  loss_cls_stage1: 0.2277  loss_box_reg_stage1: 0.3277  loss_cls_stage2: 0.1716  loss_box_reg_stage2: 0.2742  loss_mask: 0.5104  loss_rpn_cls: 0.05676  loss_rpn_loc: 0.02947  validation_loss: 2.052  time: 1.5242  data_time: 0.0231  lr: 2.2693e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:09:12 d2.utils.events]: \u001b[0m eta: 1:21:30  iter: 6859  total_loss: 2.403  loss_cls_stage0: 0.3401  loss_box_reg_stage0: 0.2446  loss_cls_stage1: 0.2904  loss_box_reg_stage1: 0.374  loss_cls_stage2: 0.2062  loss_box_reg_stage2: 0.2934  loss_mask: 0.5937  loss_rpn_cls: 0.05681  loss_rpn_loc: 0.03606  validation_loss: 2.052  time: 1.5243  data_time: 0.0253  lr: 2.2431e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:09:43 d2.utils.events]: \u001b[0m eta: 1:21:01  iter: 6879  total_loss: 2.41  loss_cls_stage0: 0.3341  loss_box_reg_stage0: 0.2552  loss_cls_stage1: 0.2883  loss_box_reg_stage1: 0.3488  loss_cls_stage2: 0.2074  loss_box_reg_stage2: 0.2859  loss_mask: 0.6002  loss_rpn_cls: 0.07069  loss_rpn_loc: 0.03473  validation_loss: 2.052  time: 1.5245  data_time: 0.0254  lr: 2.2169e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:10:15 d2.utils.events]: \u001b[0m eta: 1:20:29  iter: 6899  total_loss: 2.21  loss_cls_stage0: 0.296  loss_box_reg_stage0: 0.2408  loss_cls_stage1: 0.2381  loss_box_reg_stage1: 0.33  loss_cls_stage2: 0.1658  loss_box_reg_stage2: 0.2672  loss_mask: 0.53  loss_rpn_cls: 0.05615  loss_rpn_loc: 0.03048  validation_loss: 2.052  time: 1.5245  data_time: 0.0243  lr: 2.1909e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:10:46 d2.utils.events]: \u001b[0m eta: 1:19:56  iter: 6919  total_loss: 2.175  loss_cls_stage0: 0.2984  loss_box_reg_stage0: 0.2327  loss_cls_stage1: 0.2542  loss_box_reg_stage1: 0.3592  loss_cls_stage2: 0.1841  loss_box_reg_stage2: 0.2929  loss_mask: 0.5235  loss_rpn_cls: 0.05683  loss_rpn_loc: 0.03213  validation_loss: 2.052  time: 1.5247  data_time: 0.0259  lr: 2.1649e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:11:17 d2.utils.events]: \u001b[0m eta: 1:19:27  iter: 6939  total_loss: 2.082  loss_cls_stage0: 0.2958  loss_box_reg_stage0: 0.2186  loss_cls_stage1: 0.2325  loss_box_reg_stage1: 0.3298  loss_cls_stage2: 0.1707  loss_box_reg_stage2: 0.2801  loss_mask: 0.5555  loss_rpn_cls: 0.06292  loss_rpn_loc: 0.03391  validation_loss: 2.052  time: 1.5248  data_time: 0.0248  lr: 2.1391e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:11:49 d2.utils.events]: \u001b[0m eta: 1:18:56  iter: 6959  total_loss: 2.369  loss_cls_stage0: 0.3269  loss_box_reg_stage0: 0.262  loss_cls_stage1: 0.2663  loss_box_reg_stage1: 0.3622  loss_cls_stage2: 0.1935  loss_box_reg_stage2: 0.3221  loss_mask: 0.495  loss_rpn_cls: 0.06824  loss_rpn_loc: 0.03778  validation_loss: 2.052  time: 1.5249  data_time: 0.0255  lr: 2.1134e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:12:20 d2.utils.events]: \u001b[0m eta: 1:18:26  iter: 6979  total_loss: 2.483  loss_cls_stage0: 0.3317  loss_box_reg_stage0: 0.2605  loss_cls_stage1: 0.2872  loss_box_reg_stage1: 0.3665  loss_cls_stage2: 0.2046  loss_box_reg_stage2: 0.2729  loss_mask: 0.5638  loss_rpn_cls: 0.06975  loss_rpn_loc: 0.04013  validation_loss: 2.052  time: 1.5250  data_time: 0.0239  lr: 2.0878e-05  max_mem: 12121M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/27 10:12:53 d2.data.common]: \u001b[0mSerializing 883 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/27 10:12:53 d2.data.common]: \u001b[0mSerialized dataset takes 0.91 MiB\n",
      "\u001b[32m[03/27 10:12:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 883 images\n",
      "\u001b[32m[03/27 10:12:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/883. 0.0822 s / img. ETA=0:02:03\n",
      "\u001b[32m[03/27 10:13:01 d2.evaluation.evaluator]: \u001b[0mInference done 55/883. 0.0808 s / img. ETA=0:01:38\n",
      "\u001b[32m[03/27 10:13:06 d2.evaluation.evaluator]: \u001b[0mInference done 95/883. 0.0809 s / img. ETA=0:01:35\n",
      "\u001b[32m[03/27 10:13:11 d2.evaluation.evaluator]: \u001b[0mInference done 135/883. 0.0811 s / img. ETA=0:01:32\n",
      "\u001b[32m[03/27 10:13:16 d2.evaluation.evaluator]: \u001b[0mInference done 178/883. 0.0810 s / img. ETA=0:01:26\n",
      "\u001b[32m[03/27 10:13:21 d2.evaluation.evaluator]: \u001b[0mInference done 222/883. 0.0809 s / img. ETA=0:01:19\n",
      "\u001b[32m[03/27 10:13:26 d2.evaluation.evaluator]: \u001b[0mInference done 263/883. 0.0809 s / img. ETA=0:01:15\n",
      "\u001b[32m[03/27 10:13:31 d2.evaluation.evaluator]: \u001b[0mInference done 304/883. 0.0809 s / img. ETA=0:01:10\n",
      "\u001b[32m[03/27 10:13:36 d2.evaluation.evaluator]: \u001b[0mInference done 346/883. 0.0810 s / img. ETA=0:01:05\n",
      "\u001b[32m[03/27 10:13:41 d2.evaluation.evaluator]: \u001b[0mInference done 387/883. 0.0810 s / img. ETA=0:01:00\n",
      "\u001b[32m[03/27 10:13:46 d2.evaluation.evaluator]: \u001b[0mInference done 424/883. 0.0814 s / img. ETA=0:00:56\n",
      "\u001b[32m[03/27 10:13:51 d2.evaluation.evaluator]: \u001b[0mInference done 467/883. 0.0813 s / img. ETA=0:00:50\n",
      "\u001b[32m[03/27 10:13:56 d2.evaluation.evaluator]: \u001b[0mInference done 509/883. 0.0812 s / img. ETA=0:00:45\n",
      "\u001b[32m[03/27 10:14:01 d2.evaluation.evaluator]: \u001b[0mInference done 554/883. 0.0812 s / img. ETA=0:00:39\n",
      "\u001b[32m[03/27 10:14:06 d2.evaluation.evaluator]: \u001b[0mInference done 599/883. 0.0811 s / img. ETA=0:00:34\n",
      "\u001b[32m[03/27 10:14:11 d2.evaluation.evaluator]: \u001b[0mInference done 642/883. 0.0811 s / img. ETA=0:00:29\n",
      "\u001b[32m[03/27 10:14:17 d2.evaluation.evaluator]: \u001b[0mInference done 687/883. 0.0810 s / img. ETA=0:00:23\n",
      "\u001b[32m[03/27 10:14:22 d2.evaluation.evaluator]: \u001b[0mInference done 728/883. 0.0810 s / img. ETA=0:00:18\n",
      "\u001b[32m[03/27 10:14:27 d2.evaluation.evaluator]: \u001b[0mInference done 770/883. 0.0810 s / img. ETA=0:00:13\n",
      "\u001b[32m[03/27 10:14:32 d2.evaluation.evaluator]: \u001b[0mInference done 811/883. 0.0810 s / img. ETA=0:00:08\n",
      "\u001b[32m[03/27 10:14:37 d2.evaluation.evaluator]: \u001b[0mInference done 853/883. 0.0810 s / img. ETA=0:00:03\n",
      "\u001b[32m[03/27 10:14:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:45.667920 (0.120351 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/27 10:14:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:11 (0.080937 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.33 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.081\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.136\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.153\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.034\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.088\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.123\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.161\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.161\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.046\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.183\n",
      "\u001b[32m[03/27 10:14:41 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold5 in csv format:\n",
      "\u001b[32m[03/27 10:14:41 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/27 10:14:41 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/27 10:14:41 d2.evaluation.testing]: \u001b[0mcopypaste: 8.0515,13.6470,15.2558,0.1735,3.4266,8.7935\n",
      "validation do loss eval 2.3835909338429357\n",
      "\u001b[32m[03/27 10:16:13 d2.utils.events]: \u001b[0m eta: 1:17:56  iter: 6999  total_loss: 2.325  loss_cls_stage0: 0.3312  loss_box_reg_stage0: 0.2711  loss_cls_stage1: 0.2687  loss_box_reg_stage1: 0.3751  loss_cls_stage2: 0.1944  loss_box_reg_stage2: 0.3012  loss_mask: 0.5559  loss_rpn_cls: 0.05838  loss_rpn_loc: 0.03675  validation_loss: 2.11  time: 1.5252  data_time: 0.0250  lr: 2.0623e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:16:44 d2.utils.events]: \u001b[0m eta: 1:17:26  iter: 7019  total_loss: 2.341  loss_cls_stage0: 0.329  loss_box_reg_stage0: 0.2563  loss_cls_stage1: 0.2788  loss_box_reg_stage1: 0.3439  loss_cls_stage2: 0.1796  loss_box_reg_stage2: 0.2759  loss_mask: 0.5466  loss_rpn_cls: 0.06407  loss_rpn_loc: 0.03647  validation_loss: 2.11  time: 1.5252  data_time: 0.0257  lr: 2.037e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:17:15 d2.utils.events]: \u001b[0m eta: 1:16:55  iter: 7039  total_loss: 2.288  loss_cls_stage0: 0.3296  loss_box_reg_stage0: 0.2563  loss_cls_stage1: 0.2713  loss_box_reg_stage1: 0.3383  loss_cls_stage2: 0.1885  loss_box_reg_stage2: 0.2735  loss_mask: 0.5295  loss_rpn_cls: 0.06869  loss_rpn_loc: 0.03595  validation_loss: 2.11  time: 1.5253  data_time: 0.0250  lr: 2.0117e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:17:46 d2.utils.events]: \u001b[0m eta: 1:16:24  iter: 7059  total_loss: 2.219  loss_cls_stage0: 0.3063  loss_box_reg_stage0: 0.2417  loss_cls_stage1: 0.2496  loss_box_reg_stage1: 0.3529  loss_cls_stage2: 0.1777  loss_box_reg_stage2: 0.31  loss_mask: 0.5285  loss_rpn_cls: 0.05342  loss_rpn_loc: 0.03145  validation_loss: 2.11  time: 1.5254  data_time: 0.0232  lr: 1.9866e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:18:17 d2.utils.events]: \u001b[0m eta: 1:15:54  iter: 7079  total_loss: 2.296  loss_cls_stage0: 0.3221  loss_box_reg_stage0: 0.2404  loss_cls_stage1: 0.2741  loss_box_reg_stage1: 0.3448  loss_cls_stage2: 0.1943  loss_box_reg_stage2: 0.288  loss_mask: 0.4974  loss_rpn_cls: 0.07605  loss_rpn_loc: 0.03642  validation_loss: 2.11  time: 1.5255  data_time: 0.0240  lr: 1.9616e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:18:49 d2.utils.events]: \u001b[0m eta: 1:15:25  iter: 7099  total_loss: 2.362  loss_cls_stage0: 0.3367  loss_box_reg_stage0: 0.2558  loss_cls_stage1: 0.2823  loss_box_reg_stage1: 0.3789  loss_cls_stage2: 0.204  loss_box_reg_stage2: 0.3056  loss_mask: 0.5481  loss_rpn_cls: 0.06233  loss_rpn_loc: 0.0381  validation_loss: 2.11  time: 1.5256  data_time: 0.0237  lr: 1.9367e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:19:21 d2.utils.events]: \u001b[0m eta: 1:14:55  iter: 7119  total_loss: 2.716  loss_cls_stage0: 0.4002  loss_box_reg_stage0: 0.3187  loss_cls_stage1: 0.3169  loss_box_reg_stage1: 0.416  loss_cls_stage2: 0.2193  loss_box_reg_stage2: 0.3022  loss_mask: 0.549  loss_rpn_cls: 0.0639  loss_rpn_loc: 0.04255  validation_loss: 2.11  time: 1.5258  data_time: 0.0233  lr: 1.9119e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:19:52 d2.utils.events]: \u001b[0m eta: 1:14:24  iter: 7139  total_loss: 2.489  loss_cls_stage0: 0.3308  loss_box_reg_stage0: 0.2813  loss_cls_stage1: 0.2906  loss_box_reg_stage1: 0.3959  loss_cls_stage2: 0.2003  loss_box_reg_stage2: 0.3018  loss_mask: 0.5947  loss_rpn_cls: 0.0716  loss_rpn_loc: 0.03959  validation_loss: 2.11  time: 1.5259  data_time: 0.0247  lr: 1.8873e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:20:24 d2.utils.events]: \u001b[0m eta: 1:13:53  iter: 7159  total_loss: 2.421  loss_cls_stage0: 0.3291  loss_box_reg_stage0: 0.2667  loss_cls_stage1: 0.2699  loss_box_reg_stage1: 0.3895  loss_cls_stage2: 0.1916  loss_box_reg_stage2: 0.3195  loss_mask: 0.5793  loss_rpn_cls: 0.06823  loss_rpn_loc: 0.03905  validation_loss: 2.11  time: 1.5260  data_time: 0.0243  lr: 1.8628e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:20:55 d2.utils.events]: \u001b[0m eta: 1:13:21  iter: 7179  total_loss: 2.28  loss_cls_stage0: 0.2966  loss_box_reg_stage0: 0.2385  loss_cls_stage1: 0.244  loss_box_reg_stage1: 0.346  loss_cls_stage2: 0.1785  loss_box_reg_stage2: 0.2887  loss_mask: 0.5311  loss_rpn_cls: 0.05856  loss_rpn_loc: 0.0329  validation_loss: 2.11  time: 1.5262  data_time: 0.0242  lr: 1.8384e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:21:26 d2.utils.events]: \u001b[0m eta: 1:12:50  iter: 7199  total_loss: 2.452  loss_cls_stage0: 0.3597  loss_box_reg_stage0: 0.2881  loss_cls_stage1: 0.2872  loss_box_reg_stage1: 0.3588  loss_cls_stage2: 0.1959  loss_box_reg_stage2: 0.276  loss_mask: 0.5432  loss_rpn_cls: 0.06107  loss_rpn_loc: 0.0368  validation_loss: 2.11  time: 1.5263  data_time: 0.0241  lr: 1.8141e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:21:58 d2.utils.events]: \u001b[0m eta: 1:12:19  iter: 7219  total_loss: 2.398  loss_cls_stage0: 0.3182  loss_box_reg_stage0: 0.2488  loss_cls_stage1: 0.2691  loss_box_reg_stage1: 0.3471  loss_cls_stage2: 0.205  loss_box_reg_stage2: 0.3047  loss_mask: 0.5732  loss_rpn_cls: 0.0669  loss_rpn_loc: 0.03619  validation_loss: 2.11  time: 1.5264  data_time: 0.0245  lr: 1.7899e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:22:29 d2.utils.events]: \u001b[0m eta: 1:11:48  iter: 7239  total_loss: 2.358  loss_cls_stage0: 0.3459  loss_box_reg_stage0: 0.2592  loss_cls_stage1: 0.2701  loss_box_reg_stage1: 0.3674  loss_cls_stage2: 0.1889  loss_box_reg_stage2: 0.2784  loss_mask: 0.5707  loss_rpn_cls: 0.05938  loss_rpn_loc: 0.0386  validation_loss: 2.11  time: 1.5265  data_time: 0.0242  lr: 1.7659e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:23:00 d2.utils.events]: \u001b[0m eta: 1:11:17  iter: 7259  total_loss: 2.252  loss_cls_stage0: 0.2957  loss_box_reg_stage0: 0.2383  loss_cls_stage1: 0.2311  loss_box_reg_stage1: 0.3388  loss_cls_stage2: 0.1749  loss_box_reg_stage2: 0.2853  loss_mask: 0.5649  loss_rpn_cls: 0.05518  loss_rpn_loc: 0.03495  validation_loss: 2.11  time: 1.5266  data_time: 0.0247  lr: 1.742e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:23:31 d2.utils.events]: \u001b[0m eta: 1:10:46  iter: 7279  total_loss: 2.417  loss_cls_stage0: 0.3045  loss_box_reg_stage0: 0.2486  loss_cls_stage1: 0.2499  loss_box_reg_stage1: 0.3846  loss_cls_stage2: 0.1991  loss_box_reg_stage2: 0.3148  loss_mask: 0.5696  loss_rpn_cls: 0.06304  loss_rpn_loc: 0.03669  validation_loss: 2.11  time: 1.5267  data_time: 0.0320  lr: 1.7183e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:24:02 d2.utils.events]: \u001b[0m eta: 1:10:14  iter: 7299  total_loss: 2.318  loss_cls_stage0: 0.2994  loss_box_reg_stage0: 0.2466  loss_cls_stage1: 0.2467  loss_box_reg_stage1: 0.3373  loss_cls_stage2: 0.1978  loss_box_reg_stage2: 0.2888  loss_mask: 0.5776  loss_rpn_cls: 0.05607  loss_rpn_loc: 0.03465  validation_loss: 2.11  time: 1.5267  data_time: 0.0234  lr: 1.6946e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:24:34 d2.utils.events]: \u001b[0m eta: 1:09:43  iter: 7319  total_loss: 2.33  loss_cls_stage0: 0.3336  loss_box_reg_stage0: 0.263  loss_cls_stage1: 0.2712  loss_box_reg_stage1: 0.3543  loss_cls_stage2: 0.1905  loss_box_reg_stage2: 0.2846  loss_mask: 0.5425  loss_rpn_cls: 0.06208  loss_rpn_loc: 0.03339  validation_loss: 2.11  time: 1.5268  data_time: 0.0249  lr: 1.6711e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:25:05 d2.utils.events]: \u001b[0m eta: 1:09:13  iter: 7339  total_loss: 2.336  loss_cls_stage0: 0.3462  loss_box_reg_stage0: 0.2653  loss_cls_stage1: 0.2754  loss_box_reg_stage1: 0.386  loss_cls_stage2: 0.1984  loss_box_reg_stage2: 0.3228  loss_mask: 0.5176  loss_rpn_cls: 0.07044  loss_rpn_loc: 0.03816  validation_loss: 2.11  time: 1.5269  data_time: 0.0227  lr: 1.6477e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:25:36 d2.utils.events]: \u001b[0m eta: 1:08:41  iter: 7359  total_loss: 2.211  loss_cls_stage0: 0.2977  loss_box_reg_stage0: 0.2383  loss_cls_stage1: 0.2573  loss_box_reg_stage1: 0.3643  loss_cls_stage2: 0.1894  loss_box_reg_stage2: 0.3144  loss_mask: 0.5302  loss_rpn_cls: 0.06274  loss_rpn_loc: 0.03431  validation_loss: 2.11  time: 1.5271  data_time: 0.0237  lr: 1.6245e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:26:08 d2.utils.events]: \u001b[0m eta: 1:08:10  iter: 7379  total_loss: 2.49  loss_cls_stage0: 0.3401  loss_box_reg_stage0: 0.2524  loss_cls_stage1: 0.2816  loss_box_reg_stage1: 0.3812  loss_cls_stage2: 0.2065  loss_box_reg_stage2: 0.2938  loss_mask: 0.5683  loss_rpn_cls: 0.05344  loss_rpn_loc: 0.03367  validation_loss: 2.11  time: 1.5272  data_time: 0.0253  lr: 1.6014e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:26:39 d2.utils.events]: \u001b[0m eta: 1:07:39  iter: 7399  total_loss: 2.171  loss_cls_stage0: 0.2963  loss_box_reg_stage0: 0.2232  loss_cls_stage1: 0.2483  loss_box_reg_stage1: 0.3221  loss_cls_stage2: 0.1843  loss_box_reg_stage2: 0.2678  loss_mask: 0.4793  loss_rpn_cls: 0.06318  loss_rpn_loc: 0.03672  validation_loss: 2.11  time: 1.5273  data_time: 0.0247  lr: 1.5784e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:27:10 d2.utils.events]: \u001b[0m eta: 1:07:07  iter: 7419  total_loss: 2.223  loss_cls_stage0: 0.3077  loss_box_reg_stage0: 0.2536  loss_cls_stage1: 0.2511  loss_box_reg_stage1: 0.3215  loss_cls_stage2: 0.1812  loss_box_reg_stage2: 0.2712  loss_mask: 0.573  loss_rpn_cls: 0.06006  loss_rpn_loc: 0.0352  validation_loss: 2.11  time: 1.5274  data_time: 0.0242  lr: 1.5556e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:27:41 d2.utils.events]: \u001b[0m eta: 1:06:37  iter: 7439  total_loss: 2.172  loss_cls_stage0: 0.2756  loss_box_reg_stage0: 0.2421  loss_cls_stage1: 0.2316  loss_box_reg_stage1: 0.3497  loss_cls_stage2: 0.1703  loss_box_reg_stage2: 0.2748  loss_mask: 0.5626  loss_rpn_cls: 0.05703  loss_rpn_loc: 0.03268  validation_loss: 2.11  time: 1.5274  data_time: 0.0252  lr: 1.5329e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:28:13 d2.utils.events]: \u001b[0m eta: 1:06:05  iter: 7459  total_loss: 2.218  loss_cls_stage0: 0.3377  loss_box_reg_stage0: 0.2413  loss_cls_stage1: 0.2569  loss_box_reg_stage1: 0.3254  loss_cls_stage2: 0.1888  loss_box_reg_stage2: 0.2811  loss_mask: 0.5032  loss_rpn_cls: 0.05784  loss_rpn_loc: 0.0287  validation_loss: 2.11  time: 1.5275  data_time: 0.0255  lr: 1.5103e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:28:44 d2.utils.events]: \u001b[0m eta: 1:05:33  iter: 7479  total_loss: 2.292  loss_cls_stage0: 0.3002  loss_box_reg_stage0: 0.2433  loss_cls_stage1: 0.2482  loss_box_reg_stage1: 0.3297  loss_cls_stage2: 0.1736  loss_box_reg_stage2: 0.2837  loss_mask: 0.5411  loss_rpn_cls: 0.06132  loss_rpn_loc: 0.03645  validation_loss: 2.11  time: 1.5276  data_time: 0.0236  lr: 1.4879e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:29:15 d2.utils.events]: \u001b[0m eta: 1:05:03  iter: 7499  total_loss: 2.39  loss_cls_stage0: 0.3543  loss_box_reg_stage0: 0.2773  loss_cls_stage1: 0.2894  loss_box_reg_stage1: 0.3659  loss_cls_stage2: 0.2052  loss_box_reg_stage2: 0.3119  loss_mask: 0.5513  loss_rpn_cls: 0.05958  loss_rpn_loc: 0.03806  validation_loss: 2.11  time: 1.5277  data_time: 0.0243  lr: 1.4656e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:29:47 d2.utils.events]: \u001b[0m eta: 1:04:31  iter: 7519  total_loss: 2.211  loss_cls_stage0: 0.2939  loss_box_reg_stage0: 0.2198  loss_cls_stage1: 0.2388  loss_box_reg_stage1: 0.3166  loss_cls_stage2: 0.1748  loss_box_reg_stage2: 0.2894  loss_mask: 0.5124  loss_rpn_cls: 0.06272  loss_rpn_loc: 0.03497  validation_loss: 2.11  time: 1.5278  data_time: 0.0239  lr: 1.4434e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:30:18 d2.utils.events]: \u001b[0m eta: 1:04:00  iter: 7539  total_loss: 2.409  loss_cls_stage0: 0.3347  loss_box_reg_stage0: 0.2662  loss_cls_stage1: 0.2723  loss_box_reg_stage1: 0.3752  loss_cls_stage2: 0.1926  loss_box_reg_stage2: 0.2942  loss_mask: 0.5818  loss_rpn_cls: 0.06703  loss_rpn_loc: 0.03493  validation_loss: 2.11  time: 1.5279  data_time: 0.0245  lr: 1.4214e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:30:49 d2.utils.events]: \u001b[0m eta: 1:03:29  iter: 7559  total_loss: 2.313  loss_cls_stage0: 0.3231  loss_box_reg_stage0: 0.2637  loss_cls_stage1: 0.2669  loss_box_reg_stage1: 0.3479  loss_cls_stage2: 0.1849  loss_box_reg_stage2: 0.2748  loss_mask: 0.5368  loss_rpn_cls: 0.06491  loss_rpn_loc: 0.03601  validation_loss: 2.11  time: 1.5281  data_time: 0.0249  lr: 1.3995e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:31:21 d2.utils.events]: \u001b[0m eta: 1:02:57  iter: 7579  total_loss: 2.221  loss_cls_stage0: 0.2902  loss_box_reg_stage0: 0.2306  loss_cls_stage1: 0.2437  loss_box_reg_stage1: 0.3228  loss_cls_stage2: 0.1818  loss_box_reg_stage2: 0.3153  loss_mask: 0.4932  loss_rpn_cls: 0.05463  loss_rpn_loc: 0.03303  validation_loss: 2.11  time: 1.5281  data_time: 0.0243  lr: 1.3778e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:31:52 d2.utils.events]: \u001b[0m eta: 1:02:26  iter: 7599  total_loss: 2.377  loss_cls_stage0: 0.3142  loss_box_reg_stage0: 0.2379  loss_cls_stage1: 0.2653  loss_box_reg_stage1: 0.3479  loss_cls_stage2: 0.1999  loss_box_reg_stage2: 0.3082  loss_mask: 0.5336  loss_rpn_cls: 0.06872  loss_rpn_loc: 0.03352  validation_loss: 2.11  time: 1.5282  data_time: 0.0242  lr: 1.3562e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:32:24 d2.utils.events]: \u001b[0m eta: 1:01:56  iter: 7619  total_loss: 2.637  loss_cls_stage0: 0.3752  loss_box_reg_stage0: 0.2897  loss_cls_stage1: 0.3137  loss_box_reg_stage1: 0.4025  loss_cls_stage2: 0.2342  loss_box_reg_stage2: 0.2955  loss_mask: 0.5373  loss_rpn_cls: 0.06303  loss_rpn_loc: 0.03798  validation_loss: 2.11  time: 1.5284  data_time: 0.0247  lr: 1.3348e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:32:55 d2.utils.events]: \u001b[0m eta: 1:01:25  iter: 7639  total_loss: 2.351  loss_cls_stage0: 0.3234  loss_box_reg_stage0: 0.2382  loss_cls_stage1: 0.2605  loss_box_reg_stage1: 0.347  loss_cls_stage2: 0.1982  loss_box_reg_stage2: 0.3  loss_mask: 0.5552  loss_rpn_cls: 0.06853  loss_rpn_loc: 0.03709  validation_loss: 2.11  time: 1.5285  data_time: 0.0247  lr: 1.3135e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:33:26 d2.utils.events]: \u001b[0m eta: 1:00:53  iter: 7659  total_loss: 2.248  loss_cls_stage0: 0.2944  loss_box_reg_stage0: 0.2258  loss_cls_stage1: 0.2523  loss_box_reg_stage1: 0.3425  loss_cls_stage2: 0.1933  loss_box_reg_stage2: 0.2943  loss_mask: 0.468  loss_rpn_cls: 0.05959  loss_rpn_loc: 0.03041  validation_loss: 2.11  time: 1.5285  data_time: 0.0238  lr: 1.2923e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:33:57 d2.utils.events]: \u001b[0m eta: 1:00:22  iter: 7679  total_loss: 2.296  loss_cls_stage0: 0.3454  loss_box_reg_stage0: 0.262  loss_cls_stage1: 0.2694  loss_box_reg_stage1: 0.3637  loss_cls_stage2: 0.1913  loss_box_reg_stage2: 0.2905  loss_mask: 0.5021  loss_rpn_cls: 0.06318  loss_rpn_loc: 0.03405  validation_loss: 2.11  time: 1.5286  data_time: 0.0237  lr: 1.2713e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:34:29 d2.utils.events]: \u001b[0m eta: 0:59:51  iter: 7699  total_loss: 2.367  loss_cls_stage0: 0.3366  loss_box_reg_stage0: 0.2566  loss_cls_stage1: 0.283  loss_box_reg_stage1: 0.363  loss_cls_stage2: 0.203  loss_box_reg_stage2: 0.3136  loss_mask: 0.4939  loss_rpn_cls: 0.07602  loss_rpn_loc: 0.04103  validation_loss: 2.11  time: 1.5287  data_time: 0.0222  lr: 1.2505e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:35:00 d2.utils.events]: \u001b[0m eta: 0:59:20  iter: 7719  total_loss: 2.325  loss_cls_stage0: 0.3285  loss_box_reg_stage0: 0.2673  loss_cls_stage1: 0.2951  loss_box_reg_stage1: 0.3601  loss_cls_stage2: 0.2055  loss_box_reg_stage2: 0.2932  loss_mask: 0.5058  loss_rpn_cls: 0.05908  loss_rpn_loc: 0.03406  validation_loss: 2.11  time: 1.5288  data_time: 0.0231  lr: 1.2298e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:35:31 d2.utils.events]: \u001b[0m eta: 0:58:49  iter: 7739  total_loss: 2.228  loss_cls_stage0: 0.3035  loss_box_reg_stage0: 0.242  loss_cls_stage1: 0.2542  loss_box_reg_stage1: 0.3497  loss_cls_stage2: 0.1996  loss_box_reg_stage2: 0.2891  loss_mask: 0.4613  loss_rpn_cls: 0.06067  loss_rpn_loc: 0.03281  validation_loss: 2.11  time: 1.5289  data_time: 0.0236  lr: 1.2092e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:36:02 d2.utils.events]: \u001b[0m eta: 0:58:17  iter: 7759  total_loss: 2.248  loss_cls_stage0: 0.282  loss_box_reg_stage0: 0.2253  loss_cls_stage1: 0.2321  loss_box_reg_stage1: 0.3297  loss_cls_stage2: 0.1685  loss_box_reg_stage2: 0.273  loss_mask: 0.5972  loss_rpn_cls: 0.06563  loss_rpn_loc: 0.03503  validation_loss: 2.11  time: 1.5289  data_time: 0.0237  lr: 1.1888e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:36:33 d2.utils.events]: \u001b[0m eta: 0:57:45  iter: 7779  total_loss: 2.408  loss_cls_stage0: 0.3093  loss_box_reg_stage0: 0.2599  loss_cls_stage1: 0.2677  loss_box_reg_stage1: 0.358  loss_cls_stage2: 0.1929  loss_box_reg_stage2: 0.3109  loss_mask: 0.5625  loss_rpn_cls: 0.06648  loss_rpn_loc: 0.03499  validation_loss: 2.11  time: 1.5290  data_time: 0.0245  lr: 1.1685e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:37:05 d2.utils.events]: \u001b[0m eta: 0:57:14  iter: 7799  total_loss: 2.283  loss_cls_stage0: 0.3304  loss_box_reg_stage0: 0.2574  loss_cls_stage1: 0.2628  loss_box_reg_stage1: 0.3545  loss_cls_stage2: 0.1938  loss_box_reg_stage2: 0.2991  loss_mask: 0.5387  loss_rpn_cls: 0.06025  loss_rpn_loc: 0.03169  validation_loss: 2.11  time: 1.5291  data_time: 0.0257  lr: 1.1484e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:37:36 d2.utils.events]: \u001b[0m eta: 0:56:43  iter: 7819  total_loss: 2.559  loss_cls_stage0: 0.393  loss_box_reg_stage0: 0.3052  loss_cls_stage1: 0.3232  loss_box_reg_stage1: 0.4208  loss_cls_stage2: 0.2219  loss_box_reg_stage2: 0.3007  loss_mask: 0.5126  loss_rpn_cls: 0.06523  loss_rpn_loc: 0.04379  validation_loss: 2.11  time: 1.5293  data_time: 0.0252  lr: 1.1285e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:38:08 d2.utils.events]: \u001b[0m eta: 0:56:12  iter: 7839  total_loss: 2.464  loss_cls_stage0: 0.3379  loss_box_reg_stage0: 0.2656  loss_cls_stage1: 0.2668  loss_box_reg_stage1: 0.3767  loss_cls_stage2: 0.191  loss_box_reg_stage2: 0.3058  loss_mask: 0.59  loss_rpn_cls: 0.0593  loss_rpn_loc: 0.03577  validation_loss: 2.11  time: 1.5294  data_time: 0.0243  lr: 1.1087e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:38:39 d2.utils.events]: \u001b[0m eta: 0:55:41  iter: 7859  total_loss: 2.318  loss_cls_stage0: 0.3349  loss_box_reg_stage0: 0.2481  loss_cls_stage1: 0.2654  loss_box_reg_stage1: 0.3439  loss_cls_stage2: 0.1846  loss_box_reg_stage2: 0.2906  loss_mask: 0.5502  loss_rpn_cls: 0.07294  loss_rpn_loc: 0.03658  validation_loss: 2.11  time: 1.5294  data_time: 0.0239  lr: 1.089e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:39:10 d2.utils.events]: \u001b[0m eta: 0:55:10  iter: 7879  total_loss: 2.584  loss_cls_stage0: 0.3285  loss_box_reg_stage0: 0.2775  loss_cls_stage1: 0.2902  loss_box_reg_stage1: 0.3822  loss_cls_stage2: 0.2039  loss_box_reg_stage2: 0.2989  loss_mask: 0.5856  loss_rpn_cls: 0.07036  loss_rpn_loc: 0.0387  validation_loss: 2.11  time: 1.5295  data_time: 0.0245  lr: 1.0695e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:39:42 d2.utils.events]: \u001b[0m eta: 0:54:39  iter: 7899  total_loss: 2.384  loss_cls_stage0: 0.33  loss_box_reg_stage0: 0.2679  loss_cls_stage1: 0.2673  loss_box_reg_stage1: 0.3742  loss_cls_stage2: 0.187  loss_box_reg_stage2: 0.2931  loss_mask: 0.5083  loss_rpn_cls: 0.06095  loss_rpn_loc: 0.03928  validation_loss: 2.11  time: 1.5296  data_time: 0.0254  lr: 1.0502e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:40:13 d2.utils.events]: \u001b[0m eta: 0:54:08  iter: 7919  total_loss: 2.537  loss_cls_stage0: 0.3519  loss_box_reg_stage0: 0.2695  loss_cls_stage1: 0.2922  loss_box_reg_stage1: 0.3602  loss_cls_stage2: 0.2092  loss_box_reg_stage2: 0.3256  loss_mask: 0.5707  loss_rpn_cls: 0.06175  loss_rpn_loc: 0.03596  validation_loss: 2.11  time: 1.5298  data_time: 0.0239  lr: 1.031e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:40:44 d2.utils.events]: \u001b[0m eta: 0:53:37  iter: 7939  total_loss: 2.249  loss_cls_stage0: 0.2947  loss_box_reg_stage0: 0.2451  loss_cls_stage1: 0.2466  loss_box_reg_stage1: 0.3505  loss_cls_stage2: 0.1857  loss_box_reg_stage2: 0.3011  loss_mask: 0.5314  loss_rpn_cls: 0.05951  loss_rpn_loc: 0.03364  validation_loss: 2.11  time: 1.5298  data_time: 0.0248  lr: 1.012e-05  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:41:16 d2.utils.events]: \u001b[0m eta: 0:53:05  iter: 7959  total_loss: 2.303  loss_cls_stage0: 0.3186  loss_box_reg_stage0: 0.2628  loss_cls_stage1: 0.2549  loss_box_reg_stage1: 0.3444  loss_cls_stage2: 0.1956  loss_box_reg_stage2: 0.2857  loss_mask: 0.5597  loss_rpn_cls: 0.06337  loss_rpn_loc: 0.03703  validation_loss: 2.11  time: 1.5299  data_time: 0.0252  lr: 9.931e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:41:47 d2.utils.events]: \u001b[0m eta: 0:52:34  iter: 7979  total_loss: 2.467  loss_cls_stage0: 0.332  loss_box_reg_stage0: 0.2686  loss_cls_stage1: 0.2728  loss_box_reg_stage1: 0.3826  loss_cls_stage2: 0.2035  loss_box_reg_stage2: 0.318  loss_mask: 0.5223  loss_rpn_cls: 0.0574  loss_rpn_loc: 0.03777  validation_loss: 2.11  time: 1.5300  data_time: 0.0243  lr: 9.7439e-06  max_mem: 12121M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/27 10:42:21 d2.data.common]: \u001b[0mSerializing 883 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/27 10:42:21 d2.data.common]: \u001b[0mSerialized dataset takes 0.91 MiB\n",
      "\u001b[32m[03/27 10:42:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 883 images\n",
      "\u001b[32m[03/27 10:42:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/883. 0.0821 s / img. ETA=0:02:01\n",
      "\u001b[32m[03/27 10:42:28 d2.evaluation.evaluator]: \u001b[0mInference done 54/883. 0.0807 s / img. ETA=0:01:39\n",
      "\u001b[32m[03/27 10:42:33 d2.evaluation.evaluator]: \u001b[0mInference done 91/883. 0.0813 s / img. ETA=0:01:40\n",
      "\u001b[32m[03/27 10:42:38 d2.evaluation.evaluator]: \u001b[0mInference done 131/883. 0.0813 s / img. ETA=0:01:35\n",
      "\u001b[32m[03/27 10:42:43 d2.evaluation.evaluator]: \u001b[0mInference done 171/883. 0.0813 s / img. ETA=0:01:30\n",
      "\u001b[32m[03/27 10:42:48 d2.evaluation.evaluator]: \u001b[0mInference done 213/883. 0.0812 s / img. ETA=0:01:24\n",
      "\u001b[32m[03/27 10:42:53 d2.evaluation.evaluator]: \u001b[0mInference done 253/883. 0.0812 s / img. ETA=0:01:19\n",
      "\u001b[32m[03/27 10:42:58 d2.evaluation.evaluator]: \u001b[0mInference done 293/883. 0.0812 s / img. ETA=0:01:14\n",
      "\u001b[32m[03/27 10:43:03 d2.evaluation.evaluator]: \u001b[0mInference done 332/883. 0.0813 s / img. ETA=0:01:09\n",
      "\u001b[32m[03/27 10:43:08 d2.evaluation.evaluator]: \u001b[0mInference done 371/883. 0.0813 s / img. ETA=0:01:04\n",
      "\u001b[32m[03/27 10:43:13 d2.evaluation.evaluator]: \u001b[0mInference done 406/883. 0.0814 s / img. ETA=0:01:01\n",
      "\u001b[32m[03/27 10:43:19 d2.evaluation.evaluator]: \u001b[0mInference done 446/883. 0.0814 s / img. ETA=0:00:55\n",
      "\u001b[32m[03/27 10:43:24 d2.evaluation.evaluator]: \u001b[0mInference done 486/883. 0.0814 s / img. ETA=0:00:50\n",
      "\u001b[32m[03/27 10:43:29 d2.evaluation.evaluator]: \u001b[0mInference done 527/883. 0.0814 s / img. ETA=0:00:45\n",
      "\u001b[32m[03/27 10:43:34 d2.evaluation.evaluator]: \u001b[0mInference done 569/883. 0.0814 s / img. ETA=0:00:39\n",
      "\u001b[32m[03/27 10:43:39 d2.evaluation.evaluator]: \u001b[0mInference done 612/883. 0.0814 s / img. ETA=0:00:34\n",
      "\u001b[32m[03/27 10:43:44 d2.evaluation.evaluator]: \u001b[0mInference done 653/883. 0.0813 s / img. ETA=0:00:29\n",
      "\u001b[32m[03/27 10:43:49 d2.evaluation.evaluator]: \u001b[0mInference done 695/883. 0.0813 s / img. ETA=0:00:23\n",
      "\u001b[32m[03/27 10:43:54 d2.evaluation.evaluator]: \u001b[0mInference done 732/883. 0.0814 s / img. ETA=0:00:19\n",
      "\u001b[32m[03/27 10:43:59 d2.evaluation.evaluator]: \u001b[0mInference done 772/883. 0.0814 s / img. ETA=0:00:14\n",
      "\u001b[32m[03/27 10:44:04 d2.evaluation.evaluator]: \u001b[0mInference done 811/883. 0.0814 s / img. ETA=0:00:09\n",
      "\u001b[32m[03/27 10:44:09 d2.evaluation.evaluator]: \u001b[0mInference done 851/883. 0.0814 s / img. ETA=0:00:04\n",
      "\u001b[32m[03/27 10:44:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:51.048609 (0.126479 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/27 10:44:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:11 (0.081372 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.53 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.10 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.142\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.159\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.037\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.092\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.131\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.174\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.175\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.052\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.201\n",
      "\u001b[32m[03/27 10:44:14 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold5 in csv format:\n",
      "\u001b[32m[03/27 10:44:14 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/27 10:44:14 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/27 10:44:14 d2.evaluation.testing]: \u001b[0mcopypaste: 8.3693,14.1688,15.8712,0.2097,3.6899,9.1783\n",
      "validation do loss eval 2.40205174012994\n",
      "\u001b[32m[03/27 10:45:46 d2.utils.events]: \u001b[0m eta: 0:52:03  iter: 7999  total_loss: 2.486  loss_cls_stage0: 0.3495  loss_box_reg_stage0: 0.2817  loss_cls_stage1: 0.2918  loss_box_reg_stage1: 0.3864  loss_cls_stage2: 0.2262  loss_box_reg_stage2: 0.3132  loss_mask: 0.5519  loss_rpn_cls: 0.05806  loss_rpn_loc: 0.03639  validation_loss: 2.197  time: 1.5301  data_time: 0.0250  lr: 9.5584e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:46:17 d2.utils.events]: \u001b[0m eta: 0:51:32  iter: 8019  total_loss: 2.365  loss_cls_stage0: 0.3142  loss_box_reg_stage0: 0.2637  loss_cls_stage1: 0.2425  loss_box_reg_stage1: 0.3568  loss_cls_stage2: 0.1797  loss_box_reg_stage2: 0.3093  loss_mask: 0.5344  loss_rpn_cls: 0.06637  loss_rpn_loc: 0.03748  validation_loss: 2.197  time: 1.5301  data_time: 0.0235  lr: 9.3744e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:46:48 d2.utils.events]: \u001b[0m eta: 0:51:00  iter: 8039  total_loss: 2.098  loss_cls_stage0: 0.2487  loss_box_reg_stage0: 0.2052  loss_cls_stage1: 0.2248  loss_box_reg_stage1: 0.3253  loss_cls_stage2: 0.1697  loss_box_reg_stage2: 0.288  loss_mask: 0.5486  loss_rpn_cls: 0.05359  loss_rpn_loc: 0.02727  validation_loss: 2.197  time: 1.5302  data_time: 0.0245  lr: 9.1921e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:47:19 d2.utils.events]: \u001b[0m eta: 0:50:29  iter: 8059  total_loss: 2.277  loss_cls_stage0: 0.3137  loss_box_reg_stage0: 0.2391  loss_cls_stage1: 0.2495  loss_box_reg_stage1: 0.3444  loss_cls_stage2: 0.1879  loss_box_reg_stage2: 0.2924  loss_mask: 0.5144  loss_rpn_cls: 0.05169  loss_rpn_loc: 0.03408  validation_loss: 2.197  time: 1.5303  data_time: 0.0252  lr: 9.0114e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:47:51 d2.utils.events]: \u001b[0m eta: 0:49:58  iter: 8079  total_loss: 2.393  loss_cls_stage0: 0.337  loss_box_reg_stage0: 0.2612  loss_cls_stage1: 0.2747  loss_box_reg_stage1: 0.3569  loss_cls_stage2: 0.1902  loss_box_reg_stage2: 0.285  loss_mask: 0.5649  loss_rpn_cls: 0.05921  loss_rpn_loc: 0.03177  validation_loss: 2.197  time: 1.5304  data_time: 0.0246  lr: 8.8323e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:48:22 d2.utils.events]: \u001b[0m eta: 0:49:26  iter: 8099  total_loss: 2.351  loss_cls_stage0: 0.3109  loss_box_reg_stage0: 0.2279  loss_cls_stage1: 0.2639  loss_box_reg_stage1: 0.3603  loss_cls_stage2: 0.1913  loss_box_reg_stage2: 0.3101  loss_mask: 0.5831  loss_rpn_cls: 0.05715  loss_rpn_loc: 0.03288  validation_loss: 2.197  time: 1.5304  data_time: 0.0246  lr: 8.6548e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:48:53 d2.utils.events]: \u001b[0m eta: 0:48:55  iter: 8119  total_loss: 2.431  loss_cls_stage0: 0.3534  loss_box_reg_stage0: 0.2756  loss_cls_stage1: 0.2934  loss_box_reg_stage1: 0.3543  loss_cls_stage2: 0.2096  loss_box_reg_stage2: 0.2833  loss_mask: 0.5432  loss_rpn_cls: 0.0697  loss_rpn_loc: 0.04395  validation_loss: 2.197  time: 1.5305  data_time: 0.0241  lr: 8.479e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:49:25 d2.utils.events]: \u001b[0m eta: 0:48:23  iter: 8139  total_loss: 2.376  loss_cls_stage0: 0.3038  loss_box_reg_stage0: 0.2523  loss_cls_stage1: 0.2626  loss_box_reg_stage1: 0.3679  loss_cls_stage2: 0.1855  loss_box_reg_stage2: 0.2991  loss_mask: 0.5116  loss_rpn_cls: 0.05323  loss_rpn_loc: 0.03327  validation_loss: 2.197  time: 1.5306  data_time: 0.0246  lr: 8.3047e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:49:56 d2.utils.events]: \u001b[0m eta: 0:47:52  iter: 8159  total_loss: 2.247  loss_cls_stage0: 0.3133  loss_box_reg_stage0: 0.2448  loss_cls_stage1: 0.2619  loss_box_reg_stage1: 0.3478  loss_cls_stage2: 0.1887  loss_box_reg_stage2: 0.2986  loss_mask: 0.5372  loss_rpn_cls: 0.06517  loss_rpn_loc: 0.03496  validation_loss: 2.197  time: 1.5307  data_time: 0.0245  lr: 8.1322e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:50:27 d2.utils.events]: \u001b[0m eta: 0:47:21  iter: 8179  total_loss: 2.308  loss_cls_stage0: 0.3203  loss_box_reg_stage0: 0.2327  loss_cls_stage1: 0.2683  loss_box_reg_stage1: 0.3365  loss_cls_stage2: 0.1983  loss_box_reg_stage2: 0.278  loss_mask: 0.5132  loss_rpn_cls: 0.07014  loss_rpn_loc: 0.03869  validation_loss: 2.197  time: 1.5308  data_time: 0.0252  lr: 7.9613e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:50:58 d2.utils.events]: \u001b[0m eta: 0:46:50  iter: 8199  total_loss: 2.312  loss_cls_stage0: 0.3265  loss_box_reg_stage0: 0.2289  loss_cls_stage1: 0.2802  loss_box_reg_stage1: 0.3211  loss_cls_stage2: 0.1843  loss_box_reg_stage2: 0.2716  loss_mask: 0.5338  loss_rpn_cls: 0.05907  loss_rpn_loc: 0.03781  validation_loss: 2.197  time: 1.5308  data_time: 0.0250  lr: 7.792e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:51:30 d2.utils.events]: \u001b[0m eta: 0:46:19  iter: 8219  total_loss: 2.382  loss_cls_stage0: 0.336  loss_box_reg_stage0: 0.2721  loss_cls_stage1: 0.2901  loss_box_reg_stage1: 0.3692  loss_cls_stage2: 0.2116  loss_box_reg_stage2: 0.3029  loss_mask: 0.5498  loss_rpn_cls: 0.06433  loss_rpn_loc: 0.03681  validation_loss: 2.197  time: 1.5310  data_time: 0.0248  lr: 7.6244e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:52:01 d2.utils.events]: \u001b[0m eta: 0:45:47  iter: 8239  total_loss: 2.437  loss_cls_stage0: 0.3423  loss_box_reg_stage0: 0.2639  loss_cls_stage1: 0.2754  loss_box_reg_stage1: 0.3666  loss_cls_stage2: 0.193  loss_box_reg_stage2: 0.2799  loss_mask: 0.5739  loss_rpn_cls: 0.05564  loss_rpn_loc: 0.03469  validation_loss: 2.197  time: 1.5310  data_time: 0.0251  lr: 7.4585e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:52:33 d2.utils.events]: \u001b[0m eta: 0:45:16  iter: 8259  total_loss: 2.393  loss_cls_stage0: 0.3369  loss_box_reg_stage0: 0.2729  loss_cls_stage1: 0.2762  loss_box_reg_stage1: 0.3581  loss_cls_stage2: 0.181  loss_box_reg_stage2: 0.2787  loss_mask: 0.5196  loss_rpn_cls: 0.05751  loss_rpn_loc: 0.03795  validation_loss: 2.197  time: 1.5311  data_time: 0.0240  lr: 7.2943e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:53:04 d2.utils.events]: \u001b[0m eta: 0:44:45  iter: 8279  total_loss: 2.327  loss_cls_stage0: 0.3322  loss_box_reg_stage0: 0.2566  loss_cls_stage1: 0.2828  loss_box_reg_stage1: 0.3533  loss_cls_stage2: 0.2047  loss_box_reg_stage2: 0.3021  loss_mask: 0.5079  loss_rpn_cls: 0.0557  loss_rpn_loc: 0.03635  validation_loss: 2.197  time: 1.5312  data_time: 0.0254  lr: 7.1318e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:53:35 d2.utils.events]: \u001b[0m eta: 0:44:14  iter: 8299  total_loss: 2.208  loss_cls_stage0: 0.3159  loss_box_reg_stage0: 0.2376  loss_cls_stage1: 0.2728  loss_box_reg_stage1: 0.3406  loss_cls_stage2: 0.1935  loss_box_reg_stage2: 0.3013  loss_mask: 0.5052  loss_rpn_cls: 0.05497  loss_rpn_loc: 0.03505  validation_loss: 2.197  time: 1.5313  data_time: 0.0236  lr: 6.9709e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:54:06 d2.utils.events]: \u001b[0m eta: 0:43:42  iter: 8319  total_loss: 2.236  loss_cls_stage0: 0.2997  loss_box_reg_stage0: 0.236  loss_cls_stage1: 0.2517  loss_box_reg_stage1: 0.3453  loss_cls_stage2: 0.1842  loss_box_reg_stage2: 0.287  loss_mask: 0.5505  loss_rpn_cls: 0.05953  loss_rpn_loc: 0.03383  validation_loss: 2.197  time: 1.5314  data_time: 0.0246  lr: 6.8117e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:54:38 d2.utils.events]: \u001b[0m eta: 0:43:12  iter: 8339  total_loss: 2.452  loss_cls_stage0: 0.3461  loss_box_reg_stage0: 0.2823  loss_cls_stage1: 0.29  loss_box_reg_stage1: 0.3769  loss_cls_stage2: 0.2084  loss_box_reg_stage2: 0.3146  loss_mask: 0.5086  loss_rpn_cls: 0.05975  loss_rpn_loc: 0.03991  validation_loss: 2.197  time: 1.5315  data_time: 0.0247  lr: 6.6543e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:55:09 d2.utils.events]: \u001b[0m eta: 0:42:40  iter: 8359  total_loss: 2.438  loss_cls_stage0: 0.3218  loss_box_reg_stage0: 0.2631  loss_cls_stage1: 0.2665  loss_box_reg_stage1: 0.3771  loss_cls_stage2: 0.2005  loss_box_reg_stage2: 0.2933  loss_mask: 0.5897  loss_rpn_cls: 0.06874  loss_rpn_loc: 0.03521  validation_loss: 2.197  time: 1.5316  data_time: 0.0265  lr: 6.4986e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:55:41 d2.utils.events]: \u001b[0m eta: 0:42:09  iter: 8379  total_loss: 2.295  loss_cls_stage0: 0.3262  loss_box_reg_stage0: 0.2693  loss_cls_stage1: 0.2696  loss_box_reg_stage1: 0.3719  loss_cls_stage2: 0.197  loss_box_reg_stage2: 0.3034  loss_mask: 0.4633  loss_rpn_cls: 0.06725  loss_rpn_loc: 0.04073  validation_loss: 2.197  time: 1.5316  data_time: 0.0242  lr: 6.3445e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:56:12 d2.utils.events]: \u001b[0m eta: 0:41:38  iter: 8399  total_loss: 2.327  loss_cls_stage0: 0.3313  loss_box_reg_stage0: 0.2632  loss_cls_stage1: 0.2654  loss_box_reg_stage1: 0.3582  loss_cls_stage2: 0.1862  loss_box_reg_stage2: 0.3008  loss_mask: 0.5484  loss_rpn_cls: 0.05831  loss_rpn_loc: 0.03712  validation_loss: 2.197  time: 1.5317  data_time: 0.0245  lr: 6.1922e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:56:43 d2.utils.events]: \u001b[0m eta: 0:41:07  iter: 8419  total_loss: 2.443  loss_cls_stage0: 0.343  loss_box_reg_stage0: 0.2703  loss_cls_stage1: 0.2862  loss_box_reg_stage1: 0.398  loss_cls_stage2: 0.2043  loss_box_reg_stage2: 0.2969  loss_mask: 0.5778  loss_rpn_cls: 0.06  loss_rpn_loc: 0.0334  validation_loss: 2.197  time: 1.5318  data_time: 0.0233  lr: 6.0417e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:57:15 d2.utils.events]: \u001b[0m eta: 0:40:37  iter: 8439  total_loss: 2.436  loss_cls_stage0: 0.3484  loss_box_reg_stage0: 0.2754  loss_cls_stage1: 0.2911  loss_box_reg_stage1: 0.378  loss_cls_stage2: 0.2165  loss_box_reg_stage2: 0.3206  loss_mask: 0.5188  loss_rpn_cls: 0.06586  loss_rpn_loc: 0.03518  validation_loss: 2.197  time: 1.5319  data_time: 0.0239  lr: 5.8928e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:57:46 d2.utils.events]: \u001b[0m eta: 0:40:05  iter: 8459  total_loss: 2.288  loss_cls_stage0: 0.3236  loss_box_reg_stage0: 0.2406  loss_cls_stage1: 0.2555  loss_box_reg_stage1: 0.3392  loss_cls_stage2: 0.185  loss_box_reg_stage2: 0.2961  loss_mask: 0.5125  loss_rpn_cls: 0.06052  loss_rpn_loc: 0.03155  validation_loss: 2.197  time: 1.5320  data_time: 0.0232  lr: 5.7457e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:58:17 d2.utils.events]: \u001b[0m eta: 0:39:34  iter: 8479  total_loss: 2.264  loss_cls_stage0: 0.3231  loss_box_reg_stage0: 0.2729  loss_cls_stage1: 0.2668  loss_box_reg_stage1: 0.3373  loss_cls_stage2: 0.1834  loss_box_reg_stage2: 0.2608  loss_mask: 0.5226  loss_rpn_cls: 0.05782  loss_rpn_loc: 0.03275  validation_loss: 2.197  time: 1.5321  data_time: 0.0239  lr: 5.6004e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:58:49 d2.utils.events]: \u001b[0m eta: 0:39:03  iter: 8499  total_loss: 2.285  loss_cls_stage0: 0.3245  loss_box_reg_stage0: 0.2487  loss_cls_stage1: 0.2672  loss_box_reg_stage1: 0.3473  loss_cls_stage2: 0.1918  loss_box_reg_stage2: 0.2901  loss_mask: 0.5375  loss_rpn_cls: 0.05501  loss_rpn_loc: 0.03517  validation_loss: 2.197  time: 1.5321  data_time: 0.0244  lr: 5.4568e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:59:20 d2.utils.events]: \u001b[0m eta: 0:38:32  iter: 8519  total_loss: 2.415  loss_cls_stage0: 0.3405  loss_box_reg_stage0: 0.2652  loss_cls_stage1: 0.263  loss_box_reg_stage1: 0.3724  loss_cls_stage2: 0.1943  loss_box_reg_stage2: 0.3189  loss_mask: 0.529  loss_rpn_cls: 0.06224  loss_rpn_loc: 0.03755  validation_loss: 2.197  time: 1.5322  data_time: 0.0245  lr: 5.315e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 10:59:52 d2.utils.events]: \u001b[0m eta: 0:38:01  iter: 8539  total_loss: 2.551  loss_cls_stage0: 0.3539  loss_box_reg_stage0: 0.2761  loss_cls_stage1: 0.2966  loss_box_reg_stage1: 0.3959  loss_cls_stage2: 0.2144  loss_box_reg_stage2: 0.2967  loss_mask: 0.5317  loss_rpn_cls: 0.06939  loss_rpn_loc: 0.03722  validation_loss: 2.197  time: 1.5323  data_time: 0.0234  lr: 5.1749e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:00:23 d2.utils.events]: \u001b[0m eta: 0:37:30  iter: 8559  total_loss: 2.377  loss_cls_stage0: 0.3234  loss_box_reg_stage0: 0.2545  loss_cls_stage1: 0.2657  loss_box_reg_stage1: 0.3642  loss_cls_stage2: 0.1801  loss_box_reg_stage2: 0.3008  loss_mask: 0.5427  loss_rpn_cls: 0.0666  loss_rpn_loc: 0.03304  validation_loss: 2.197  time: 1.5324  data_time: 0.0236  lr: 5.0366e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:00:54 d2.utils.events]: \u001b[0m eta: 0:36:59  iter: 8579  total_loss: 2.318  loss_cls_stage0: 0.3361  loss_box_reg_stage0: 0.265  loss_cls_stage1: 0.2686  loss_box_reg_stage1: 0.3613  loss_cls_stage2: 0.1985  loss_box_reg_stage2: 0.2861  loss_mask: 0.5028  loss_rpn_cls: 0.06062  loss_rpn_loc: 0.03666  validation_loss: 2.197  time: 1.5325  data_time: 0.0244  lr: 4.9001e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:01:26 d2.utils.events]: \u001b[0m eta: 0:36:28  iter: 8599  total_loss: 2.466  loss_cls_stage0: 0.3276  loss_box_reg_stage0: 0.2794  loss_cls_stage1: 0.2736  loss_box_reg_stage1: 0.3688  loss_cls_stage2: 0.1901  loss_box_reg_stage2: 0.2943  loss_mask: 0.5385  loss_rpn_cls: 0.05902  loss_rpn_loc: 0.03774  validation_loss: 2.197  time: 1.5326  data_time: 0.0247  lr: 4.7653e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:01:57 d2.utils.events]: \u001b[0m eta: 0:35:56  iter: 8619  total_loss: 2.275  loss_cls_stage0: 0.3098  loss_box_reg_stage0: 0.2657  loss_cls_stage1: 0.2578  loss_box_reg_stage1: 0.3608  loss_cls_stage2: 0.1853  loss_box_reg_stage2: 0.294  loss_mask: 0.5523  loss_rpn_cls: 0.0556  loss_rpn_loc: 0.03728  validation_loss: 2.197  time: 1.5326  data_time: 0.0244  lr: 4.6324e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:02:28 d2.utils.events]: \u001b[0m eta: 0:35:25  iter: 8639  total_loss: 2.209  loss_cls_stage0: 0.2926  loss_box_reg_stage0: 0.228  loss_cls_stage1: 0.2473  loss_box_reg_stage1: 0.3484  loss_cls_stage2: 0.1838  loss_box_reg_stage2: 0.2884  loss_mask: 0.518  loss_rpn_cls: 0.06455  loss_rpn_loc: 0.03442  validation_loss: 2.197  time: 1.5327  data_time: 0.0250  lr: 4.5012e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:02:59 d2.utils.events]: \u001b[0m eta: 0:34:54  iter: 8659  total_loss: 2.301  loss_cls_stage0: 0.3006  loss_box_reg_stage0: 0.2442  loss_cls_stage1: 0.2602  loss_box_reg_stage1: 0.3893  loss_cls_stage2: 0.188  loss_box_reg_stage2: 0.3036  loss_mask: 0.5113  loss_rpn_cls: 0.05336  loss_rpn_loc: 0.03268  validation_loss: 2.197  time: 1.5328  data_time: 0.0234  lr: 4.3718e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:03:31 d2.utils.events]: \u001b[0m eta: 0:34:23  iter: 8679  total_loss: 2.313  loss_cls_stage0: 0.3153  loss_box_reg_stage0: 0.2551  loss_cls_stage1: 0.256  loss_box_reg_stage1: 0.3524  loss_cls_stage2: 0.1772  loss_box_reg_stage2: 0.3067  loss_mask: 0.5306  loss_rpn_cls: 0.05254  loss_rpn_loc: 0.0313  validation_loss: 2.197  time: 1.5328  data_time: 0.0236  lr: 4.2443e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:04:02 d2.utils.events]: \u001b[0m eta: 0:33:51  iter: 8699  total_loss: 2.403  loss_cls_stage0: 0.33  loss_box_reg_stage0: 0.2653  loss_cls_stage1: 0.2636  loss_box_reg_stage1: 0.388  loss_cls_stage2: 0.1908  loss_box_reg_stage2: 0.3113  loss_mask: 0.5818  loss_rpn_cls: 0.05715  loss_rpn_loc: 0.03527  validation_loss: 2.197  time: 1.5329  data_time: 0.0231  lr: 4.1185e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:04:33 d2.utils.events]: \u001b[0m eta: 0:33:20  iter: 8719  total_loss: 2.373  loss_cls_stage0: 0.3323  loss_box_reg_stage0: 0.2631  loss_cls_stage1: 0.275  loss_box_reg_stage1: 0.3391  loss_cls_stage2: 0.1922  loss_box_reg_stage2: 0.2896  loss_mask: 0.5539  loss_rpn_cls: 0.05837  loss_rpn_loc: 0.03323  validation_loss: 2.197  time: 1.5330  data_time: 0.0244  lr: 3.9946e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:05:04 d2.utils.events]: \u001b[0m eta: 0:32:49  iter: 8739  total_loss: 2.249  loss_cls_stage0: 0.2965  loss_box_reg_stage0: 0.25  loss_cls_stage1: 0.2462  loss_box_reg_stage1: 0.3467  loss_cls_stage2: 0.1808  loss_box_reg_stage2: 0.2832  loss_mask: 0.5242  loss_rpn_cls: 0.06195  loss_rpn_loc: 0.03737  validation_loss: 2.197  time: 1.5330  data_time: 0.0237  lr: 3.8724e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:05:36 d2.utils.events]: \u001b[0m eta: 0:32:18  iter: 8759  total_loss: 2.53  loss_cls_stage0: 0.3472  loss_box_reg_stage0: 0.2964  loss_cls_stage1: 0.2858  loss_box_reg_stage1: 0.3984  loss_cls_stage2: 0.1999  loss_box_reg_stage2: 0.3121  loss_mask: 0.5048  loss_rpn_cls: 0.06282  loss_rpn_loc: 0.04157  validation_loss: 2.197  time: 1.5331  data_time: 0.0231  lr: 3.7521e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:06:07 d2.utils.events]: \u001b[0m eta: 0:31:47  iter: 8779  total_loss: 2.478  loss_cls_stage0: 0.3601  loss_box_reg_stage0: 0.2727  loss_cls_stage1: 0.299  loss_box_reg_stage1: 0.4096  loss_cls_stage2: 0.2249  loss_box_reg_stage2: 0.3395  loss_mask: 0.5063  loss_rpn_cls: 0.05725  loss_rpn_loc: 0.03523  validation_loss: 2.197  time: 1.5332  data_time: 0.0229  lr: 3.6336e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:06:39 d2.utils.events]: \u001b[0m eta: 0:31:16  iter: 8799  total_loss: 2.378  loss_cls_stage0: 0.3459  loss_box_reg_stage0: 0.2496  loss_cls_stage1: 0.3075  loss_box_reg_stage1: 0.3542  loss_cls_stage2: 0.2127  loss_box_reg_stage2: 0.3112  loss_mask: 0.5138  loss_rpn_cls: 0.06325  loss_rpn_loc: 0.03781  validation_loss: 2.197  time: 1.5333  data_time: 0.0237  lr: 3.517e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:07:10 d2.utils.events]: \u001b[0m eta: 0:30:44  iter: 8819  total_loss: 2.473  loss_cls_stage0: 0.3143  loss_box_reg_stage0: 0.2565  loss_cls_stage1: 0.2713  loss_box_reg_stage1: 0.3862  loss_cls_stage2: 0.2097  loss_box_reg_stage2: 0.3235  loss_mask: 0.5458  loss_rpn_cls: 0.06091  loss_rpn_loc: 0.03403  validation_loss: 2.197  time: 1.5334  data_time: 0.0260  lr: 3.4021e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:07:42 d2.utils.events]: \u001b[0m eta: 0:30:13  iter: 8839  total_loss: 2.444  loss_cls_stage0: 0.3534  loss_box_reg_stage0: 0.2712  loss_cls_stage1: 0.2999  loss_box_reg_stage1: 0.3672  loss_cls_stage2: 0.2075  loss_box_reg_stage2: 0.2945  loss_mask: 0.5376  loss_rpn_cls: 0.05657  loss_rpn_loc: 0.03556  validation_loss: 2.197  time: 1.5335  data_time: 0.0246  lr: 3.2892e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:08:13 d2.utils.events]: \u001b[0m eta: 0:29:42  iter: 8859  total_loss: 2.476  loss_cls_stage0: 0.3523  loss_box_reg_stage0: 0.27  loss_cls_stage1: 0.2863  loss_box_reg_stage1: 0.3813  loss_cls_stage2: 0.2078  loss_box_reg_stage2: 0.3039  loss_mask: 0.5872  loss_rpn_cls: 0.06067  loss_rpn_loc: 0.03574  validation_loss: 2.197  time: 1.5336  data_time: 0.0232  lr: 3.178e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:08:45 d2.utils.events]: \u001b[0m eta: 0:29:11  iter: 8879  total_loss: 2.49  loss_cls_stage0: 0.3483  loss_box_reg_stage0: 0.2444  loss_cls_stage1: 0.3049  loss_box_reg_stage1: 0.3528  loss_cls_stage2: 0.2014  loss_box_reg_stage2: 0.2866  loss_mask: 0.5347  loss_rpn_cls: 0.06387  loss_rpn_loc: 0.03961  validation_loss: 2.197  time: 1.5337  data_time: 0.0253  lr: 3.0687e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:09:16 d2.utils.events]: \u001b[0m eta: 0:28:40  iter: 8899  total_loss: 2.416  loss_cls_stage0: 0.3278  loss_box_reg_stage0: 0.2692  loss_cls_stage1: 0.27  loss_box_reg_stage1: 0.3697  loss_cls_stage2: 0.1922  loss_box_reg_stage2: 0.2795  loss_mask: 0.555  loss_rpn_cls: 0.06096  loss_rpn_loc: 0.03418  validation_loss: 2.197  time: 1.5337  data_time: 0.0245  lr: 2.9613e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:09:48 d2.utils.events]: \u001b[0m eta: 0:28:08  iter: 8919  total_loss: 2.518  loss_cls_stage0: 0.3274  loss_box_reg_stage0: 0.2836  loss_cls_stage1: 0.2837  loss_box_reg_stage1: 0.3753  loss_cls_stage2: 0.2037  loss_box_reg_stage2: 0.3011  loss_mask: 0.5499  loss_rpn_cls: 0.0628  loss_rpn_loc: 0.03995  validation_loss: 2.197  time: 1.5338  data_time: 0.0254  lr: 2.8557e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:10:19 d2.utils.events]: \u001b[0m eta: 0:27:38  iter: 8939  total_loss: 2.538  loss_cls_stage0: 0.3522  loss_box_reg_stage0: 0.2701  loss_cls_stage1: 0.2902  loss_box_reg_stage1: 0.4005  loss_cls_stage2: 0.2106  loss_box_reg_stage2: 0.2988  loss_mask: 0.5796  loss_rpn_cls: 0.06625  loss_rpn_loc: 0.03883  validation_loss: 2.197  time: 1.5339  data_time: 0.0241  lr: 2.752e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:10:50 d2.utils.events]: \u001b[0m eta: 0:27:06  iter: 8959  total_loss: 2.287  loss_cls_stage0: 0.3179  loss_box_reg_stage0: 0.2508  loss_cls_stage1: 0.2538  loss_box_reg_stage1: 0.3564  loss_cls_stage2: 0.1811  loss_box_reg_stage2: 0.2874  loss_mask: 0.5123  loss_rpn_cls: 0.06075  loss_rpn_loc: 0.03425  validation_loss: 2.197  time: 1.5340  data_time: 0.0323  lr: 2.6501e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:11:22 d2.utils.events]: \u001b[0m eta: 0:26:35  iter: 8979  total_loss: 2.35  loss_cls_stage0: 0.3297  loss_box_reg_stage0: 0.2612  loss_cls_stage1: 0.2757  loss_box_reg_stage1: 0.3594  loss_cls_stage2: 0.1963  loss_box_reg_stage2: 0.2834  loss_mask: 0.4838  loss_rpn_cls: 0.05847  loss_rpn_loc: 0.03608  validation_loss: 2.197  time: 1.5340  data_time: 0.0240  lr: 2.5501e-06  max_mem: 12121M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/27 11:11:55 d2.data.common]: \u001b[0mSerializing 883 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/27 11:11:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.91 MiB\n",
      "\u001b[32m[03/27 11:11:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 883 images\n",
      "\u001b[32m[03/27 11:11:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/883. 0.0820 s / img. ETA=0:01:58\n",
      "\u001b[32m[03/27 11:12:02 d2.evaluation.evaluator]: \u001b[0mInference done 55/883. 0.0806 s / img. ETA=0:01:38\n",
      "\u001b[32m[03/27 11:12:07 d2.evaluation.evaluator]: \u001b[0mInference done 95/883. 0.0808 s / img. ETA=0:01:36\n",
      "\u001b[32m[03/27 11:12:12 d2.evaluation.evaluator]: \u001b[0mInference done 134/883. 0.0810 s / img. ETA=0:01:32\n",
      "\u001b[32m[03/27 11:12:17 d2.evaluation.evaluator]: \u001b[0mInference done 176/883. 0.0809 s / img. ETA=0:01:27\n",
      "\u001b[32m[03/27 11:12:22 d2.evaluation.evaluator]: \u001b[0mInference done 218/883. 0.0809 s / img. ETA=0:01:21\n",
      "\u001b[32m[03/27 11:12:27 d2.evaluation.evaluator]: \u001b[0mInference done 259/883. 0.0809 s / img. ETA=0:01:16\n",
      "\u001b[32m[03/27 11:12:32 d2.evaluation.evaluator]: \u001b[0mInference done 300/883. 0.0809 s / img. ETA=0:01:11\n",
      "\u001b[32m[03/27 11:12:37 d2.evaluation.evaluator]: \u001b[0mInference done 342/883. 0.0809 s / img. ETA=0:01:06\n",
      "\u001b[32m[03/27 11:12:42 d2.evaluation.evaluator]: \u001b[0mInference done 383/883. 0.0809 s / img. ETA=0:01:01\n",
      "\u001b[32m[03/27 11:12:47 d2.evaluation.evaluator]: \u001b[0mInference done 420/883. 0.0810 s / img. ETA=0:00:57\n",
      "\u001b[32m[03/27 11:12:52 d2.evaluation.evaluator]: \u001b[0mInference done 461/883. 0.0810 s / img. ETA=0:00:52\n",
      "\u001b[32m[03/27 11:12:58 d2.evaluation.evaluator]: \u001b[0mInference done 503/883. 0.0810 s / img. ETA=0:00:47\n",
      "\u001b[32m[03/27 11:13:03 d2.evaluation.evaluator]: \u001b[0mInference done 547/883. 0.0809 s / img. ETA=0:00:41\n",
      "\u001b[32m[03/27 11:13:08 d2.evaluation.evaluator]: \u001b[0mInference done 591/883. 0.0809 s / img. ETA=0:00:35\n",
      "\u001b[32m[03/27 11:13:13 d2.evaluation.evaluator]: \u001b[0mInference done 634/883. 0.0809 s / img. ETA=0:00:30\n",
      "\u001b[32m[03/27 11:13:18 d2.evaluation.evaluator]: \u001b[0mInference done 677/883. 0.0809 s / img. ETA=0:00:25\n",
      "\u001b[32m[03/27 11:13:23 d2.evaluation.evaluator]: \u001b[0mInference done 717/883. 0.0809 s / img. ETA=0:00:20\n",
      "\u001b[32m[03/27 11:13:28 d2.evaluation.evaluator]: \u001b[0mInference done 758/883. 0.0809 s / img. ETA=0:00:15\n",
      "\u001b[32m[03/27 11:13:33 d2.evaluation.evaluator]: \u001b[0mInference done 802/883. 0.0809 s / img. ETA=0:00:09\n",
      "\u001b[32m[03/27 11:13:38 d2.evaluation.evaluator]: \u001b[0mInference done 841/883. 0.0809 s / img. ETA=0:00:05\n",
      "\u001b[32m[03/27 11:13:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:47.270526 (0.122176 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/27 11:13:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:11 (0.080878 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.48 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.140\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.160\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.041\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.091\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.127\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.168\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.169\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.055\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.191\n",
      "\u001b[32m[03/27 11:13:44 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold5 in csv format:\n",
      "\u001b[32m[03/27 11:13:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/27 11:13:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/27 11:13:44 d2.evaluation.testing]: \u001b[0mcopypaste: 8.3725,14.0471,15.9511,0.2103,4.0991,9.1042\n",
      "validation do loss eval 2.412988285094659\n",
      "\u001b[32m[03/27 11:15:16 d2.utils.events]: \u001b[0m eta: 0:26:03  iter: 8999  total_loss: 2.21  loss_cls_stage0: 0.2799  loss_box_reg_stage0: 0.227  loss_cls_stage1: 0.2465  loss_box_reg_stage1: 0.3334  loss_cls_stage2: 0.1657  loss_box_reg_stage2: 0.2767  loss_mask: 0.4958  loss_rpn_cls: 0.067  loss_rpn_loc: 0.03527  validation_loss: 2.284  time: 1.5341  data_time: 0.0229  lr: 2.452e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:15:47 d2.utils.events]: \u001b[0m eta: 0:25:32  iter: 9019  total_loss: 2.357  loss_cls_stage0: 0.3368  loss_box_reg_stage0: 0.2626  loss_cls_stage1: 0.2672  loss_box_reg_stage1: 0.3576  loss_cls_stage2: 0.1942  loss_box_reg_stage2: 0.2844  loss_mask: 0.5703  loss_rpn_cls: 0.06475  loss_rpn_loc: 0.03498  validation_loss: 2.284  time: 1.5341  data_time: 0.0245  lr: 2.3558e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:16:18 d2.utils.events]: \u001b[0m eta: 0:25:01  iter: 9039  total_loss: 2.497  loss_cls_stage0: 0.3629  loss_box_reg_stage0: 0.2903  loss_cls_stage1: 0.3063  loss_box_reg_stage1: 0.4007  loss_cls_stage2: 0.2057  loss_box_reg_stage2: 0.3134  loss_mask: 0.4981  loss_rpn_cls: 0.05645  loss_rpn_loc: 0.03586  validation_loss: 2.284  time: 1.5342  data_time: 0.0269  lr: 2.2614e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:16:50 d2.utils.events]: \u001b[0m eta: 0:24:30  iter: 9059  total_loss: 2.37  loss_cls_stage0: 0.345  loss_box_reg_stage0: 0.2578  loss_cls_stage1: 0.2694  loss_box_reg_stage1: 0.3833  loss_cls_stage2: 0.2022  loss_box_reg_stage2: 0.3535  loss_mask: 0.5111  loss_rpn_cls: 0.06084  loss_rpn_loc: 0.0373  validation_loss: 2.284  time: 1.5343  data_time: 0.0245  lr: 2.169e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:17:21 d2.utils.events]: \u001b[0m eta: 0:23:58  iter: 9079  total_loss: 2.309  loss_cls_stage0: 0.3056  loss_box_reg_stage0: 0.2424  loss_cls_stage1: 0.2549  loss_box_reg_stage1: 0.3448  loss_cls_stage2: 0.1943  loss_box_reg_stage2: 0.3085  loss_mask: 0.53  loss_rpn_cls: 0.06378  loss_rpn_loc: 0.03498  validation_loss: 2.284  time: 1.5344  data_time: 0.0241  lr: 2.0784e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:17:53 d2.utils.events]: \u001b[0m eta: 0:23:27  iter: 9099  total_loss: 2.449  loss_cls_stage0: 0.345  loss_box_reg_stage0: 0.2722  loss_cls_stage1: 0.283  loss_box_reg_stage1: 0.3784  loss_cls_stage2: 0.1928  loss_box_reg_stage2: 0.3038  loss_mask: 0.5479  loss_rpn_cls: 0.05628  loss_rpn_loc: 0.03472  validation_loss: 2.284  time: 1.5344  data_time: 0.0242  lr: 1.9897e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:18:24 d2.utils.events]: \u001b[0m eta: 0:22:56  iter: 9119  total_loss: 2.243  loss_cls_stage0: 0.3127  loss_box_reg_stage0: 0.2404  loss_cls_stage1: 0.2491  loss_box_reg_stage1: 0.3453  loss_cls_stage2: 0.1794  loss_box_reg_stage2: 0.2981  loss_mask: 0.5506  loss_rpn_cls: 0.0667  loss_rpn_loc: 0.03492  validation_loss: 2.284  time: 1.5345  data_time: 0.0240  lr: 1.9029e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:18:55 d2.utils.events]: \u001b[0m eta: 0:22:24  iter: 9139  total_loss: 2.32  loss_cls_stage0: 0.3036  loss_box_reg_stage0: 0.2484  loss_cls_stage1: 0.2519  loss_box_reg_stage1: 0.383  loss_cls_stage2: 0.1878  loss_box_reg_stage2: 0.3171  loss_mask: 0.5406  loss_rpn_cls: 0.0643  loss_rpn_loc: 0.03646  validation_loss: 2.284  time: 1.5346  data_time: 0.0245  lr: 1.818e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:19:27 d2.utils.events]: \u001b[0m eta: 0:21:53  iter: 9159  total_loss: 2.328  loss_cls_stage0: 0.334  loss_box_reg_stage0: 0.2617  loss_cls_stage1: 0.2784  loss_box_reg_stage1: 0.3606  loss_cls_stage2: 0.2009  loss_box_reg_stage2: 0.3166  loss_mask: 0.4934  loss_rpn_cls: 0.06609  loss_rpn_loc: 0.03299  validation_loss: 2.284  time: 1.5346  data_time: 0.0244  lr: 1.735e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:19:58 d2.utils.events]: \u001b[0m eta: 0:21:23  iter: 9179  total_loss: 2.371  loss_cls_stage0: 0.3345  loss_box_reg_stage0: 0.288  loss_cls_stage1: 0.2688  loss_box_reg_stage1: 0.3838  loss_cls_stage2: 0.1933  loss_box_reg_stage2: 0.3017  loss_mask: 0.527  loss_rpn_cls: 0.06008  loss_rpn_loc: 0.0404  validation_loss: 2.284  time: 1.5347  data_time: 0.0225  lr: 1.6539e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:20:30 d2.utils.events]: \u001b[0m eta: 0:20:52  iter: 9199  total_loss: 2.461  loss_cls_stage0: 0.3416  loss_box_reg_stage0: 0.2706  loss_cls_stage1: 0.2828  loss_box_reg_stage1: 0.3919  loss_cls_stage2: 0.2039  loss_box_reg_stage2: 0.3176  loss_mask: 0.5485  loss_rpn_cls: 0.06043  loss_rpn_loc: 0.04144  validation_loss: 2.284  time: 1.5348  data_time: 0.0243  lr: 1.5748e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:21:01 d2.utils.events]: \u001b[0m eta: 0:20:20  iter: 9219  total_loss: 2.35  loss_cls_stage0: 0.3396  loss_box_reg_stage0: 0.2606  loss_cls_stage1: 0.2775  loss_box_reg_stage1: 0.3565  loss_cls_stage2: 0.1903  loss_box_reg_stage2: 0.2904  loss_mask: 0.5646  loss_rpn_cls: 0.06023  loss_rpn_loc: 0.03608  validation_loss: 2.284  time: 1.5349  data_time: 0.0237  lr: 1.4975e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:21:32 d2.utils.events]: \u001b[0m eta: 0:19:49  iter: 9239  total_loss: 2.455  loss_cls_stage0: 0.3385  loss_box_reg_stage0: 0.2501  loss_cls_stage1: 0.2999  loss_box_reg_stage1: 0.3561  loss_cls_stage2: 0.2174  loss_box_reg_stage2: 0.2956  loss_mask: 0.5584  loss_rpn_cls: 0.06488  loss_rpn_loc: 0.03442  validation_loss: 2.284  time: 1.5349  data_time: 0.0239  lr: 1.4221e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:22:04 d2.utils.events]: \u001b[0m eta: 0:19:17  iter: 9259  total_loss: 2.198  loss_cls_stage0: 0.3219  loss_box_reg_stage0: 0.2231  loss_cls_stage1: 0.2628  loss_box_reg_stage1: 0.3324  loss_cls_stage2: 0.1915  loss_box_reg_stage2: 0.2928  loss_mask: 0.5449  loss_rpn_cls: 0.0606  loss_rpn_loc: 0.03565  validation_loss: 2.284  time: 1.5350  data_time: 0.0246  lr: 1.3487e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:22:35 d2.utils.events]: \u001b[0m eta: 0:18:46  iter: 9279  total_loss: 2.321  loss_cls_stage0: 0.3071  loss_box_reg_stage0: 0.2561  loss_cls_stage1: 0.2698  loss_box_reg_stage1: 0.3853  loss_cls_stage2: 0.1933  loss_box_reg_stage2: 0.3146  loss_mask: 0.5599  loss_rpn_cls: 0.06189  loss_rpn_loc: 0.03776  validation_loss: 2.284  time: 1.5351  data_time: 0.0234  lr: 1.2772e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:23:06 d2.utils.events]: \u001b[0m eta: 0:18:15  iter: 9299  total_loss: 2.295  loss_cls_stage0: 0.3322  loss_box_reg_stage0: 0.239  loss_cls_stage1: 0.2835  loss_box_reg_stage1: 0.3506  loss_cls_stage2: 0.2011  loss_box_reg_stage2: 0.3108  loss_mask: 0.5549  loss_rpn_cls: 0.05592  loss_rpn_loc: 0.03346  validation_loss: 2.284  time: 1.5352  data_time: 0.0250  lr: 1.2076e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:23:37 d2.utils.events]: \u001b[0m eta: 0:17:44  iter: 9319  total_loss: 2.203  loss_cls_stage0: 0.3105  loss_box_reg_stage0: 0.2413  loss_cls_stage1: 0.2381  loss_box_reg_stage1: 0.337  loss_cls_stage2: 0.1775  loss_box_reg_stage2: 0.2849  loss_mask: 0.5193  loss_rpn_cls: 0.05751  loss_rpn_loc: 0.03188  validation_loss: 2.284  time: 1.5352  data_time: 0.0249  lr: 1.1399e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:24:09 d2.utils.events]: \u001b[0m eta: 0:17:12  iter: 9339  total_loss: 2.432  loss_cls_stage0: 0.353  loss_box_reg_stage0: 0.2814  loss_cls_stage1: 0.2854  loss_box_reg_stage1: 0.3583  loss_cls_stage2: 0.1979  loss_box_reg_stage2: 0.283  loss_mask: 0.5829  loss_rpn_cls: 0.06738  loss_rpn_loc: 0.03795  validation_loss: 2.284  time: 1.5353  data_time: 0.0258  lr: 1.0742e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:24:40 d2.utils.events]: \u001b[0m eta: 0:16:41  iter: 9359  total_loss: 2.479  loss_cls_stage0: 0.297  loss_box_reg_stage0: 0.2457  loss_cls_stage1: 0.2608  loss_box_reg_stage1: 0.3775  loss_cls_stage2: 0.2041  loss_box_reg_stage2: 0.3229  loss_mask: 0.5446  loss_rpn_cls: 0.07062  loss_rpn_loc: 0.03773  validation_loss: 2.284  time: 1.5354  data_time: 0.0239  lr: 1.0104e-06  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:25:12 d2.utils.events]: \u001b[0m eta: 0:16:10  iter: 9379  total_loss: 2.446  loss_cls_stage0: 0.3405  loss_box_reg_stage0: 0.2602  loss_cls_stage1: 0.2815  loss_box_reg_stage1: 0.3662  loss_cls_stage2: 0.2043  loss_box_reg_stage2: 0.3243  loss_mask: 0.5619  loss_rpn_cls: 0.07771  loss_rpn_loc: 0.03943  validation_loss: 2.284  time: 1.5354  data_time: 0.0239  lr: 9.4852e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:25:43 d2.utils.events]: \u001b[0m eta: 0:15:39  iter: 9399  total_loss: 2.496  loss_cls_stage0: 0.3372  loss_box_reg_stage0: 0.2749  loss_cls_stage1: 0.2886  loss_box_reg_stage1: 0.3964  loss_cls_stage2: 0.2067  loss_box_reg_stage2: 0.3216  loss_mask: 0.5438  loss_rpn_cls: 0.06606  loss_rpn_loc: 0.03609  validation_loss: 2.284  time: 1.5355  data_time: 0.0246  lr: 8.8858e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:26:14 d2.utils.events]: \u001b[0m eta: 0:15:07  iter: 9419  total_loss: 2.263  loss_cls_stage0: 0.3008  loss_box_reg_stage0: 0.2355  loss_cls_stage1: 0.2431  loss_box_reg_stage1: 0.3434  loss_cls_stage2: 0.1802  loss_box_reg_stage2: 0.2905  loss_mask: 0.4962  loss_rpn_cls: 0.0587  loss_rpn_loc: 0.03111  validation_loss: 2.284  time: 1.5356  data_time: 0.0245  lr: 8.3059e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:26:46 d2.utils.events]: \u001b[0m eta: 0:14:36  iter: 9439  total_loss: 2.484  loss_cls_stage0: 0.324  loss_box_reg_stage0: 0.2597  loss_cls_stage1: 0.2672  loss_box_reg_stage1: 0.3819  loss_cls_stage2: 0.2003  loss_box_reg_stage2: 0.3162  loss_mask: 0.5432  loss_rpn_cls: 0.05332  loss_rpn_loc: 0.03495  validation_loss: 2.284  time: 1.5356  data_time: 0.0240  lr: 7.7453e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:27:17 d2.utils.events]: \u001b[0m eta: 0:14:05  iter: 9459  total_loss: 2.522  loss_cls_stage0: 0.3677  loss_box_reg_stage0: 0.2869  loss_cls_stage1: 0.2877  loss_box_reg_stage1: 0.3952  loss_cls_stage2: 0.1982  loss_box_reg_stage2: 0.323  loss_mask: 0.5351  loss_rpn_cls: 0.06285  loss_rpn_loc: 0.03695  validation_loss: 2.284  time: 1.5357  data_time: 0.0250  lr: 7.2042e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:27:49 d2.utils.events]: \u001b[0m eta: 0:13:33  iter: 9479  total_loss: 2.451  loss_cls_stage0: 0.3466  loss_box_reg_stage0: 0.2645  loss_cls_stage1: 0.2822  loss_box_reg_stage1: 0.3799  loss_cls_stage2: 0.209  loss_box_reg_stage2: 0.31  loss_mask: 0.5245  loss_rpn_cls: 0.05941  loss_rpn_loc: 0.03187  validation_loss: 2.284  time: 1.5358  data_time: 0.0253  lr: 6.6826e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:28:20 d2.utils.events]: \u001b[0m eta: 0:13:02  iter: 9499  total_loss: 2.513  loss_cls_stage0: 0.3608  loss_box_reg_stage0: 0.3097  loss_cls_stage1: 0.293  loss_box_reg_stage1: 0.3935  loss_cls_stage2: 0.2036  loss_box_reg_stage2: 0.2998  loss_mask: 0.496  loss_rpn_cls: 0.05771  loss_rpn_loc: 0.0408  validation_loss: 2.284  time: 1.5359  data_time: 0.0261  lr: 6.1804e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:28:52 d2.utils.events]: \u001b[0m eta: 0:12:31  iter: 9519  total_loss: 2.412  loss_cls_stage0: 0.3411  loss_box_reg_stage0: 0.2775  loss_cls_stage1: 0.2728  loss_box_reg_stage1: 0.3772  loss_cls_stage2: 0.1957  loss_box_reg_stage2: 0.3282  loss_mask: 0.5448  loss_rpn_cls: 0.06757  loss_rpn_loc: 0.03617  validation_loss: 2.284  time: 1.5359  data_time: 0.0245  lr: 5.6977e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:29:23 d2.utils.events]: \u001b[0m eta: 0:11:59  iter: 9539  total_loss: 2.324  loss_cls_stage0: 0.3121  loss_box_reg_stage0: 0.2663  loss_cls_stage1: 0.2551  loss_box_reg_stage1: 0.3519  loss_cls_stage2: 0.176  loss_box_reg_stage2: 0.3042  loss_mask: 0.526  loss_rpn_cls: 0.06445  loss_rpn_loc: 0.03461  validation_loss: 2.284  time: 1.5360  data_time: 0.0243  lr: 5.2346e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:29:54 d2.utils.events]: \u001b[0m eta: 0:11:28  iter: 9559  total_loss: 2.385  loss_cls_stage0: 0.3444  loss_box_reg_stage0: 0.2696  loss_cls_stage1: 0.2836  loss_box_reg_stage1: 0.3871  loss_cls_stage2: 0.2  loss_box_reg_stage2: 0.2706  loss_mask: 0.5599  loss_rpn_cls: 0.06004  loss_rpn_loc: 0.0363  validation_loss: 2.284  time: 1.5361  data_time: 0.0235  lr: 4.791e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:30:26 d2.utils.events]: \u001b[0m eta: 0:10:57  iter: 9579  total_loss: 2.37  loss_cls_stage0: 0.3384  loss_box_reg_stage0: 0.2807  loss_cls_stage1: 0.2736  loss_box_reg_stage1: 0.379  loss_cls_stage2: 0.1925  loss_box_reg_stage2: 0.2978  loss_mask: 0.5095  loss_rpn_cls: 0.06771  loss_rpn_loc: 0.03896  validation_loss: 2.284  time: 1.5361  data_time: 0.0250  lr: 4.3669e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:30:57 d2.utils.events]: \u001b[0m eta: 0:10:25  iter: 9599  total_loss: 2.21  loss_cls_stage0: 0.3009  loss_box_reg_stage0: 0.2421  loss_cls_stage1: 0.2358  loss_box_reg_stage1: 0.335  loss_cls_stage2: 0.1801  loss_box_reg_stage2: 0.2773  loss_mask: 0.5781  loss_rpn_cls: 0.06068  loss_rpn_loc: 0.03315  validation_loss: 2.284  time: 1.5362  data_time: 0.0311  lr: 3.9624e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:31:28 d2.utils.events]: \u001b[0m eta: 0:09:54  iter: 9619  total_loss: 2.431  loss_cls_stage0: 0.354  loss_box_reg_stage0: 0.2766  loss_cls_stage1: 0.2915  loss_box_reg_stage1: 0.3688  loss_cls_stage2: 0.1975  loss_box_reg_stage2: 0.2789  loss_mask: 0.5538  loss_rpn_cls: 0.06352  loss_rpn_loc: 0.04118  validation_loss: 2.284  time: 1.5362  data_time: 0.0254  lr: 3.5774e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:32:00 d2.utils.events]: \u001b[0m eta: 0:09:23  iter: 9639  total_loss: 2.217  loss_cls_stage0: 0.3043  loss_box_reg_stage0: 0.2374  loss_cls_stage1: 0.2584  loss_box_reg_stage1: 0.3366  loss_cls_stage2: 0.1884  loss_box_reg_stage2: 0.3189  loss_mask: 0.5147  loss_rpn_cls: 0.0571  loss_rpn_loc: 0.03418  validation_loss: 2.284  time: 1.5363  data_time: 0.0249  lr: 3.2121e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:32:31 d2.utils.events]: \u001b[0m eta: 0:08:52  iter: 9659  total_loss: 2.252  loss_cls_stage0: 0.317  loss_box_reg_stage0: 0.2402  loss_cls_stage1: 0.2663  loss_box_reg_stage1: 0.3712  loss_cls_stage2: 0.1918  loss_box_reg_stage2: 0.3256  loss_mask: 0.5053  loss_rpn_cls: 0.05305  loss_rpn_loc: 0.03427  validation_loss: 2.284  time: 1.5364  data_time: 0.0243  lr: 2.8664e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:33:02 d2.utils.events]: \u001b[0m eta: 0:08:20  iter: 9679  total_loss: 2.521  loss_cls_stage0: 0.3691  loss_box_reg_stage0: 0.2638  loss_cls_stage1: 0.2852  loss_box_reg_stage1: 0.3731  loss_cls_stage2: 0.208  loss_box_reg_stage2: 0.3081  loss_mask: 0.5959  loss_rpn_cls: 0.06228  loss_rpn_loc: 0.03798  validation_loss: 2.284  time: 1.5364  data_time: 0.0249  lr: 2.5403e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:33:34 d2.utils.events]: \u001b[0m eta: 0:07:49  iter: 9699  total_loss: 2.347  loss_cls_stage0: 0.3146  loss_box_reg_stage0: 0.2435  loss_cls_stage1: 0.2538  loss_box_reg_stage1: 0.3525  loss_cls_stage2: 0.1919  loss_box_reg_stage2: 0.297  loss_mask: 0.5321  loss_rpn_cls: 0.05054  loss_rpn_loc: 0.03026  validation_loss: 2.284  time: 1.5365  data_time: 0.0230  lr: 2.2338e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:34:05 d2.utils.events]: \u001b[0m eta: 0:07:18  iter: 9719  total_loss: 2.344  loss_cls_stage0: 0.3272  loss_box_reg_stage0: 0.271  loss_cls_stage1: 0.2688  loss_box_reg_stage1: 0.3733  loss_cls_stage2: 0.1864  loss_box_reg_stage2: 0.2841  loss_mask: 0.554  loss_rpn_cls: 0.05471  loss_rpn_loc: 0.03578  validation_loss: 2.284  time: 1.5366  data_time: 0.0240  lr: 1.947e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:34:36 d2.utils.events]: \u001b[0m eta: 0:06:46  iter: 9739  total_loss: 2.333  loss_cls_stage0: 0.3019  loss_box_reg_stage0: 0.2309  loss_cls_stage1: 0.238  loss_box_reg_stage1: 0.3279  loss_cls_stage2: 0.1864  loss_box_reg_stage2: 0.2868  loss_mask: 0.5404  loss_rpn_cls: 0.06349  loss_rpn_loc: 0.03307  validation_loss: 2.284  time: 1.5366  data_time: 0.0253  lr: 1.6799e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:35:07 d2.utils.events]: \u001b[0m eta: 0:06:15  iter: 9759  total_loss: 2.295  loss_cls_stage0: 0.3063  loss_box_reg_stage0: 0.2396  loss_cls_stage1: 0.2546  loss_box_reg_stage1: 0.3491  loss_cls_stage2: 0.1761  loss_box_reg_stage2: 0.2716  loss_mask: 0.5592  loss_rpn_cls: 0.05655  loss_rpn_loc: 0.03423  validation_loss: 2.284  time: 1.5366  data_time: 0.0243  lr: 1.4324e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:35:38 d2.utils.events]: \u001b[0m eta: 0:05:44  iter: 9779  total_loss: 2.132  loss_cls_stage0: 0.3159  loss_box_reg_stage0: 0.2437  loss_cls_stage1: 0.2531  loss_box_reg_stage1: 0.3502  loss_cls_stage2: 0.1719  loss_box_reg_stage2: 0.2826  loss_mask: 0.5349  loss_rpn_cls: 0.052  loss_rpn_loc: 0.03019  validation_loss: 2.284  time: 1.5367  data_time: 0.0238  lr: 1.2046e-07  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:36:10 d2.utils.events]: \u001b[0m eta: 0:05:12  iter: 9799  total_loss: 2.237  loss_cls_stage0: 0.2917  loss_box_reg_stage0: 0.2561  loss_cls_stage1: 0.2403  loss_box_reg_stage1: 0.3518  loss_cls_stage2: 0.1884  loss_box_reg_stage2: 0.301  loss_mask: 0.5056  loss_rpn_cls: 0.05713  loss_rpn_loc: 0.0345  validation_loss: 2.284  time: 1.5367  data_time: 0.0229  lr: 9.9652e-08  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:36:41 d2.utils.events]: \u001b[0m eta: 0:04:41  iter: 9819  total_loss: 2.518  loss_cls_stage0: 0.3487  loss_box_reg_stage0: 0.2863  loss_cls_stage1: 0.2928  loss_box_reg_stage1: 0.3694  loss_cls_stage2: 0.2021  loss_box_reg_stage2: 0.3307  loss_mask: 0.5544  loss_rpn_cls: 0.0548  loss_rpn_loc: 0.03626  validation_loss: 2.284  time: 1.5368  data_time: 0.0229  lr: 8.0813e-08  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:37:12 d2.utils.events]: \u001b[0m eta: 0:04:10  iter: 9839  total_loss: 2.39  loss_cls_stage0: 0.3364  loss_box_reg_stage0: 0.2509  loss_cls_stage1: 0.2895  loss_box_reg_stage1: 0.3735  loss_cls_stage2: 0.1994  loss_box_reg_stage2: 0.3031  loss_mask: 0.5254  loss_rpn_cls: 0.06912  loss_rpn_loc: 0.03645  validation_loss: 2.284  time: 1.5369  data_time: 0.0237  lr: 6.3944e-08  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:37:44 d2.utils.events]: \u001b[0m eta: 0:03:38  iter: 9859  total_loss: 2.221  loss_cls_stage0: 0.2993  loss_box_reg_stage0: 0.2354  loss_cls_stage1: 0.2399  loss_box_reg_stage1: 0.3361  loss_cls_stage2: 0.1801  loss_box_reg_stage2: 0.2974  loss_mask: 0.5461  loss_rpn_cls: 0.04984  loss_rpn_loc: 0.02949  validation_loss: 2.284  time: 1.5369  data_time: 0.0243  lr: 4.9046e-08  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:38:15 d2.utils.events]: \u001b[0m eta: 0:03:07  iter: 9879  total_loss: 2.239  loss_cls_stage0: 0.3148  loss_box_reg_stage0: 0.2341  loss_cls_stage1: 0.273  loss_box_reg_stage1: 0.3471  loss_cls_stage2: 0.1999  loss_box_reg_stage2: 0.2889  loss_mask: 0.5331  loss_rpn_cls: 0.05934  loss_rpn_loc: 0.03821  validation_loss: 2.284  time: 1.5370  data_time: 0.0239  lr: 3.6121e-08  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:38:46 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 9899  total_loss: 2.34  loss_cls_stage0: 0.3252  loss_box_reg_stage0: 0.2511  loss_cls_stage1: 0.2672  loss_box_reg_stage1: 0.3664  loss_cls_stage2: 0.1927  loss_box_reg_stage2: 0.293  loss_mask: 0.574  loss_rpn_cls: 0.06162  loss_rpn_loc: 0.0394  validation_loss: 2.284  time: 1.5370  data_time: 0.0245  lr: 2.5168e-08  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:39:18 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 9919  total_loss: 2.295  loss_cls_stage0: 0.299  loss_box_reg_stage0: 0.2332  loss_cls_stage1: 0.2538  loss_box_reg_stage1: 0.354  loss_cls_stage2: 0.1912  loss_box_reg_stage2: 0.3184  loss_mask: 0.5266  loss_rpn_cls: 0.06112  loss_rpn_loc: 0.03276  validation_loss: 2.284  time: 1.5371  data_time: 0.0247  lr: 1.6188e-08  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:39:49 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 9939  total_loss: 2.46  loss_cls_stage0: 0.3701  loss_box_reg_stage0: 0.2821  loss_cls_stage1: 0.2973  loss_box_reg_stage1: 0.3665  loss_cls_stage2: 0.1994  loss_box_reg_stage2: 0.304  loss_mask: 0.523  loss_rpn_cls: 0.07021  loss_rpn_loc: 0.03884  validation_loss: 2.284  time: 1.5371  data_time: 0.0234  lr: 9.1809e-09  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:40:20 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 9959  total_loss: 2.258  loss_cls_stage0: 0.3091  loss_box_reg_stage0: 0.2491  loss_cls_stage1: 0.2476  loss_box_reg_stage1: 0.3525  loss_cls_stage2: 0.1937  loss_box_reg_stage2: 0.3109  loss_mask: 0.5764  loss_rpn_cls: 0.05696  loss_rpn_loc: 0.03148  validation_loss: 2.284  time: 1.5372  data_time: 0.0243  lr: 4.1476e-09  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:40:52 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 9979  total_loss: 2.522  loss_cls_stage0: 0.3635  loss_box_reg_stage0: 0.2838  loss_cls_stage1: 0.3003  loss_box_reg_stage1: 0.387  loss_cls_stage2: 0.2024  loss_box_reg_stage2: 0.3325  loss_mask: 0.545  loss_rpn_cls: 0.06831  loss_rpn_loc: 0.03561  validation_loss: 2.284  time: 1.5373  data_time: 0.0240  lr: 1.0881e-09  max_mem: 12121M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/27 11:41:26 d2.data.common]: \u001b[0mSerializing 883 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/27 11:41:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.91 MiB\n",
      "\u001b[32m[03/27 11:41:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 883 images\n",
      "\u001b[32m[03/27 11:41:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/883. 0.0818 s / img. ETA=0:02:25\n",
      "\u001b[32m[03/27 11:41:34 d2.evaluation.evaluator]: \u001b[0mInference done 55/883. 0.0807 s / img. ETA=0:01:41\n",
      "\u001b[32m[03/27 11:41:39 d2.evaluation.evaluator]: \u001b[0mInference done 95/883. 0.0809 s / img. ETA=0:01:37\n",
      "\u001b[32m[03/27 11:41:44 d2.evaluation.evaluator]: \u001b[0mInference done 134/883. 0.0811 s / img. ETA=0:01:34\n",
      "\u001b[32m[03/27 11:41:49 d2.evaluation.evaluator]: \u001b[0mInference done 176/883. 0.0810 s / img. ETA=0:01:28\n",
      "\u001b[32m[03/27 11:41:54 d2.evaluation.evaluator]: \u001b[0mInference done 218/883. 0.0810 s / img. ETA=0:01:22\n",
      "\u001b[32m[03/27 11:41:59 d2.evaluation.evaluator]: \u001b[0mInference done 258/883. 0.0810 s / img. ETA=0:01:17\n",
      "\u001b[32m[03/27 11:42:04 d2.evaluation.evaluator]: \u001b[0mInference done 299/883. 0.0810 s / img. ETA=0:01:12\n",
      "\u001b[32m[03/27 11:42:09 d2.evaluation.evaluator]: \u001b[0mInference done 340/883. 0.0810 s / img. ETA=0:01:07\n",
      "\u001b[32m[03/27 11:42:14 d2.evaluation.evaluator]: \u001b[0mInference done 380/883. 0.0810 s / img. ETA=0:01:02\n",
      "\u001b[32m[03/27 11:42:19 d2.evaluation.evaluator]: \u001b[0mInference done 416/883. 0.0811 s / img. ETA=0:00:58\n",
      "\u001b[32m[03/27 11:42:25 d2.evaluation.evaluator]: \u001b[0mInference done 458/883. 0.0811 s / img. ETA=0:00:53\n",
      "\u001b[32m[03/27 11:42:30 d2.evaluation.evaluator]: \u001b[0mInference done 500/883. 0.0811 s / img. ETA=0:00:47\n",
      "\u001b[32m[03/27 11:42:35 d2.evaluation.evaluator]: \u001b[0mInference done 543/883. 0.0811 s / img. ETA=0:00:42\n",
      "\u001b[32m[03/27 11:42:40 d2.evaluation.evaluator]: \u001b[0mInference done 586/883. 0.0810 s / img. ETA=0:00:36\n",
      "\u001b[32m[03/27 11:42:45 d2.evaluation.evaluator]: \u001b[0mInference done 628/883. 0.0810 s / img. ETA=0:00:31\n",
      "\u001b[32m[03/27 11:42:50 d2.evaluation.evaluator]: \u001b[0mInference done 671/883. 0.0810 s / img. ETA=0:00:26\n",
      "\u001b[32m[03/27 11:42:55 d2.evaluation.evaluator]: \u001b[0mInference done 712/883. 0.0810 s / img. ETA=0:00:21\n",
      "\u001b[32m[03/27 11:43:00 d2.evaluation.evaluator]: \u001b[0mInference done 752/883. 0.0810 s / img. ETA=0:00:16\n",
      "\u001b[32m[03/27 11:43:05 d2.evaluation.evaluator]: \u001b[0mInference done 794/883. 0.0810 s / img. ETA=0:00:10\n",
      "\u001b[32m[03/27 11:43:10 d2.evaluation.evaluator]: \u001b[0mInference done 831/883. 0.0810 s / img. ETA=0:00:06\n",
      "\u001b[32m[03/27 11:43:15 d2.evaluation.evaluator]: \u001b[0mInference done 874/883. 0.0810 s / img. ETA=0:00:01\n",
      "\u001b[32m[03/27 11:43:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:48.388072 (0.123449 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/27 11:43:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:11 (0.080974 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.52 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.09 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.141\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.159\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.037\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.092\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.128\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.171\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.172\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.052\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.196\n",
      "\u001b[32m[03/27 11:43:17 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold5 in csv format:\n",
      "\u001b[32m[03/27 11:43:17 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/27 11:43:17 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/27 11:43:17 d2.evaluation.testing]: \u001b[0mcopypaste: 8.4088,14.1422,15.9183,0.2131,3.7347,9.1904\n",
      "validation do loss eval 2.411668274060919\n",
      "\u001b[32m[03/27 11:44:49 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 2.37  loss_cls_stage0: 0.3089  loss_box_reg_stage0: 0.2568  loss_cls_stage1: 0.2669  loss_box_reg_stage1: 0.396  loss_cls_stage2: 0.195  loss_box_reg_stage2: 0.3392  loss_mask: 0.547  loss_rpn_cls: 0.05689  loss_rpn_loc: 0.03531  validation_loss: 2.299  time: 1.5373  data_time: 0.0235  lr: 2.4674e-12  max_mem: 12121M\n",
      "\u001b[32m[03/27 11:44:49 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 4:16:10 (1.5373 s / it)\n",
      "\u001b[32m[03/27 11:44:49 d2.engine.hooks]: \u001b[0mTotal training time: 4:48:23 (0:32:13 on hooks)\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})\n",
      "\u001b[32m[03/27 11:44:49 d2.data.common]: \u001b[0mSerializing 883 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/27 11:44:49 d2.data.common]: \u001b[0mSerialized dataset takes 0.91 MiB\n",
      "\u001b[32m[03/27 11:44:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 883 images\n",
      "\u001b[32m[03/27 11:44:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/883. 0.0815 s / img. ETA=0:02:03\n",
      "\u001b[32m[03/27 11:44:56 d2.evaluation.evaluator]: \u001b[0mInference done 55/883. 0.0803 s / img. ETA=0:01:40\n",
      "\u001b[32m[03/27 11:45:01 d2.evaluation.evaluator]: \u001b[0mInference done 94/883. 0.0807 s / img. ETA=0:01:38\n",
      "\u001b[32m[03/27 11:45:06 d2.evaluation.evaluator]: \u001b[0mInference done 133/883. 0.0809 s / img. ETA=0:01:34\n",
      "\u001b[32m[03/27 11:45:11 d2.evaluation.evaluator]: \u001b[0mInference done 175/883. 0.0809 s / img. ETA=0:01:28\n",
      "\u001b[32m[03/27 11:45:16 d2.evaluation.evaluator]: \u001b[0mInference done 218/883. 0.0808 s / img. ETA=0:01:22\n",
      "\u001b[32m[03/27 11:45:22 d2.evaluation.evaluator]: \u001b[0mInference done 259/883. 0.0809 s / img. ETA=0:01:17\n",
      "\u001b[32m[03/27 11:45:27 d2.evaluation.evaluator]: \u001b[0mInference done 300/883. 0.0809 s / img. ETA=0:01:11\n",
      "\u001b[32m[03/27 11:45:32 d2.evaluation.evaluator]: \u001b[0mInference done 342/883. 0.0809 s / img. ETA=0:01:06\n",
      "\u001b[32m[03/27 11:45:37 d2.evaluation.evaluator]: \u001b[0mInference done 383/883. 0.0809 s / img. ETA=0:01:01\n",
      "\u001b[32m[03/27 11:45:42 d2.evaluation.evaluator]: \u001b[0mInference done 420/883. 0.0810 s / img. ETA=0:00:57\n",
      "\u001b[32m[03/27 11:45:47 d2.evaluation.evaluator]: \u001b[0mInference done 462/883. 0.0810 s / img. ETA=0:00:52\n",
      "\u001b[32m[03/27 11:45:52 d2.evaluation.evaluator]: \u001b[0mInference done 503/883. 0.0810 s / img. ETA=0:00:47\n",
      "\u001b[32m[03/27 11:45:57 d2.evaluation.evaluator]: \u001b[0mInference done 547/883. 0.0809 s / img. ETA=0:00:41\n",
      "\u001b[32m[03/27 11:46:02 d2.evaluation.evaluator]: \u001b[0mInference done 591/883. 0.0809 s / img. ETA=0:00:35\n",
      "\u001b[32m[03/27 11:46:07 d2.evaluation.evaluator]: \u001b[0mInference done 634/883. 0.0809 s / img. ETA=0:00:30\n",
      "\u001b[32m[03/27 11:46:12 d2.evaluation.evaluator]: \u001b[0mInference done 676/883. 0.0809 s / img. ETA=0:00:25\n",
      "\u001b[32m[03/27 11:46:17 d2.evaluation.evaluator]: \u001b[0mInference done 717/883. 0.0809 s / img. ETA=0:00:20\n",
      "\u001b[32m[03/27 11:46:22 d2.evaluation.evaluator]: \u001b[0mInference done 759/883. 0.0809 s / img. ETA=0:00:15\n",
      "\u001b[32m[03/27 11:46:27 d2.evaluation.evaluator]: \u001b[0mInference done 802/883. 0.0809 s / img. ETA=0:00:09\n",
      "\u001b[32m[03/27 11:46:33 d2.evaluation.evaluator]: \u001b[0mInference done 841/883. 0.0809 s / img. ETA=0:00:05\n",
      "\u001b[32m[03/27 11:46:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:47.275559 (0.122182 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/27 11:46:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:11 (0.080918 s / img per device, on 1 devices)\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.141\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.159\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.037\n",
      " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.092\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.128\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.171\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.172\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.052\n",
      " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.196\n",
      "\u001b[32m[03/27 11:46:38 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid_fold5 in csv format:\n",
      "\u001b[32m[03/27 11:46:38 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/27 11:46:38 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/27 11:46:38 d2.evaluation.testing]: \u001b[0mcopypaste: 8.4088,14.1422,15.9183,0.2131,3.7347,9.1904\n"
     ]
    }
   ],
   "source": [
    "from detectron2.config.config import CfgNode as CN\n",
    "\n",
    "\n",
    "torch.cuda.set_device(config.device_id)\n",
    "\n",
    "for fold, (train_df, valid_df) in enumerate(mkf):\n",
    "    seed_everything(seed=config.seed, device=config.device)\n",
    "    \n",
    "    outdir = base_dir / config.outdir / f'fold-{fold + 1}'\n",
    "    \n",
    "    train_idx = list(pd.DataFrame({'image_id': [dd['image_id'] for dd in dataset_dicts]}).query(f\"image_id in {train_df['image_id'].values.tolist()}\").index)\n",
    "    valid_idx = list(pd.DataFrame({'image_id': [dd['image_id'] for dd in dataset_dicts]}).query(f\"image_id in {valid_df['image_id'].values.tolist()}\").index)\n",
    "        \n",
    "    DatasetCatalog.register(\n",
    "        f\"vinbigdata_train_fold{fold + 1}\",\n",
    "        lambda: [dataset_dicts[i] for i in train_idx],\n",
    "    )\n",
    "    MetadataCatalog.get(f\"vinbigdata_train_fold{fold + 1}\").set(thing_classes=classes_nms)\n",
    "\n",
    "    DatasetCatalog.register(\n",
    "        f\"vinbigdata_valid_fold{fold + 1}\",\n",
    "        lambda: [dataset_dicts[i] for i in valid_idx],\n",
    "    )\n",
    "    MetadataCatalog.get(f\"vinbigdata_valid_fold{fold + 1}\").set(thing_classes=classes_nms)\n",
    "    \n",
    "    cfg = get_cfg()\n",
    "    cfg.aug_kwargs = CN(config.aug_kwargs)  # pass aug_kwargs to cfg\n",
    "\n",
    "    original_output_dir = cfg.OUTPUT_DIR\n",
    "    cfg.OUTPUT_DIR = str(outdir)\n",
    "    print(f\"cfg.OUTPUT_DIR {original_output_dir} -> {cfg.OUTPUT_DIR}\")\n",
    "\n",
    "    config_name = config.model_config\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(config_name))\n",
    "    cfg.DATASETS.TRAIN = (f\"vinbigdata_train_fold{fold + 1}\",)\n",
    "    cfg.DATASETS.TEST = (f\"vinbigdata_valid_fold{fold + 1}\",)\n",
    "    cfg.TEST.EVAL_PERIOD = config.eval_period\n",
    "\n",
    "    cfg.DATALOADER.NUM_WORKERS = config.num_workers\n",
    "    # Let training initialize from model zoo\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(config_name)\n",
    "    cfg.SOLVER.IMS_PER_BATCH = config.batch_size\n",
    "    cfg.SOLVER.LR_SCHEDULER_NAME = config.lr_scheduler_name\n",
    "    cfg.SOLVER.BASE_LR = config.base_lr  # pick a good LR\n",
    "    cfg.SOLVER.MAX_ITER = config.iter\n",
    "    cfg.SOLVER.CHECKPOINT_PERIOD = config.checkpoint_period  # Small value=Frequent save need a lot of storage.\n",
    "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = config.roi_batch_size_per_image\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(classes_nms)\n",
    "    \n",
    "    # NOTE: this config means the number of classes,\n",
    "    # but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "\n",
    "    cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[16], [32], [64], [128], [256], [512], [1024]]\n",
    "    cfg.MODEL.RPN.IN_FEATURES = ['p2', 'p2', 'p3', 'p4', 'p5', 'p6', 'p6']\n",
    "    cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.33, 0.5, 1.0, 2.0, 3.0]]\n",
    "    \n",
    "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    repeat_factors = get_repeat_factor(weight_by_folds[fold], [dataset_dicts[i] for i in train_idx])\n",
    "    \n",
    "    trainer = MyTrainer(cfg, RepeatFactorTrainingSampler(repeat_factors=repeat_factors, seed=config.seed))\n",
    "    trainer.resume_or_load(resume=False)\n",
    "    trainer.train()\n",
    "    \n",
    "    del trainer, cfg, train_idx, valid_idx\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-formation",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-circulation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "renewable-irrigation",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "internal-sixth",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, valid_df = mkf[0]\n",
    "valid_idx = list(pd.DataFrame({'image_id': [dd['image_id'] for dd in dataset_dicts]}).query(f\"image_id in {valid_df['image_id'].values.tolist()}\").index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "transsexual-stopping",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading config /home/yamaguchi-milkcocholate/.pyenv/versions/3.7.6/envs/VinBigData/lib/python3.7/site-packages/detectron2/model_zoo/configs/COCO-Detection/../Base-RetinaNet.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cfg.OUTPUT_DIR ./output -> /home/yamaguchi-milkcocholate/VinBigData/src/VinBigData-ObjectDetection/detectron2_results/results00/fold-1\n",
      "Original thresh 0.05\n",
      "Changed  thresh 0.0\n"
     ]
    }
   ],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.aug_kwargs = CN(config.aug_kwargs)  # pass aug_kwargs to cfg\n",
    "\n",
    "original_output_dir = cfg.OUTPUT_DIR\n",
    "cfg.OUTPUT_DIR = str(outdir)\n",
    "print(f\"cfg.OUTPUT_DIR {original_output_dir} -> {cfg.OUTPUT_DIR}\")\n",
    "\n",
    "config_name = config.model_config\n",
    "cfg.merge_from_file(model_zoo.get_config_file(config_name))\n",
    "cfg.DATASETS.TRAIN = (f\"vinbigdata_train_fold{fold + 1}\",)\n",
    "cfg.DATASETS.TEST = (f\"vinbigdata_valid_fold{fold + 1}\",)\n",
    "cfg.TEST.EVAL_PERIOD = config.eval_period\n",
    "\n",
    "cfg.DATALOADER.NUM_WORKERS = config.num_workers\n",
    "\n",
    "cfg.MODEL.WEIGHTS = str(base_dir / config.outdir / 'fold-1' /\"model_final.pth\")\n",
    "cfg.SOLVER.IMS_PER_BATCH = config.batch_size\n",
    "cfg.SOLVER.LR_SCHEDULER_NAME = config.lr_scheduler_name\n",
    "cfg.SOLVER.BASE_LR = config.base_lr  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = config.iter\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = config.checkpoint_period  # Small value=Frequent save need a lot of storage.\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = config.roi_batch_size_per_image\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(classes_nms)\n",
    "\n",
    "print(\"Original thresh\", cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST)  # 0.05\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0. # set a custom testing threshold\n",
    "print(\"Changed  thresh\", cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST)\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "outside-container",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating image data...\n",
      "Generating category data...\n",
      "Generating annotation data...\n"
     ]
    }
   ],
   "source": [
    "dataset_dicts_valid = [dataset_dicts[i] for i in valid_idx]\n",
    "cols = ['x_min', 'y_min', 'x_max', 'y_max']\n",
    "train_ = train.drop(columns=['x_min', 'y_min', 'x_max', 'y_max']).rename(columns={f'{c}_{config.img_size}': c for c in cols})\n",
    "valid_evaluator = VinBigDataEval(train_.query(f\"image_id in {[dd['image_id'] for dd in dataset_dicts_valid]}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "certain-pregnancy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05919cd7b6242fea5f3eb16415ff3f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/441 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "records = {'image_id': list(), 'PredictionString': list()}\n",
    "\n",
    "for i in tqdm(range(ceil(len(dataset_dicts_valid) / config.batch_size))):\n",
    "    inds = list(range(config.batch_size * i, min(config.batch_size * (i + 1), len(dataset_dicts_valid))))\n",
    "    dataset_dicts_test_batch = [dataset_dicts_valid[i] for i in inds]\n",
    "    im_list = [cv2.imread(d[\"file_name\"]) for d in dataset_dicts_test_batch]\n",
    "    outputs_list = predict_batch(predictor, im_list)\n",
    "    \n",
    "    for outputs, dd in zip(outputs_list, dataset_dicts_test_batch):\n",
    "        instances = outputs[\"instances\"]\n",
    "        fields: Dict[str, Any] = instances.get_fields()\n",
    "        pred_classes = fields[\"pred_classes\"].cpu().numpy()\n",
    "        pred_scores = fields[\"scores\"].cpu().numpy()\n",
    "        pred_boxes = fields[\"pred_boxes\"].tensor.cpu().numpy()\n",
    "        \n",
    "        records['image_id'] += [dd['image_id']]\n",
    "        records['PredictionString'] += [format_pred(pred_classes, pred_boxes, pred_scores)]\n",
    "    \n",
    "pred_valid_df = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "starting-filename",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_lowscore(pred_df: pd.DataFrame, threshes: List[float]):\n",
    "    assert len(classes_nms) == len(threshes)\n",
    "    pred_df_ = pred_df.copy()\n",
    "    \n",
    "    for i in pred_df_.index:\n",
    "        pred_str = list()\n",
    "        for obj in np.array(pred_df_.loc[i, 'PredictionString'].split(' ')).reshape(-1, 6):\n",
    "            try:\n",
    "                thresh = threshes[int(obj[0])]\n",
    "            except IndexError as e:\n",
    "                continue\n",
    "            \n",
    "            if float(obj[1]) > thresh:\n",
    "                pred_str += obj.tolist()\n",
    "                \n",
    "        pred_df_.loc[i, 'PredictionString'] = ' '.join(pred_str)\n",
    "    \n",
    "    return pred_df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "tender-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mAP(valid_pred_df: pd.DataFrame):\n",
    "    mAPs = dict()\n",
    "    for cls_id, cls_nm in tqdm(classes_dict.items()):\n",
    "        results = valid_evaluator.evaluate(valid_pred_df, category_ids=[cls_id])\n",
    "        mAPs[cls_nm] = results.stats[0]\n",
    "\n",
    "    results = valid_evaluator.evaluate(valid_pred_df)\n",
    "    mAPs['all'] = results.stats[0]\n",
    "    \n",
    "    return mAPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bridal-adelaide",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90c6bc48835437eac60bed4b7dafd89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating prediction data...\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.23s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.772\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.772\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.929\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.798\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=  1 ] = 0.426\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets= 10 ] = 0.968\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.968\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.971\n",
      "Generating prediction data...\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.11s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.439\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.439\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.018\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.465\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=  1 ] = 0.453\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets= 10 ] = 0.875\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.875\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.667\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.885\n",
      "Generating prediction data...\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.20s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.337\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.337\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 0.221\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.344\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.496\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=  1 ] = 0.381\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets= 10 ] = 0.843\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.886\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 0.964\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.896\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.872\n",
      "Generating prediction data...\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.20s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.632\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.632\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.633\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=  1 ] = 0.424\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets= 10 ] = 0.928\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.928\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.928\n",
      "Generating prediction data...\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.12s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.399\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.399\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.240\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.444\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=  1 ] = 0.582\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets= 10 ] = 0.936\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.936\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.800\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.950\n",
      "Generating prediction data...\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.17s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.438\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.438\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.039\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.445\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=  1 ] = 0.315\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets= 10 ] = 0.946\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.946\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.945\n",
      "Generating prediction data...\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.16s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.492\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.492\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.405\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.507\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=  1 ] = 0.464\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets= 10 ] = 0.945\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.954\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.778\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.968\n",
      "Generating prediction data...\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.26s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.05s).\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.477\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.477\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 0.152\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.329\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.526\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=  1 ] = 0.427\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets= 10 ] = 0.913\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.942\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 0.667\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.892\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.959\n",
      "Generating prediction data...\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.23s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.335\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.335\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 0.315\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.467\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.385\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=  1 ] = 0.243\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets= 10 ] = 0.775\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.856\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 0.891\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.889\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.840\n",
      "Generating prediction data...\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.29s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.06s).\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.174\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.174\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 0.171\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.116\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.223\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=  1 ] = 0.269\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets= 10 ] = 0.774\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.847\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 0.800\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.821\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.882\n",
      "Generating prediction data...\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.20s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.721\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.721\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 0.660\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.666\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.796\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=  1 ] = 0.369\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets= 10 ] = 0.970\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.970\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 0.857\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.961\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.981\n",
      "Generating prediction data...\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.33s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.06s).\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.478\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.478\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 0.785\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.516\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.517\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=  1 ] = 0.294\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets= 10 ] = 0.910\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.946\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 0.929\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.981\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.851\n",
      "Generating prediction data...\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.07s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.592\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.592\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.606\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=  1 ] = 0.327\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets= 10 ] = 0.857\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.857\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.875\n",
      "Generating prediction data...\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.29s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.05s).\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.649\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.649\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 0.675\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.602\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.739\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=  1 ] = 0.284\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets= 10 ] = 0.911\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.960\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 0.909\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.935\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.984\n",
      "Generating prediction data...\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.58s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.48s).\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.495\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.495\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 0.497\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.359\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.541\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=  1 ] = 0.376\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets= 10 ] = 0.897\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.919\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 0.877\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.817\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.921\n"
     ]
    }
   ],
   "source": [
    "mAPs = evaluate_mAP(pred_valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "analyzed-fisher",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "ax.bar(mAPs.keys(), mAPs.values())\n",
    "ax.set_ylabel('mAP@.4')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "devoted-victorian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Aortic enlargement': 0.7715037188921522,\n",
       " 'Atelectasis': 0.4389502918479661,\n",
       " 'Calcification': 0.3369935103449311,\n",
       " 'Cardiomegaly': 0.6319310959043464,\n",
       " 'Consolidation': 0.3990124238375785,\n",
       " 'ILD': 0.43786637046397914,\n",
       " 'Infiltration': 0.4922277102359513,\n",
       " 'Lung Opacity': 0.47691001852315223,\n",
       " 'Nodule/Mass': 0.3352686031942788,\n",
       " 'Other lesion': 0.17439454047770703,\n",
       " 'Pleural effusion': 0.7205817883627935,\n",
       " 'Pleural thickening': 0.47808137402204964,\n",
       " 'Pneumothorax': 0.5919994527015022,\n",
       " 'Pulmonary fibrosis': 0.6485216942912988,\n",
       " 'all': 0.49530304236426337}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mAPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "reflected-vegetarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = {'image_id': valid_pred_df['image_id'].values.tolist(), 'PredictionString': list()}\n",
    "\n",
    "for dd, pred_str in zip(dataset_dicts_valid, valid_pred_df.values[:, 1]):\n",
    "    objs = np.array(pred_str.split(' ')).reshape((-1, 6))\n",
    "    \n",
    "    boxes, scores, labels = list(), list(), list()\n",
    "    for obj in objs:\n",
    "        boxes += [[\n",
    "            int(obj[2]) / config.img_size,\n",
    "            int(obj[3]) / config.img_size,\n",
    "            int(obj[4]) / config.img_size,\n",
    "            int(obj[5]) / config.img_size,\n",
    "        ]]\n",
    "        labels += [int(obj[0])]\n",
    "        scores += [float(obj[1])]\n",
    "    \n",
    "    boxes, scores, labels = weighted_boxes_fusion([boxes], [scores], [labels], weights=None, iou_thr=config.iou_thr, skip_box_thr=config.skip_box_thr)\n",
    "    boxes *= config.img_size\n",
    "    records['PredictionString'] += [format_pred(labels, boxes, scores)]\n",
    "    \n",
    "valid_pred_df_wbf = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "sealed-qualification",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "343d21e388714982a1f5b053ad948309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating prediction data...\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.21s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.750\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.750\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.922\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.774\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=  1 ] = 0.426\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets= 10 ] = 0.943\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.943\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.981\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.953\n",
      "Generating prediction data...\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.08s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.220\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.220\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.044\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.227\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=  1 ] = 0.422\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets= 10 ] = 0.688\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.688\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.667\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.689\n",
      "Generating prediction data...\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.57s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.188\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.188\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 0.134\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.246\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.527\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=  1 ] = 0.314\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets= 10 ] = 0.748\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.781\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 0.750\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.844\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.756\n",
      "Generating prediction data...\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.22s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.523\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.523\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.524\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=  1 ] = 0.425\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets= 10 ] = 0.684\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.684\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.684\n",
      "Generating prediction data...\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.10s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.387\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.387\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.274\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.411\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=  1 ] = 0.564\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets= 10 ] = 0.927\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.927\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.900\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.930\n",
      "Generating prediction data...\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.20s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.358\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.358\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.364\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=  1 ] = 0.320\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets= 10 ] = 0.966\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.970\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.970\n",
      "Generating prediction data...\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.16s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.496\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.496\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.501\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.509\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=  1 ] = 0.468\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets= 10 ] = 0.924\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.928\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.833\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.941\n",
      "Generating prediction data...\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.21s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.429\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.429\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 0.116\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.277\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.480\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=  1 ] = 0.402\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets= 10 ] = 0.911\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.926\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 0.444\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.867\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.949\n",
      "Generating prediction data...\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.20s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.316\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.316\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 0.275\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.438\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.413\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=  1 ] = 0.245\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets= 10 ] = 0.753\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.814\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 0.848\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.838\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.840\n",
      "Generating prediction data...\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.64s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.05s).\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.171\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.171\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 0.162\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.092\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.209\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=  1 ] = 0.251\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets= 10 ] = 0.713\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.788\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 0.745\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.800\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.799\n",
      "Generating prediction data...\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.16s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.711\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.711\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 0.614\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.620\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.810\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=  1 ] = 0.375\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets= 10 ] = 0.974\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.978\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 0.857\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.965\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.993\n",
      "Generating prediction data...\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.35s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.06s).\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.408\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.408\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 0.804\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.417\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.491\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=  1 ] = 0.284\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets= 10 ] = 0.873\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.939\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 0.893\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.968\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.860\n",
      "Generating prediction data...\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.05s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.016\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.016\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.016\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=  1 ] = 0.041\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets= 10 ] = 0.041\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.041\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.042\n",
      "Generating prediction data...\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.31s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.05s).\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.584\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.584\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 0.695\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.523\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.693\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=  1 ] = 0.266\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets= 10 ] = 0.888\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.965\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 0.955\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.948\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.978\n",
      "Generating prediction data...\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.65s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.47s).\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.397\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.397\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 0.475\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.412\n",
      " Average Precision  (AP) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.461\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=  1 ] = 0.343\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets= 10 ] = 0.788\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=   all | maxDets=100 ] = 0.812\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= small | maxDets=100 ] = 0.812\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area=medium | maxDets=100 ] = 0.816\n",
      " Average Recall     (AR) @[ IoU=0.40:0.40 | area= large | maxDets=100 ] = 0.813\n"
     ]
    }
   ],
   "source": [
    "mAPs_wbf = evaluate_mAP(valid_pred_df_wbf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
