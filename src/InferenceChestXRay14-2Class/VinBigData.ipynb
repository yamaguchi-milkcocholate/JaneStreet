{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ongoing-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from typing import *\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "pd.set_option('max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "related-spray",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field, asdict\n",
    "import yaml\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    # General\n",
    "    device: str = 'cuda'\n",
    "    # Data config\n",
    "    imgconf_file: str = '../../data/VinBigData/train.csv'\n",
    "    imgdir_name: str = \"../../data/ChestXRay14\"\n",
    "    # Model\n",
    "    model_dir: str = \"../VinBigData-2Class/results\"\n",
    "    model_mode: str = 'normal'\n",
    "    model_name: str = 'resnet18'\n",
    "    \n",
    "    # Evaluation\n",
    "    batch_size: int = 32\n",
    "    num_workers: int = 4\n",
    "\n",
    "    def update(self, param_dict: Dict) -> \"Config\":\n",
    "        # Overwrite by `param_dict`\n",
    "        for key, value in param_dict.items():\n",
    "            if not hasattr(self, key):\n",
    "                raise ValueError(f\"[ERROR] Unexpected key for flag = {key}\")\n",
    "            setattr(self, key, value)\n",
    "        return self\n",
    "    \n",
    "    def to_yaml(self, filepath: str, width: int = 120):\n",
    "        with open(filepath, 'w') as f:\n",
    "            yaml.dump(asdict(self), f, width=width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "congressional-president",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fail to import apex_C: apex was not installed or installed without --cpp_ext.\n",
      "fail to import amp_C: apex was not installed or installed without --cpp_ext.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "\n",
    "\n",
    "class CNNFixedPredictor(nn.Module):\n",
    "    def __init__(self, cnn: nn.Module, num_classes: int = 2):\n",
    "        super(CNNFixedPredictor, self).__init__()\n",
    "        self.cnn = cnn\n",
    "        self.lin = Linear(cnn.num_features, num_classes)\n",
    "        print(\"cnn.num_features\", cnn.num_features)\n",
    "\n",
    "        # We do not learn CNN parameters.\n",
    "        # https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
    "        for param in self.cnn.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.cnn(x)\n",
    "        return self.lin(feat)\n",
    "\n",
    "\n",
    "def build_predictor(model_name: str, model_mode: str = \"normal\"):\n",
    "    if model_mode == \"normal\":\n",
    "        # normal configuration. train all parameters.\n",
    "        return timm.create_model(model_name, pretrained=True, num_classes=2, in_chans=3)\n",
    "    elif model_mode == \"cnn_fixed\":\n",
    "        # normal configuration. train all parameters.\n",
    "        # https://rwightman.github.io/pytorch-image-models/feature_extraction/\n",
    "        timm_model = timm.create_model(model_name, pretrained=True, num_classes=0, in_chans=3)\n",
    "        return CNNFixedPredictor(timm_model, num_classes=2)\n",
    "    else:\n",
    "        raise ValueError(f\"[ERROR] Unexpected value model_mode={model_mode}\")\n",
    "\n",
    "        \n",
    "def accuracy(y: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Computes multi-class classification accuracy\"\"\"\n",
    "    assert y.shape[:-1] == t.shape, f\"y {y.shape}, t {t.shape} is inconsistent.\"\n",
    "    pred_label = torch.max(y.detach(), dim=-1)[1]\n",
    "    count = t.nelement()\n",
    "    correct = (pred_label == t).sum().float()\n",
    "    acc = correct / count\n",
    "    return acc\n",
    "\n",
    "\n",
    "def accuracy_with_logits(y: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Computes multi-class classification accuracy\"\"\"\n",
    "    assert y.shape == t.shape\n",
    "    gt_label = torch.max(t.detach(), dim=-1)[1]\n",
    "    return accuracy(y, gt_label)\n",
    "\n",
    "\n",
    "def cross_entropy_with_logits(input, target, dim=-1):\n",
    "    loss = torch.sum(- target * F.log_softmax(input, dim), dim)\n",
    "    return loss.mean()\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import pytorch_pfn_extras as ppe\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    \"\"\"two class classfication\"\"\"\n",
    "\n",
    "    def __init__(self, predictor, lossfun=cross_entropy_with_logits):\n",
    "        super().__init__()\n",
    "        self.predictor = predictor\n",
    "        self.lossfun = lossfun\n",
    "        self.prefix = \"\"\n",
    "\n",
    "    def forward(self, image, targets):\n",
    "        outputs = self.predictor(image)\n",
    "        loss = self.lossfun(outputs, targets)\n",
    "        metrics = {\n",
    "            f\"{self.prefix}loss\": loss.item(),\n",
    "            f\"{self.prefix}acc\": accuracy_with_logits(outputs, targets).item()\n",
    "        }\n",
    "        ppe.reporting.report(metrics, self)\n",
    "        return loss, metrics\n",
    "\n",
    "    def predict(self, data_loader):\n",
    "        pred = self.predict_proba(data_loader)\n",
    "        label = torch.argmax(pred, dim=1)\n",
    "        return label\n",
    "\n",
    "    def predict_proba(self, data_loader):\n",
    "        device: torch.device = next(self.parameters()).device\n",
    "        y_list = []\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in data_loader:\n",
    "                if isinstance(batch, (tuple, list)):\n",
    "                    # Assumes first argument is \"image\"\n",
    "                    batch = batch[0].to(device)\n",
    "                else:\n",
    "                    batch = batch.to(device)\n",
    "                y = self.predictor(batch)\n",
    "                y = torch.softmax(y, dim=-1)\n",
    "                y_list.append(y)\n",
    "        pred = torch.cat(y_list)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sitting-flavor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "\n",
    "class Transform:\n",
    "    def __init__(self, aug_kwargs: Dict):\n",
    "        self.transform = A.Compose([getattr(A, name)(**kwargs) for name, kwargs in aug_kwargs.items()])\n",
    "\n",
    "    def __call__(self, image):\n",
    "        image = self.transform(image=image)[\"image\"]\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "developed-lafayette",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestRayDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, filepaths: List[str], labels: List[int], label_smoothing: float = 0., mixup_prob: float = 0., image_transform: Transform = None):\n",
    "        self.filepaths = filepaths\n",
    "        self.labels = labels\n",
    "        self.label_smoothing = label_smoothing\n",
    "        self.mixup_prob = mixup_prob\n",
    "        self.image_transform = image_transform\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.filepaths)\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        img, label = self.__get_single_example(idx=idx)\n",
    "        img, label = self.__mixup(img=img, label=label)\n",
    "        \n",
    "        label_logit = torch.tensor([1 - label, label], dtype=torch.float32)\n",
    "        \n",
    "        return img, label_logit\n",
    "    \n",
    "    def __get_single_example(self, idx: int) -> Tuple[torch.Tensor, float]:\n",
    "        img = cv2.imread(self.filepaths[idx])\n",
    "        if self.image_transform:\n",
    "            img = self.image_transform(img)\n",
    "        img = torch.tensor(np.transpose(img, (2, 0, 1)).astype(np.float32))\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        if label == 0:\n",
    "            return img, float(label) + self.label_smoothing\n",
    "        else:\n",
    "            return img, float(label) - self.label_smoothing\n",
    "    \n",
    "    def __mixup(self, img: torch.Tensor, label: float):\n",
    "        if np.random.uniform() < self.mixup_prob:\n",
    "            pair_idx = np.random.randint(0, len(filepaths))\n",
    "            prob = np.random.uniform()\n",
    "            pair_img, pair_label = self.__get_single_example(idx=pair_idx)\n",
    "            img = img * p + pair_img * (1 - p)\n",
    "            label = label * p + pair_label * (1 - p)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "advanced-spray",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import cv2\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "\n",
    "class StratifiedKFoldWrapper:\n",
    "    def __init__(self, datadir: Path, n_splits: int, shuffle: bool, seed: int, \n",
    "                 label_smoothing: float = 0., mixup_prob: float = 0., aug_kwargs: Dict = {}):\n",
    "        self.datadir = datadir\n",
    "        fl = self.__load_filelist()\n",
    "        fp = self.__load_filepath()\n",
    "        \n",
    "        df = pd.merge(fl, fp, how='left', on='Image Index')[['Image Index', 'Normal', 'Unique Image Index', 'File Path']]  \n",
    "        df = df.groupby('Unique Image Index').first().reset_index()\n",
    "        self.datalist = df\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=shuffle, random_state=seed)\n",
    "        self.split_idxs = list(skf.split(self.datalist['File Path'].values, self.datalist['Normal'].values))\n",
    "        self.__i = -1\n",
    "        \n",
    "        self.label_smoothing = label_smoothing\n",
    "        self.mixup_prob = mixup_prob\n",
    "        self.image_transform = Transform(aug_kwargs=aug_kwargs)\n",
    "        \n",
    "    def __load_filelist(self):\n",
    "        df = pd.read_csv(self.datadir / 'Data_Entry_2017.csv')\n",
    "        df['Unique Image Index'] = df['Image Index'].map(lambda x: x.split('_')[0])\n",
    "        df['Normal'] = (df['Finding Labels'] == 'No Finding').astype('int8')\n",
    "        return df\n",
    "        \n",
    "    def __load_filepath(self):\n",
    "        records = {'Image Index': [], 'File Path': []}\n",
    "        \n",
    "        for dn in [tmp for tmp in sorted(os.listdir(self.datadir)) if 'image' in tmp]:\n",
    "            for fn in sorted(os.listdir(self.datadir / dn / 'images')):\n",
    "                records['Image Index'] += [fn]\n",
    "                records['File Path'] += [str(self.datadir / dn / 'images' / fn)]\n",
    "                \n",
    "        return pd.DataFrame(records)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        self.__i = -1\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        self.__i += 1\n",
    "        if self.__i < 0 or len(self.split_idxs) <= self.__i:\n",
    "            raise StopIteration()\n",
    "        return self.generate_datasets()\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.split_idxs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if idx < 0 or len(self.split_idxs) <= idx:\n",
    "            raise ValueError()\n",
    "        self.__i = idx\n",
    "        return self.generate_datasets()\n",
    "        \n",
    "    def generate_datasets(self) -> ChestRayDataset:\n",
    "        train_idx, valid_idx = self.split_idxs[self.__i]\n",
    "        \n",
    "        train_ds = ChestRayDataset(\n",
    "            filepaths=self.datalist['File Path'].values[train_idx].tolist(),\n",
    "            labels=self.datalist['Normal'].values[train_idx].tolist(),\n",
    "            label_smoothing=self.label_smoothing,\n",
    "            mixup_prob=self.mixup_prob,\n",
    "            image_transform=self.image_transform\n",
    "        )\n",
    "        valid_ds = ChestRayDataset(\n",
    "            filepaths=self.datalist['File Path'].values[valid_idx].tolist(),\n",
    "            labels=self.datalist['Normal'].values[valid_idx].tolist(),\n",
    "        )\n",
    "        \n",
    "        return train_ds, valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "collaborative-maple",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = {}\n",
    "config = Config().update(config_dict)\n",
    "base_dir = Path().resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "restricted-vision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config(device='cuda', imgconf_file='../../data/VinBigData/train.csv', imgdir_name='../../data/ChestXRay14', model_dir='../VinBigData-2Class/results', model_mode='normal', model_name='resnet18', batch_size=32, num_workers=4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "professional-acrobat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(config.device)\n",
    "predictor = build_predictor(model_name=config.model_name, model_mode=config.model_mode)\n",
    "predictor.load_state_dict(torch.load(base_dir / config.model_dir / 'predictor_last.pt'))\n",
    "predictor.eval()\n",
    "\n",
    "classifier = Classifier(predictor)\n",
    "classifier.to(device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "automated-faculty",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(base_dir / config.imgconf_file)\n",
    "\n",
    "skf = StratifiedKFoldWrapper(\n",
    "    datadir=base_dir / config.imgdir_name,\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    seed=111,\n",
    "    label_smoothing=0,\n",
    "    mixup_prob=0,\n",
    "    aug_kwargs={}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "generous-midwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "\n",
    "valid_dataset = skf[0][1]  # 0th fold, validation data\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    num_workers=config.num_workers,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "valid_pred = classifier.predict_proba(valid_loader).cpu().numpy()\n",
    "valid_pred_df = pd.DataFrame({\n",
    "    \"class0\": valid_pred[:, 0],\n",
    "    \"class1\": valid_pred[:, 1],\n",
    "    \"truth\": valid_dataset.labels,\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
